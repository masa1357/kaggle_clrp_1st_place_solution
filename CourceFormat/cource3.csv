userid,今日の内容で、分かったこと・できたことを書いてください,今日の内容で、分からなかったこと・できなかったことを書いてください,今日の内容を自分なりの言葉で説明してみてください,今日の授業の感想や反省を書いてください,質問があれば書いてください
B-2020_U10,"データの捏造や改竄、盗用は絶対に行ってはいけない不正行為であるということ。
引用する際は、参考文献について明確に記さなければならないということ。",途中すこしだけ寝落ちしてしまった,,,
B-2020_U11,,プライバシーポリシーはなんとなくは分かったけど、詳しくはわからない。,,今日は私たちが今後とてもしっかりと考えなければいけないことを学びました。これから3年生ぐらいになると研究も始まると思うし、理系の人は特に気をつけていかないといけないものだと思いました。,
B-2020_U13,研究に求められる倫理についてよく分かった。,情報倫理規定が難しく、よく分からない部分があった。,,,
B-2020_U14,,シングル・ブラインドによりどのような効果が期待できるのかわからなかった。,研究をするときに守らなければならないルールと持っておくべき倫理観,,
B-2020_U15,,,責任ある研究者として、研究倫理を以って不正を働かず、客観的に研究を行う。客観性を高めるために査読を行う。企業との共同研究においては、様々な問題が発生する恐れがあるのでコミュニケーションが重要である。利益相反は個人的な利益を考えることで客観性が失われる可能性がある状況である。九州大学には情報倫理の規定やセキュリティポリシーが定められている。,,
B-2020_U16,九州大学で情報倫理規定が定められていること。また、その内容。,,,,
B-2020_U17,,,研究行為においてのルールは全て明文化されている訳ではなく、個人の倫理観に頼るところが大きい。感情的な過ちや共同研究者、企業との摩擦が起きないように、誠実な態度を忘れず周りの専門家や研究者と審査しあう事が大切だ。各方面に影響を及ぼす研究不正を行うと、クライアントの利益を守る責任を果たせない恐れもある。情報資産保護においては法的な措置や各団体のガイドラインが制定されており、自分が所属する組織のセキュリティポリシーを確認する必要がある。,,
B-2020_U18,,,研究における責任感、研究不正の原因と対策、利益相反の問題点、九州大学の情報倫理,,
B-2020_U19,モラルや倫理によって研究しやすい環境が作られているのだとわかった。不正が起こる動機を知ることができた。自分なりに不正について考えることができた。,,大学など研究機関で研究活動を行う際、必ずしも明文化されているというわけではないが守らなくてはならない規則のようなものがある。それらを守るためにも、情報モラルを学び研究者として持つ社会的責任に対し自覚を持つことが重要である。また研究活動において個人の保護や倫理の重視がなされており、それらは社会の発展に寄与している。しかし現在の環境においても研究不正が起きているため、改善の余地がある。,,
B-2020_U21,"研究における不正や、客観的な研究を行うための倫理について学んだ。
これから守っていかなければならないこと、常に念頭に置いておくべきことで、まだよく考えたことがなかったので、とても有意義な授業だった。",シリアスゲームで今日学んだ内容を正しく応用することができなかった。,,4年生になって卒業論文などを書くことになると必要で重要になってくる知識だったので、自分でも調べてより深く正しく理解しようと思った。,
B-2020_U22,,,研究倫理や情報倫理といった、研究に対する姿勢的な部分の多くは各個人が注意すべきである。また、ある程度国や組織が明文化して規範を示すことも重要である。,"今回の授業で研究や論文執筆に対する姿勢で気をつけなければいけないことを理解できたため、3,4年生になり研究活動を行う際には、そういった点に留意することに最新の注意を払うよう意識しようと感じた。",
B-2020_U23,不利益を被らないよう、他者に迷惑をかけないよう、研究し論文を書く前にモラルや規則をしっかり学びたい。,,,,
B-2020_U24,自分が研究をしたと仮定したときの心構えを知ることができた。データの改ざんなどが研究による焦りや、自身の仮定に自信があったからなど大変創造しやすかったので、もしも将来、研究をすることになったら気を付けようと思った。,,今回の講義は研究者としての倫理、情報倫理について学んだ。研究倫理については研究者としての倫理、例えば、研究には中立、客観性が必要であること、論文を発表するときの査読者への配慮、企業との共同研究についての注意点、利益相反についてを学んだ。情報倫理では、九州大学での情報倫理の規定、情報についての管理と分類、物理的セキュリティ保護の方針についてを学んだ。,不具合により途中参加だったので次からは10分前には来て、迅速に対処しようと思った。理系で大学院にいくかもしれないので今回はより身近に感じることができた。研究にも知っておくべきルールがあって驚いたが、今回のようにどこの界隈でもルールがあるのだと思って行動していきたいと思った。,
B-2020_U26,研究不正について・共同研究における研究倫理,,研究における倫理と情報の扱い,,
B-2020_U31,,,,今日の授業は、元々、なんとなくは理解している内容だったが、3年後自分らが研究する時にとても重要なことなのでこれを機にしっかり理解したい。また、レポート課題を提出する際には出典を明示し、情報を適切に扱っていきたい。,
B-2020_U32,,, 研究活動は、正直に、正確に、客観的に行うことが必要であり、また、限りある資源を無駄なく利用するために効率的に行わなければならない。捏造、改竄、盗用などの研究不正は、個人だけでなく社会の信頼にも影響する。共同研究の際には、研究者個人で研究に対する姿勢、成果の共有の姿勢、経済的ニーズなどの違いが存在することを認識して、きちんとしたコミュニケーションをとり、役割分担、オーサーシップ、リーダーシップを確立させることが必要である。利益相反とは、個人的利害を優先させることで本来あるべき客観性が失われ、研究不正が起こりやすいような状態のことであり、形を有さない思い入れなどにより引き起こされる場合が多い。,,
B-2020_U33,,特にわからなかったことはないが、利益相反の具体例を少し知りたいと思った。,,"見直しの時間が長いと感じた。
今日やったのは当たり前のことだと思ったが、知らなかったでは済まされない、というのが怖いと思った。",
B-2020_U34,研究を行う際に気をつけなければいけないことがわかった,,"研究活動の際には、責任を持ち行動規範に則って研究することが求められる。また、捏造・改竄・盗用などの研究不正を行ってはならず、研究データを倫理的に扱わなければならない。ピア・レビューと言って、専門家同士の査読が普通行われる。共同研究の際には、互いの違いを理解し、問題が起こらないよう注意しなければならない。利害を考慮することによって客観性が失われる状況を利益相反と言い、学問的な思い入れによる場合が多い。
九州大学では情報資産の利用に関する情報倫理規定やセキュリティポリシーが定められている。",,
B-2020_U35,,,研究に関するマナーについて,,
B-2020_U36,将来研究をする上で重要なことを理解できた。,,研究における様々な注意点,研究における不正についての漠然とした理解を深めることができました。,
B-2020_U38,あたりまえの話だが、研究にももちろん倫理があるということ。倫理はしっかり文字にしてさだめられるものものではないが予防するためにガイドラインや規範があることも知った。,,,,
B-2020_U39,九州大学にも情報倫理規定が存在すること。,,研究発表には不正があってはならず、それを行うと様々な面からの信用がなくなってしまう。そうならないためにも、常に中立的立場に立ち、事前調査やピア・レビューをしっかり行うことが大切である。,,
B-2020_U4,,,,"今回の倫理は社会的名誉に関わるものだったので、規律やガイドラインを面倒くさがらずに知る必要性を実感できた。
サイバーセキュリティ基礎論の学びは学問としてだけでなく、生きていく上で大切なものであると感じられた。",
B-2020_U40,研究において、気をつけなくてはいけないことが多数あること。特に、研究に使用する情報の扱いには十分注意しなくてはならないということ。,,,,研究において他者のデータ等を使う際に、了解がなくても出典さえ書いておけば良いのか、もしくはなるべく了解もとって出典を書いたほうが良いのでしょうか。
B-2020_U41,,,研究はより良い社会を作ったり、世界の仕組みを解き明かすために行われるものである。そこに携わる人たちには、正直であることや誠実であることが求められる。研究は中立性、客観性をもった内容であるべきなので、決して改竄や捏造、盗用があってはならない。成果主義や金銭問題、偏った意見によって利益相反の状況が発生することもある。研究者個人や組織が情報モラルを正しく理解することは非常に重要。,,
B-2020_U43,,,研究の時には自分の願望などに囚われずに正直でなくてはならない,,
B-2020_U44,研究や論文を書くときに不正行為にならないようにするためにはどうすれば良いかがわかった,予習の時に分からないところにマーカーを引くのを忘れていた,,将来研究をしていくときに今日学んだことを活かしていきたい。,
B-2020_U45,論文等はいろんな立場からの意見をもらえた方がいいと思っていたから、ピア・レビューの話で同じ研究の専門家から意見をもらうことに驚いた。,やはりスポンサーの方が立場が強くなりやすいと思うので、研究が倫理的に行えるよう具体的に何が行われているのか気になった。,,,
B-2020_U46,,,研究を行う際は研究倫理を守り、責任のある研究活動を行わなければならない。研究倫理は曖昧ではあるが、研究を公開して爵位に貢献すること、中立であること、客観的であることが重要である。研究不正には、捏造、改竄、盗用などがあり、社会への裏切りであり、所属している集団やその人個人にも影響が出る。知らなかったでは済まないので、ガイドラインや日本化学界会員行動規範などに目を通しておくと良い。論文の質を高めるための方法としてピア・レビューがある。同じ分野の人が発表前の論文を査読することだ。査読者には強制はできないが守らなければならない査読者の倫理が存在し、また公正に行うため、査読者の名前を伏せるシングル・ブラインド、また著者の名前も伏せるダブル・ブラインドをすると良い。研究者は嘘をついて社会の進歩をさまたあげないことが大切だ。,"ありがとうございまいした。
自分が大学生で、この先研究をしたり、論文を書いたりするということを改めて自覚しました。",
B-2020_U47,,ピア・レビューをボランティアなどでやっているが全体でどれぐらいの人が行っているのか,,,
B-2020_U5,,,研究するときや情報を扱う時に個人が持っておくべき道徳心についての内容。,"先週の授業を受けた次の日、スマホが壊れ、全く使えなくなってしまった。前日授業でバックアップの話があり、確認もしていたからデータがある程度戻る可能性はあるけれど、怖いと思った。
よって、今日の授業を通して、セキュリティや倫理などといった感覚はやはり早くからたくさん身につけて損はないと改めて思った。",
B-2020_U50,研究におけるルールブックのようなものがないことがわかった。,,,,
B-2020_U51,,,,今日の授業でも、予習から真剣に取り組むことができ、研究をする上での責任と役割を学ことができた。,
B-2020_U53,,,,高年次に研究をする際には、責任感を持ち、不正をしないようにしたいです。論文の査読では、公平性を保つために情報が伏せられると知って納得しました。,
B-2020_U54,研究において大切な態度を理解することができた。正直さや、正確さなど、どれも当たり前のように感じるが、いざ自分が研究をするとなると、周りの評価を気にしたり、プレッシャーを感じたりすることから、適切な研究をやり遂げることはもしかすると難しいことなのかもしれないとも感じた。,九州大学の組織の構造が難しかった。そのような存在があることすら知らなかったから、これから学んでいきたい。,適切な研究の方法、研究不正となる行為を学んだ。,,
B-2020_U56,,自分が研究する立場になった時の具体的な行動を確認できなかった。,,,
B-2020_U57,,,研究する際に持つべき価値観は、効率を意識しながら、正直に、得られた結果に忠実に報告内容をまとめる事が必要。捏造改竄盗用は不正行為であり、自身の信頼を失うことに繋がる。名前を伏せた査読者が査読をして、利益相反などがないか確かめる。情報倫理は情報を扱う上で必要な行動規範。情報モラルは情報社会での考え方と態度。,,
B-2020_U58,,,研究における中立、客観性、不正、利益相反について理解する。,,
B-2020_U59,研究で不正を行わないことの大切さがわかった。研究は社会や専門家集団、個々の研究者への信頼を伴うものだとわかりました。,物理的セキュリティ保護の方針についてが難しかったです。,,,
B-2020_U6,,,研究不正とはどのようなものでどんな対策が行われているかや、情報倫理について,この先研究をするようになる時に、自分が研究不正をしないことはもちろんだし、周りの環境も大きな研究不正の原因になっていることがわかったので、自分の周りで研究不正が起こらないようにも気をつけたいと思いました。,
B-2020_U60,"研究の信頼性はある程度、研究者のモラルに任されている部分があるという事
また不正が行われる原因",,研究における倫理と情報を扱う際のモラル,,
B-2020_U62,,,,,特にありません
B-2020_U63,,"研究成果を発表する上で、他の文献から引用したいときはどうすればいいのか。
",,九大も情報ネットワークの管理をしっかり行なっているとわかって安心した。,
B-2020_U64,どのようなことが研究不正となるのか,,,,
B-2020_U65,研究を審査する際に、著者と査読者、お互いが誰かを知ることをできなくする方法があることは知らなかったです。,情報ネットワーク接続の管理のスライドが少し難しかったです。,,,
B-2020_U67,研究論理と情報倫理について,,,オンライン授業に少し慣れてきました,
B-2020_U68,情報や研究を行うときに守るべきりんりについて分かった,,,今回学んでことをこれからも守っていこうと思った,
B-2020_U69,利益相反が生じるなど研究者個人の注意だけでは防ぎきれない研究不正が起こりうる可能性があることはあまり考えたことが無かったが今日の講義を聞き研究者の周囲の人間の責任について改めて考えさせられた,最後のスライドの内容を正確に理解することが出来なかった,,,
B-2020_U70,,,研究倫理、情報倫理について。,,
B-2020_U71,研究を行うために様々な原則があることが分かりました。,,,,
B-2020_U73,研究における一般的な規範や中立・客観性について知ることができた。それと関連する「利益相反」という言葉の意味と内容についても理解できた。,,研究に際しての規範や倫理的なマナーのようなものの確認と、情報の取り扱いや保管についての倫理規定について,,
B-2020_U74,,30ページのバックドアなどの細かな用語,,予習がぎりぎりになってしまったので次回は土日などの時間を使って行おうと思う。,特にありません
B-2020_U77,,,,４年生になってからの卒業研究のに対する不安が生まれました,
B-2020_U79,　研究をする上で最低限守るべきことを学べた。,,　研究をするにあったて、守るべき倫理やルールがある。それを守らないと、研究自体の信憑性が落ちるだけではなく、その人自身の信頼も失われる。利益や実績などの欲に負けずに清く研究をする事が大切だ。,,
B-2020_U8,"研究不正が起きないようにどんな対策が取られているのかわかった。そして、それらは、人として当たり前のことだな、と思った。
九州大学は、しっかりとした規定やポリシーを持っていることがわかった。",様々な組織や団体が規範やガイドラインを発表していて、ややこしくなった。,"研究とは何か、また研究を行う際に必要な研究倫理について、何が必要か、何が駄目なのかを理解する。
そして、情報倫理について、九州大学の例を見ながら理解する。","利益相反など、人間だからこそ起きる状況などから研究不正が起きることや、何が不正で、どのように防ぐのかがわかった。
行政によって規範が違うことがわかり、どの国の規範が一番甘いのか気になった。
九州大学生であるから、九州大学の規定やポリシーを理解していきたい。",
B-2020_U81,,,,今日の授業で、研究する上での注意点や知っておくべき大事なことを多く学びました。私は、研究職に就く予定はありませんが、違うところでも、今日の学びを生かしていきたいと思います。,
B-2020_U83,,,,こういった倫理に関する問題はしばしニュースで取り上げられたりなど話題になっているので自分はそういったものの当事者にならないようにしていきたいです。,
B-2020_U84,,,,これから自分が研究する時、研究不正が発生する場合があるので、注意しなければならないです。,
B-2020_U85,,,"研究をする上で研究倫理は遵守する必要があり、明文化された規範にはしっかり従い、されていないルールにも従う必要がある。
",研究が意外と身近に迫っているモノだと感じてビクビクしています,
B-2020_U86,九大に情報セキュリティーポリシーが明文化された物が存在していることを知りました。,30ページ目の内容がなんとなくでしか理解できませんでした。,研究をするにあたって個人の利害にとらわれず、公正かつ客観的な態度を持つことが重要である。また、九州大学の情報倫理規定は学内のデータを適切に扱うために細かく定められている。,,
B-2020_U87,,,"研究を行う際に倫理的な考えと態度が必要。
不正を犯すと関係者に迷惑がかかり信用を失う。","たまにニュースで不正な研究が報道されることもあって、倫理的な考えは常に頭に入れておかないといけないなと思った。
それでも一定数は悪気がなくても不正をしてしまいそうだが。",
B-2020_U89,,,,過去の講義でも言えることですが、セキュリティと人間心理は密接に関わっていて、セキュリティの戦いとは即ち心の弱さとの戦いではないかと思いました。,
B-2020_U9,研究者の守らなければならないルールがあり、組織や研究者としての責任も分かりました。,「利益相反を開示する」というのがどういうことかいまいち分かりません。,,,
B-2020_U92,,,研究と一言に言っても自分だけのものではないのだと分かった。,,
B-2020_U93,研究で何が問題になるか,,,今回のは前回、前々回よりやりやすかったです,
B-2020_U94,,九大の情報規制のところ。言葉が難しい。,,今後研究、論文の発表というような場が増えていくだろうから、このような情報倫理を大切にしていきたい。,
B-2020_U95,,,,今までは、漠然と研究者は研究しているイメージしかなかったけれど、実際には原則や基準がある上で行われていることがわかり、見方が変わった。,
C-2021-1_U10,,U(M)＝log₂Mの証明,,"今回の内容は計算や定義が多くて難しかったので演習問題などを通して復習しておきたい。
情報の量というのがどのようなものか分からなかったけど、曖昧さの減少ということを知り驚いたとともに、それが数値で表せること感心した。",
C-2021-1_U101,質問を繰り返して曖昧さ（選択肢）が減っていく事を「得られた情報の量」と表現し、曖昧さをU(M)で表すということがわかった。また、確率Pの事象の生起を知ることにより、曖昧さが-logpになるということが分かった。この事から、サイコロを振ったことにより１が出た事を知るのと１位外が出た事を知るのでは１が出た方を知る,,,,U(S）＝H(S）、H(s）＝情報量の期待値なら、H(s）＝情報量の期待値という事でしょうか。
C-2021-1_U103,エントロピーの大まかな理解が出来ました,証明があんまり理解できませんでした,,,特にありません
C-2021-1_U104,,,,今回の講義は情報量が多かったので前回の講義とも合わせてしっかり復習したい。,
C-2021-1_U105,得られる情報量の期待値はエントロピーに等しく、確率１/２のとき、エントロピーの値は最大値１をとる。,確率変数の相互情報量の例題と問題が理解できない。また、曖昧さの定義がlog₂Mとなる証明も理解ができなかった。,曖昧さの量を定義し、情報を得ていくことで曖昧さは減少していく。曖昧さはlog₂Mで表される。生起確率ｐの事象の生起を知ることによってーlog₂ｐの情報が得られる。つまり、めったに起こらないことの生起を知ることで得られる情報量は大きい。,曖昧さを定義するということに驚いた。エントロピーなどの情報と計算が難しく、自力で解けるように頑張りたいと思った。,
C-2021-1_U106,,相互情報量について,,,
C-2021-1_U11,情報量の計算について理解を深めれた。,計算式が難しかったので演習を重ねていきたい。,情報量は-log2pで表し、事象が起こる確率が小さいほど得られる情報量は大きくなる。,演習問題に取り掛かるのが遅くなってしまって、習ったことを思い出すのに時間を取られてしまったので、早めに取り掛かれるようにしたい。,
C-2021-1_U12,"曖昧さは、加法性であること。そこから、曖昧さがlog(2)Mで表すことが証明できる。
滅多に起きない事がおきるほど、情報量は多い。
条件付エントロピー＝条件ありの情報量の曖昧さ",,曖昧さの減少や情報量などについて、数式で表す。,証明のところを自分でかける様にしたいです。,
C-2021-1_U13,情報量や情報量の期待値の求め方。,煩雑な計算においてのミスが目立った。,,,特にありません。
C-2021-1_U15,二つの事象の関係性を起算できるようになったと思う,,少し複雑な内容になってきたと思える内容だった。,どんどん学習を進めていきたい,
C-2021-1_U19,,,曖昧さが減少することによって情報が得られるということ。,,
C-2021-1_U2,,,情報源の曖昧さの減少を習った。また、情報量の期待値はエントロピーに一致することや、二つの事象の相互情報量について考えた。,,
C-2021-1_U23,曖昧さの減少量が情報量であるということがわかった。前回の講義で学んだエントロピーの式で、対数の底が２である理由が何となくわかった。情報量の期待値を平均の考えるほうが、感覚的にわかりやすかった。,,,情報量の期待値を、平均と考えるほうが、感覚的にわかりやすかった。曖昧さも情報量の期待値も、言葉の定義が違うのに、エントロピーの値と一致するのが、不思議だと感じた。,
C-2021-1_U24,U(M)=log_2(M)の証明は予習段階では理解できなかったが、Uの加法性や関数の単調増加性などつまづいていた箇所を授業内で振り返ることができたため、最終的に理解できた。情報量とその期待値、相互情報量を求めることができた。,,「曖昧さ」を定量化し、「曖昧さ」と情報量の関係について考えた。情報量の期待値と相互情報量について学んだ。,,
C-2021-1_U25,曖昧な情報の量を数値化できた,期待値の意味,,まだまだ聞いてるだけだと何をしてるか正直わかってない、復習しっかりします,
C-2021-1_U26,logを使った公式の形をおぼえた。,曖昧さや条件の言葉のイメージがわからなかった,"情報の計算の公式をたくさん学んだ。
","むずかしかった。
演習をもっとがんばりたい。",
C-2021-1_U27,,"・条件付きエントロピーがよくわかりません。
・相互情報量がよくわかりません。",,相互情報量のあたりからよくわからなくなっていったので、教科書を読みなおしたり、演習問題を解いたりして復習したいと思う。,
C-2021-1_U28,,"エントロピーのlogの証明がよくわからなかった。
これを自力で導けるようにしたい。",,"エントロピーについて前回の時より理解を深めることができた。
しかし相互情報量など複雑なものについては、1回ではあまり理解できなかったので復習をしていきたい。
",
C-2021-1_U29,曖昧さやエントロピーのことが少しわかった。, U(M)＝log２Mの証明が難しかった。,情報とエントロピーについて学習した。,,
C-2021-1_U30,,曖昧さ＝log　の証明,,,
C-2021-1_U31,,,,数学的な考え方があって面白かった。,さいころ二つの場合の加法性の説明が理解できなかった。
C-2021-1_U32,起こる確率が大きい事象は1と近似され、平均に含まれないことがわかった。,どこまで近似できてどこから近似できないのか調べてみようと思った。,得られる情報の量は「曖昧さの減少」で表され、-log2(M)となる。また、期待値はエントロピーに一致する。,難しかったが、前回の内容と合わせて理解出来た。,
C-2021-1_U33,"エントロピーは情報量に関係していること。
",エントロピーっていう言葉がでてくると頭が分からないモードになってしまった。,,,
C-2021-1_U34,エントロピーや期待値、情報の曖昧さの計算方法について出来る様になった。,条件付きエントロピーの計算理解できなかった。,"得られた情報からその事象に対する曖昧さがどのように減少していくかについての計算方法について学んだ。
条件付きエントロピーの計算にしかた、表記の仕方について学んだ。",,
C-2021-1_U35,,,例を通して、情報量や情報源の曖昧さについて学習しました。情報量の期待値、エントロピー関数とはどういうものか、またその関数計算について確認しました。,エントロピーなどは若干の不安がありましたが、今日の講義ではそのあたりの確認ができてよかったです。,
C-2021-1_U36,"・情報量＝曖昧さの減少→U(M)=log2M
　☆単調増加、加法性がある
　☆Mは生起した事象の確率、これを知ったことによる曖昧さの減少が-log2M
・得られる情報量の期待値＝エントロピー",もう一度復習すればわかりそうです,"・情報量とは
・エントロピーとの関係
・同時確率と条件付確率、条件つきエントロピー",まだ納得できていない部分もありますが、エントロピーと確率の関係が興味深いです。証明を自分でしてみるとしっかり理解できたのでよかったです。ゴールデンウイークで忘れないように復習を定期的にしていこうと思います。,
C-2021-1_U38,,,曖昧さの減少が得られた情報と同じであるということ。相互情報量とエントロピーの関係。,,
C-2021-1_U39,エントロピー関数がグラフで描かれてあったので理解しやすかったです。,条件付き確率のエントロピーのところが難しかったです。,「曖昧さ」の減少は情報量と関わりがあることを学びました。,復習をしっかりしたいです。,
C-2021-1_U40,前回エントロピーがよく分かってなかったが今回で定義がはっきりしだした。情報付きエントロピーは情報付き確率の要領。,,エントロピーが情報の曖昧さを示している。情報が稀になるほど情報量が多くなる。,確率とエントロピーの関係が結びついて分かった,
C-2021-1_U41,,,情報源の曖昧さはエントロピーを用いて計算することができる。,,
C-2021-1_U42,,エントロピーに関して。,,エントロピーについてまだいまいちわかってないのでこれからしっかり復習していきたい。,
C-2021-1_U43,エントロピーがどういうものなのかを理解することができた。,,,,
C-2021-1_U44,"情報量の期待値や確率分布がどのようなときに利用されるのかがわかった。
情報の曖昧さの減少は理解できた。","相互情報量がよくわからなかった。
",エントロピー、確率分布、情報の曖昧さやその減少、相互情報量について,,
C-2021-1_U45,情報量の計算はできました。期待値も自信はありませんが、理解できたと思います。,相互情報量の定義がよく理解できませんでした。全体的に内容が難しかったです。,"曖昧さの減少が情報量であり、生起確率が小さい情報ほど情報量は大きい。
また、エントロピーとは情報量の期待値であり、確率0.5の時エントロピーは最大となる。","ざっくりとした内容は理解できましたが、細かいところはよく分かっていないので、復習をしっかりしたいと思います。
",
C-2021-1_U46,めったに起きない事象の生起を知ることで得られる情報量は大きい。また、情報量とその期待値を求められた。,やはりエントロピーはよく分からない。,生起確率pの事象の生起をしったことで得られる情報量を、それによる曖昧さの減少量と定める。,,
C-2021-1_U47,情報の曖昧さを計算することによって得られる情報量の大きさを求めることができた。,相互情報量のところが少しわからなかった。,情報の曖昧さなどを定理を使って数式として導くことができる。,初めて知るようなことが多くありとても楽しかったです。,
C-2021-1_U48,情報量の計算方式がわかった。エントロピーのイメージが掴むことができた。,条件付きになるとこんがらがってきてしまった。相互情報量が理解できなかった。,情報量は曖昧さの減少である。滅多に起きない事象から得られる情報量は大きい。情報量の期待値＝エントロピーである。,,
C-2021-1_U49,"・情報の曖昧度＝log2（M）で表される
・得られた情報量＝情報を絞っていく中で減少した情報の曖昧度
・エントロピー＝得られる情報量の期待値
・情報は二つの記号のみで表されるので曖昧度ないし情報量、エントロピーをしめすときの対数の底が２になっている
・生起確率pの事象から得られる情報量＝-log2（p）
・生起確率の小さい事象ほど得られる情報量が多い",・前半の方に出てきた曖昧さの定理がいまいちよく理解できなかった。,"・情報の曖昧度＝log2（M）で表される
・得られた情報量＝情報を絞っていく中で減少した情報の曖昧度
・エントロピー＝得られる情報量の期待値（）
・得られた情報にはいくつかの物差しがあり、そうして得られたものを相互情報量という",・数式などがたくさん出るようになってきて、難しくもなってきたが、理解する楽しさも感じてきた。,・前回の平均符号長のとき出てきたエントロピーと今回のものがどう繋がってくるのか
C-2021-1_U50,,,,"数学的要素が多くて、少し苦手意識があったが、実際に問題を解いてみると意外と解けて安心した。これからも演習問題などを通して理解を深めていきたい。
",
C-2021-1_U51,"情報量と曖昧量は相関の関係にあり、得られた情報の量が多いほど曖昧量は減少していくことが改めて分かっただけでなく、
その値を対数をとって求めることができるという事も分かりました。",特にありません。,得られる情報の量の求め方、それに伴う曖昧量の求め方を学びました。,"情報量を求める方法が分かれば、効率的に欲しい情報を得られることができるようになると思うのでとても便利だなと思いました。
",特にありません。
C-2021-1_U52,情報の期待値の考え方,表の見方,情報の期待値,だんだん内容が難しくなってきたように感じた。エントロピー増大の法則など国語の教科書できいいたことある言葉だったがどう言ったものか実感できずにいる,
C-2021-1_U53,,条件付きエントロピーの理解が少し難しかった。,,猫などの実際の例を利用しての説明がとても分かりやすかったです。曖昧さが対数で表されるのかがまだよくわかっていないのでもう一度復習したいです。,
C-2021-1_U56,情報は相互に関係している場合を考えるために、一つの指標ではなく複数の指標を扱う必要があるということ。,"相互情報量の公式がなぜI[X,Y]=H[X]-H[X|Y]となるのか理解しきれなかった。",,前回理解が浅かったエントロピーについて今回の講義で確認することができた。相互情報量などよくわからない点しておきたい。,
C-2021-1_U57,情報量の期待値はエントロピーに一致する,主に計算,情報の期待値とは、大体どのくらいの情報を得られるかを示すものである,今回の授業は計算が難しかった,
C-2021-1_U59,"エントロピーの値H(p)は、p=1/2の時に最大値をとる
",エントロピーの計算（相互情報量など）,"曖昧さが減少すると得られた情報の量は増える
","エントロピーというものが初めてで馴染みのないものだったので難しく感じました。
計算がよくわかっていないので、演習を通してしっかり理解できるようにしたいです。",
C-2021-1_U60,,,,面白かった,
C-2021-1_U61,得られる情報の量が多ければ多いほど曖昧さが減少する。,U(M)=log₂Mの証明がわかりにくかった。結局エントロピーが何かということがぼんやりとしか分からなかった。,"ある事象の知ると曖昧さが減少する。
確率を用いることで、エントロピーが求められる。","回を重ねるごとに内容を難しいと感じるようになっているから、復習を大切にしようと思った。
計算を見ると、ちょっと難しそうに思うが、よく考えて見るとそこまで難しくないなと思った。",
C-2021-1_U62,曖昧さの減少量の定義など,期待値のあたりから難しくなった,サイコロの出目が６つのうちどれかを絞り込んでいく過程で曖昧さが減っていく過程を数値化して分析しやすくした。,,
C-2021-1_U63,情報の曖昧さの減少＝得られた情報量として定義できること。得られた情報量の平均をとることを情報の期待値といい、それがエントロピーと一致すること。,,情報の曖昧さを数値として捉えたとき、情報の曖昧さは-log_2M と表すことができ、情報の曖昧さの減少が得られた情報量として捉えることができる。どの事象が生起したかで得られる情報量の期待値はエントロピーの数式と一致する。またある条件縛りでどの事象が生起したかで得られる情報量の期待値を考えるとき、条件と事象に関する相互情報量と言える。,情報量の曖昧さを定義するというのは、言葉の綾もあってか新鮮で驚いた。情報量の曖昧さを定義すれば、滅多に起こらない事象が生起した時に得られる情報量が多くなるという経験的に理解しているものが数式的に証明されているのは納得がいくものだった。,
C-2021-1_U65,曖昧さに数値があったことがわかった。,,,曖昧さの数値にlogを使うことが面白かった。」,
C-2021-1_U66,,,情報量の曖昧さと得られる情報によるエントロピーの違い,,
C-2021-1_U68,,,情報の曖昧さを定量化して、エントロピーを求めることができる。また生起確率から求められる情報量の期待値はエントロピーに等しい。,,
C-2021-1_U69,情報を得たら曖昧さが減って何かがわかるというのは感覚的に当たり前だと思っていたが、今回の授業でそれらを計算によって求められることを知った。,なぜlogをつかうのかよくわからない。,情報とは曖昧さの減少量のこと。サイコロの場合、目が多いほど曖昧さが大きい。曖昧さの数値はエントロピーに等しい。起りにくい事象から得られる情報量は大きいが情報の期待値は小さい。,新しいことがたくさん出てきたが、例が身近なことでわかりやすかった。,ありません
C-2021-1_U7,,最初のU(M)=log₂Mの証明がよくわからなかった,,,
C-2021-1_U70,計算は基本的にできた,,数学の発展的な感じ、情報量と期待値の計算,,
C-2021-1_U71,情報量を定式化して、具体的な事象に対してその情報量を具体的に計算できることがわかった。,特にありません。,"得られる情報量＝曖昧さの減少という考え方から情報量を生起する確率と対数関数を用いて定式化した。
得られる情報量の期待値が前回学んだエントロピーとして計算できることを学んだ。
2つの事象の関連性を表すものとして相互情報量を学んだ。
相互情報量は、片方の事象の情報からもう片方の事象の情報をどれだけ得られるかを表しており、2つの事象が独立なら相互情報量は0となる。",情報量の定式化の仕方がおもしろかったです。整合性がとれているなあと勝手ながら思いました。,
C-2021-1_U72,先週わからなかったエントロピーについて詳しくしることができた。,基本的にわからなかったことはなく、理解できた。,情報の曖昧さ、エントロピーについて。,情報についてここまで詳しく知れるとは思ってなかった。,
C-2021-1_U73,"曖昧さの減少は－log₂ｐで表されるのでｐすなわち、ある事象が起きる確率が小さい場合は得られる情報は大きくなる。ある事象X,Yの相互関係がない場合はYについての情報を得てもXの情報を得るために役に立たない。",エントロピーの定義や考え方に慣れていないのでもう一度復習しようと思う。情報の期待値とエントロピーが一致するのいうのが結局どういうことなのかがわからない。条件付きエントロピーについてがよくわからなかった。,,,
C-2021-1_U74,,全体的にまだ理解が足りてない気がする。要復習だ。,,,
C-2021-1_U75,,,情報量は情報の曖昧さが少ないほど多くなる。情報の曖昧さはそれがある事象の生起確率の連続関数であるという仮定の元でエントロピーに一致する。生起確率が少ない事象の生起を知ることによって得られる情報量は大きくなる。情報量の期待値について、それぞれの事象の生起確率と、-log2(生起確率)の積の和で表され、エントロピーと一致する。,計算式が出てきたが、前回よりは分かりやすかった。定義を理解して式について考えることができた。,
C-2021-1_U76,"確率を知ることによって、曖昧さの現象、得られる情報量がどれくらいかがわかる。
","曖昧さの量がlogで表されることの証明が少し理解しにくかった。
","情報量、情報量の期待値、相互情報量について
",,
C-2021-1_U77,情報量の計算ができる様になった。,,実際に情報量を計算する段階に入った。計算式の運用が必要であった。,実際に計算するのは最初は億劫ですが楽しいものです。,
C-2021-1_U78,,,エントロピーの計算,,
C-2021-1_U79,,情報の期待値や相互情報量はあまりわからなかった。条件付きエントロピーが最もよくわからなかった。,"情報を得ることである事象に関する曖昧さが減っていく。滅多に起きない情報を手にするとより曖昧さが減る。
ある一つの情報により得られるもう一個の事象に関する曖昧さを相互情報量という",ある一つの情報からたくさんのことを知れるということがわかった。,
C-2021-1_U8,猫の機嫌と尻尾の状態といった一見数学っぽくない事を数学することができた,計算がわからなかった,,復習が必要だと感じた,
C-2021-1_U80,,相互相互情報量の同時確率と条件付き確率の部分がよく分からなかった。また、条件付きエントロピーの意味がよく分からないし、日常生活での用法がわからなかった。,,,（３）の部分です。
C-2021-1_U82,"U(M)＝ログ２底Mの証明
得られる情報の期待値はエントロピーと一致する
",,"情報の量は曖昧さと関係があり、（曖昧さの減少）＝（得られた情報の量）ということ。
確率を用いて情報量を計算できる

",今日は数学的な証明がいくつかあり、より論理的に授業の内容を理解することができた。,
C-2021-1_U83,猫の機嫌での例えが面白かったです。サイコロの説明が分かりやすくて、曖昧さの減少をlogで表した部分もイメージが出来ました。相互情報と期待値の部分は完全に理解することはできなかったものの、作用しあう情報を把握することで、ある事象の可能性が高まることが計算できるというようなことかと解釈しました。,,情報源の曖昧さU(S)は、log₂Mで与えられる。生起確率が低い事象がおこれば、曖昧さは減少する。また、相互に作用しあう情報があれば、曖昧さはさらに減少する。これらは、エントロピーや期待値を用いて計算できる。,,
C-2021-1_U84,エントロピーの仕組みについて理解することができた。,,確率やエントロピーによって情報の曖昧さの段階を知ることができる。,計算が難しかった。,
C-2021-1_U85,情報量というのが、曖昧さという表現もできること。これから得る情報によって得られるであろう推定情報量のことを期待値ということ。情報量は式を使って求めることができること。,,情報量というのは、その情報の曖昧さと密接に関係している。曖昧さがなくなればなくなるほど情報量は大きくなる。希少な事象であればあるほど、大きくなる。複数の事象の関係を求める際は、条件付き確率のようにして絞って足す必要がある。,期待値という言葉で情報量の推定を表すのは面白いなと思いました。今まで確率の問題などやってきたことが、情報量などに使えるとは思っていなくて、とても面白かったです。エントロピーの定義をもっとちゃんと把握しておけば、さらに面白かっただろうにな、と反省しています。,
C-2021-1_U87,情報量の大きさや期待値を対数を取って計算できることがわかった。,相互情報量について理解ができなかった,"情報源の曖昧さは、情報源のエントロピーと一致していて、その減少量を情報量という。滅多に起きない事象の生起を知ることで得られる情報量は大きい。
情報量の期待値、つまりエントロピーは確率二分の一の時最大値１をとる。",数学的になり、理解するのが大変になってきた。,
C-2021-1_U88,エントロピーについて先週よりかは理解できたと思う。曖昧さを数値化するということが予習の段階では難しかったが、授業を聞いて理解できた。,情報量の期待値のあたりがまだよくわかっていない。,曖昧さの量をU（M）で表しMの数が大きければ大きいほど曖昧になる。一様に分布する無記憶定常情報源の曖昧さは、情報源のエントロピーに等しい。滅多に起きないことの情報量は多い。エントロピーの値は、p1+p2=1となるとき、p1=0.5の時に最大値を取る。同時確立と条件付き確率を求めるときでは、分母が異なる。相互情報量とは、２つの事象の関係性の強さを示す。,先週は予習ができていなかったので、今週は予習をした。１度予習しておくことで授業の内容が入ってきやすかったように思う。,
C-2021-1_U89,"エントロピーについての理解が少し深まった。
",,"曖昧さの減少は情報量である。
そして曖昧さはエントロピーのことである。",,
C-2021-1_U9,"曖昧さはMが増えるとUも増える。つまり、Mに関して単調増加。
",,,,
C-2021-1_U91,エントロピーを用いた計算の仕方がある程度できるようになった。,エントロピーの理解が難しかった。,確率をエントロピーを用いた計算方法で表すこと。,エントロピーの理解が難しくて、今後が少し不安。,
C-2021-1_U92,情報量を知りたいという所からエントロピーなどを考えている。,正直かなりわからなかった。,"エントロピーについての授業だった。
いろいろな要素がエントロピーにつながっていた。",予習復習をしっかりすべきだと思いました。,
C-2021-1_U93,あいまいさが減少すると得られる情報の量が増えるということ,計算の仕方,エントロピーについて,自分が愚かすぎて授業に全然ついていけなかったです。,
C-2021-1_U94,"情報量の曖昧さの減少量は得られた情報量を表すということ、珍しい情報を知ったときに得た情報量は大きいこと、情報量の期待値はエントロピーと一致することが分かった。
情報量を求めたり情報量の期待値を求めることができた。",求める式は理解できたが、なぜその式になるかは分からない,,,
C-2021-1_U96,"エントロピーの定義の意味。
",情報量の期待値が割切れなかった時の対処法。,情報量とは何か、「曖昧さの現象＝得られた情報の量」はヌメロンというゲームで一つの質問で相手の数が絞れた具合。,わかりやすかったです。,"情報量の期待値が割切れなかった時はどうすればいいですか。
"
C-2021-1_U97,logを用いることで、情報量の期待値が求められる。,確率の計算が苦手なので、早くマスターしたい。,曖昧さが減少していけば、得られる情報量も小さくなる。,,
C-2021-1_U98,前回あまり理解出来ていなかったエントロピーが理解でき計算できるようになった。,後半の複雑な計算は少し難しく感じたのでよく復習しようと思う。,エントロピーについて学んだ。高校数学で確率を学んだが、今回の授業はより実践的だった。,自分で手を動かしたり考えることが多かったんで楽しかった。,
C-2021-1_U99,エントロピーとは何かということをある程度理解することができた。,記号として書かれたときにその意味がまだ瞬時には思い出せないので演習を通して定着させたい。,エントロピーは不規則性の程度を表す量すなわち曖昧さであり、エントロピーが高ければ高いほどそのデータによって得られる情報に価値がある。,予習復習を徹底して難しい内容でも理解できるようにしたい。,
C-2021-2_U1,曖昧さがエントロピーに関連づけられることで情報量が数式で表されたり、その期待値の大きさも二分の一で最大になることなどが理解できた。,条件付きエントロピーの式の成り立ちが少し理解しずらかった。,エントロピーと情報量の曖昧さとして定義でき、曖昧さの差が情報量になる。,数式の背景の理解が多かったので復習して理解したい。,
C-2021-2_U100,情報量が増えると確かになっていくのは分かっていたけど、それが曖昧さの減少と定義した上で、計算で度合いを出せると言うことを学んだ。期待値自体は知っていたけれどそれが、確率などによるその情報を得られる可能性を表すと言うことを理解した。,,情報には曖昧さがあり、情報量が多くなると曖昧さが減少することから、情報量は曖昧さの減少量である。また、発生率によってその事象の情報を得られる可能性が変わり、それを計算したものを期待値という。,今まで理解していなかった、期待値のことをしれて良かったと思った。情報の曖昧さなどを定義した上での情報の正確さを定めているあたりが回りくどいと思ったけど、説明を聞くと合理的でとてもわかりやすい考え方だと思った。,
C-2021-2_U101,今日の講義で前回ぼんやりとした理解だったエントロピーについてより詳しいことが分かった。「曖昧さ」「情報量」「エントロピー」というキーワードとそれらの関連性を自分の中で整理をつけることができたように感じる。また、予習段階で条件付きエントロピーに引っ掛かりを感じていたが、授業を聞く中で情報が整理され、自分で納得がいく程度に内容を理解することができた。,特にありません。,"曖昧さの量はU(M)=log(2)Mで表され、Mが大きいほど曖昧さは大きくなり、U(M)には加法性があるという特徴がある。また、定常無記憶情報源SのときU(S)が生起確率の連続関数であると仮定の下ではエントロピーH(S)とも等しくなる。情報の曖昧さの減少は得られた情報量と等しく、生起確率pとすると-log(2)pと表せるので、生起確率が低いものの情報を得た時に値は大きくなる。さらに、どの事象が生起したかを教えてもらうときに得られる情報量の期待値はエントロピーに一致する。
条件付きエントロピーとはある情報を得た状態での曖昧さの期待値を計算したものであり、情報を得る前のエントロピーから条件付きエントロピーをひくことによって、二つの事柄がどの程度の相関を持っているかを明らかにすることができる。この値は相互情報量と呼ばれ、I(X,Y)と表されるが、XとYが入れ替わっても同じ値となる。相互情報量が０のとき情報を得たとしても曖昧さが変化しなかったということだから、その二つの事柄は無関係であるといえる。",今回も具体例によって理解が深まったように感じる。一方で、今回は予習の段階では「なんとなく分かった気がする」という程度であったものが、講義を聴くことによって「分かった」という感覚に変わり、自分がつまづいていた点や曖昧な理解で済ませてしまっていた点に気づいた。復習もしっかりと行って自分の中に情報を定着させたいと思う。また、今後も予習で自分の理解度をきちんとチェックすることで授業を有意義なものにしたいと思った。,
C-2021-2_U102,情報の曖昧さがエントロピーで数値化できることがわかった。情報の曖昧さをエントロピーで定義することで得られた情報量がわかるようになることを理解することができた。エントロピーをどのように使って問題を解いていくのかを理解することができた。,エントロピーの証明などの部分が一部わからなかった。,本日の講義では情報の曖昧さとエントロピーの関係について学んだ。情報の曖昧さはエントロピーで表すことによって数値化することができ、エントロピーが減少することは情報が得られたことをあらわす。,情報の曖昧さという抽象的なものを数値化できることに感動した。数値化をすることで明確にどれくらい情報を得ることができたのかを知ることができて非常に面白いと感じた。まだ完全に理解しきれていない部分もあるのでしっかりと復習をしていきたい。,
C-2021-2_U103,情報を、その曖昧さや複数の情報同士の関係性の強さの指標を数学的な考え方をもとに導入し、具体的に数値化していることが分かった。,,情報源のあいまいさの減少量を得られる情報量と定義し、得られる情報量の期待値はエントロピーと一致する。また、情報量に関する考え方を複数の事柄にも適用し、それらの事柄の関係性の強さを表す指標が相互情報量である。,今日の講義を聞いて、情報の世界では、当然と言えばそうだが、期待値や条件付き確率など数学の考え方がその基盤であるということがはっきりとわかって面白かった。具体例が豊富でとても分かりやすかった。,
C-2021-2_U104,,公式にあてはめて計算することはできたが、なぜその公式になるのかは理解できたようで、もやもやが残った。,,理解できたかあやしい部分が多かったので、復習して理解を深めたいと思った。,
C-2021-2_U105,生起確率がpの事象が起きた時に得られた情報量は-log2pで表すことができる。,一般の情報源の曖昧さが、情報源のエントロピーに一致するという所が難しかった。,"曖昧さの減少が、得られた情報の量である。情報源の曖昧さは定量化できる。計算によって求められる。得られる情報量の期待値はエントロピーに一致する。
。",かなり本格的な内容に入ってきて、とてもややこしくなった。途中から、こんがらがってしまったのでしっかり復習しようと思った。,
C-2021-2_U106,なぜ先週の授業でいきなりエントロピーの計算をlog2を用いて行うかについてすこし理解が足りていなかったが今日の授業でエントロピーと情報の曖昧さとの関係を知って頭の中がスッキリしました。,なぜ情報の期待値とエントロピーが一致するのかその背景があまりわからなかった。,情報の曖昧さの定量化や曖昧さの性質、曖昧さとエントロピーや情報量との関係、情報量の期待値の求め方、およびある二つの事象に関しての相互情報量や条件付き確率に伴う条件付きエントロピーの求め方について学びました。,相互情報量や情報の曖昧さなどについて学ぶことができたため今まで以上にある複数の事象の相関関係について詳しくしることができるようになったと思いました。、また数学、物理や化学などの異なる教科がつながっていることを感じれたのでとても面白かったです。,
C-2021-2_U107,エントロピー関数が何を表しているのか理解しづらく、縦軸と横軸の表すものとその関係がうまくイメージできなかったが、導出の手順を詳しく説明してもらったため理解できた。,,得られる情報量の求め方と、その期待値の定義と求め方,"情報量の期待値について、各事象の生起確率がそろうほど曖昧さが増すという考え方は図や例を用いて示すとかなり分かりやすかった。
授業中にパソコンが熱暴走でフリーズしてしまったので、授業の録画があって助かった。",
C-2021-2_U108,,,情報の「曖昧さ」を情報量の数値としてどのように表示するかを学んだ。数学をフル活用して確率・期待値やエントロピー（物事の乱雑さ・曖昧さ）に帰着することで情報を評価しうる。,,
C-2021-2_U109,情報量(曖昧さ)とエントロピーが深くつながっていることを式を通して理解することができた。概念としてのエントロピー、相互情報量をつかむことができた。,"相互情報量のI(X,Y)=I(Y,X)という関係が式を見れば納得できるものの、直感的に理解できなかった。",情報量の定義、曖昧さとエントロピーの関係、相互情報量の定義,数学的な内容がかなり大きくなってきて、概念も難しくなってきたと感じた。,
C-2021-2_U11,"情報量の大きさ、情報の期待値、相互情報量を求めること
エントロピー関数について
",,"情報量を曖昧さという測り方ではかるということ、情報の曖昧さをlog2を用いて表すことの証明
情報量の期待値というものがエントロピーに一致するということ
相互情報量：他の情報を入れることによって、曖昧さが変化しうる","曖昧さという表現に最初は戸惑ったものの、色々な例などを見ていくうちになんとなく理解できた
曖昧さの減少が起こった現象で決まるということに驚いた",
C-2021-2_U110,,相互情報量については、予習から授業を通して、計算はできるものの、何をやっているのかが分からない感じでした。,,情報量やエントロピーについて、分かったような分からなかったような状態になってしまった。復習をして、より精密に理解していきたい。,
C-2021-2_U111,エントロピーが何の値に一致するのか、なぜその式で表せるのかを理解することができた。,U(M)=log2Mの証明がよく分からなかった。,"ある情報源の曖昧さはエントロピーに一致する。情報量＝曖昧さの減少＝-log2pである。ここでのpは、その事象が起きる確率pに一致する。情報量の期待値はエントロピーに一致する。相互情報量とは確率変数X,Yの関係の強さを示す指標の一つであり、0のときX,Yは無関係である。",,
C-2021-2_U112,エントロピーの考え方や意味が完璧ではないですけど、前の授業よりはよく理解ができるようになったかなと思います。情報量についてもそれが何を表すか、理解することが出来ました。相互情報量についてはXとYの関係を数値で表すことができることを理解できましたし、面白いなと思いました。,期待値が高校で学習していなかったので詳しくはわかりませんが、何となくイメージはできた気がします。情報量などについては理解はできましたが、問題を解くにはまだまだしっかりと全体を把握して、取り組む必要があるなと思いました。,情報量が増えると情報の曖昧さが減少する。また、曖昧さの量をU(M)とすると、これはMに関して単調増加する。曖昧さの減少量は確率で表すことができる。逆に、確率から、得られる情報量も求めることができる。情報量の期待値はエントロピーに一致する。エントロピーは曖昧さに一致する。相互情報量とはX、Yの関係の強さを示す。相互情報量が０のとき、X、Yは無関係である。すなわち、たとえばXの情報を得てもYの曖昧さが変わらない状態を表している。,エントロピーとは何かについて知ったとき様々な考えや捉え方があって面白いなと思い、興味が湧きました。情報量が増えると情報の曖昧さが減少することは、普段の生活の中でも無意識で認識していることだと思いますが、無意識に理解していることを言葉にして、それを情報科学という分野で利用していくことはすごいなと思いました。また、2つのことの関係の強さを数値であらわしていくことが面白いなと思いました。,特にありません。
C-2021-2_U113,証明を通して、なぜエントロピーにlogを使うのかが分かりました。,相互情報量について、数式が複雑になったので理解しきれていないところがあると思います。,曖昧さの計算の仕方と相互に関係のある情報について。,いよいよ内容が複雑になってきました。授業をしっかり聞くだけではなく、予習復習もしっかりやりたいです。,ありません。
C-2021-2_U114,確率pの事象の生起を知ったことによる曖昧さの減少量は-log₂pであることが分かりました。前回分からなかったエントロピーが理解できてよかったです。,相互情報量の計算式をもう一度復習しようと思います。,曖昧さの減少は得られた情報量に等しい。得られた情報が希少であればあるほど曖昧さはなくなる。得られる情報量の期待値はエントロピーに等しく、エントロピーは曖昧さの一つの指標だと言える。エントロピー関数の最大値は二つの事象の確率が1/2のときである。また、ある情報を知ることで他方の情報に関する曖昧さの減少量を相互情報量という。,情報量の期待値という概念を知るのが初めてでしたが、理解できたと思います。例えがとても分かりやすくて毎回助かっています。ありがとうございます。,
C-2021-2_U115,情報量の全体像がつかめてきた気がする。,期待値を高校の時にそこまでやらなかったのでイメージしにくかった。,曖昧さを定量化して、その減少量で得られる情報量を出すことで異なる事象を比較しやすくなった。またそれに確率をかけることで期待値がだせる。,相互情報量のところの理解があまりできていないのでそこに注力したい。,
C-2021-2_U117,前回まで全くわからなかったエントロピーという概念が少し理解出来た。,条件付きエントロピーの式で、なぜH(p)に前提とする条件の確率をかけるのか分からなかった。,"情報の量を測る手段として、情報源の曖昧さを定量化するというやり方がある。これには単調増加や加法性という性質がある。一般に、確率pの事象の生起を知ったことによる曖昧さの減少は-log2pである。また、情報量の期待値はエントロピーに一致する。確率変数X,Yの関係の強さを表す度合いに相互情報量I(X,Y)があり、I(X,Y)=H(X)-H(X|Ｙ)と定められている。",今回学んだことは数学などでやった事ありそうでない考え方や計算だった。エントロピー関数のグラフをイメージ出来れば具体的な数字を出さなくてもp=1/2からの距離で値の大小を比べられて便利だと思った。要素が多くなると理解が追いつかなかったので次回から整理して丁寧に追っていきたい。,エントロピーが実際にどのような場面どのように使われているのか気になる。
C-2021-2_U118,曖昧さの定義と曖昧さの減少の測り方についてわかった。また、それによって自動的に情報量についてもわかる事が理解できた。,資料10ページの証明が途中でわからなくなってしまったので、自分でもやってみてしっかり理解できるようにしたい。,,少し難しい証明なども入ってきてよくわからなくなってしまった部分もあったので、しっかり復習して理解できるようにしたい。,
C-2021-2_U119,あいまいさの性質について、情報量の期待値について理解することができた,,情報の量を求めたり、期待値求めたり、計算のことが多めの授業だった。,今回の授業では、いろんな計算が出てきたが予習の段階ではわからなかった証明が授業を聞くことで少し理解することができた。授業後にもう一度考え直した結果ちゃんと理解することができたので予習と復習の重要性を改めて感じることができた。,
C-2021-2_U12,"得られる情報量を求めることが一応できた気がする。
","情報量の演習問題は例題を参考にして解くことができたが、内容の本質は深く理解することができなかった。
期待値は例題を参考にしても求めることができなかった。H(機嫌)の部分がわからなかった。
","曖昧さの現象＝情報量の増加
めったに起きない事象の生起がわかることによって得られる情報量は大きい。",,
C-2021-2_U120,情報量の期待値の計算。条件付きエントロピーの計算方法。,条件付きエントロピーの計算方法は分かったが、なぜ計算過程で新たな確率をかけたのか分からなくなってしまった。,"エントロピーには情報量の期待値という側面がある。また、曖昧さの減少は与えられた情報量と等しい。
",エントロピーについて違う視点から知ることができた。期待値の計算には初めて触れたが難しいこともなくてよかった。,
C-2021-2_U121,,U(M）＝log2Mの証明の説明がほとんど理解できなかった。,,たくさんの計算式が出てきて、理解するのに時間がかかってしまった。その中でも、（３）で述べた部分についてはほとんど理解できなかったし、理解できたところについても整理する必要があると思うので復習を必ずしなければならないと思った。,
C-2021-2_U122,期待値の求め方　相互情報量の求め方,,"エントロピー　情報量の求め方　期待値の求め方　相互情報量の求め方
情報量は曖昧さの減少",情報量が曖昧さの減少というのがおもしろかったです。高校では確立の問題として扱ってきた問題が情報量を求める問題として扱われていて新鮮で楽しかったです。,
C-2021-2_U124,曖昧さの減少についての考え方を理解し、求めるための計算ができるようになった。また、情報の期待値を求められる世になった。,U(M)=log₂Mの証明が難しく理解するのに時間がかかった。,"曖昧さの減少は得られた情報の量と同じである。
確率ｐの事象の生起を知ったことによる曖昧さの減少は－log₂ｐと表すことができる。
情報量の期待値はエントロピーに一致する。","今日も知らなかったことを知ることができてよかった。
曖昧さの減少は得られた情報の量と同じという考え方がとても自分の中で腑に落ちて面白かった。",
C-2021-2_U125,情報の曖昧さには単調増加性、加法性があること。曖昧さ、情報量の期待値はエントロピーに一致する。曖昧さの減少が得られた情報量に一致する。曖昧さの減少というのは、生起確率ｐを用いて-log2(p)とおくことができる。,曖昧さU(M)=log2(M)の証明。条件付きエントロピーについて。,情報量の曖昧さ、得られる情報量について。ある情報を得ることによって情報量の曖昧さが減少する。曖昧さは情報源のエントロピーに等しく、また、事象ｐの生起確率を知ったことによる曖昧さの減少は-log2(p)と表される。また、複数の情報量の相互関係を表した相互情報量というものがある。,予習の際に理解できなかったところや、何となく理解していたところが授業を聞いてより理解が深まったり、理解できた部分もあるが、やはり条件付きエントロピーは難しかった。自分で理解できるようになるまで手を動かして計算してみようと思う。,
C-2021-2_U126,,,情報量が増える＝情報の曖昧さが減るという事ができ、「情報の曖昧さ」を定量化したものがエントロピーと等しい。また、ある条件下で得られる情報の期待値もエントロピーと等しい。2つの情報を組み合わせて得ることができる情報量をそれら2つの情報の相互情報量という。,数式や証明がところどころ出てきて、苦手意識ができそうだが、復習の際にもう一度証明を自分で書いてみたりして理解を深めようと思う。,
C-2021-2_U127,,,事象に伴って得られる情報量は曖昧さの減少であり、曖昧さは、単調増加性・加法性を持つ。また、情報源Sの曖昧さをU(S)とすると、U(S)が任意の事象の確率pの連続関数であるという仮定があるとき、SのエントロピーH(S)=[p*(-log2p)の総和]に一致する。さらに、確率pの事象の発生で得られる情報量は曖昧さの減少-log2pで表すことができる。そして、情報量の期待値は、任意の事象の確率をqとしたとき、q(-log2q)の総和で求めることができ、これはエントロピーに一致するため、情報量の期待値を考えるときに、エントロピー関数を用いることは有益であろう。条件付きエントロピーを用いて算出される、確率変数の相互情報量は、確率変数の関係の強さを示す。,,今回学習した情報量の期待値や相互情報量は実際にどのような場面で活用されているのでしょうか。
C-2021-2_U128,,,,今回は高校でもなんとなく聞いたことがある期待値について知れて理解を深めることができましたが、上記にも述べた点がわからなかったので、何卒開設の方宜しくお願い致します。,ネズミが猫に噛みついたという情報が大きいというのはサイコロと同じように考えれば、確率的に低いことが起こったので、「あ、この事象も起こり得るんだ。」という風に捉えることができるからということでしょうか？
C-2021-2_U13,,,情報量は曖昧さの減少であり、得られる情報の期待値はエントロピーと一致する。また、ある事象について観察することによって得られる他の事象についての情報量を相互情報量といい、これは２つの事象の関係の強さを表すものである。,数式が並んでいると思考が止まってしまいがちなので恐れず向き合っていきたい。,
C-2021-2_U130,エントロピーという言葉自体があまり私にとって身近ではなかったので初めは少し難しく感じられたが、実際に授業を聞いてみると、エントロピーの概念や基本の情報量の計算方法は想像していたよりも単純なものだったので、基本的な部分は理解できたと思う。,言葉の概念や基本的なところは理解しているつもりだが、少し複雑な部分になっても応用が効くようにしたいと思う,エントロピーとは何かについての詳しい説明と、その情報量の計算方法、情報の種類について学んだ。,前回の授業より詳しく学べたので、前回までと比べて少し理解できるスピードが早くなれたと思う。,
C-2021-2_U131,情報量と期待値の計算の公式を覚えて実際に問題を解くことができた。,,,,
C-2021-2_U132,情報量は確率が求められればわかるということ,なぜ曖昧さがlogを使って表されるのかがイマイチわからなかった,曖昧さというアバウトな概念が数式で表すことができることに驚いた。,もっと証明のところをしっかり聞けばよかった,
C-2021-2_U133,曖昧さが減少することは情報を得られているということであるというのが、計算例を参考に理解できたと思う。,"相互情報量のXとYが無関係のときI（X,Y)=0というのが曖昧にしか理解できなかった。",今日の講義では情報の曖昧さやエントロピーと期待値との関係性を数値を用いて確かめた。得られる情報量というのを確率的に求められることを学んだ。,例題の計算をやってみながら授業を受けることで、理解しやすかった。条件つきエントロピーなど複雑なところもあって少し難しく感じた。しっかり復習をして、次の授業に臨みたいと思う。,
C-2021-2_U134,エントロピーと曖昧さ、情報量という概念について知り、計算することができるようになった。,,エントロピーの算出の仕方や確率の概念の元々に戻って理解することができた。,集中して活動することができた。エントロピーを知ることによって、確率と期待値は高校ではやったものの、機械的に理解していることがあったのでわかってとても良かったと思う。,
C-2021-2_U135,数理統計学を学んでおくとかなり見通しが良くなった。エントロピーの理解や期待値の理解がしやすいと感じました。,,情報の曖昧さ、という把握しにくいものを定量化して表すことで一般的に理解できるように、客観的に比較できるようにしている。,他の教科との関連性が早くも見えて面白いと思った,
C-2021-2_U136,情報量を計算で解けるようになりました。,特にありません。,情報量が増えるとより明確な値になる。,公式の仕組みをまだ理解できてないので練習して慣れようと思いました。,特にありません。
C-2021-2_U137,曖昧さについて学習していく中で、前回理解できなかったエントロピーについても理解することができました。情報量や、情報量の期待値の計算方法について理解することができました。,相互情報量についてまだ理解できていない部分があるので、復習を通して次回の授業までに理解しておきたいです。,情報源には曖昧さがあり、その曖昧さを減らすのが情報量である。また、情報量の期待値も存在し、どれだけ曖昧さを減らすことができるかという見積りも立てることができる。また、二つの情報を合わせて、相互情報量として情報源を分析することもできる。,今日の数理統計学の授業で期待値について学習したのですが、情報量にも期待値があることを学習し、いろいろな期待値が存在するのが面白いなと思いました。また、曖昧さの性質から、U(M)=log₂Mを導いたのがとても綺麗で、素晴らしいなと思いました。今日の授業では、相互情報量について完全に理解できたということができないので、より予習が必要だと反省しました。,相互情報量が必要になってくるのは具体的にどのような場面なのかなと思いました。
C-2021-2_U138,前回の講義から引き続きエントロピーが出てきて、しっかり理解することが出来た。,,,,
C-2021-2_U139,期待値の原理や算出方法を理解っすることができた。,,,,
C-2021-2_U14,情報の曖昧さとエンタルピーの関係性がよく分かった。得られた情報量が多いほどその曖昧さが減少していくことが理解できた。,"I(X,Y)=0のときXとYは無関係というところで、H(X)=H(X|Y)になるのがどんなときかわからなかった。",得られた情報の量によって曖昧さは減少する。曖昧さU(M)はMに関して単調に増加し、加法性がある。ある無記憶定常情報源Sの曖昧さU(S)はSのエントロピーに一致する。またエントロピーは情報の期待値に一致する。相互情報量によって2つの情報の関係の強さが分かる。,情報の曖昧さを感覚ではなく数値として表すことができるのがとても面白いと思った。アルファベット表記で混乱したところがあるので復習して区別をしたい。,
C-2021-2_U140,ある情報がもたらした情報量の多さを数式によって表すこと。,エントロフィーの使用用途,情報量を測るための、数式について学んだ。,,
C-2021-2_U141,情報量と期待値の意味を理解し、その計算ができるようになった。,条件付きエントロピーの計算が少し理解できなかった。,情報と情報量の意味、情報量および期待値の解説と計算方法、そして条件付きエントロピーを紹介した。,期待値の意味と計算方法は分かったが、その数値からわかることに対してぼんやりであった。講義前の予習だけでなく、あとの復習と分からなかった部分の補足も大事だと思った。,
C-2021-2_U142,情報量＝曖昧さの減少という意味とその求め方について理解できました。また、相互情報量がある事象ともう一つの事象についての関係の強さを表すということも分かりました。,情報量の期待値の求め方が、猫の機嫌の話から理解が中途半端になってしまいました。,"情報の曖昧さを定量化するという考え方があり、これは情報源をSとすると、Sのエントロピーに等しくなる。
情報量とは曖昧さの減少のことである。また、相互情報量とは、確率変数をX、Yとすると、その関係の強さを表す指標となる。",情報や情報量という単語は普段もよくも耳にする単語ですが、情報量のことを曖昧さの減少というふうに考えるのはおもしろいなと思いました。,
C-2021-2_U143,,,前回に引き続き、エントロピーについての詳しい解説があった。情報源の曖昧さと得られる情報量の関係について学び、その計算方法はエントロピーの計算と同じであることを学んだ。また、前提条件の有無によって、期待値が違いを学んだ。,予習は行うようにしていたが、後半に進むにつれ予習が足りなく感じた。自分がどこを理解できていないのか、講義の前に把握し、その部分を集中して聴けるようにもっと予習に力を入れるようにしたい。,
C-2021-2_U144,,,情報の量や曖昧さ、情報量の期待値を定量的にすること。,,
C-2021-2_U145,"一般の情報限のあいまいさがその情報限のエントロピーに一致すること。
情報量、情報量の期待値の求め方",二回目の授業と今回の内容につながりを見つけること,情報量の定義と測り方、また、情報量の期待値と相互情報量について,"小テストで解答するときに不安な点があったので、第二回の復習も必要だと思いました。
予習でマーカーを引き忘れたこと。",
C-2021-2_U146,,,情報量を数字で表すことで、比較することができるということ。,,
C-2021-2_U147,情報量を数式化できることにびっくりした。情報量＝曖昧さの減少　が確かにそうだなとわかった。,,情報の量について。情報の量＝曖昧さの減少　ということから、曖昧さを計算することで情報を知っていく。,猫の機嫌と尻尾の関係は数値化できるものなのかと不思議に思いました。,
C-2021-2_U148,情報のあいまいさはエントロピーと一致していることが分かり、実際に情報のあいまいさを計算して求めることができた。,U（M)=log2Mの証明で不等式の導出までは理解できたけどその後なぜ極限を使い求めるのかがわかりませんでした。,情報を得るとあいまいさが減少する。情報のあいまいさをU(M)とするとU(M)=log2(M)となり、あいまいさとエントロピーは等しい。生起確率pの事象の生起を知ることで得られる情報量はlog2(P)である。,前回あいまいだった情報円斗ルピーについて理解が深まってよかった。,
C-2021-2_U15,,条件付き確率が絡んだエントロピーの算出,,,
C-2021-2_U151,,,得られる情報量とは、曖昧さの減少量と一致する。また、情報量の期待値はエントロピーを一致する。,たまにしっかり集中できておらず、聞き逃していることがあるため、もっと集中したい。,
C-2021-2_U152,,,情報の曖昧さ,,
C-2021-2_U153,情報量、情報の期待値、情報量の減少、相互情報量の定義、内容、計算をしっかりとできるようになったと思います。,特にないです。U(M)＝log2Mの証明も予習の段階では理解が難しかったですが、授業と復習で理解できました。,情報の曖昧(情報量)を式にして数値化することについて学びました。また、それに加えて情報量の期待値や相互情報量なども学びました。簡潔にまとめると色々なパターンの情報量の数値化について学びました。,前回の授業に比べて内容の理解がよくできたと思います。内容が理解できれば今のところ計算は高校数学レベルなのでとにかく定義や式の意味を理解できるようにしていきたいです。,
C-2021-2_U154,,,,前回の授業ではエントロピーについてしっかり理解することはできなかったけど今回の授業できちんと理解することができたと思います。復習をしっかりして見直したいと思います。,
C-2021-2_U156,期待値を考えることでエントロピーがわかる,なぜlog2を使うのか、まだ腑に落ちない,曖昧さの減少＝得られた情報量,「入念に説明しました」とおっしゃっていましたが、まだ理解が追いついていないと感じています。,なぜlog2を使うのか再度説明していただきたい
C-2021-2_U158,エントロピーの計算方法と確率の関係,エントロピーの母数が多い時の計算,エントロピーの定理と計算方法。,簡単なエントロピーの計算はできるようになったが、複雑なのになるとできなくなってしまった。,
C-2021-2_U159,情報量の求め方、期待値の求め方,,情報量とは曖昧さの減少であり、対数を用いた公式で導くことができる。その情報量の期待値はエントロピーと一致する。,久々の対数計算で数学の問題を解くことが懐かしく感じた。,
C-2021-2_U16,"与えられる情報がめったに起きない、確率の低いものであれば得られる情報量の値は大きくなることが分かった
logを使った簡単な計算は理解したうえでできるようになった","エントロピー関数が、H（ｐ）で求められることが分からなかったが、友達と一緒に勉強してグラフの意味を理解できたので、ある程度は理解できた。
計算自体はできるが、U(M)=log₂Mの証明が理解できていない","エントロピー関数について
得られた情報量が、事象のあいまいさを減少させるという",,情報量の期待値のところで出てくるPrが何を表しているのかがわかりません。
C-2021-2_U160,"曖昧さの減少＝得られた情報の量

確率pの事象の生起を知ったことによる曖昧さの減少は　-log2p

情報の期待値
相互情報量の求め方がわかった。","logの計算

logの割り算","質問を繰り返して、情報を得る
曖昧さを減らす＝情報を得る



","情報は直に情報を得るのではなく、曖昧さを減らしていって情報を得る。
計算を覚えて理解することが、まず大事だと思った。",
C-2021-2_U161,今回の授業における猫の機嫌と尻尾の関係の例を聞いて相互情報量について理解を深めることができた。,,,今回は数学的な考え方をすることが多くて理解を深めるのに苦しんだが、例題を解いたり、説明を聞いたりすることで理解することができた。,
C-2021-2_U162,情報量を求める公式にあてはめて情報量を求めることができるようになった。何度も例題を見ていくうちに何を求めているのかがわかるようになってきた。文字がいっぱいではじめは分からなかったけれど説明を聞いて証明が理解できた。,,,,
C-2021-2_U163,"情報量の計算方法
情報量の期待値の計算方法

",相互情報量,"情報の曖昧さは、情報量が増えると、減り、情報量が減ると、増える。
また、情報源の曖昧さは、その生起確率により変化する。
",実際に公式を使えて理解がすすみました,
C-2021-2_U164,,,エントロピーを詳しく知る。,,
C-2021-2_U165,情報のあいまいさを数値によってあらわせること、また前回の授業で出てきたエントロピーの活用などについて学べた。,,情報のあいまいさを数学的に表す、また情報量の期待値を求める。,,
C-2021-2_U166,エントロピー関数で二分の一の確率で起こる事象の情報量が多くなること,,情報量の調べ方,,
C-2021-2_U167,"・曖昧さの減少は、情報量の増加として示すことができる。
・情報源の曖昧さ、得られる情報量の期待値はエントロピーで示すことができる。
・曖昧さの性質は、単調増加性と加法性である。さいころの例で理解できた。
・エントロピーは大切",,曖昧さが情報量の増加で示せるものとして、情報源の曖昧さ、得られる情報量の期待値はエントロピーで示すことができる。,自分は非常に数学が苦手なので計算がたくさん出て大変でしたが、解説を聞いていると面白いと思うことができました。しかし、期末試験では計算すくなめだと嬉しいです。,・相互情報量の定義において登場する[｜]の計算処理の方法
C-2021-2_U168,得られる情報量、情報量の期待値、相互情報量の計算は、できるようになった。,条件付きエントロピーの求め方があまりわからなかったので、例に示されている解き方を参考にして、解いていきたい。,一般の情報源のあいまいさは情報源のエントロピーに一致する。情報量の増加は曖昧さの減少である。,今日の授業内容は、ほとんど公式を覚えるといったものだったので、例題や演習問題を通して、習得できたと思う。条件付きエントロピーがあまりよくわからなかったので、復習して、完璧にしたい。,
C-2021-2_U169,公式を使った演習問題が解けました。,公式の深い意味がよくわかっていません。,"曖昧さU(M)＝log2M。生起確率pの事象の生起を知ったことで得られる情報量を、それにより曖昧さの減少量、すなわち-log2pと定める。p1＝p,p2=1-pとすると、エントロピーの値はH(p)=p(-log2p)+(1-p)(-log2(1-p))となる。これをエントロピー関数と言い、H(p)はp=1/2の時に最大となる。また、確率変数X,Yの相互情報量をI(X,Y)＝H(X)－H(XlY)で定める。",,
C-2021-2_U17,それぞれの公式に数字をどう当てはめてどう答えを出していくのか分かった。また、なぜこのような式にになるのか理解できたため、演習で実際に計算することができた。,,,"課題や日誌の提出が遅かったので、もう少し早く提出するようにしようと思う。
また授業の予習でもう少し内容の理解を深くしようと思う。",自分の中では理解できたと思っていますが、実際課題の答案があっているのかが知りたいです。
C-2021-2_U170,,,,今日は文系の範囲ではない数3が関わっていたのですごく難しいと思ったし、それと同時に、プログラマーなどの情報を扱うことを職としている人はすごいと思いました。,
C-2021-2_U171,得られる情報の量は曖昧さの減少によって決まることが分かった。曖昧さの定量化の仕方が分かった。,,,対数の計算を少し忘れていたので高校で習った数学の内容を復習しようと思う。,
C-2021-2_U174,,,曖昧さ、エントロピーの言葉の意味とその計算方法。,,
C-2021-2_U18,エントロピーと情報量だったり式の意味が分かった。,,エントロピーとは情報の曖昧さを表したりするものでその計算によって情報量の減少だったりを計算することができる。,情報の曖昧さや量など普段考えもしない新しい考え方がわかった。,
C-2021-2_U19,今回は予習ができたのである程度理解した状態で授業を受けることができた。,定義としての数式を覚えることはできたが、なぜそうなるのかを完全に理解できたかは怪しい。,情報の曖昧さと得られる情報量、その期待値は数値としてあらわすことができる。,前回よりも具体的な話で理解しやすかった。,
C-2021-2_U20,定義は知れた。なんとなく、そうなんだ程度の理解。,,,,
C-2021-2_U21,曖昧さの減少＝得られた情報の量ということは理解できた。,相互情報量がいまいちよくわからなかった。,情報の曖昧さについて、「曖昧でなくなればなくなるほど多くの情報を得られた」ということであると確認し、曖昧さを定量化しその性質や定理を学んだ。,理解できたところ・理解できなかったところをはっきりさせることができた。予習・復習の大切さを改めて実感した。,
C-2021-2_U23,,,,今までの授業の中で一番難しかったです。,
C-2021-2_U24,情報量の計算,相互情報量の理解が少し難しかった,#NAME?,大量に数字が出てきてパニック案件でしたが、順を追って丁寧に見れば複雑ではなかったように思います。,
C-2021-2_U25,エントロピー関数が最大になるとき。,エントロピーを完全に理解すること。,情報量、情報の期待値、あいまいさの関係。,小テストで、わかっていたのに選択肢を間違えるという一番やってはいけないミスをしてしまった。次回からは絶対にそのようなことがないよう気を付けたい。,
C-2021-2_U26,"曖昧さの減少は数式で定量化することができると分かった。
また、事象の生起確率がどのようであるときに情報量の期待値が大きくなるのか知ることができた。
",特にありません。,"知識の曖昧さが減少することに伴って、得られた情報の量は増加する。
情報源Sの曖昧さは log2(M)で与えられ、これはSのエントロピーに等しい。
生起確率pの事象の生起を知ったことで得られる情報量は -log2(p)と定められている。
よって、滅多に起きない事象の生起を知ることで得られる情報量は、よく起きる事象の生起を知ることで得られる情報量よりも大きくなる。",前回の授業ではエントロピーがどのようなものかきちんと理解できていなかったが、今回の授業を通して理解することができた。曖昧さの減少を定量化することで、得られた情報の量や情報量の期待値を求められることに驚いた。次回の授業も頑張りたい。,特にありません。
C-2021-2_U29,"与えられた情報の量は曖昧さの減少である。
今回習った情報量の期待値や相互情報量に関する考え方や計算方法が分かった。",U(M)=log2Mを導出する過程のところでわからないところがあったので復習をしていきたい,"曖昧さU(Ｍ)がlog2Ｍになること。
情報量の期待値。相互情報量や計算方法。","前回と比べて難しくなったと感じたので予習復習をしかっりして理解できるようになりたいです。
情報量のエントロピーについてもっと知りたいと思いました",
C-2021-2_U3,曖昧さや曖昧さの減少という数値化できないというもが情報化により見える形、計算できる形にできることがわかりいました。また、今までの授業で習った確率がこのようにはたらく、用いることができるのだということもわかりました。,相互情報量についてあまりしっかりと理解できなかった。,"・曖昧さU(M)について
性質：Mに関して単調増加・加法性(=1...MNの目を持つサイコロを振った場合と同様)
定理：U(M)＝log2M
　　　情報源Sのエントロピー=曖昧さU(S)
　　　確率pの事象の正気を知ったことによる、曖昧さの減少はーlog2
・エントロピー関数
　p1=p,p2=1-pとすると、エントロピーの値はH (p )=p (-log2p)＋(1-p)（-log2(1-p))
　H(p)はp=1/2のとき最大になる
・相互情報量
定義：確率変数X,Yの相互情報量をI(X、Y )=H (X )-H(X｜Y)で定める。",多くの人がわからないと思っていたところをゆっくり解説してくださってわかりやすかったです。,
C-2021-2_U30,曖昧さが大きいとエントロピーが大きくなる,,エントロピーを数値で表現する,曖昧さというのがいまいちわからなかったが、どれかに確率が偏っているときは曖昧さが小さいということだと分かった。,
C-2021-2_U31,"得られる情報量を数値で求めることができた。
エントロピーの重要性を理解した。",公式の意味を深くまで理解することができなかった。,情報源Sの曖昧さはSのエントロピーと一致する。また、生起条件pの事象を知ったことで得られる情報量を、曖昧さの減少量と考えることで、公式を使い求められる。この公式からめったに起きない事象ほど、得られる情報量が多いことが分かる。情報量の期待値はエントロピーと一致する。,"様々な公式が出てきて、計算内容も複雑であったので少し難しかった。
情報量などを数値で表せることはおもしろいと思った。",
C-2021-2_U33,候補が絞られるほど情報源の曖昧さは減少することを理解し、それが-log2pであることを受け入れた。例題を通じて理解を深めることができた。,最後の相互情報量が分かりにくかったです。復習を通じて理解します。,"情報源の曖昧さとエントロピーの概念を学んだ。情報源SとSのエントロピーＨ(S)は一致する。候補が絞られるほど情報源の曖昧さは減少する。その時確率pに対する
曖昧さの減少は-log2pになる。H(p)はp=1/2の時に最大になる。",少し難しかったですが、猫のご機嫌と尻尾の関係が例になって理解に役立ちました。今回もありがとうございました。,
C-2021-2_U34,一般の情報源の曖昧さはそのエントロピーに一致するということを計算式を踏まえて理解することができた。,,情報量、情報量の期待値を求める計算方法について。,,
C-2021-2_U35,,,"生起確率ｐの事象の生起を知ったことで得られる情報量=曖昧さの減少量となる。その曖昧さの減少量はーlog₂ｐであらわされる。情報量の期待値はエントロピーに一致する。
",,
C-2021-2_U36,得られる情報量をその事象の生起確率を用いることによって、求めることができた。また、得られる情報量の期待値の大小もそれを表す式の意味を理解し、エントロピー関数を用いることで区別することができた。,相互情報量がなぜあのように定義されるのかがわからなかった。,"一般の情報量の曖昧さの減少量は生起確率ｐの事象の生起を知ったことによって得られた情報量に等しく-log₂pとあらわすことができる。また、情報量の期待値はエントロピーの値と一致する。
",得られる情報量はlogの計算によって数値化できるということを学んだ。なぜ得られる情報量の期待値がエントロピーを表す式に一致するのかということはそれぞれの事象の曖昧さの減少量にその事象の生起確率をかけて足し合わせたものだととらえれば納得のいくことであると思った。,
C-2021-2_U37,エントロピーの意味　またその定義式の意味,,エントロピーと情報量,これからも情報について学んでいきたい,
C-2021-2_U38,,10ページの証明が完全に理解できませんでした。,,,
C-2021-2_U39,情報の曖昧さの導出、得られる情報量の計算とエントロピーについて分かりました。,ありません。,,どんどん数字や文字が出て行って、難しくなり、数学っぽくなる感じでした。,また、この日誌を提出する時間が遅くなりましたが、日誌って次の授業の前にだけ提出すればいいですか。
C-2021-2_U4,エントロピー,,,,
C-2021-2_U40,,,,U(M)=log[2]Mの証明で久々に数学らしいことをした。自力で示すまではいかないが証明を見て納得がいく程度まで理解できているので少し安心した。今日の講義は数学の側面が強かったので置いていかれないようしっかり復習したい。,
C-2021-2_U41,log2p（底は２である）は曖昧さを表現して、ーlog2pは情報の曖昧さの減少を示すということが分かりました。また、曖昧さはエントロピーと一致するということ、すなわちエントロピーは曖昧さを示す１つの指標となることが分かりました。,曖昧さのU(S)がlog2S(ここで２は底である）となる証明があまり分かりませんでした。log2xの単調増加性よりk<nlog2M<k+1となるのがよくわかりませんでした。,"得られた情報の量が多ければ多いほど曖昧さは減少する。ここで、曖昧さをU（M）として表現すると、U(M)　は単調増加であり、U(MN)=U(M)+U(N)が成りたつ。ここで確率がｘで一様なとき、U(M)はlog2x（ここで2は底である）と等しく、Mのエントロピーと等しい。無記憶定常情報源の場合も情報の曖昧さU(S)はSのエントロピーと等しい。ここで確率ｐが起こったことを知るときに減少する情報の曖昧さはーlog2pである。また、確率p1,p1,p3...pnである事象があるとき、どの事象が起こったか知ったことにより得られた情報量の期待値はp1(-log2p1)+p2(-log2p2)+・・pn(log2pn)で計算でき、エントロピーと一致する。このとき事象が二つしかないとき、確率が１／２のときにエントロピーは最大の値となる。また、二つの事象の関係の強さを示す指標として相互情報量というものがあり、これは２個の事象のうちの１個の事象（ここでこれをAとするとそして他方の事象をBとすると）のエントロピーから、条件付きエントロピー（H（A／B））を引いたものである。相互情報量が０となるとき、この２個の事象のAとBの関係性は全くないということになる。","曖昧さU(M)＝log2M（ここで２は底）となる証明をもう一度紙にちゃんと書いて考えてみようと思いました。
",log2xの単調増加性よりk<nlog2M<k+1となぜなるのですか？
C-2021-2_U42,情報量とは曖昧さの減少のことを表しており、生起確率ｐの事象の生起を知ったことで得られる情報量を−log2⁡𝑝で表す。,,知識の曖昧さについて、その量をU(M)で表す。また、この値はMに関して単調増加し、加法性も持つ。一様に分布する情報源Sの曖昧さU(S)はSのエントロピーに等しい。,普段の事象の生起が数学と密接につながっていることを改めて知ることができた。現在履修している数理統計学とのつながりも意識しながら学んでいきたいと思った。,
C-2021-2_U43,得られる情報量の期待値はエントロピーに一致し、エントロピー関数より、Ｐ＝１/2の時に最大値をとる。,条件付きエントロピーが難しかった。,情報量はあいまいさの減少分と考えることができる。また、得られる情報量の期待値という概念が存在する。,期待値とエントロピーが一致するというのが衝撃的でした。,特にありません。
C-2021-2_U44,情報の期待値を導く方法と、その応用となる相互情報量の求め方が理解できた。,,情報の量を測る際に重要となるのは曖昧さの量であり、得られた情報の量を曖昧さの減少量で測ることができる。また、得られる情報量の期待値はエントロピーに一致する。,予習段階ではあまり理解できていませんでしたが、説明を聞いて納得できました。,
C-2021-2_U46,与えられた情報によってどれだけ曖昧さが減少するかがわかる。2種類の情報源があるとき、どちらの方がより質が高い（曖昧さが減少するか）がわかる。,,与えられた情報の質によって減少する曖昧さが異なる。,,
C-2021-2_U47,期待値とエントロピー関数の関係を理解しました。演習問題２のような問題であれば、生起確率が分かった時点で回答可能であることが分かりました。,情報量と曖昧さの関係が感覚的にはなんとなくわかるのですが、しっかり理解できているのか不安です。,「曖昧さ」を量で表せるようにしたい。曖昧さが減ることで情報量が増える。情報の期待値はエントロピーと等しい。,,（３）の内容がいまいち理解しきれてない感じがします。
C-2021-2_U5,曖昧さの定理を活用し、無秩序な事象から情報量を得られた。また、二次関数のグラフの概要からエントロピーの大小を視覚的に捉えられた。,数Ⅲに触れてないので、証明の中の極限の部分がしっくりこなかった。,サイコロを振ったり、トランプを引いする事象の情報源は曖昧である。そこでこの曖昧さが情報源のエントロピーに等しいことを利用して定理化し、事象の確率を代入することで情報量を求めることができるようになった。また、この情報量の期待値はエントロピーに一致する。,ハイペースで課題が解けたので楽しかった。自分にもエントロピーが扱えているという自信を得た。,
C-2021-2_U51,曖昧さの期待値ということが理解できた。,,情報の量を１か０かで判別していき、徐々に絞っていくようあ考え方を習った。,結構数字がたくさん出てきて、文系の自分にとっては難しく感じたが、身につければ普段の思考の基礎となりうるような内容だったのでしっかり理解したい。,
C-2021-2_U53,久しぶりにがっつり計算したのでとても楽しかったです。情報量を計算できるなんて知らなかったので、また一つ七期を増やせてうれしいです。,今回の内容は、まだ簡単な方だと思うので特にわからなかったことはないです。,今回は、情報量や、情報量の期待値について勉強しました。ログなどを使って情報量を計算することが可能ということを知りました。期待値の出し方が納得する方法でとても面白い。,とても面白い講義でした。情報量の出し方や、計算がとても面白かったです。ログの計算が少し複雑になっていて苦戦しましたが、達成感を得ることも出来ました。また頑張ります。,
C-2021-2_U54,,,曖昧さが減るということは、得られた情報の量が増えたということである。その曖昧さの減少は-log2pで表すことができる。条件付き確率のように条件付きエントロピーを計算することができる。,小テストは満点だったのでこれからもこの調子でいきたいです。前回分からなかったところは家で復習すると分かったので、今回もしっかり復習しようと思います。エントロピーを計算することで期待値や曖昧性、条件付きエントロピーまで求めることができて、万能だと思いました。,
C-2021-2_U55,情報量の具体的な求め方を知ることができた。,今日の内容で分からなかったことは特になかったのでしっかり復習したい。,"曖昧さの減少は得られた情報の量であり、これを求めるとき生起確率をPとするとーlog₂Pとなる。情報量の期待値はp1(-log₂p1)+....pm(-log₂p)となり、エントロピーと一致する。相互情報量について確率変数X,Yの相互情報量をI(X,Y)=H(X)-H(X|Y)で定める。XとYが無関係の場合、I(X,Y)=0。
",まず、得られた情報量が曖昧さの減少と一致することの説明を聞いてとても納得しました。前回や前々回の内容とも関連付けられて非常の面白かったです。,
C-2021-2_U56,情報量の期待値を求める方法を理解することができた。またU(M)＝log_2(M)の証明方法も分かった。,相互情報量のところが条件付き確率も絡んできているので理解しづらかった。自力でとくのは難しいと感じた。,"曖昧さの減少は得られた情報の量と同値である。曖昧さU(M)の性質としてはMに関して単調増加し、加法性を持つことが挙げられる。情報源Sの曖昧さU(S)はU(S)が確率p1,p2‥の連続関数であるという仮定の下でSのエントロピーH(S)に一致する。めったに起きない事象の生起を知ることで得られる情報量は大きい。情報量の期待値はエントロピーに一致する。相互情報量をI(X,Y)＝H(X)-H(X | Y)で定めると、I(X,Y)＝0のときXとYは無関係である。",表やイラストでイメージしやすく、わかりにくいところもなんとか理解できたのでとても勉強になった授業でした。,
C-2021-2_U57,「これは曖昧過ぎてよくわからない」、「これでかなりの情報が得られた」などの言葉は日常でも登場するが今回の授業を聞くことで、それを具体的な数値として考えることができるようになった。,特にありません。,今日の授業を一言で表すと、「情報の精度や量を数値で表す」と言える。情報源のあいまいさと得られる情報量の期待値は情報源Sのエントロピーで表すことができる。ほかにも相互情報量なども定義されているので数値で表すことができる。,今回の授業は予習をしっかりとしたうえで臨めたので内容がより頭に入ったと感じた。次からの授業も予習、復習を怠らずに頑張りたいと思う。,特にありません。
C-2021-2_U58,"エントロピーの使い方が分かった。
",証明は文系なのでまったくわからなかった。,"曖昧さとエントロピーは等しい。
起こりにくい事象ほど起こった時に得られる情報量は大きくなる。
","難しい。
ついていけるか不安。","提出場所がいまだにわからない。
"
C-2021-2_U59,前回習ったエントロピーを用いながら、情報量の期待値を求めることができた。また、予習で分からなかった10ページの証明をある程度理解することができた。,情報量の「期待値」という言葉が分かりにくかった。,,,特にありません。
C-2021-2_U6,エントロピーがなぜあの式になるのかの確かめ算的なものができたことで、なんとなくエントロピーを理解できた。相互情報量の意味も理解することが出来た。,曖昧さの減少の証明で数三の知識（極限や挟み撃ち）が必要になったので、一気に意味不明になった。エントロピー関数についても意味がよく分からなかったので復習したい。,試行回数（情報量）が増えると曖昧さが減少するということを利用して、エントロピーの式が正しいことがわかる。またその逆のようなものである事象の生起確率を知ることで情報を得ることが出来、めったに起きない事象の方が得られる情報は多い。二つの情報があるとき、その条件付確率から条件付エントロピーが求められる。またその二つの情報の関係から相互情報量が求められる。,全体的になんとなくは理解できたものの、逆になんとなくしか理解できていない気がする。しっかりと理解ができていない状態で次にすすむと余計にわからなくなるので、今回の内容は演習等をりようしてしっかり定着させたい。,
C-2021-2_U60,エントロピーそのものが情報源の曖昧さと一致することが分かった。,相互情報量を求めることで、何が分かるのかが分からなかった。,"無記憶定常情報源Sの曖昧さをU(S)とすると、確率pの事象が起こった時、それによる曖昧さの減少量は-log₂pで表される。
事象Akが生起する確率をそれぞれpk(k=1~n)とすると、得られる情報量の期待値は∑(k=1~n)(-log₂pk)/pkで表すことが出来る。これは曖昧さUやそのエントロピーHに一致する。
確率変数X,Yの相互情報量はI(X,Y)=H(X)-H(X|Y)で表すことが出来る。条件付きエントロピーH(X|Y)は、Yが生起する事象Yk(k=1~n)を用いて、H(X|Y)=∑(k=1~n)pYk*H(pX(Yk))で表すことが出来る。",段々、内容が難しくなってきているため、日々の予習、復習をキチンとせねば、と思いました。,
C-2021-2_U61,情報量によって曖昧さが減る,エントロピーの辺りはよくわからなかったので復習します,情報量とエントロピーの関係,急に難しくなった感ある,
C-2021-2_U62,,,曖昧さの減少や得られた情報量、エントロピーなどは対数を用いて数値化することができる。,,
C-2021-2_U63,情報量や相互情報量の求め方使い方,完璧に理解したわけではなくなんとなくという感じ,,,
C-2021-2_U64,まず、情報量がわかることで曖昧さが減少し、この曖昧さは情報にとってとても重要であることがわかった。また、曖昧さはエントロピーに等しく、エントロピーの式やエントロピー関数を利用することで情報量や情報量の期待値の大小を比較する問題を解くことができた。また、相互情報量が条件付きエントロピーによって求められることとその計算の仕方がわかった。,曖昧さU(M)についての証明が難しいと感じた。また、情報量の期待値やエントロピーと曖昧さが等しくなることについてなんとなくの理解はできたが、深くまで理解することができなかった。,第３回の授業では情報量と情報量の期待値について学んだ。得られた情報量は、曖昧さの減少に繋がり、この曖昧さというのは加法性がある。この曖昧さU(S)はSのエントロピーH(S)に等しく、これにより情報量も計算できる。また、情報量の期待値はエントロピーに一致し、エントロピー関数により情報量の期待値の大小を比較することができる。条件付きエントロピーを求めることにより相互情報量を求めることができ、これによって情報の曖昧さの減少を図ることができる。,今日は、情報量について詳しく学ぶことができた。また、曖昧さや情報量の計算も演習問題を通して解くことができて良かった。引き続き予習、復習をしっかりして授業内容を深くまで理解できるようにしたい。,
C-2021-2_U65,エントロピーの計算,"相互情報量からが難しかった。
復習してわかった。例がとても分かりやすい","確率ｐの事象の生起を知る＝あいまいさが-log₂ｐ減る
（めったに起きないことを知った方が情報量を多く得られる）←意外だった

情報量の期待値＝エントロピー
エントロピーの値はｐ＝１/２の時に最大となる

確率変数X,Yの相互情報量
I（X,Y）＝H（X)-H(X|Y)　　←無関係だと０",,特にありません
C-2021-2_U66,得られる情報量の大きさを具体的な数字で表すことができるようになった。期待値は高校のころにやっていたのと同じ感覚だったので理解できた。相互情報量の求め方と、それが意味するところが分かった。,いまだに人に教えられるほどlog2の理解ができていない。,情報量＝曖昧の減少というのを数式を用いて表す。相互情報量の意味とその定義。,めったに起きない事象の生起を知ることで得られる情報量が大きいことは言葉にするとよくわかりますが、－log2Pでそれが表せるのが不思議です。Pが小さくなる（確率が小さくなる）と値が大きくなる、つまり得られる情報量が大きくなるというのはわかりますが、やはりまだlog2の理解が足りないのかなと思いました。前回の動画でLog2について話しているところを見直して理解ができるようにしたいです。,
C-2021-2_U67,情報を示すとき高校のころには確率としてしか考えていなかったのでlogを用いた示し方があるとは知らなかった。相互情報量の部分以外はしっかりと内容を理解することができた。,,曖昧な情報の量を具体的に示すつまり定量化するとき、曖昧さとエントロピーは一致する。まためったに起きない場合の情報量は大きくなる。そして情報量の期待値を求めるとき、またエントロピーと一致する。この時、二つしかない場合、1/2の時が最大となる。また関連のある四つ程度の情報を示すとき相互情報量というものを示すことができる。,,
C-2021-2_U68,前回出てきたエントロピーという概念が情報量の期待値と一致するというのが分かった。,,確率pの事象が起きたと知って得られる情報量は-log2(p)と表される。これは曖昧さの減少量と等しく、珍しい事象が起きたことを知ればその分得られる情報量は多い(同時に曖昧さの減少量が多い)。,"情報量は-log₂(p)と定義されていたが、これは絶対起こる事象(p=1)が起きることが分かっても何も情報は得られない(-log₂1=0)ということを満たしていて興味深いと感じた。
情報量の期待値の計算は、(情報量)*(確率)の総和であり、平均符号語長と計算方法が似ていてイメージがしやすかった。",
C-2021-2_U69,,,今回の講義の主な内容は情報量についてであった。情報量の中でも情報の曖昧さと情報の期待値について学び、曖昧さと期待値を実際に数値として出す出し方を学んだ。,,
C-2021-2_U7,"情報量も数式で定義できるということ
",Hがわからなかった,"情報量の測り方
　曖昧さを減少することで情報量を獲得することができる
　曖昧さの性質には加法性
　生起確率をPとするとその情報量は-log2 P
　情報量の期待値はエントロピーに一致
　生起確率×（-log2 生起確率）の和
　相互情報量
　",,
C-2021-2_U70,生起確率がわかれば情報量を数式として求めることができ、その大きさを比較することができることがわかった。,エントロピー関数の説明がよくわからなかった。,情報量とは、曖昧さの減少量であり、この曖昧さが小さいほうが大きな情報を得ることができる。そして、生起確率から数式として情報量とその期待値を計算することができる。,今回の授業では自分の手で計算することが多く、今までの授業よりもより集中して取り組むことができた。,
C-2021-2_U71,今日の講義では、情報の曖昧さの定量化と情報の期待値の学習をしました。情報の曖昧さは新たな情報を得ていくことによって減少しその量はlogを使って定義することが出来る。また期待値は確立を用いて表すことが出来る。,今日の講義ではU(M)=log(2)Mの導出の式が理解できなかったので自分の手を動かして理解しようと思います。,情報の量を測るというテーマで、情報の曖昧さと情報の期待値について学びます。情報の曖昧さはlogを使って定量化することが可能で、期待値は確立とlogを使って表現することが可能であり、これはエントロピーに一致する。相互情報についても勉強した。,今日の授業は今までの中で一番数学チックだったので難しかったです。予習復習をしっかりしていきたいと思います。,
C-2021-2_U72,エントロピーの実態が掴めたことがスッキリした。,特にありません,「曖昧さ」という概念が追加された。これは例えば１からM（Mは２以上の自然数）までのN個の数字の中から１つ選んだ時、それが何であるかを知るための情報が欠落する、つまり選択肢が多くなるほど値が大きくなると定義されるものである。曖昧さをMについての関数とみなすと、この関数は単調増加であり、U(MN)=U(M)+U(N)を満たす関数である。このことから、U(M)=log2(M)が導かれる。任意の無記憶定常情報源Sの曖昧さS(M)はSのエントロピーと一致する。1からMまであった選択肢が１からM’まで減る、つまり確率M'/Mの事象が生起すると、M'/M=pとして曖昧さの減少は-log2(p)と表される。とすると確率pの事象が生起した時に得られる情報の期待値もまたSのエントロピーと一致する。これすなわちエントロピーの正体は、ある情報を得た際の期待値であるとも表せることが示された。相互情報量という概念も用意した。これは条件付き確率を利用したもので、ある事象の正体を掴んだ時のもう１方の事象の曖昧さがどれだけ減少するかを数値化したものである。,今回の内容はかなり頭に入りやすいものであった。,
C-2021-2_U74,エントロピーを求めたところから期待値を考えられるようになった。,,定理の証明やエントロピーの様々な利用方法,,
C-2021-2_U75,情報における曖昧さという概念がどのようなものなのか分かりました。曖昧さを表す記号や関数は難しそうだと思っていましたが、意味をとらえていって理解することができたのでよかったです。,たくさん計算が出てきて少しややこしかった部分があったので、実際に演習問題などを解いて自分で計算できるようになりたいと思います。,"情報において、曖昧さが減少すると得られる情報量は増加する。曖昧さはU(M)で表し、U(2)＝１と仮定するとU(M)＝log₂Mを得る。ある情報源Sの曖昧さU(S)はSのエントロピーに一致する。
生起確率ｐの事象の生起を知ることで得られる情報量を曖昧さの減少量ーlog₂ｐと定められる。
また、ある事象の生起を教えてもらうとき得られる情報の期待値はエントロピーに一致する。
ある確率変数Ｘ、Ｙの相互情報量I(X,Y)は、ＸのエントロピーとＹのもとでXの条件付きエントロピーを用いてI(X,Y)=H(X)-H(X/Y)と表される。
",計算が難しそうなものが多いと感じたので次の授業までに計算に慣れておけるように練習をしておきたいです。,
C-2021-2_U76,今日の内容で曖昧さの減少から与えられる情報量をログを使って求めることができた。,エントロピー関数の用い方と相互情報量の計算がとても難しかった。,"ある事象に対して、質問への回答を得ることにより曖昧さが減少し、これは得られた情報の量に等しい。曖昧さの量をU(M)とするとMに関して単調増加であり、加法性が成り立つことからU(M)=log2(M)が成り立つ。また一般の情報源U(S)の曖昧さはSのエントロピーに一致する。確定変数X Yの相互情報量はI(X,Y)=H(X)-H(X|Y)で定められ、I(X,Y)=0の時XとYは互いに影響を与えない無関係なものとして扱われる。",今日は、前の授業と比べて、計算の内容が多くなっているのでしっかりと復習をして定着させていきたい。また「〇〇を聞くことでわかる情報量」というように実体がないものを予想してもとめる計算がとても面白く感じた。,
C-2021-2_U78,あいまいさの量を定量化できることや、曖昧の減少は得られた情報量と一致することを学んだ。,曖昧の量や期待値の計算はなぜそうなるのかを知ることができなかった。,あいまいさの量について学んだ。また、曖昧さの性質や、情報量の期待値を知った。,あいまいさが定量化できることを知って驚いた。,
C-2021-2_U79,情報量とは曖昧さの減少を意味していて、稀な事象ほど、その事象の生起を知ることで得られる情報量が大きいということ。,,情報の「量」を測るというテーマの下で、情報源の曖昧さを定量化する方法を学んだり、情報量の期待値を導出したりをした。,,
C-2021-2_U8,平均符号語長の下限であるエントロピーと情報源のあいまいさは等しく、可視化ができるということが分かった。同時確率と条件付確率の考え方を思い出すことができた。情報量の簡単な計算はできるようになった。,相互情報量の計算がよくわからなかった。また、情報の量が複数になった際の情報量の計算で少し手間取った。,"情報の量を測るにあたり、あいまいさの減少が得られた情報の量に等しくなる。曖昧さの量はU(M)であらわされる。曖昧さU(M)はＭに関して単調増加し、加法性を持つという性質を持っている。情報源Ｓの曖昧さＵ(Ｓ)は連続関数であるという仮定の下でＳのエントロピーに一致し、U(S)＝log₂Mで与えられる。よって確率ｐの事象の生起を知ったことによるあいまいさの減少は－log₂ｐとなる。すなわち、めったに起きない事象の生起を知ることで得られる情報量は大きい。事象Ａ₁ ,~,Ａⅿの生起確率がそれぞれｐ₁,~,ｐｍのとき得られる情報の期待値はｐ₁（-log₂ｐ₁）+~+ｐｍ(-log₂ｐｍ)となり、これはエントロピーと一致する。また、エントロピー関数ではp=1/2の時に最大となる。ある二つの事象の関係性を加味したものを相互情報量という。確率には同時確率と条件付確率がある。確率変数X,Yの相互情報量をI(X,Y)＝H(X)-H(X｜Y)であらわす。この時XとYが入れ替わっても答えは同じ、XとYが無関係の時I(X,Y)＝０という性質がある。",今回の授業では計算を必要とする場面が多くあり、数学の知識も大いに必要であると感じた。高校時代に勉強した内容も多く必要となるのでこれを機にしっかり復習しよう思った。,相互情報量の計算で使用する確率は条件付確率でないといけないのですか。
C-2021-2_U80,曖昧さが減少するという考え方を身につけることができたと思います。また、得られる情報量の期待値とエントロピーの関係についても知ることができました。,相互情報量についての理解が少し怪しいです。,情報の量と曖昧さの性質や減少についての説明がありました。また、情報量の期待値とエントロピーの関係や相互情報量についての説明もありました。,今日の授業では、曖昧さの減少という概念を知ることができたのが最も印象に残っています。「言われてみれば確かに」という感覚で、このような考え方を利用する学問があるということが興味深いです。,特にありません。
C-2021-2_U81,情報量の計測の方法、具体的な計算、期待値や相互情報量について理解できた。,,情報の「量」について、曖昧さという観点で分析、測ることを学び、それにまつわる定理を学習した。,ますます理系チックに進んでいく。予習に時間をかけたのでスムーズに学習できた。,
C-2021-2_U82,情報量の期待値を理解することができた。,特にありません。,情報の曖昧さや情報量の期待値についての内容だった。,しっかりと授業についていくことができました。,特にありません。
C-2021-2_U83,生起確率とエントロピーの減少の関係がわかった,,エントロピーは情報量、曖昧さの減少,,
C-2021-2_U85,"曖昧さの減少は得られた情報量のことである。曖昧さの量はU(M)で表す。曖昧さU(M)はMに関して単調増加であり、加法性がある。生起確率ｐの事象の生起を知ったことで得られる情報量を、それによる曖昧さの減少量、すなわち－log₂ｐと定める。滅多に起きない事象の生起を知ることで得られる情報量は大きい。
事A₁、…、Amの生起確率が、それぞれp₁、…ｐMであるとする。どの事象が生起したかを教えてもらうとき、得られる情報量の期待値はp₁(－log₂p₁)＋…＋pM(－log₂pM)
となる。これはエントロピーに一致する。



",計算で少し躓いた。,"情報量とは何かや情報量とエントロピーの関係性について学んだ。
また計算を用いた情報量の求め方を学んだ。",久しぶりにlogの計算があったので少し難しかったが、どうにか理解することができた。もっと授業について行けるように頑張りたい。,
C-2021-2_U86,情報量の表し方がわかった。,U(M)=log₂Mの証明が分からなかった。,情報量＝曖昧さの減少であり、生起確率ｐの事象の生起を知ることで得られる情報量を－log₂ｐで表す。,数式が多く混乱してしまったので、自分で手を動かして計算をして理解しようと思った。,
C-2021-2_U87,曖昧さ、情報の期待値ともにエントロピーの計算と同じ方法,H(p)の計算の仕方　なぜ教科書では一瞬でできているか分からない,,だんだん難しくなってきた,log₂ｐの値は自分で調べるのですか
C-2021-2_U88,情報量というものの概念の概形をとらえることができた。情報量を求める手法を学び、実践することができた。,情報量というものがどのようなものかは何となくわかったが、想像しにくくなれるのに時間がかかりそうである。,主に情報量についてを中心に学んだ。特に情報量がどういった定義か、そしてどのように求めるかが重要だった。,日常生活でコンピューターに触れていく中でも今回やった内容のように、いかに効率よく情報を得るかどうかという視点で最適化された挙動があることに気が付いた。計算ミスをかなりするので見直しをしっかりしたい。,
C-2021-2_U89,なぜエントロピーを計算するときに、底２のlogを使うのか理由が分かった。,相互情報量の部分が少し煩雑で、時間をかけて勉強しないと分からない内容だった。,曖昧さの減少＝得られた情報の量。確率1/Mのときの曖昧さの量をU(M)と定義すると、U(M)はMに関して単調増加で、加法性U(MN)=U(M)+U(N)が成り立つ。これらの性質と、U(2)=1としたときに、U(M)=log2Mが得られる。エントロピー＝得られる情報の期待値。確率Pの事象の生起を知ったことによる、曖昧さの減少は-log2P。,今日の授業は全体的に難しい内容だったが、自分なりに納得できた。相互情報量の部分は、授業の時は分からなかったが、あとで勉強して理解できた。,
C-2021-2_U9,,,,難しかったです。途中で混乱してしまった部分も多かったので、定期的に復習しようと思います。,特にありません。
C-2021-2_U92,"エントロピーや条件付きエントロピーは高校までに習った確率の考え方、期待値の考え方を応用して求められる。
曖昧さを数式で表す際の証明",,,予習段階ではよくわからないものも多かったが、授業を聞き、数式の証明では実際に手を動かすことで理解度が深まったように思われる。,
C-2021-2_U93,曖昧さの減少を式で表す方法が分かった。,,様々な確率的事象に関して、試行の結果を知ることにより生じる曖昧さの減少を数式を使って表す方法を学んだ。,,
C-2021-2_U94,あいまいさの性質を知ることのにより情報量を求めれるようになりました。さらに期待値をもとめたり相互関係も把握できるようになりました,logの計算のところは聞いているだけでは完全に腑に落ちなかったので実際に手を動かしてみたいと思いました,,聞いているだけではなんとなくしか分からないうえに分かった気になってしまうような分野なので実際に演習問題を解き解決したいと思います,
C-2021-2_U96,情報量の期待値について理解することができた。エントロピーについても、ようやく理解することができた。,相互情報量について。うまく理解できなかった。,,だんだん内容のレベルが上がっているように感じられるが、しっかり聞いて理解していきたい。,
C-2021-2_U97,,,・エントロピーについて・情報量の期待値について,,
C-2021-2_U98,情報量の理解と計算方法の仕組みの理解,,曖昧さを定量的に評価できる情報量とい概念を学びその計算方法について勉強した,相互情報量の理解が少し手こずったが復習して理解する,
C-2021-2_U99,情報量を数値化し、比較する方法が分かった。エントロピーが何なのかが先週はよくわからなかったが、今回の説明でよくわかった。,後半の相互情報量について、あまりよくわからなかった。,,数字が多くなってきて理解するのがむずしくなってきたので、もう少し気を引き締めて授業を受けていこうと思った。,
C-2022-1_U10,,符号語は離れている方がいいことはわかったが、スライドのイラストにおいて「３以上離れるとき」などがイメージではすぐには理解できなかったのでもう一回復習します。,,,
C-2022-1_U11,,,ビット列を伝送する際にノイズによりビットの反転が起きる。この反転が起きたとしても正しくビット列を受信できるように符号化を工夫する。自動誤り検出や訂正のためには、ビット列のブロックを冗長化する。自動誤り検出や訂正が可能かどうかの判断に用いるのがハミング距離であり、高々s個の誤りを自動検出するためにはs＋１以上符号語が離れていなければならず、高々t個の誤りを自動訂正するためには2t＋1以上符号語が離れていなければならない。,,
C-2022-1_U12,あり地獄の例で富豪か同士の距離と自動検出の不可がわかりました。,47ページの表の2段目3段目が全て2になる理由がわからなかったです。,"誤りがあった時自動で訂正してくれるのには符号同士の距離が関係する。
符号同士の距離を稼いで訂正されるようにしたいが距離を増やすと時間とお金がかかる。そこで通信路符号化定理を用いる。","今日は予習をしていったことで授業の理解度が上がりました。
これからも忘れずにしていきたいと思います。","ハミング距離っていうのはビットの違いの数のことですか？
それでいくと47ページ以降の表がうまくいかなくて困っています。
認識に違いがありましたら教えてください。"
C-2022-1_U13,"たとえノイズによって誤って伝達してしまったとしても一定の条件をクリアしていれば自動で誤りを検出し訂正することが出来ること。
伝達時の誤りを防ぐために冗長化することは有効であるが長くなった分符号化効率が小さくなり、伝達速度が低下してしまうという短所を持っているということ。
ブロック誤り率を数値で求めること。",通信路符号化定理が曖昧なので復習をしっかりしたい,"符号語同士がｓ＋１以上離れているとき多くともｓ個の誤りについて自動検出ができる。
符号語同士が２ｔ＋１以上離れているとき多くともｔ個の誤りについて自動訂正ができる。
符号を冗長化することで伝送する際のブロック誤り率は低くすることが出来る一方で、ある量の情報を送るために多くの符号を必要とするため符号化効率が０に近づいていく。",,
C-2022-1_U14,,ハミング距離が難しかったです。,,ビットの反転を直すためにいろんな方法が考えられていてすごいなと思いました。,
C-2022-1_U15,ブロック誤り率を低減するには様々な方法があり、中でも符号を冗長化する方法は理解しやすかった。,,"通信路を介してビット列を転送する際、電磁波などの影響によりビットの反転が起こるがその確率を反転確率と呼び、ブロックを転送する際の誤り率をブロック誤り率と呼ぶ、これらの対策として通信路を改善したり符号化を工夫することが挙げられるが前者は個人では難しい。後者の一部として自動誤り検出や自動誤り訂正があり、符号語同士がs+1以上離れているならば高々s個の誤りについて自動検出が可能となり、符号語同士が2t+1以上離れているならば高々t個の誤りについて自動訂正が可能となるというものであり、ここでの距離は長さの等しい二つのビット列のビットが異なった個数を指しこれをハミング距離と呼ぶ。また繰り返し符号による誤り訂正の手段もあり、符号化の際１ビットの情報を２k＋１ビットの情報に変換し、転送の際ビットの反転がk個以下のとき多数決で元の正しい情報へと復合するといった方法があり、ブロック誤り率は小さくできるが転送速度は低下してしまう。
",,
C-2022-1_U16,,,,これまで、なんとなく二進数でコンピュータは動いていると漠然としていましたが、これまでの授業と今日の授業を統合して、自分の中でさまざまなことが腑に落ちました。,
C-2022-1_U17,ビットの反転の起こる対策のために誤り検出を行う。自動で誤りを検出できるの場合とできない場合がある。,,誤り検出について,話が複雑になってきたためしっかり復習が必要だと思い、復習できてよかった。,
C-2022-1_U19,正確な情報を伝達するためには符号同士の距離を大きくし、誤り検出・訂正を可能なようにすれば良いが、デメリットとして符号化効率が小さくなり、伝達速度が遅くなってしまう。,通信路によって固有。。通信路同士の違いというのは、各通信路の反転確率の違いのことか。,情報源符号化で生じたある誤りを検出ができるのか、はたまた訂正までできるのかを定理づけて理解する。,通信路符号化定理があることで、最適解の存在が保証されているということが情報技術の発達においては非常に需要な点であると思った。,
C-2022-1_U20,,間違いに気づくために多くの記号を送ることになってしまうのは早く伝わることと両立できなくなりそう,,,
C-2022-1_U21,,,今日は通信路符号化について学びました。誤りを減らすための対策として、通信路を改善して数式のpを小さくすると良いとわかりました。しかしこのやり方だとアンテナをデカくしたりして物理的にも経済的にも難しい場合があるので、符号化の仕方を工夫するといいとわかりました。誤り修正コンピューターができるの本当にすごいと思いました。,,
C-2022-1_U22,反転確率、ブロック誤り率については理解できた。ハミング距離の定義は理解できた。,「高々」という専門用語があまりよくわからなかった。,通信路符号化においてビットが反転することで、送信した情報と受信する情報が変わってしまう。ビット反転そのものを防ぐことは難しいので、ビット反転したとしてもきちんと復号できるようにする工夫が行われる。,かなり内容が難しくなってきた気がした。少しわからない所があったので理解できている人に教えてもらいたい。,自動誤り検出というのは、誤りの可能性があることを検出するのですか、それとも確実に誤りが存在することを検出するのですか。
C-2022-1_U24,,まだ通信路容量のグラフや式について少し理解が足りていないところがあるため、自分でネットで検索してみようと思う。,,,
C-2022-1_U25,データを大きなブロックで送ると平均符号語長がエントロピーに近づく。,通信路符号化定理がわからなかった。,"ビットの反転確率をｐとする。ブロックを伝送する際のブロック誤り率は、ｐ＝1－（1－ｐ）↑ｋとなる。ここでブロックのサイズをｋビットとする。pを小さくするには、送信電力を大きくし信号対雑音電力比を向上する、大型のアンテナを使い受信信号電力を向上する、受信アンプを冷却し受信器内の熱雑音を減少する、より広い周波数帯域を利用するなどがある。
自動誤り検出とは、ビット反転があったことを検出し、再送してもらうことである。
自動誤り訂正とは、自動誤り検出の後ビット反転を訂正することである。
自動誤り検出や自動誤り訂正ができるように、符号語が似ていないように冗長化する。
ハミング距離とは、ビットが異なる長さの等しい2つのビット列のことである。
符号語どうしがｓ＋1以上離れているとき、高々ｓ個の誤りについて自動検出が可能。
符号語どうしが2ｔ＋1以上離れているとき、高々ｔ個の誤りについて自動訂正が可能。
ｎ次繰り返し符号（ｎ＝2ｋ＋1）において各ブロック（ｎビット）におけるビットの反転がｋ個以下のとき、誤り訂正が可能。ｋ＋1個以上のとき、誤り訂正は不可能。",自動検出や自動訂正ができる条件が難しかった。,
C-2022-1_U26,受信した信号を変換する時点で間違えていても修正できること,,"少し間違っても誤り訂正で修正できる
2t＋1文字以上間違ってればたかだかt個の誤りを修正可能
",回を重ねるごとに前の授業のわからなかったことが解決できたりしてだんだん理解しやすくなってきた,
C-2022-1_U27,,,,私たちが日常で出会う機械のノイズとその原因についてわかった。ハミング距離の練習問題も解けて通信路符号化について理解を深めることができた。,
C-2022-1_U28,ノイズへの対策で冗長をつくることなど,ブロック誤り率の計算方法,,,
C-2022-1_U29,,,,　後半部分の理解が追いつかなかったので、通信路符号化定理について調べてみたらなんとなくイメージは掴めた気がします。ちなみに証明はあまりよく分からなかったです。,
C-2022-1_U3,"誤りの検出と訂正を行うにはそれぞれどれだけ符号語同士が離れている必要があるのかがわかり、簡単な数を当てはめて具体的に状況をイメージすることができた。
また、通信路符号化の具体的な手段とその長所、短所がわかった。",高々t個の誤り検出や訂正を考える際、tに１など簡単な数を当てはめると具体例を考えることが出来たが、一般式にすると状況がよくわからなくなった。,情報を伝送する際、ビットの反転によってエラーが起こることがある。通信路符号化では、各ブロックを冗長化し符号語同士が似ないようび設計することで、こうした誤りを自動的に検出したり訂正したりする。同じ符号を繰り返し多数決の要領で誤りを訂正する方法もあるが、もっと効率的に通信路符号化を行うには情報ビットと検査ビットを分けて考え、符号語間のハミング距離をなるべく大きくする。,"　通信路の符号化により誤りの検出や訂正を行なっているということを知り、不自由なく通信機器を使うためには誤りがあった場合の対処法まで考えて様々な工夫を施す必要があるということを実感しました。今後何かのシステムを作る機会があるときはそうした視点を忘れないようにしようと思いました。
　前回の学習日誌で（５）だけ回答しそびれていました。申し訳ございません。書き加えましたので見ていただけると幸いです。",
C-2022-1_U30,,,今日の授業は情報源符号化について学んだ。情報源を伝達するときに、符号化することによって、通信を早くできたり通信間での情報の盗難を防いだりできる。通信路ではノイズの影響により、ビットが反転する。それが起きる確率を反転確率といい、ブロックを伝送する際の誤り率をブロック誤り率という。反転確率と誤り率は比例しない。符号化した情報を復元するときには自動誤り検出、訂正が行われる。誤り検出訂正ができる場合には制限があり、いつでも働くわけではない。一般に、符号語同士がs +１以上離れているときは高々s個の誤りについて自動検出が可能である。また、一般に、符号語同士が２t +１以上離れている時は高々t個の誤りについて自動訂正が可能である。ブロック誤り率と符号化効率ではnを大きくしていくと誤り率は小さくなりメリットとなり、しかし符号化効率は０に近づきデメリットとなる。,情報を正確に伝達させるために自動誤り検出訂正などのさまざまなシステムを使っていることを初めて知った。また、そういう機能があるのでどんなに優れた機械とかでもミスは０にはできないんだなと思った。ミスや不具合を想定してブロック誤り率を減らす工夫をしたり、自動誤り検出訂正について一般項や条件を見つけるようなことはとても大事な仕組みであると思うし、情報源符号化による情報伝達の場面だけでなく、普段の生活でもそういうことを考えて工夫しながら効率的に勉強とかもやっていきたいと思います。,
C-2022-1_U31,,通信路符号化定理と通信路容量があまり理解できなかった。　　,,,
C-2022-1_U32,,,,今日習った通信路符号化は九州大学の学生IDに通じているのかなと思いながら、日常のことと関連したことを学べたのでよかった,
C-2022-1_U33,さまざまな誤り検出、訂正の方法があることがわかりました,,通信路符号化と誤り検出について,,
C-2022-1_U34,,,,蟻地獄や受付嬢の話はとても分かりやすかった。テストはリンクを見つけられなかったこともあり、かなり焦ってしまった。次からは前回の内容を余裕をもって見直しておき、短時間でも回答できるようにしておきたいと思った。,
C-2022-1_U35,,今日習った定義の理解が曖昧なので理解できるように復習したい。,,,
C-2022-1_U37,誤り検出、訂正するためには、符号語を離すことが大切だと分かった。,,,,
C-2022-1_U39,,,"情報を送るときに、ノイズが発生してしまうが、それではもとの情報が書き換えられてしまう（ビット列を通信路を通して送るとき、ノイズの影響でビットの反転が起きてしまう→まったく違う情報が送られてしまうよね！！）。そこで通信路符号化のところでそこを対策する。（通信路…情報を通す道）ビット反転が起こる確率をpとすると、ブロック（情報のかたまり）を伝送するときの間違える確率は、ｐB=1-(1-p)＾ｋ（ブロックの大きさｋビット）（すべてのブロックが正しく遅れる確率以外の確率、１－ｐは正しくすべてのブロックを送れた確率だね！）となる。反転確率は、１ビットだと小さくても、１０００ビットだと反転確率はかなり大きくなってしまう。→もっと確率を小さくしなくては。→符号化の仕方を工夫してノイズに負けたとしても正しく受信できるようにする。→ビット列をブロックに分割して各ブロックを符号語同士が互いに一定以上違っているように冗長化、少しぐらいなら間違っても大丈夫にする。（自動誤り検出…ビット反転があったことを検出して再送してもらう／自動誤り訂正…自動誤り検出の後、ビット反転を訂正する）（ハミング距離…長さの等しいビット列の同じ位置のビットが違うものの個数のこと）〈多くてもｓ個の誤り検出については、符号語同士がｓ＋１以上離れていれば自動検出が可能である（誤り検出できる場合っていうのはそもそもかぶってない状態であるから、2個以上違うものがあれば、符号語１か２のどっちかであるという、せいぜい誤り検出ができる）。〉〈多くてもｔ個の誤り訂正については、符号語同士が２ｔ＋１以上離れていれば自動訂正が可能である（訂正については誤ったやつがどの符号に当てはまるか一意に決まらなくちゃ自動訂正できないよね！！）。〉たとえば送りたい符号が、〇〇〇と●●●だとすると（ハミング距離３）、間違えたっていう符号が、各〇〇〇、●●●からハミング距離が１以下の場合は誤り訂正が可能である（守備範囲がかぶらないから）。しかしｎ次繰り返し符号は、ｎを大きくすればいくらでもブロック誤り率を小さくできるけど、符号化効率はｎをおおきくすればするほど０に近づくから、伝送速度が低下するし電力消費するし、あんまり効率的ではない。→通信路符号化定理というものがある！！繰り返すんじゃなくて、もっと効率がいい方法がある！→各ブロックに必要なだけ検査ビットを追加して離れさせる。
",山田鈴木の話が分かりやすかった。,
C-2022-1_U42,"・通信路の途中、ノイズで０→１（逆も然り）のように反転してしまうことがある。送電電力を大きくし大きくしたり、大型のアンテナを使ったり、受信アンプを冷却したりする手があるが、携帯などでは厳しい。そこで符号化を工夫する。
・自動誤り検出とは反転があったことを検出し、再送してもらうようにする機能。s +１以上のハミング距離があれば多くてもs個の誤りを検出できる。また、自動誤り訂正とは自動誤り検出の後に訂正をする機能。２s +１以上のハミング距離があれば多くてもs個の誤りを訂正できる。
・例えば１ビットを３ビットにして送ったりするということのように、ビット数を増やすことを繰り返し符号という。こうすることで誤り率が小さくなるが、ビット数が大きくなってしまうというデメリットがある。",,"・通信路符号化とは
・自動誤り検出、訂正とは
・繰り返し符号とは",大学に入ってこの情報科学を受けるまでは、ただ情報を送っているだけだと思っていたのですが、その道中に自動誤り検出、訂正があったことを知りませんでした。さらに今回の授業で自動誤り検出、訂正の仕組みを習い、奥が深くとても興味が湧きました。送信電力の大きさや受信アンプの冷却など携帯では難しいと思われていたノイズ対策ですが、繰り返し符号を使うことによって可能になったことに情報の世界の発想力の凄さに感動しました。,僕は冗長化するということをハミング距離をつけるようにするためのものと思っているんですが、この考えであっていますか。
C-2022-1_U43,,ところどころ数式の意味が分からなかった。,,,
C-2022-1_U44,,,情報を的確に伝えるための工夫を学んだ。,,
C-2022-1_U45,,とくにありません。,,,符号化効率は値が大きい方がいいのですか。
C-2022-1_U46,自動誤り検出や自動誤り訂正について分かりました。,通信路符号化定理が難しかったので、たくさん復習しようと思いました。,"・自動誤り検出...ビット反転があったことを検出し、再送してもらう
　→符号同士がs+1以上離れている（ハミング距離がs+1以上）なら、高々s個の誤りについて自動誤り検出が可能
・自動誤り訂正...自動誤り検出のあと、ビット反転を訂正する
　→符号同士が2t+1以上離れている（ハミング距離が2t+1以上）なら、高々t個の誤りについて自動誤り訂正が可能",次回は時間に余裕を持って参加できるようにがんばります。,特にありません
C-2022-1_U47,,繰り返し符号による誤り訂正のところがよくわかりませんでした。,,小テストで間違った問題があったのでしっかり復習したい。,
C-2022-1_U48,誤り検出や誤り訂正をしやすくするためにどのように符号の並びや数を工夫すれば良いかがわかった。,ミドルネームを導入するという例がいまいちピンと来なかった。,,前回に引き続き何かをしやすくするために符号の並びを工夫するのだと分かった。誤り検出や誤り訂正が便利なのはよく分かったが実際の身近なところでどこに使われているのだろうかと思った。,
C-2022-1_U49,情報をできるだけ誤りのないように送るためには単に符号を長くするのではなく利用者のことまで考えて検査ビットを使うといったような工夫がなされているということ。,ありません,通信路を利用し情報を送るとき、符号同士のハミング距離が離れている、つまり符号が異なっているほうが誤りの訂正や検出が可能となる。そのため符号に余分なものを付け加えるという作業を行う(冗長化)。符号を長くすると誤りは減るがデータが大きくなり伝送速度が低下する。また情報ビットに対し検査ビットを加えることで伝送速度をあまり低下させずにブロック誤り率を下げることができる。,蟻地獄の例がわかりやすかったです。,ありません
C-2022-1_U5,,ブロック誤り率の訂正後の式がなぜそうなるのかがよく理解できなかった。,,段々話が難しくなってきたなと感じた。蟻地獄の例えが分かりやすくてなんとか理解することができた。,
C-2022-1_U51,反転する確率がたとえ0．001％ほどしかなかったとしても、誤りの発生する確率が0．001％な訳ではなくもっと大きな確率で誤りは発生する。,何度やってもうまく送信ができないときに、どうやってその原因を調べるのか。,通信するときには何らかの事情によって信号が反転することがある。,自動で誤りを検出できる機能はとてもすごいと思った。,
C-2022-1_U52,上のことを理解しました,,,このまま頑張りたいです,
C-2022-1_U53,,,,ノイズなどによる誤りへの対策が綿密になされているということに感心した。,
C-2022-1_U54,誤った情報の検出や訂正も、内容によって行うことの難易度が違うことがわかった。送る符号のハミング距離によって、高々いくつの誤りを検出することができるのかがわかった。誤り検出の守備範囲が被らなければ誤りの訂正が可能であることがわかった。その訂正を効かせるためにも、たとえば社員名簿であったらミドルネームをつけるなどの工夫を行う必要がある。,,,予習の範囲を間違えてしまい、予習が不十分だったので、授業を理解するのがいつもより難しかった。次からは範囲を間違えないようにする。,
C-2022-1_U56,蟻地獄の例によって誤り検出、訂正の定理の理解ができた。,,符号化する段階においてビットの反転等誤った情報が送られることも多く、通信路を改善して反転確率を小さくするための工夫がなされている。ある一定距離以上符号が離れている場合自動誤り検出と自動誤り訂正が発動する。符号化効率の上限が通信路容量として数式、グラフによって表せる。,数式が多くてわかりずらかったが実際に計算をして理解をすることができてよかった。,
C-2022-1_U58,通信の際にはビットの反転が起き情報に誤りが生じることがある。そのため、通信路を改善したり符号化を工夫したりする必要がある。,,"通信路符号化の際は通信路を改善することで、ビットの反転確率を低下し、ブロック誤り率を下げることができる。また、通信路の改善が難しい場合は、符号化を工夫することで低下させることができる。
自動誤り検出と自動誤り訂正がある。符号語同士がs+1個以上離れていれば高々sこの誤りを自動検出することが可能である。また、符号語同士が2t+1以上離れていれば高々t個の誤りを自動訂正することが可能である。
n次繰り返し符号はnを大きくすればブロック誤り率をいくらでも小さくすることが可能であるが符号化効率も低くなっていくため、伝達速度が低下してしまう。通信路容量は通信路に固有の値で符号化効率の上限であり、計算で求めることが可能である。",,
C-2022-1_U59,ハミング距離　1ビット→3ビットに長くする理由が、ミドルネームの考え方で分かった,後半部分の通信容量,,,
C-2022-1_U6,誤り率を計算式でも求められると知った。通信路符号化ではまず各ブロックに分け、冗長化することがポイントだと知った。また、符号化効率とブロック誤り率のバランスも大切だとわかった。,小テストで二進法の計算を誤ってしまった。今度からは紙に書いてちゃんと解こうと思う。,情報源符号化器と情報源復号器の間にはノイズが発生するため、ビットの反転を防ぐのに符号化を工夫する手段として通信路符号化がある。ビットの反転率、反転確率が小さくてもブロックのサイズが大きければ、ブロック誤り率は大きくなってしまう。そこで、物理的に冷やしたり電力を大きくするのも一つの手段だが、これらが難しいときかくブロックを冗長化するという手段をとる。符号語同士がｓ＋1以上離れているとき、たかだかs個の誤りについて自動検出可能であり、2t＋1以上離れていれば高々ｔこの誤りについて自動訂正可能である。また、多数決符号というやり方もあるがブロック誤り率が小さくても、データ量が大きくなり符号化効率が悪い、つまり伝達速度が遅くなってしまう。この対策としてはハミング距離を大きくすることがあげられる。,,
C-2022-1_U60,山田太一の例えが分かりやすすぎた。また何度か繰り返すことでこの符号を誤ったのだろうと導けることがわかった。,符号化の工夫によって、ブロック謝り率を下げるということは必ずしも平均符号語長が長が最短をとることでは無いのかなと思ったら、冗長と出てきてうぉってなった。,誤り訂正とハミング距離。,,BRmapの期限を忘れてしまいました。
C-2022-1_U61,通信路を介してビット列を伝送する際、ノイズの影響により、ビットの反転が起きる。通信路を改善したり、符号化を工夫したりして、対策する。,,通信路という概念の導入,数字が多くなってきて集中力切れてしまった,
C-2022-1_U62,,,,ビットの反転が起こる確率は小さいけどブロックで見ると反転が起こる確率は大きくなることが分かったので、誤り訂正は必要だと思った,
C-2022-1_U63,"符号語同士がs+1離れていれば、s個の誤りを自動検出できて、2t+1離れていれば、t個の誤りを自動訂正できる。
自動で検出するだけでなく、訂正するほうが距離が必要。",,,,
C-2022-1_U64,"情報を送るとビット反転がおきる
それを改善するために通信路符号化・誤り検出",,情報の誤りとそれの改善,,
C-2022-1_U65,,"3次繰り返し符号によるブロック誤り率の式を理解することが難しかった。
一回説明を聞いてもわからなかったので、後でもう一度調べ直してみようと思う。
","通信路符号化について
白丸と黒丸で情報を送るとき、ノイズの影響によりビットの反転が起こる。今回の授業では、その誤りをどうしたら検出でき、訂正できるかを中心に学んだ。
そのビットが反転する確率（反転確率）をｐ（0＜ｐ＜0.5）とおくと、ブロック誤り率は　1-（1-p）^k　と求められる。
ただし、ｐの値が小さくても、ブロックサイズが大きいと、ブロック誤り率は大きくなるので注意。
符号化する際、まずビットをブロックに分割し、各ブロックを冗長化する。各ブロックごとのビット列を符号語という。この符号語同士が互いに似ていないように設計する。なぜかというと、似ていないという設定にすると、いざ反転が起こった時に自動で誤りを訂正することができるからである。
ここから、誤り検出、訂正ができる場合について検討すると、「ハミング距離」という言葉がキーワードになる。ハミング距離というのは、端的に言うと長さの等しい二つのビット列に対し、違うところがいくつあるかというものである。また、誤り検出よりも誤り訂正の方がハミング距離は大きくなる。例えば、符号語同士が2以上離れている時、高々1個の誤りについて自動検出が可能であるのに対し、自動訂正の場合、3以上離れているとき高々1個の誤りのみになる。
また、繰り返し記号による誤り訂正もある。例えば、一つのビットを三倍し、符号語同士のハミング距離を3にする。このとき、ブロックにおける反転が高々1ビットであるとき誤り訂正が可能になる。こうすることによってブロック誤り率を小さくすることができるが、ビット数が3倍になるため符号化効率は小さくなる。
まとめると、ハミング距離の最小値を大きくするほど多くの誤り訂正が可能になるが、冗長のビットを付加することによって符号化効率は落ちて伝達速度は低下することになる。
","パソコンではなく紙にまとめながら説明を聞くことによって、前回よりも講義をスムーズに理解することができた。
また、講義が終わった後に見返して内容を振り返ることができたので、わかるところとわからないところを明確化して、次回の講義までに友達に聞くか調べるなどして理解を深めておこうと思う。",
C-2022-1_U66,"ビット列における誤りの数をハミング距離といい、三次繰り返し符号において各符号語の守備範囲をハミング距離1以下にすることで高々1ビットの誤り訂正ができる。
通信路容量は通信路に固有の値で符号化効率の上限である。
通信路符号化定理により、ブロック誤り率をいくらでも小さくできるうえに、符号化効率も通信路容量に近づけれる。",受信した側は受け取ったビット列が正しいかどうかなんてわからないのに、どうして自動で誤りを検出できるのか不思議に感じた。社員名簿の例だと受信側に似た情報が存在しているから誤りを検出劇るかもしれないが、写真などの情報を一方的に送信する場合は受け取る側に検証の余地はないのではと思った。,,ブロックを冗長化したり、繰り返し符号を使うなど、様々な方法で誤りの検出や訂正ができるとしれてよかった。,
C-2022-1_U67,"情報を送るときには符号の反転もおこっているが、送る途中に訂正されていたことがわかった。
",誤り率の計算式のうち、訂正後の式の意味や成り立ちがよくわかりませんでした。,通信路符号化をすることでいかに正確にノイズに負けることなく情報を送れるようにするのかについて。,"アルファベットがたくさん出てきて、どのアルファベットが何の意味を示すのかまだ慣れていなくて、ひとつひとつ確認しながらだったので、内容を理解するのに少し苦労しました。
早く演習問題などを通して慣れていきたいと思いました。",とくにありません。
C-2022-1_U68,ブロック誤り率を減らすために、ブロックを冗長化することで少しの間違いなら訂正できるが、ただただブロックを長くすればいいという問題ではないということがわかった。,,,,
C-2022-1_U69,どのような符号語にすれば自動誤り訂正ができるのか、またハミング距離とはなんなのかがわかった。,誤り訂正が可能と誤り検出が可能の違いがよくわかりませんでした。,通信路を介してデータを伝送する際、ビットが反転し誤ったブロックを送ってしまうことがある。それを防ぐためにデータを符号化するときに各ブロックを助長化し、複合化するときに自動誤り訂正ができるようにすると良いが、それにより通信速度が低下し過ぎないために通信路符号化定理を利用することが望ましい。,,
C-2022-1_U7,情報を送るときの長所短所を理解できました。,高々〇個の誤り検出・訂正のところがまだ少し曖昧です。,ビット反転は情報を伝送するときのノイズなどによっておこる。反転確率を下げるために符号化を工夫する。ハミング距離に基づいて誤りを検出できるか訂正できるかが決まる。三次繰り返し符号では長所もあるが、伝達速度が低下してしまう短所がある。よって、メッセージをロックに分割し、各ブロックに検査ビットを付加して符号化効率が低下しないようにする。,,
C-2022-1_U70,,"高々何個の誤りを検出できるかの問題が難しかった。自動検出と自動訂正の区別が難しかったが、授業の後半の方で理解することができた。
",,,
C-2022-1_U71,,ハミング距離が大きいと、送る事が可能なデータがすくなるのではないか。,,,
C-2022-1_U72,誤り訂正の基本的な考え方を理解することができた。,,,,
C-2022-1_U73,,誤り検出（２１ページ以降）、高々t個の誤り訂正がわからない。蟻地獄もよくわからない。,,"ハミング距離の定義自体は理解できているつもりでも、その後のスライドでの実際の使われ方や蟻地獄で考えているのは理解できなかった。
だんだんついていけなくなるのが怖いので調べたりしてきちんと理解したい。",
C-2022-1_U74,"符号が三文字以上違えば即座に誤りが検出、訂正できる。一文字違いがあると厳しい。
ハミング距離",,誤りの検出について　自動検出、検出が不可能なもの,,
C-2022-1_U75,自動検出と自動訂正の違いについてわかりました。どういう場合にどちらが可能なのか理解できました。,3次繰り返し符号あたりから難しかったです。計算が複雑でした。,通信路符号化ではビットが反転することがあるので、通信路や符号化を工夫しなければならない。自動誤り検出と自動誤り訂正があり、それぞれできる場合が限定される。2つのビット列に対し、ハミング距離が定義される。,だんだん難しくなってきて予習復習が必要になってくると思いました。予習が追いついていないところがあるので、しっかり頑張りたいです。,
C-2022-1_U76,ブロック誤り率の計算を理解できた。なぜ誤り検出ができ、どんな場合に誤り検出ができないかわかった。,,,"具体例のふたつがわかりやすかった。
",
C-2022-1_U77,,,,,特にありません
C-2022-1_U78,誤り検出・訂正ができる条件がわかった。,ブロック誤り率の式の意味がよくわからなかった。,,理解できた。,
C-2022-1_U79,,式を覚えただけで、ブロック誤り率のところががよく分からなかった。,,なかなか一回ではピンと来なかったが、何度かbookrollを読んで少し理解できたかな、と思う。図を使った考え方が分かりやすくて助かった。,
C-2022-1_U8,予習段階ではハミング距離がいまいちよく分かっていなかったが、符号の異なる組み合わせ数という説明を聞いたときに、自動検出・訂正の範囲を理解することが出来た。,"ブロック誤り率の訂正後の計算が少しわからなかった。
高校の教科書を使って、再度復習したい。",,予習段階では、冗長化を行う意味がよく分かっていなかったが、今回の講義を通して、それをすることによって、検出・訂正が容易になる一方で、効率の問題もあるということを知り、難しいなと思った。,ありません。
C-2022-1_U80,,,,楽しかった。,
C-2022-1_U81,,エントロピーの計算や尻尾の問題,曖昧さ、エントロピー,難しかった,
C-2022-1_U82,,,,今日の講義では、情報源符号化に引き続き、通信路符号化について学んだ。理解が難しく、慣れないところもいくつかあったが、具体的な例を示してくださったので分かりやすかった。私たちの元に正確な情報が届くためには、やはり様々な過程が必要なのだということがわかったし、その仕組みを学ぶことが段々と面白くなってきた。,
C-2022-1_U83,情報が変わってしまった際の訂正方法や情報変更をなるべく減らす伝達方法,間違いを発見訂正できるかの基準が全くわからなかった。,データの重なり具合によって間違いを発見・訂正できるか変わってくる　データは何個かの粒が集まったブロック単位で送られている　間違いを防ぐために個数を多くして送っている,"予習が不十分だったのでわからなかったと思ったと思うので次回はもっと予習を入念に行いたいと思う。
",
C-2022-1_U84,,"通信路容量の定義。それがわかることで、他のものにどのように影響を与えるのかがわからなかった。
ハミング距離が離れていると誤りの検出が簡易になる理由がわからないです。",今日の内容は、誤りがどのように起きるかと、どのように訂正するのか、されるようになってるのかを学んだ。繰り返し符合による誤り訂正がかなり有効であるように思える。,,
C-2022-1_U85,ブロック誤り率は余事象を使うとでき、送信電力を大きくしたり、大型アンテナを使用したり、受信アンプを冷却したりして改善ができる。１字違いが１つなら誤り訂正ができるが、２字以上の違いや２つ以上の候補があると誤り検出すらできない。,どうしてミドルネームを導入したら自動検出、訂正が可能なのか,,小テストで計算ミスをしてしまったため次回からはもう1度計算して間違いをなくしたい。情報科学が学問らしくなってきてさらに深めたいと思った。,
C-2022-1_U86,ハミング距離を条件以上にすることにより誤りの自動検出を可能にする,P３７以降の内容がいまいち理解できなかった,通信路符号化について,今なおよいよい通信の方法を模索しているのだなと思った,
C-2022-1_U87,通信の符号を送るときにビットの反転が起きることがあり、その際には誤り検出し、またその場にあった検出が必要である,ハミング距離の意味がわかりませんでした。,符号の過ちを検出するときには、名前の例えにあったようにミドルネームを入れるなどして、それぞれの差を大きくすれば簡単に検出できるとこを学んだ。,,
C-2022-1_U88,"通信路符号化、反転率、ブロック誤り率、自動誤り検出、自動誤り訂正、ハミング距離、符号化効率などの用語を理解した。
ノイズに通信路符号化の基本を理解した。
",,,,
C-2022-1_U89,,通信路符号化定理の演算が授業中にはあまり早く解けませんでした。また、ハミング距離などで途中で頭の中が混乱しかけそうな箇所があり、計算系をもっと頑張って理解しようとすべきだと思いました。授業後にスライドを繰り返し見ていたらだんだん頭の中にしっくり入ってくるようになったので、予習と復習をしっかりツ続けようと思いました。また、高校数学の教科書も見返して復習しようと思います。,,,
C-2022-1_U9,"符号同士がs+1以上離れていると高々s個の誤りを検出できる。
符号同士が2t+1以上離れているなら高々t個の誤りを自動訂正できる。
",ハミング距離について,符号の誤りを検出できる範囲について,誤りを自動訂正するために自分から符号を増やすことが、一瞬不思議だなと思った。,
C-2022-1_U90,まずエントロピーを理解しなければならない。,,,途中でトイレに行ってから理解できなくなった。後で復習します。,
C-2022-1_U91,社員の名前の例えで自動訂正について分かった,,少しのミスならば自動訂正可能,今後理解を深めていきたい,上の（３）の内容
C-2022-1_U92,エントロピーの考え方が分かった,,猫とご機嫌と尻尾の関係では表に表すことでなんらかの関係性が理解できるようになっていた,前回と同様です,
C-2022-1_U93,誤りの訂正について理解することができた。,通信符号化定理があんまりよくわかってない,符号語の形を工夫しお互いに区別しやすくすることで、間違いを減らすことができる。,最初見るスライドを間違えていた。,
C-2022-1_U94,反転確率から、ブッロク誤り率をもとめれるようになった。,,情報を送るにあたって、ノイズによって反転が起こることがある。その確率を反転確立という。ブロック誤り率を下げるには、反転確率を小さくする必要がある。また、自動誤り検出や自動誤り訂正もまなんだ。,,
C-2022-1_U96,"演習問題１、、、、できた！
演習問題２、ハミング距離が４の時、高々３個の誤り検出
　　　　　　　　　　　　　　　　　高々１個の誤り訂正
　　　　　　ハミング距離が５の時、高々４個の誤り検出　　　　
　　　　　　　　　　　　　　　　　高々２個の誤り訂正",通信容量がわからなかった。,前回の授業で習った情報源符号化機と情報源複号機の後よ前につけられる通信路符号化機と通信路復号機について学んだ。通信路を通って人列が送信されるときノイズの影響によってビットの反転が起きる。ビットの反転確率をpを用いて表す。少しのpでもブロック誤り率はかなり大きなものになる。ノイズ対策のためにハードウェア系を大きくするのにはコストがかかりすぎてしまう。二つ目の対策案としては符号化を工夫することである。これが通信路符号化である。内容としては自動誤り検出と自動誤り訂正である。ビット列が似ないような設定をすることで自動で誤りを検出し、訂正するのだ。xとyのビット列の被っていないビットの個数をハミング距離という。ビット列つまり符号語の間隔によって誤りを検出できるかどうかが決まる。n次繰り返し符号のとき半分以上があやまりだと訂正できない。n次繰り返し符号はnを大きくすることで誤り率は小さくできるが、その分通信速度が低下してしまうことができる。,定義理由について調べたい。,似通っているかどうかをいうときに距離を用いるのはなぜですか。
D-2020_U10,,,,フーリエ級数の復習が必要だと感じた,
D-2020_U13,,,周期信号とフーリエ級数について学んだ,今回から計算式がたくさん出てきたので手を動かしてしっかりと理解できるように努力したい。,
D-2020_U14,フーリエは数学で既習なので今日の内容は復習だった,,フーリエ変換の説明,,
D-2020_U16,何故フーリエ級数で表すか,,,,
D-2020_U18,,複素フーリエ級数がどのようなことに応用できるのか？,,"一見複雑な式でとっつきにくいフーリエ級数が少し身近なものに感じられた。
また、すべての信号が正弦波の足し合わせで表現できると知って驚いた。",
D-2020_U2,フーリエ級数や複素フーリエ級数で表現できるようになった．,特にありません．,任意の信号は周波数の異なる正弦波の足し合わせで表現することができる．正弦波をフーリエ級数表現と正弦波の代わりに複素正弦波を用いる複素フーリエ級数表現がある．複素フーリエ級数だと計算が簡単になるというメリットがある．,,
D-2020_U21,忘れかけていたフーリエ変換を思い出すことができた。,,フーリエ変換の復習,,
D-2020_U22,,,,昨年の数学演習の授業でフーリエ級数は学習していたので問題なく理解ができました。,
D-2020_U23,フーリエ級数の概要の理解,,,短時間でまとまっていて集中しやすく、理解しやすかった,
D-2020_U25,三角関数と複素それぞれでのフーリエ級数での表し方,,周期信号と、それをフーリエ級数という足し合わせで表す方法,,
D-2020_U27,フーリエ変換の公式を、複素フーリエ級数展開の式から導く過程を理解した。また、デルタ関数などの重要な性質を持つ関数について理解した。,,,,
D-2020_U28,,特にありませんでした。,周期信号とフーリエ級数について。,,特にありません。
D-2020_U29,,,フーリエ級数展開、複素フーリエ級数展開、スペクトルについての説明。,やはりフーリエ級数展開は計算が本当に大変。+-の符号が多くでて間違えやすく、怖すぎる。,
D-2020_U3,どんな波形も正弦波と余弦波の重ねあいで表現できることが分かった,,,,
D-2020_U31,,,"周期信号は正弦波の無限級数で表現することができる。
また、オイラーの公式を用いて複素数を用いて表すこともできる。",フーリエ変換は二年で習ったので難しい内容ではなかった。,
D-2020_U32,フーリエ係数・複素フーリエ係数の求め方。スペクトルとは何かが分かった。,,,,
D-2020_U33,フーリエ係数の意味,,,,
D-2020_U34,,,フーリエ級数展開についての概要,フーリエ級数の公式を忘れてしまいそうになるので、証明などをして頭に記憶させたいと思った。,
D-2020_U35,複素フーリエ級数にすると、フーリエ級数の項を減らすことができる,スペクトルの必要性,周期信号は、周期の異なる正弦波の組み合わせで表現できる,,
D-2020_U36,どのような周期関数もフーリエ級数によって表現できること。,フーリエ級数展開の物理的な意味,,内容がやや難解になってきたので、フーリエ級数の復習をしっかり行っておきたい。,
D-2020_U37,,,,演習を解いてみると思いの外時間がかかった,
D-2020_U38,,,すべての周期信号はフーリエ級数で表現出来る,,
D-2020_U39,フーリエ級数によって周期関数を表すことができることが図から分かった。,,周期関数をフーリエ級数を用いて表す。,,
D-2020_U4,,,周期信号のフーリエ級数について,,
D-2020_U40,フーリエ級数の求め方と場合に応じて計算を短縮すること,,周期信号のフーリエ級数変換とその方法,,
D-2020_U41,,,フーリエ級数と、複素フーリエ級数,,
D-2020_U42,周期波形はどんなものであれ正弦波と余弦波を用いて形を表すことができること、また複素数を用いることで式が簡略化されわかりやすくなること,,,,
D-2020_U43,,特にありません。,"周期信号の表し方について。
周期信号は正弦波を無限級数で表現することができる→フーリエ級数表現
これにオイラーの公式を使うと正弦波ではなく複素数で表現できる→複素フーリエ級数
複素フーリエ級数はフーリエ級数よりも簡単な形をとり、計算が容易になる",スライドの予習で理解していたつもりでしたが、先生の説明を聞いてなるほどと思うことが多くあったので、スライドだけでなく自分で調べて理解しておく必要もあるな思いました。,
D-2020_U44,,,フーリエ変換,,
D-2020_U45,フーリエ級数の求め方がわかった,スペクトルを活用する事例,,,
D-2020_U46,信号とフーリエ級数の関係を理解することができた。,,,,
D-2020_U47,フーリエ級数や複素フーリエ級数に関しては既習でしたので良い復習となりました。また、波の合成の様子に関しては動画などでしっかりと予習していたのでイメージをうまくつかむことができた。,スペクトルに関しては、内容や計算方法などの理解はできたがどう用いるかについてまだ理解できていないのでこれを課題とする。,複数の波の重ね合わせでどんな波でも再現できる,,
D-2020_U48,"周期信号が正弦波と余弦波の合成で得られることが分かった. また, その性質を利用した周期信号のフーリエ級数表現と複素フーリエ級数表現について知ることができた.",フーリエ係数の求め方がどうしてその形になるのかが分からなかった.,"周期信号について, 主にフーリエ級数で表現する方法.","一部分からない部分(そんなに重要でもなさそうな部分)もあったが, 大まかな考え方やフーリエ級数の求め方については理解することができたと思う.  ぼけーっとしててスペクトルについてちゃんと聞いていなかったので, 反省したい.",
D-2020_U49,高調波の次数を上げれば上げるほど元の信号の形に近くなる。,,,,
D-2020_U5,"周期信号は正弦波と余弦波の合成で表せ、フーリエ級数で表せる。
さらにオイラーの公式により、複素フーリエ級数で表せる。",,周期信号とフーリエ級数について学んだ。,,
D-2020_U50,どんな周期関数も正弦波と余弦波を合成することで作れる。複素フーリエ級数で表現した方が計算が楽になる。,,周期信号をフーリエ級数(または複素フーリエ級数)で表現できる。フーリエ級数(複素フーリエ級数)の求め方。,,
D-2020_U52,,,信号処理に使われるフーリエ変換、フーリエ級数の基礎について学んだ。,学習済みの内容ではあったが忘れているところもあると思うので、演習問題を解いたり、ノートにまとめるなどして再度確認しようと思った。,
D-2020_U53,,スペクトルについての理解があまりできなかった,,演習をしてみた感じ計算が複雑なので計算をしっかりできるようにしていきたい,
D-2020_U54,信号は正弦波の足し合わせで表現でき、周期信号の場合はフーリエ級数展開で表現できること,,,今までに習った内容なので、復習しつつ理解を深めていきたい,
D-2020_U57,フーリエ級数展開の導出過程がわかった,,"任意の信号は正弦波の足し合わせで表現できる
周期信号をフーリエ級数展開できる
複素フーリエ級数も利用でき、計算はこっちのほうが容易にできる",,
D-2020_U59,,,,以前フーリエ級数を習ったことがあるので理解が難しいところはほとんどなかった,
D-2020_U62,信号は異なる正弦波の和で表現できる。周期信号はフーリエ級数や複素フーリエ級数を用いて表すことができる。スペクトルについて。,,周期信号はフーリエ級数を用いて表現できる。,今日は信号がフーリエ級数を用いて表すことができることを学んだ。これから演習問題などの数をこなして、周期信号のフーリエ変換についてもっと理解を深めていきたい。,
D-2020_U63,どのようにフーリエ級数を求めるか,複素フーリエ級数の計算が上手くいかなかった,,反省点を復習していきたい,
D-2020_U64,信号をフーリエ変換する方法がよく分かった。また、オイラーの公式を用いて、複素数の形にすると、計算が簡単になることがわかった。,,任意の信号は周波数の異なるsin、cosの重ね合わせで表現できる。周期信号であれば、正弦波の無限級数で表現できる。,,
D-2020_U65,,,,難しかった。,
D-2020_U66,全ての周期関数はsinとcosの級数で表せる。,,,,
D-2020_U67,,,"フーリエ級数展開の周期Tを無限大にする極限を取り、周期関数ではない関数にもフーリエ級数展開を適応できるようにした。
",,
D-2020_U69,,,フーリエ級数、複素フーリエ級数としての処理,,
D-2020_U7,フーリエ級数展開/複素フーリエ級数と波形の対応関係,要点にあった「ある信号周期が与えられると，そのフーリエ級数の各正弦波の大きさを求めることが可能：フーリエ係数」とあったが，フーリエ係数の意味するところが理解できなかった。,"信号をフーリエ級数展開または複素フーリエ級数で表す方法を学んだ。
あらゆる波形は正弦波の重ね合わせで表現することができるが，その１つの手段として上記の方法は有用である。
また，計算の工夫の１つとしてフーリエ級数展開と複素フーリエ級数を適宜使い分けたり，偶関数/奇関数の性質を利用したり，積分区間を工夫することも有効である。
またスペクトルは振幅に関する情報と位相に関する情報を持った量である。","フーリエ級数展開/複素フーリエ級数は復讐となった。
計算方法などをきちんと復習するとともに，数式の意味するところを直感的に理解していくことも復習の過程で目指したい。",
D-2020_U8,,,,短時間だったこともあり集中できた。,
D-2020_U9,"どんな周期波形も様々な周波数と振幅の正弦波、余弦波の組み合わせで表現できる。
オイラーの公式に基づき、複素関数で表現することもできる。",,,,
D-2021_U1,,畳み込み積分のイメージ,,式を追ってフーリエ変換を理解できたと思う。,
D-2021_U100,フーリエ係数の求め方について理解できた。,,"同じ波形の繰り返しである周期信号は三角関数のフーリエ級数や複素フーリエ級数で表すことができる。三角関数のフーリエ級数について具体的に述べると、その信号のフーリエ係数を求めることにより信号の直流成分と基本周波数の波の、ｎ次高周波の係数がわかりそれらで表現できるということである。どのような周期関数も正弦波と余弦波で表すことができる。複素フーリエの場合は周期信号を指数で表現することができ、三角関数のフーリエ級数よりも簡単に求められる。
フーリエ級数級数のフーリエ係数はスペクトルと呼ばれ振幅スペクトルと位相スペクトルがある。",三角関数のフーリエ級数について絵的に理解することができたので良かった。,
D-2021_U101,,,,数学的な考え方を知るとフーリエは面白い,
D-2021_U102,,フーリエ級数の意味は分かったが実際に計算してみると難しかった,周期信号のフーリエ級数表現について学んだ。またフーリエ級数の意味についても学んだ,フーリエ級数の計算は量が多く時間がかかってしまったので計算を早くできるようにしたい,
D-2021_U103,フーリエ級数、複素フーリエ級数について導出、演習ができた。,,フーリエ級数のやり方の確認が行われた。,"高専で学んだときとフーリエ級数の定義が違い、少し戸惑い理解が遅れてしまった。
改めて再確認が必要であると感じた。",リロードし忘れで、自動出欠が欠席になってしまいました。確認お願いします。
D-2021_U104,計算の仕方は具体的な演習をつうじて求めることができたので、よかった。,,今日はフーリエ変換の基本的な考え方と計算方法の確認を行なった。どのような周期関数も正弦波と余弦波と直流成分で表せられるという表現がフーリエ級数の本質的な部分なのでしっかり覚えておきたい。,時間内に演習まで終わらせられなかったので、次回からは先にノートを取っておいて、授業と演習を並列処理してみる。,
D-2021_U13,,"周期信号をフーリエ級数展開した後どのようにして処理するのか
(より滑らかな曲線のアナログ信号をどのように処理していくのか)",,フーリエ級数展開について理解を深められたので良かった,
D-2021_U14,フーリエ級数展開などを思い出す,,"フーリエ級数展開、フーリエ係数、複素フーリエ級数の計算
これらを組み合わせることでどんな信号も正弦波にできる",,
D-2021_U15,フーリエ級数、フーリエ変換の利用方法を再確認できた,,,計算がやや複雑なのでミスをしないよう心がけようと思った。,
D-2021_U16,周期信号をフーリエ級数で表現できるようになった。,特に無かったが、フーリエ級数の直流成分についての説明があればうれしい。,,,
D-2021_U17,cnのことをスぺクトルと呼ぶことが分かった。,,フーリエ級数,,
D-2021_U18,,,信号を数学的に表現,専門的な分野になってきて楽しい,
D-2021_U19,,単位インパルス,,,
D-2021_U20,フーリエ係数や複素フーリエ係数を求めること,,,,
D-2021_U21,フーリエ級数は２つの方法がある。,複素フーリエ級数,,,
D-2021_U22,,,周期信号、フーリエ級数について学習した。,,
D-2021_U23,"フーリエ級数、複素フーリエ級数の展開の計算は複素数、積分、sin,coxが絡み面倒なことが多いので、遇関数、奇関数などを見極め計算の量を減らすのが重要だとわかった。",,周期信号をフーリエ級数、複素フーリエ級数で展開する公式。,,
D-2021_U27,"任意の信号は周波数の異なる二つの正弦波の足し合わせで表現できる。周期信号は正弦波の無限級数で表現できる＝フーリエ級数展開
与えられた周期信号から、フーリエ級数の正弦波の大きさを求められる＝フーリエ係数
正弦波の代わりに複素正弦波によるフーリエ級数＝複素フーリエ級数
複素正弦波を用いると計算が容易になる。",スペクトル,,,
D-2021_U28,,,周期信号のフーリエ級数表現,本格的な計算が出てきて少し大変でした,
D-2021_U30,,"名前が似ていて混乱してしまった
定義に沿った変換",フーリエ変換、フーリエ級数,,
D-2021_U31,,複素フーリエ級数から三角関数のフーリエ級数を求める問題の一部,,フーリエ級数、複素フーリエ級数共によく使うものなので理解を深めたい,
D-2021_U32,,,,忘れてしまっていた内容が多かったので、復習しようと思います。,
D-2021_U41,,,周期信号のフーリエ級数変換と複素フーリエ級数変換,説明が簡潔で講義はすぐに終わったので、自分で調べて勉強する時間が多く取れてよかった。,
D-2021_U43,フーリエ変換,フーリエ逆変換,,わからないところがわからなかった,
D-2021_U45,複素正弦波を使うと計算が簡単になる,,様々なフーリエ級数,,
D-2021_U46,"任意の信号は周波数のことなる正弦波のたしあわせで表現可能である
周期信号に対してはフーリエ級数展開にて表現可能",,周期信号のフーリエ級数表現について学んだ,,
D-2021_U49,"フーリエ変換、複素フーリエ変換のやり方を学べた。
周期信号は正弦波、余弦波のみで表せる。",導出が少し難しくあったが、わからないところはなっかった。,"フーリエ変換、複素フーリエ変換の学習。
周期信号を正弦波、余弦波を用いて表す。",,
D-2021_U54,,複素フーリエ級数が難しかった。,フーリエ級数についての理解を深める。,,
D-2021_U57,代表的なフーリエ変換の計算,,,色々覚えることが多いなと思いました。,
D-2021_U61,フーリエ変換の三角関数、複素フーリエ変換の公式の理解,,信号を変換する際にフーリエ変換を用い、三角関数のものと複素数表現のものがあるということ,もっとゆとりをもって学習に臨むべきだと感じた。,複素フーリエ変換でn=0の時の場合分けは意識すべきでしょうか？
D-2021_U62,信号のフーリエ級数、複素フーリエ級数の表現の数式、また信号x(t)が偶関数、奇関数の場合におけるフーリエ係数の求め方。また振幅スペクトルと位相スペクトルの数学的表現について学んだ。,,,,
D-2021_U63,フーリエ級数、複素フーリエ級数の求め方や原理が分かった。,位相スペクトルのあたりの話がいまいち理解できなかった。,フーリエ変換をするためのフーリエ級数の求め方や、複素フーリエ級数の求め方を学習した、,,
D-2021_U64,フーリエ級数・複素フーリエ級数の式,フーリエ級数の係数の導出,フーリエ級数・複素フーリエ級数,正弦波に分解できるということがわかった,
D-2021_U67,,,,計算が多くて大変でした。,
D-2021_U69,,,,,授業内容ではないのですが、BookRoll+LADのチャット機能は授業中使用してもよいのでしょうか。
D-2021_U70,フーリエ級数の求め方、周期信号との関係について理解できた,,,,
D-2021_U72,,演習課題の具体的な数値でフーリエ級数を求める問題が全然出来なかった,周期信号を正弦波で表すことが可能である。,,演習課題の2-3と2-4の解説が欲しいです
D-2021_U73,"三角関数、複素数どちらのフーリエ展開も行うことができた。
1年前の復習を行うことができた。
係数の導入を自分で調べて記述することができた。","特になかった。
締め切りの時間を勘違いしていて、演習問題の提出が少し遅れてしまったので、来週から気をつけたい。",周期信号でのフーリエ級数展開,,
D-2021_U74,,,周期信号は正弦波の無限級数で表すことができる。それに用いるのがフーリエ係数である。複素フーリエ級数はフーリエ級数にオイラーの公式を適用することで求めることができる。複素正弦波を使うと計算が容易になる。,フーリエ級数の計算は2年生で習ったので、その復習をすることができた。,
D-2021_U75,,,フーリエ級数についての復習。,計算を解くのに手間取って時間を要することがあったので、定期的に復習したい。,
D-2021_U76,,,,,ありません。
D-2021_U77,フーリエ級数を利用する周期信号の表現方式が分かった。,,周期信号とはある時間間隔を置いて同じ信号のパターンが繰り返される信号をいい、同じ信号のパターンが繰り返される最小の時間間隔を周期という。ある信号が周期関数である場合、その信号は三角関数のフーリエ級数により表現することができる。,去年勉強したフーリエ級数の内容を少し復習したいと思った。,
D-2021_U79,,,,2年生の時に学習したフーリエ級数の知識が生きた感じがした。計算が煩雑になるが、信号処理に用いられる上で大事な概念であることを理解できた。,
D-2021_U81,周期信号をフーリエ級数や複素フーリエ級数で表現すること。,"スペクトルは何に使うのだろう。
フーリエ級数の計算は複雑でなかなか計算が合わなかった。",,フーリエ変換は二年生の授業で一度やったことがあったので見覚えはあったが、計算が複雑で式変換などミスをすることが多かったので気を付ける。,
D-2021_U82,,結局、スペクトルってなんなんだ,,フーリエ変換は大学に入ってからよく出てくる話なので重要な事項なんだとおもった,
D-2021_U83,,,フーリエ級数、複素フーリエ級数、スペクトル,ノートを取りながら授業を受けたので、理解しやすかった。,
D-2021_U84,,,"フーリエ級数、複素フーリエ級数について中心的に学んだ
なぜフーリエ級数を使うのかについても学んだ",復習も多くほとんどの内容は理解しやすかった,
D-2021_U86,,,,"感想を書き忘れました
",
D-2021_U89,"フーリエ級数表現ですべての信号を正弦波で表せる
フーリエ係数は偶周期か奇周期かで計算の簡略化可能
複素フーリエ級数だともっと式を簡略に表現できる",,,先のフーリエ変換は以前習ったことがあったのだが、その土台となるフーリエ級数をあまりわかっていなかったのでよい復習の機会となった,
D-2021_U90,,,本日はフーリエ級数の求め方を2年生の内容を踏まえて復習した。,,
D-2021_U91,,,,計算が難しそうだった。,
D-2021_U93,フーリエ級数から複素フーリエ級数に導出する方法がわかった。,,"全ての周期信号は正弦波を組み合わせて表現（フーリエ変換）することができる。
正弦波の代わりに複素正弦波を使うこともできる。",2年の時にフーリエ変換は学習していたので、それを思い出す良い機会になった。,
D-2021_U94,フーリエ級数は復習的な内容が多かったのでわかった。,具体的な計算については忘れていてできないことがあった。,周期信号についてのフーリエ級数で表すものであったり、正弦波と余弦波の重ね合わせで周期信号は表現できるということを学んだ。,,
D-2021_U96,,,,積分で置換積分を多用するので計算ミスをしないように注意が必要であると感じた．,
D-2021_U97,"偶周期信号のときはbn=0、奇周期信号のときはa0=an=0
様々な周期信号でフーリエ級数の計算ができた。",,,,
D-2021_U98,"非周期関数を無理やり周期無限大の関数として見ることで、非周期関数でも三角関数の級数和で表現したい気持ちがわかった。
周期を無限大にすると起こることを式変形で感じることができた。",授業スピードがはやいので、ノートを取りながら理解することの難しさを感じた。,フーリエ級数からフーリエ変換の導入,,
D-2021_U99,フーリエ係数の導出を頑張った。,,,,
D-2022_U1,フーリエ係数が直交性から求められることが確認できた。,スペクトルの意味がなんとなくしか分からなかった。,,,
D-2022_U10,代表的なフーリエ変換と性質,,様々なフーリエ変換とその性質,,
D-2022_U14,,スペクトル、フーリエ級数の直流成分について,,,
D-2022_U20,,偶信号、奇信号のときのフーリエ級数の求め方,"周期関数をフーリエ級数を用いて表す方法
",,
D-2022_U21,,,フーリエ級数と複素フーリエ級数の計算方法,,cnでもnが分数にくることがあるので、c0は別に求めてシグマの前に書いたほうがいいのかが気になった。課題では一応書いている。
D-2022_U25,任意の波形は周波数の異なる正弦波と予言派の合成によって得られる。,どういうときにフーリエ級数が用いられ、どういうときに複素フーリエ級数が用いられるのかがわからない,周期信号はフーリエ級数によって表現することができる。フーリエ係数は三角関数の直交性を利用して求めることができる。またどんな周期波形は正弦波と余弦波の合成によって得ることができる。複素フーリエ級数は正弦波のかわりに複素正弦波によってあらわされたもの。,,
D-2022_U26,　フーリエ級数表現によって信号の波が正弦波と余弦波の集まりであることやフーリエ級数表現の仕方がわかりました。,, フーリエ級数の図形的な意味やフーリエ級数表現の仕方,,
D-2022_U29,フーリエ級数展開の意味、導出,,,,
D-2022_U30,フーリエ級数の計算方法がわかった。,フーリエ係数の導出に少し手こずった。,,,
D-2022_U31,,演習課題が計算が間違って一部手こずった。,"周期信号はフーリエ級数で表せる。
フーリエ級数は数学的変換で複素フーリエ級数として表せる。",,
D-2022_U32,周期信号はフーリエ級数により表現することができ、計算することができる。また計算には複素フーリエ級数を使うことにより簡単にすることができる。,,周期信号をフーリエ級数により表現することとその計算,,
D-2022_U33,,,フーリエ級数の復習をした。,,
D-2022_U35,,,信号x(t)が周期関数の時、x(t)は三角関数のフーリエ級数によって表すことができ、また、オイラーの公式を適用することで、複素フーリエ級数によって表すこともできる。,,
D-2022_U36,,,,懐かしかった。,
D-2022_U39,フーリエ変換の性質,フーリエ級数からフーリエ変換になるまでの過程が自分の中で曖昧だった。,"周期信号の周期を無限大に大きくすると非周期信号になる。
フーリエ変換には様々な性質がある。
パーセバルの等式は時間領域のエネルギーと周波数領域のエネルギーが等しいことを表した等式である。",,
D-2022_U40,フーリエ級数を使った周期信号についての考え方,スペクトルの特性について,,,
D-2022_U41,,,周期信号はフーリエ級数で表現できる,"フーリエ変換できなかったのできちんと復習したい
",
D-2022_U42,,演習にあるが、フーリエ級数の証明の類はきちんとしておきたい。,フーリエ級数の内容と信号との関係について学んだ,フーリエ級数自体は他の講義で習い、演習などもしたがそれがどのような意味をもつのか知ることができたのがよかった。,
D-2022_U43,フーリエ係数を複素などで求められるようになった．,,,2年の時から履修している内容だったので割と理解しやすかった．,
D-2022_U45,,,周期信号のフーリエ級数での表現,"式変形の共有は役に立った
自分で計算してみて定着させたい","授業ノートを手書きというか
ipadでの手書きノートで書いているのですが大丈夫でしょうか？"
D-2022_U47,,,波を三角関数や指数関数の重なりで表す方法,以前数学で扱ったフーリエ展開を復習できた．,
D-2022_U51,,なぜフーリエ系数が今回学んだ式で表されるのかをまだ完全に理解できない,,今日の授業は教授が実際に等式の証明をしていたが、その時に、見るだけでなく自分も手を動かしてみればよかった,
D-2022_U54,,,フーリエ級数は以前一度習ったが、忘れていた,,
D-2022_U55,内容を完璧に理解し課題に取り組むことができた。,,周期信号は三角関数の重ね合わせにより、級数で近似することができる。複素数を扱うことで計算のしやすい複素フーリエ級数にも拡張できる。,,
D-2022_U56,フーリエ級数の意味、フーリエ級数の求め方。,,,他の授業でもフーリエ級数については学んでいたので、復習することができた。,
D-2022_U57,全ての信号は，正弦波の合成によって表せることがわかった．また，複素フーリエ級数を用いることで，表現が簡潔になった．しかし少し手計算では面倒だった．,,周期信号のフーリエ級数について学んだ．,前回に引き続き授業中に気になったことや重要なことをノートにメモしながら聞けた．フーリエ級数の計算は久しぶりだったので思い出すことができた．,
D-2022_U58,周期信号をフーリエ級数や複素フーリエ級数を用いて表現する方法を学んだ。,,周期信号のフーリエ級数表現、複素フーリエ級数表現及びスペクトル,この授業で学習したフーリエ級数はとても重要な事なのでしっかり理解しておきたい。,特にありません
D-2022_U60,フーリエ級数の復習ができた。,スペクトルの意味があまりわからなかった。,フーリエ級数についての説明,,
D-2022_U61,,複素フーリエ級数がまだスムーズに解けなかった。,フーリエ級数および複素フーリエ級数の方法を学び信号の処理の具体的な方法になった。,フーリエ級数と複素フーリエ級数のどちらのパターンでも対応できるように準備しておきたい。,
D-2022_U62,フーリエ級数及び複素フーリエ級数が、どのように導出されたものであるか。,"求め方自体は理解できたが、計算が苦手。
",,,
D-2022_U65,公式を用いて演習に回答することができた,,フーリエ級数の理解と演習,,
D-2022_U66,,,,フーリエ級数はほかの授業でも学んでいたが、覚えていないこともあったので思い出せてよかった。,
D-2022_U67,フーリエ変換によって非周期信号を数式であらわせる,,フーリエ変換によって非周期信号に含まれる複素正弦波の大きさが表現できる,ほかの授業で習ったにもかかわらずフーリエ変換が難しい。,
D-2022_U68,"フーリエ級数展開の信号波形に対する活用が出来ることを理解した。
わざわざ複素表現で複素フーリエ級数を使うのは、三角関数の微分より指数関数の微分の方が早いから。",,,,
D-2022_U69,フーリエ級数、複素フーリエ級数の求め方,フーリエ級数、複素フーリエ級数を同じ波で求めたが値が一致しなかった,,課題をぎりぎりに出してしまったこと,演習の2-3から2-5でフーリエ級数を求めたましたが、複素フーリエ級数の値がいずれもフーリエ級数の1/2倍の値になってしまいました。
D-2022_U7,フーリエ級数の意味を理解することができた。,計算や、公式などをどのように使えばいいかわからなかった。,周期信号のフーリエ級数表現,いよいよ内容が難しくなってきたなと思った。,
D-2022_U72,,スペクトルをどのような場面で用いるかについて,,フーリエ級数の説明が簡潔で分かりやすかった,
D-2022_U73,"信号はフーリエ変換を使うことで式としてあらわすこと
フーリエ変換の構造",,,,
D-2022_U74,フーリエ級数を少し思い出した,,,,
D-2022_U77,,フーリエ係数を求めるうえで求め方自体は理解しているつもりだが、計算でつまずきがち。,,2年の前期におおよそやった内容だったが忘れている部分も多いので復習しておきたい。,
D-2022_U8,,複素フーリエ級数がいまいちわかりませんでした。,,,
D-2022_U80,,,,よくわかった,
D-2022_U81,,,,以前やったフーリエ級数の求め方をわすれめいたので勉強しなおしたいと思いました。,
D-2022_U82,,,任意の信号は正弦波の足し合わせで表現できる。複素フーリエ級数を使うと計算が簡単になる。,,
D-2022_U83,フーリエ級数の求め方,,,,
D-2022_U84,,,フーリエ級数について,,
D-2022_U85,フーリエ級数の復習ができた。,,フーリエ級数、複素フーリエ級数についてと、スペクトルという言葉の意味。,,
D-2022_U87,"方形波や，ノコギリ波であっても三角関数の合成により，おおよそ近似できることを，図から理解できた．
",各所，数式の証明，導出については理論的に理解できていないので，復習したい．,,,"授業冒頭から最後まで出席していましたが，黄色moodleのリロードが遅れてしましい，遅刻として処理されてしまいました．
青色moodleでは正しく処理されているようですので，出席点評価の際はこちらを参照していただければと思います．
お手数ですが，ご検討よろしくお願いいたします．
"
D-2022_U89,,,今回はフーリエ級数の学習した。フーリエ級数の求め方や、フーリエ級数の要点について学習した。,今回の授業では、フーリエ級数を学びました。フーリエ級数は、任意の信号はを正弦波の重ね合わせで表現するもので、工学の分野では多岐にわたって使用されているものだと思います。そのため、この講義の内容をしっかり復習しておきたいと思いました。,
D-2022_U9,フーリエ変換は数学で学習したのですんなり入ってきた。,複素フーリエ変換についての理解が十分ではないなと感じた。,今日はフーリエ変換について学ぶことができた。,,
D-2022_U90,,,周期的な信号はフーリエ級数によって表現できる．つまり，いろいろな正弦波の足し合わせで表現できるのである．フーリエ級数は，オイラーの公式を用いて複素フーリエ級数に変換できる．複素フーリエ級数の方がフーリエ級数よりも簡潔に表現できる．,,
D-2022_U92,フーリエ級数の求め方が分かった。,複素数や三角関数のフーリエ級数がいまいちわからなかった。,周期信号、つまりわかりやすい信号のフーリエ級数の求め方。また、複素数や三角関数を用いてフーリエ級数の表現方法等。,,
D-2022_U93,,,周期信号のフーリエ級数展開表示,,
