id,1,2,3,4,5,target
B-2020_U10,"""Management of my device is very important, and encryption and backup are important.
Beware of spoofing and fake links""",,,,,0
B-2020_U11,,,"""What should I do if I lose it while offline on a computer, etc. Should I give up?""","""is not.""","""Today's content was very intensive, but I'm glad I got a lot of knowledge that I can use in the future.""",1
B-2020_U11,,,"""What should I do if I lose it while offline on a computer, etc. Should I give up?""","""is not.""","""Today's content was very intensive, but I'm glad I got a lot of knowledge that I can use in the future.""",1
B-2020_U11,,,"""What should I do if I lose it while offline on a computer, etc. Should I give up?""","""is not.""","""Today's content was very intensive, but I'm glad I got a lot of knowledge that I can use in the future.""",1
B-2020_U13,"""How to protect information and points to be targeted""","""Good passwords and how to protect each device, how to use wi-fi properly""",,,,1
B-2020_U13,"""How to protect information and points to be targeted""","""Good passwords and how to protect each device, how to use wi-fi properly""",,,,1
B-2020_U14,,,"""I didn't know how to restore from backup on my device.""",,,1
B-2020_U15,"Information devices contain important information, so it is important to set a password and back them up in case of loss, theft, or malware attack. Be careful and avoid entering important information.""",,,,,1
B-2020_U16,"""Attacks that exploit security vulnerabilities occur frequently, and there is no complete guarantee. However, in order to protect personal information, please set up information devices such as PCs and smartphones and update them to the latest version regularly. In addition, regarding password management, it is necessary to set passwords that can be managed by individuals so that they do not use strings that can be easily guessed or reused.""",,,,"""I myself use a Mac and an iPhone. Since they are synchronized with iCloud, if the security of one of the terminals is breached, the other will also be useless. As a countermeasure, the Mac The iPhone has fingerprint authentication, the iPhone has a face authentication system, and the password itself is set to something completely different.Based on this class, I need to make these settings again to ensure safety. I felt that.""",0
B-2020_U16,"""Attacks that exploit security vulnerabilities occur frequently, and there is no complete guarantee. However, in order to protect personal information, please set up information devices such as PCs and smartphones and update them to the latest version regularly. In addition, regarding password management, it is necessary to set passwords that can be managed by individuals so that they do not use strings that can be easily guessed or reused.""",,,,"""I myself use a Mac and an iPhone. Since they are synchronized with iCloud, if the security of one of the terminals is breached, the other will also be useless. As a countermeasure, the Mac The iPhone has fingerprint authentication, the iPhone has a face authentication system, and the password itself is set to something completely different.Based on this class, I need to make these settings again to ensure safety. I felt that.""",0
B-2020_U17,,"""Even if you have security software installed, backing up is important. Be very careful with fake links so that information such as passwords cannot be stolen. Also, do not use WEP.""",,,,0
B-2020_U18,"""The importance of passwords, the importance of backups, the importance of software updates, how to protect accounts, how wireless LAN works and things to note""",,,,,1
B-2020_U19,,,,,"""It's easy to learn because I can learn things that I didn't understand in my preparation. I was able to feel a sense of urgency when I learned that I hadn't done things like backups. I was able to set it to , thank you. """,0
B-2020_U20,"""I learned the process of how personal information such as passwords is leaked and how to deal with it.""","""In order to prevent leakage of personal information, it is better to set any password, and it is better to make it as long as possible using English characters, but it must be something that you can remember.""",,,,0
B-2020_U20,"""I learned the process of how personal information such as passwords is leaked and how to deal with it.""","""In order to prevent leakage of personal information, it is better to set any password, and it is better to make it as long as possible using English characters, but it must be something that you can remember.""",,,,0
B-2020_U22,,"""I think I need to rethink password settings for various things.
I also felt the need to understand backup and encryption settings. """,,,"""In order to deepen my understanding, I thought it necessary to do some research in advance on things I didn't understand at the preparatory stage.""",1
B-2020_U22,,"""I think I need to rethink password settings for various things.
I also felt the need to understand backup and encryption settings. """,,,"""In order to deepen my understanding, I thought it necessary to do some research in advance on things I didn't understand at the preparatory stage.""",1
B-2020_U23,"""Each device has various security measures, and safety is enhanced by locking multiple layers. However, due to the existence of fake sites and illegal wireless LANs, etc., There is always an element of danger.""",,,,,0
B-2020_U24,"""This class was about how to strengthen security as much as I can, how to take countermeasures when devices are attacked from the outside, and about wireless LAN.""","""It was more than I thought how important it is to have backups. This class taught me that I can strengthen my security if I do my own research. ""","""Nothing in particular.""",,"""I now understand how much I've been spending my days without paying much attention to security. I'm actually thinking of backing up my data on my computer from today. Thank you for today.
""",0
B-2020_U24,"""This class was about how to strengthen security as much as I can, how to take countermeasures when devices are attacked from the outside, and about wireless LAN.""","""It was more than I thought how important it is to have backups. This class taught me that I can strengthen my security if I do my own research. ""","""Nothing in particular.""",,"""I now understand how much I've been spending my days without paying much attention to security. I'm actually thinking of backing up my data on my computer from today. Thank you for today.
""",0
B-2020_U24,"""This class was about how to strengthen security as much as I can, how to take countermeasures when devices are attacked from the outside, and about wireless LAN.""","""It was more than I thought how important it is to have backups. This class taught me that I can strengthen my security if I do my own research. ""","""Nothing in particular.""",,"""I now understand how much I've been spending my days without paying much attention to security. I'm actually thinking of backing up my data on my computer from today. Thank you for today.
""",0
B-2020_U24,"""This class was about how to strengthen security as much as I can, how to take countermeasures when devices are attacked from the outside, and about wireless LAN.""","""It was more than I thought how important it is to have backups. This class taught me that I can strengthen my security if I do my own research. ""","""Nothing in particular.""",,"""I now understand how much I've been spending my days without paying much attention to security. I'm actually thinking of backing up my data on my computer from today. Thank you for today.
""",0
B-2020_U25,,,,,"""Regarding the link in the fake email. I didn't think that I could be redirected to a site that had absolutely nothing to do with the text on the link. I was under the impression that the suspicious link was a long string of characters full of symbols. So I want to be careful from now on.""",0
B-2020_U26,"""Security measures that can be done in familiar places""",,,,,0
B-2020_U27,,,,,"""I wanted only convenience, and tried not to use unknown wireless LAN or apps.
thank you very much. """,-1
B-2020_U31,,,,,"""In this class, you explained where there is a risk of being attacked, so I understood the importance of countermeasures and what kind of security exists for which attack. Practice in real life. I want to do it.""",1
B-2020_U33,,"""I was able to learn more about wireless LAN.
I was able to review the security of my mobile phone. ""","""I didn't really understand what the channel that appeared in the explanation of the wireless LAN was.""",,,0
B-2020_U33,,"""I was able to learn more about wireless LAN.
I was able to review the security of my mobile phone. ""","""I didn't really understand what the channel that appeared in the explanation of the wireless LAN was.""",,,0
B-2020_U34,"""In order to protect information devices, it is necessary to take countermeasures against theft/loss (passcode setting, screen lock, ""Search"" application, backup creation, data encryption, etc.) and malware countermeasures (software updates).
Passwords are stored on the server in the form of hashed passwords, but the risks of brute force and dictionary attacks remain. In order to protect information, it is necessary to set appropriate passwords and authentication, and manage information left on the server.
In order to protect the communication path, it is necessary to use a strong security standard such as WPA2 or connect to a highly secure base station when using a wireless LAN. ""","""I learned about the existence of stray wireless LAN.
I've been messing around with Wi-Fi settings until now, but now I know what they mean. """,,,,1
B-2020_U34,"""In order to protect information devices, it is necessary to take countermeasures against theft/loss (passcode setting, screen lock, ""Search"" application, backup creation, data encryption, etc.) and malware countermeasures (software updates).
Passwords are stored on the server in the form of hashed passwords, but the risks of brute force and dictionary attacks remain. In order to protect information, it is necessary to set appropriate passwords and authentication, and manage information left on the server.
In order to protect the communication path, it is necessary to use a strong security standard such as WPA2 or connect to a highly secure base station when using a wireless LAN. ""","""I learned about the existence of stray wireless LAN.
I've been messing around with Wi-Fi settings until now, but now I know what they mean. """,,,,1
B-2020_U35,"""Understanding device security to reduce damage from online cyberattacks""",,,,,0
B-2020_U38,,,,"""Nothing in particular""","""I was very pleased with how effectively the 'I understand' and 'I don't understand' buttons in the preparatory lessons were put to good use, and the main points of the lesson were summarized. """,0
B-2020_U38,,,,"""Nothing in particular""","""I was very pleased with how effectively the 'I understand' and 'I don't understand' buttons in the preparatory lessons were put to good use, and the main points of the lesson were summarized. """,0
B-2020_U39,,,,,"""Wirelesses that can be used in shops, public facilities, etc., and wireless in the wild are also dangerous, so I decided not to use them unnecessarily even if they can be used.""",1
B-2020_U40,"""There are many dangers on the Internet, and it is important to set up properly by yourself.""",,"""I don't know much about VPN""",,,1
B-2020_U40,"""There are many dangers on the Internet, and it is important to set up properly by yourself.""",,"""I don't know much about VPN""",,,1
B-2020_U41,"""Assuming that devices such as smartphones and personal computers are stolen, it is necessary to prepare to enable data backup, remote information deletion, and device search functions as appropriate. In addition, it is short, simple, and easy to predict. Do not use passwords or reuse passwords as it is extremely dangerous for personal information protection.
Be careful when using the Internet, as information may be stolen through fake links, URLs, and emails.
The device's OS requires regular updates, and avoid using an old OS that is vulnerable to the latest viruses.
""I need to make sure that the line I'm using is really reliable."" ""","""Create a strong password for each device and account. Don't click URL links easily.
The importance of OS updates. Wi-Fi at airports and shopping centers can be surprisingly dangerous. In addition to preventive measures, measures should be prepared to deal with worst-case scenarios. You can never be too careful! ! """,,,"""While listening to this class, I regretted that I hadn't made many assumptions and countermeasures for the worst-case scenario of what to do if my information was stolen. To be honest, information leaks or theft of smartphones, and passwords were revealed. I thought it was rare, but I thought I would take this opportunity to not only prevent cyber security breaches, but also prepare for them if they actually happen. I want to continue.""",-1
B-2020_U41,"""Assuming that devices such as smartphones and personal computers are stolen, it is necessary to prepare to enable data backup, remote information deletion, and device search functions as appropriate. In addition, it is short, simple, and easy to predict. Do not use passwords or reuse passwords as it is extremely dangerous for personal information protection.
Be careful when using the Internet, as information may be stolen through fake links, URLs, and emails.
The device's OS requires regular updates, and avoid using an old OS that is vulnerable to the latest viruses.
""I need to make sure that the line I'm using is really reliable."" ""","""Create a strong password for each device and account. Don't click URL links easily.
The importance of OS updates. Wi-Fi at airports and shopping centers can be surprisingly dangerous. In addition to preventive measures, measures should be prepared to deal with worst-case scenarios. You can never be too careful! ! """,,,"""While listening to this class, I regretted that I hadn't made many assumptions and countermeasures for the worst-case scenario of what to do if my information was stolen. To be honest, information leaks or theft of smartphones, and passwords were revealed. I thought it was rare, but I thought I would take this opportunity to not only prevent cyber security breaches, but also prepare for them if they actually happen. I want to continue.""",-1
B-2020_U41,"""Assuming that devices such as smartphones and personal computers are stolen, it is necessary to prepare to enable data backup, remote information deletion, and device search functions as appropriate. In addition, it is short, simple, and easy to predict. Do not use passwords or reuse passwords as it is extremely dangerous for personal information protection.
Be careful when using the Internet, as information may be stolen through fake links, URLs, and emails.
The device's OS requires regular updates, and avoid using an old OS that is vulnerable to the latest viruses.
""I need to make sure that the line I'm using is really reliable."" ""","""Create a strong password for each device and account. Don't click URL links easily.
The importance of OS updates. Wi-Fi at airports and shopping centers can be surprisingly dangerous. In addition to preventive measures, measures should be prepared to deal with worst-case scenarios. You can never be too careful! ! """,,,"""While listening to this class, I regretted that I hadn't made many assumptions and countermeasures for the worst-case scenario of what to do if my information was stolen. To be honest, information leaks or theft of smartphones, and passwords were revealed. I thought it was rare, but I thought I would take this opportunity to not only prevent cyber security breaches, but also prepare for them if they actually happen. I want to continue.""",-1
B-2020_U43,"""It is possible to provide a certain degree of security with apps and settings, but it is only possible to deal with what is already known, and it is weak against new things and is not perfect, so it is important to make your own decisions.""",,,,,1
B-2020_U44,"""About measures you can take to prevent your personal information from being leaked""","""The importance of passwords""","""I thought security measures were not properly implemented yet""",,"""In order to protect personal information in the future, I would like to change to a strong password and check the safety of Wi-Fi.""",-1
B-2020_U44,"""About measures you can take to prevent your personal information from being leaked""","""The importance of passwords""","""I thought security measures were not properly implemented yet""",,"""In order to protect personal information in the future, I would like to change to a strong password and check the safety of Wi-Fi.""",-1
B-2020_U44,"""About measures you can take to prevent your personal information from being leaked""","""The importance of passwords""","""I thought security measures were not properly implemented yet""",,"""In order to protect personal information in the future, I would like to change to a strong password and check the safety of Wi-Fi.""",-1
B-2020_U44,"""About measures you can take to prevent your personal information from being leaked""","""The importance of passwords""","""I thought security measures were not properly implemented yet""",,"""In order to protect personal information in the future, I would like to change to a strong password and check the safety of Wi-Fi.""",-1
B-2020_U45,"""Personal Security Measures""",,,,"""Since I was introduced to a lot of things I can do by myself with only familiar stories, I decided to put it into practice from now on.""",0
B-2020_U45,"""Personal Security Measures""",,,,"""Since I was introduced to a lot of things I can do by myself with only familiar stories, I decided to put it into practice from now on.""",0
B-2020_U46,,,,"""Will I be able to use Find My iPhone even if location information is normally turned off?""","""This time, I learned a lot from talking about things I used to use, things I knew existed but had never used.
I bought my own Mac for the first time after entering university, and both my parents and I have only used Windows so far, so there are many things I don't understand, but I will refer to the lectures and set them up little by little. """,1
B-2020_U46,,,,"""Will I be able to use Find My iPhone even if location information is normally turned off?""","""This time, I learned a lot from talking about things I used to use, things I knew existed but had never used.
I bought my own Mac for the first time after entering university, and both my parents and I have only used Windows so far, so there are many things I don't understand, but I will refer to the lectures and set them up little by little. """,1
B-2020_U47,,"""Among the passwords, I was worried about face authentication and fingerprint authentication, but if I use them in combination, I feel a little safer.
How to judge a fake site","""It was still a bit difficult to understand about wireless LAN""",,,0
B-2020_U47,,"""Among the passwords, I was worried about face authentication and fingerprint authentication, but if I use them in combination, I feel a little safer.
How to judge a fake site","""It was still a bit difficult to understand about wireless LAN""",,,0
B-2020_U48,,"""Beware of Fake Links and Suspicious Wi-Fi""",,,,1
B-2020_U49,,"""I was able to learn and understand appropriate security methods for devices, accounts, and communication paths.
・As I wrote last week, I was able to get a perfect score on the quiz. """,,,,1
B-2020_U5,,,,"""Regarding creating a password, I was wondering if it is safe to use a different character in one password.
I thought it would be nice if it was just one, because it would be easier to remember, but if it was a brute-force method, would I get it right? ""","""I tend to reuse passwords unintentionally, so I thought I'd be careful. Also, even when it's time to buy a new smartphone or computer in the future, don't neglect security measures based on the latest and correct information. I wanted to.""",0
B-2020_U5,,,,"""Regarding creating a password, I was wondering if it is safe to use a different character in one password.
I thought it would be nice if it was just one, because it would be easier to remember, but if it was a brute-force method, would I get it right? ""","""I tend to reuse passwords unintentionally, so I thought I'd be careful. Also, even when it's time to buy a new smartphone or computer in the future, don't neglect security measures based on the latest and correct information. I wanted to.""",0
B-2020_U50,,"""How to use backups, how to set a strong password""",,,,0
B-2020_U52,,"""I learned for the first time that passwords are stored on the server in the form of password hashes.
I learned to be careful when using Wi-Fi. """,,,"""It was interesting to learn things for the first time and to realize things that I usually didn't care about.""",0
B-2020_U52,,"""I learned for the first time that passwords are stored on the server in the form of password hashes.
I learned to be careful when using Wi-Fi. """,,,"""It was interesting to learn things for the first time and to realize things that I usually didn't care about.""",0
B-2020_U53,"""Importance of passwords
How do I protect my information?""","""I've found that there are some strengths of Wi-Fi security that you shouldn't use.
In order to protect the information terminal, I learned that it is important to know various methods and use them in combination. """,,,,1
B-2020_U53,"""Importance of passwords
How do I protect my information?""","""I've found that there are some strengths of Wi-Fi security that you shouldn't use.
In order to protect the information terminal, I learned that it is important to know various methods and use them in combination. """,,,,1
B-2020_U54,"""I learned how to set passwords and how to use Wi-Fi in order to use smartphones and computers safely.""",,"""I didn't understand how channels and SSIDs work. I'd like to understand these words because I see them occasionally when using smartphones.""",,,0
B-2020_U54,"""I learned how to set passwords and how to use Wi-Fi in order to use smartphones and computers safely.""",,"""I didn't understand how channels and SSIDs work. I'd like to understand these words because I see them occasionally when using smartphones.""",,,0
B-2020_U55,"""Handling and countermeasures regarding the security of the electronic devices that you own.
What kind of anti-theft and anti-malware measures are there?
What is the password authentication mechanism and what is the today's password that can be understood from it?
Types of communication standards, their security, vulnerabilities, and how to handle them. ""","""Even the passwords and personal information that you casually entrust to electronic devices can be stolen at some point.
By taking measures and being careful on a daily basis, it is possible to prevent the leakage and loss of such personal information. """,,,,0
B-2020_U55,"""Handling and countermeasures regarding the security of the electronic devices that you own.
What kind of anti-theft and anti-malware measures are there?
What is the password authentication mechanism and what is the today's password that can be understood from it?
Types of communication standards, their security, vulnerabilities, and how to handle them. ""","""Even the passwords and personal information that you casually entrust to electronic devices can be stolen at some point.
By taking measures and being careful on a daily basis, it is possible to prevent the leakage and loss of such personal information. """,,,,0
B-2020_U56,"""Measures we can take to protect our information""",,"""I couldn't really understand channels etc.""",,,-2
B-2020_U56,"""Measures we can take to protect our information""",,"""I couldn't really understand channels etc.""",,,-2
B-2020_U57,,,,,"""Until now, when connecting to free Wi-Fi in the city, I had never thought about the danger and the difference in the degree of danger. , I thought I'd be careful every time I use it in the future.In addition, since I became a university student, I have more opportunities to use computers, and the amount of data that I store has increased, so I will use what I learned this time to review security measures and save data. I plan to make frequent backups of the",1
B-2020_U59,"""In addition to protecting the information equipment itself, it is important to protect your own information on your PC and smartphone. Backups, data encryption, and password management are necessary. Malware and eavesdropping are important. Also, when using wireless LANs such as Wi-Fi, you need to be careful not to connect to anything you don't know and to avoid entering personal information such as passwords and credit card numbers.""",,,,,1
B-2020_U6,"""About measures that individuals can take to protect personal information, passwords and Wi-Fi mechanisms""",,,,"""Up until now I've been casually connecting to Wi-Fi around town, so from now on, I want to be careful to only connect to things that I can confirm are trustworthy.""",1
B-2020_U6,"""About measures that individuals can take to protect personal information, passwords and Wi-Fi mechanisms""",,,,"""Up until now I've been casually connecting to Wi-Fi around town, so from now on, I want to be careful to only connect to things that I can confirm are trustworthy.""",1
B-2020_U60,,,,,"""I think it was a good opportunity to re-learn the fear of my information being stolen and to reflect on my device settings and passwords.""",0
B-2020_U64,"""Computer Device Security""",,"""I didn't understand how the password works""",,"""I immediately decided to check the settings and do what I couldn't do.""",-1
B-2020_U64,"""Computer Device Security""",,"""I didn't understand how the password works""",,"""I immediately decided to check the settings and do what I couldn't do.""",-1
B-2020_U64,"""Computer Device Security""",,"""I didn't understand how the password works""",,"""I immediately decided to check the settings and do what I couldn't do.""",-1
B-2020_U65,,,"""I think you said it was generally okay, but the Wi-Fi security was a little difficult.""",,,0
B-2020_U67,,"""I learned a lot about Android devices for the first time""","""Voice was hard to hear.""",,"""It was a practical and interesting class.""",1
B-2020_U67,,"""I learned a lot about Android devices for the first time""","""Voice was hard to hear.""",,"""It was a practical and interesting class.""",1
B-2020_U67,,"""I learned a lot about Android devices for the first time""","""Voice was hard to hear.""",,"""It was a practical and interesting class.""",1
B-2020_U68,,,,"""You said that hashed passwords cannot be reverted directly, but are you saying that they can be reverted using some variables and abused?""",,1
B-2020_U70,"""How to set passwords, etc. for safe use of computers and smartphones.""",,,,,0
B-2020_U72,,"""The password is also encrypted on the other side of the site""",,,,-1
B-2020_U73,"""I learned how to protect my devices and information and what is good and bad.""","""At the time of preparation, I realized that the passwords I usually use on my computer and smartphone were weak, so I reconfigured them by mixing uppercase and lowercase letters, numbers, and symbols. There is.""",,,"""I thought I had listened to the class seriously and understood, but I was very disappointed that I could not make good use of what I learned in the quiz.
I still have 5 classes left, so I want to take it back. """,0
B-2020_U73,"""I learned how to protect my devices and information and what is good and bad.""","""At the time of preparation, I realized that the passwords I usually use on my computer and smartphone were weak, so I reconfigured them by mixing uppercase and lowercase letters, numbers, and symbols. There is.""",,,"""I thought I had listened to the class seriously and understood, but I was very disappointed that I could not make good use of what I learned in the quiz.
I still have 5 classes left, so I want to take it back. """,0
B-2020_U73,"""I learned how to protect my devices and information and what is good and bad.""","""At the time of preparation, I realized that the passwords I usually use on my computer and smartphone were weak, so I reconfigured them by mixing uppercase and lowercase letters, numbers, and symbols. There is.""",,,"""I thought I had listened to the class seriously and understood, but I was very disappointed that I could not make good use of what I learned in the quiz.
I still have 5 classes left, so I want to take it back. """,0
B-2020_U74,,,,"""Nothing in particular.""","""I was wondering about the frequency band when setting up the wireless LAN, and I'm glad I understood the meaning of the frequency band. I'd like to actively use markers from the next time.""",-1
B-2020_U74,,,,"""Nothing in particular.""","""I was wondering about the frequency band when setting up the wireless LAN, and I'm glad I understood the meaning of the frequency band. I'd like to actively use markers from the next time.""",-1
B-2020_U76,"""Specific measures for safe use of smartphones, computers, etc.""","""I learned how to set up on a smartphone or computer, so I want to put it into practice.""",,,,0
B-2020_U76,"""Specific measures for safe use of smartphones, computers, etc.""","""I learned how to set up on a smartphone or computer, so I want to put it into practice.""",,,,0
B-2020_U77,"""Mechanism of passwords, mechanism of WiFi (?), importance of backups, importance of updates, countermeasures in case of emergency""",,,,"""I made a mistake in one question in the quiz (1), and I misread the text.
I wanted to hear more about hash functions. """,0
B-2020_U77,"""Mechanism of passwords, mechanism of WiFi (?), importance of backups, importance of updates, countermeasures in case of emergency""",,,,"""I made a mistake in one question in the quiz (1), and I misread the text.
I wanted to hear more about hash functions. """,0
B-2020_U78,,,,,"""Among the settings introduced in class, there were settings that I hadn't done on my device, so I'm glad I was able to learn about them this time.""",1
B-2020_U79,"""There is no absolute security protection, so it is important to take measures that you can take as much as possible by acquiring the correct knowledge and measures that you can take as an individual.""",,,,,0
B-2020_U8,,"""I learned how the passwords that I used to use casually worked. Also, I was able to learn about the existence of password hashes for the first time. Among wifi, what kind of wifi is dangerous? I was able to know, and I wanted to be careful from now on.""","""I would like to review the second half of the class again and understand it firmly.""",,"""I was able to learn concretely what to do to protect smartphones and computers, which are things that are familiar to us. Also, I learned a lot about how passwords work and what kind of wifi is dangerous, etc. I'm glad I was able to know that.I was also able to understand the importance of updates.From now on, I want to make good use of location information functions and face recognition, and live in an environment where I can feel safe in the information society. .""",1
B-2020_U8,,"""I learned how the passwords that I used to use casually worked. Also, I was able to learn about the existence of password hashes for the first time. Among wifi, what kind of wifi is dangerous? I was able to know, and I wanted to be careful from now on.""","""I would like to review the second half of the class again and understand it firmly.""",,"""I was able to learn concretely what to do to protect smartphones and computers, which are things that are familiar to us. Also, I learned a lot about how passwords work and what kind of wifi is dangerous, etc. I'm glad I was able to know that.I was also able to understand the importance of updates.From now on, I want to make good use of location information functions and face recognition, and live in an environment where I can feel safe in the information society. .""",1
B-2020_U8,,"""I learned how the passwords that I used to use casually worked. Also, I was able to learn about the existence of password hashes for the first time. Among wifi, what kind of wifi is dangerous? I was able to know, and I wanted to be careful from now on.""","""I would like to review the second half of the class again and understand it firmly.""",,"""I was able to learn concretely what to do to protect smartphones and computers, which are things that are familiar to us. Also, I learned a lot about how passwords work and what kind of wifi is dangerous, etc. I'm glad I was able to know that.I was also able to understand the importance of updates.From now on, I want to make good use of location information functions and face recognition, and live in an environment where I can feel safe in the information society. .""",1
B-2020_U80,,,,,"""This is going to be a repeat of the first time, but I used to reuse passwords so I don't forget them, but I'll be more careful in the future. I'll also make a backup.""",0
B-2020_U82,,,"""I wasn't sure about the types of WEP, etc., but I found out that I shouldn't use it.""",,,0
B-2020_U83,,,"""I didn't quite understand the password hash part. I got the gist of it.""","""I'm talking about password hashing, but if I know how to calculate it, will all the passwords using that service be exposed?""","""There are things that I need to be careful about, so I will deal with them as soon as possible.""",0
B-2020_U83,,,"""I didn't quite understand the password hash part. I got the gist of it.""","""I'm talking about password hashing, but if I know how to calculate it, will all the passwords using that service be exposed?""","""There are things that I need to be careful about, so I will deal with them as soon as possible.""",0
B-2020_U83,,,"""I didn't quite understand the password hash part. I got the gist of it.""","""I'm talking about password hashing, but if I know how to calculate it, will all the passwords using that service be exposed?""","""There are things that I need to be careful about, so I will deal with them as soon as possible.""",0
B-2020_U84,,,,,"""If the password is leaked, it can cause big problems. So, I found it important to set up and manage passwords securely.""",-3
B-2020_U85,,,"""I'm not sure about password hashing yet, I'll look into it later.""",,,1
B-2020_U86,"""There is no perfect security method, so knowing about possible threats and taking appropriate measures will help you protect yourself.""","""This is the first time I've used the Find My app on my iPhone.""",,,,1
B-2020_U86,"""There is no perfect security method, so knowing about possible threats and taking appropriate measures will help you protect yourself.""","""This is the first time I've used the Find My app on my iPhone.""",,,,1
B-2020_U87,"""Take care of your own personal information. Do not provide it recklessly or tell others.
It is necessary to protect yourself by taking measures to prevent your personal information from being stolen. """,,,,"""I forgot to prepare for class, so it was a little difficult to keep up with the class.""",0
B-2020_U87,"""Take care of your own personal information. Do not provide it recklessly or tell others.
It is necessary to protect yourself by taking measures to prevent your personal information from being stolen. """,,,,"""I forgot to prepare for class, so it was a little difficult to keep up with the class.""",0
B-2020_U9,"""No matter how good the security software is, it can only deal with existing viruses and cannot deal with newly emerging viruses, so it is important to keep it up-to-date by updating. It is also important to have a backup of your data in case it could be stolen.
It is also a good way to decide on a certain word and add something associated with the service in order to make it easy to remember without reusing the password. ""","""Until now, even when I looked at the update information, I tended to put it off until the next time I have time, but I realized that that's no good. I thought I had to change everything about password settings. I knew it would be good to change some things, so I thought I would do it from now on.""",,,,1
B-2020_U9,"""No matter how good the security software is, it can only deal with existing viruses and cannot deal with newly emerging viruses, so it is important to keep it up-to-date by updating. It is also important to have a backup of your data in case it could be stolen.
It is also a good way to decide on a certain word and add something associated with the service in order to make it easy to remember without reusing the password. ""","""Until now, even when I looked at the update information, I tended to put it off until the next time I have time, but I realized that that's no good. I thought I had to change everything about password settings. I knew it would be good to change some things, so I thought I would do it from now on.""",,,,1
B-2020_U91,"""It was a lot more practical than the previous lecture, and it was very informative. I was able to check my device while taking the lecture, and I learned something for the first time, so it was a lot of surprises.""","""I was able to confirm my device and strengthen security measures.""",,,,0
B-2020_U91,"""It was a lot more practical than the previous lecture, and it was very informative. I was able to check my device while taking the lecture, and I learned something for the first time, so it was a lot of surprises.""","""I was able to confirm my device and strengthen security measures.""",,,,0
B-2020_U92,,,,"""Nothing in particular.""",,1
B-2020_U93,,,"""Nothing in particular""","""Nothing in particular""","""This time was easier than last time.""",-1
B-2020_U93,,,"""Nothing in particular""","""Nothing in particular""","""This time was easier than last time.""",-1
B-2020_U93,,,"""Nothing in particular""","""Nothing in particular""","""This time was easier than last time.""",-1
B-2020_U94,"""Passwords, how wi-fi works""","""I understand how passwords are made unbreakable, mainly hash functions.""",,,,-1
B-2020_U94,"""Passwords, how wi-fi works""","""I understand how passwords are made unbreakable, mainly hash functions.""",,,,-1
C-2021-1_U10,,"""Simply reducing the amount of code does not make the code unique, so it is necessary to investigate the average codeword length and entropy.
The average codeword length of the optimal code can be narrowed down by computation. ""","""The Meaning of the Entropy Formula""",,,-2
C-2021-1_U10,,"""Simply reducing the amount of code does not make the code unique, so it is necessary to investigate the average codeword length and entropy.
The average codeword length of the optimal code can be narrowed down by computation. ""","""The Meaning of the Entropy Formula""",,,-2
C-2021-1_U100,,,"""I didn't know much about entropy.""",,"""It was difficult to understand because there were a lot of words and words that I heard for the first time.""",-2
C-2021-1_U100,,,"""I didn't know much about entropy.""",,"""It was difficult to understand because there were a lot of words and words that I heard for the first time.""",-2
C-2021-1_U101,,"""I was able to understand how to distinguish uniquely decodable codes from those that are not. I was also able to understand prefixes and decoding processes for prefixes.""",,,"""Today's class was more fun than last time because there were more emoticons floating around. I think it's good because I know that it is, and I feel relieved.""",-2
C-2021-1_U101,,"""I was able to understand how to distinguish uniquely decodable codes from those that are not. I was also able to understand prefixes and decoding processes for prefixes.""",,,"""Today's class was more fun than last time because there were more emoticons floating around. I think it's good because I know that it is, and I feel relieved.""",-2
C-2021-1_U102,,"""I was amazed to learn that they are thinking about how to convey information efficiently and accurately.""",,,,-2
C-2021-1_U103,,,"""My understanding of the proof was ambiguous""","""Nothing in particular""","""It was difficult, so I was a little worried about the future.""",-1
C-2021-1_U103,,,"""My understanding of the proof was ambiguous""","""Nothing in particular""","""It was difficult, so I was a little worried about the future.""",-1
C-2021-1_U103,,,"""My understanding of the proof was ambiguous""","""Nothing in particular""","""It was difficult, so I was a little worried about the future.""",-1
C-2021-1_U104,"""I learned how to encode information, what kind of code is suitable for encoding, about entropy, etc.""","""Evaluation criteria for code 1, Unique combination possibility... Code string can be combined in one way 2, Instantaneous combination possibility... Can be combined with only the code that appears 3, Average code word length... · It is better to set a code that can be shortened
The optimal code is the code with the minimum average codeword length, the lower limit of the average codeword length is entropy, and if the average codeword length is in the range of entropy + 1, it is the optimal code.
""",,,,-1
C-2021-1_U104,"""I learned how to encode information, what kind of code is suitable for encoding, about entropy, etc.""","""Evaluation criteria for code 1, Unique combination possibility... Code string can be combined in one way 2, Instantaneous combination possibility... Can be combined with only the code that appears 3, Average code word length... · It is better to set a code that can be shortened
The optimal code is the code with the minimum average codeword length, the lower limit of the average codeword length is entropy, and if the average codeword length is in the range of entropy + 1, it is the optimal code.
""",,,,-1
C-2021-1_U105,"""When encoding an information source, it must be uniquely decodable so that the code can be decoded. Furthermore, in order to decode the code without looking ahead, it is necessary to satisfy the prefix code condition. Such a code is called an instantaneously decodable code.In addition to that, it is important to express it as short as possible, and as a theorem, a uniquely decodable code has a prefix code of the same code length.Also, the average codeword The lower bound of the length is called entropy.　　　　　　　　　　""","""We found that there are various conditions when encoding information. Also, from the theorem, if the average codeword length is the shortest among prefix codes, the average codeword length is the shortest among uniquely decodable codes. I found something. I want to be able to use the calculation formula for the average codeword length and how to output entropy.""","""I think there are codes that satisfy unique decodable codes, prefix conditions, and instantaneous decodable codes, but I couldn't understand the relationship between them. I understood what each word meant, I would like to understand the relationship by referring to the material on page 29.""","""About megabytes, in the world of computers, 1MB = 1,048,576B, and in the world of mathematics, 1MB = 1,000,000B, or is it 1,048,576B anyway?
""","""Compared to last time, I felt that this was a much more complicated topic. The content was difficult and I was unable to keep up with the class, so I thought I'd better prepare well before attending. Code conditions I thought it was interesting to think about and the code tree was easy to understand.""",-1
C-2021-1_U105,"""When encoding an information source, it must be uniquely decodable so that the code can be decoded. Furthermore, in order to decode the code without looking ahead, it is necessary to satisfy the prefix code condition. Such a code is called an instantaneously decodable code.In addition to that, it is important to express it as short as possible, and as a theorem, a uniquely decodable code has a prefix code of the same code length.Also, the average codeword The lower bound of the length is called entropy.　　　　　　　　　　""","""We found that there are various conditions when encoding information. Also, from the theorem, if the average codeword length is the shortest among prefix codes, the average codeword length is the shortest among uniquely decodable codes. I found something. I want to be able to use the calculation formula for the average codeword length and how to output entropy.""","""I think there are codes that satisfy unique decodable codes, prefix conditions, and instantaneous decodable codes, but I couldn't understand the relationship between them. I understood what each word meant, I would like to understand the relationship by referring to the material on page 29.""","""About megabytes, in the world of computers, 1MB = 1,048,576B, and in the world of mathematics, 1MB = 1,000,000B, or is it 1,048,576B anyway?
""","""Compared to last time, I felt that this was a much more complicated topic. The content was difficult and I was unable to keep up with the class, so I thought I'd better prepare well before attending. Code conditions I thought it was interesting to think about and the code tree was easy to understand.""",-1
C-2021-1_U105,"""When encoding an information source, it must be uniquely decodable so that the code can be decoded. Furthermore, in order to decode the code without looking ahead, it is necessary to satisfy the prefix code condition. Such a code is called an instantaneously decodable code.In addition to that, it is important to express it as short as possible, and as a theorem, a uniquely decodable code has a prefix code of the same code length.Also, the average codeword The lower bound of the length is called entropy.　　　　　　　　　　""","""We found that there are various conditions when encoding information. Also, from the theorem, if the average codeword length is the shortest among prefix codes, the average codeword length is the shortest among uniquely decodable codes. I found something. I want to be able to use the calculation formula for the average codeword length and how to output entropy.""","""I think there are codes that satisfy unique decodable codes, prefix conditions, and instantaneous decodable codes, but I couldn't understand the relationship between them. I understood what each word meant, I would like to understand the relationship by referring to the material on page 29.""","""About megabytes, in the world of computers, 1MB = 1,048,576B, and in the world of mathematics, 1MB = 1,000,000B, or is it 1,048,576B anyway?
""","""Compared to last time, I felt that this was a much more complicated topic. The content was difficult and I was unable to keep up with the class, so I thought I'd better prepare well before attending. Code conditions I thought it was interesting to think about and the code tree was easy to understand.""",-1
C-2021-1_U105,"""When encoding an information source, it must be uniquely decodable so that the code can be decoded. Furthermore, in order to decode the code without looking ahead, it is necessary to satisfy the prefix code condition. Such a code is called an instantaneously decodable code.In addition to that, it is important to express it as short as possible, and as a theorem, a uniquely decodable code has a prefix code of the same code length.Also, the average codeword The lower bound of the length is called entropy.　　　　　　　　　　""","""We found that there are various conditions when encoding information. Also, from the theorem, if the average codeword length is the shortest among prefix codes, the average codeword length is the shortest among uniquely decodable codes. I found something. I want to be able to use the calculation formula for the average codeword length and how to output entropy.""","""I think there are codes that satisfy unique decodable codes, prefix conditions, and instantaneous decodable codes, but I couldn't understand the relationship between them. I understood what each word meant, I would like to understand the relationship by referring to the material on page 29.""","""About megabytes, in the world of computers, 1MB = 1,048,576B, and in the world of mathematics, 1MB = 1,000,000B, or is it 1,048,576B anyway?
""","""Compared to last time, I felt that this was a much more complicated topic. The content was difficult and I was unable to keep up with the class, so I thought I'd better prepare well before attending. Code conditions I thought it was interesting to think about and the code tree was easy to understand.""",-1
C-2021-1_U105,"""When encoding an information source, it must be uniquely decodable so that the code can be decoded. Furthermore, in order to decode the code without looking ahead, it is necessary to satisfy the prefix code condition. Such a code is called an instantaneously decodable code.In addition to that, it is important to express it as short as possible, and as a theorem, a uniquely decodable code has a prefix code of the same code length.Also, the average codeword The lower bound of the length is called entropy.　　　　　　　　　　""","""We found that there are various conditions when encoding information. Also, from the theorem, if the average codeword length is the shortest among prefix codes, the average codeword length is the shortest among uniquely decodable codes. I found something. I want to be able to use the calculation formula for the average codeword length and how to output entropy.""","""I think there are codes that satisfy unique decodable codes, prefix conditions, and instantaneous decodable codes, but I couldn't understand the relationship between them. I understood what each word meant, I would like to understand the relationship by referring to the material on page 29.""","""About megabytes, in the world of computers, 1MB = 1,048,576B, and in the world of mathematics, 1MB = 1,000,000B, or is it 1,048,576B anyway?
""","""Compared to last time, I felt that this was a much more complicated topic. The content was difficult and I was unable to keep up with the class, so I thought I'd better prepare well before attending. Code conditions I thought it was interesting to think about and the code tree was easy to understand.""",-1
C-2021-1_U106,,"""Information source code > unique code that can be combined > initial code (= instantaneous code that can be combined)""","""On the lower bound of average word length""",,"""I felt that there were many points that were difficult to understand when thinking about things that are usually recognized by words and pictures as codes.""",-2
C-2021-1_U106,,"""Information source code > unique code that can be combined > initial code (= instantaneous code that can be combined)""","""On the lower bound of average word length""",,"""I felt that there were many points that were difficult to understand when thinking about things that are usually recognized by words and pictures as codes.""",-2
C-2021-1_U106,,"""Information source code > unique code that can be combined > initial code (= instantaneous code that can be combined)""","""On the lower bound of average word length""",,"""I felt that there were many points that were difficult to understand when thinking about things that are usually recognized by words and pictures as codes.""",-2
C-2021-1_U11,"""It is better if the code is unique and can be reversed quickly, but the code conveyed briefly changes according to the information it represents.""","""I learned that it is important to change the code used according to the situation in order to convey a short message.""","""Entropy was difficult.""",,"""The entropy calculation formula was difficult, so I want to review it thoroughly so that I can understand it.""",-3
C-2021-1_U11,"""It is better if the code is unique and can be reversed quickly, but the code conveyed briefly changes according to the information it represents.""","""I learned that it is important to change the code used according to the situation in order to convey a short message.""","""Entropy was difficult.""",,"""The entropy calculation formula was difficult, so I want to review it thoroughly so that I can understand it.""",-3
C-2021-1_U11,"""It is better if the code is unique and can be reversed quickly, but the code conveyed briefly changes according to the information it represents.""","""I learned that it is important to change the code used according to the situation in order to convey a short message.""","""Entropy was difficult.""",,"""The entropy calculation formula was difficult, so I want to review it thoroughly so that I can understand it.""",-3
C-2021-1_U11,"""It is better if the code is unique and can be reversed quickly, but the code conveyed briefly changes according to the information it represents.""","""I learned that it is important to change the code used according to the situation in order to convey a short message.""","""Entropy was difficult.""",,"""The entropy calculation formula was difficult, so I want to review it thoroughly so that I can understand it.""",-3
C-2021-1_U12,"""
Simple rules and conventions for sending information""","""It is important that the code can be restored uniquely and quickly, and the arrangement of white and black is important for returning to the first place. For speed, it is as short as possible, and it is an array that can be deciphered without looking ahead. need to think about
""","""1MG bytes was not 10000 bytes""",,"""There were a lot of difficult words, so I thought I had to help.""",-1
C-2021-1_U12,"""
Simple rules and conventions for sending information""","""It is important that the code can be restored uniquely and quickly, and the arrangement of white and black is important for returning to the first place. For speed, it is as short as possible, and it is an array that can be deciphered without looking ahead. need to think about
""","""1MG bytes was not 10000 bytes""",,"""There were a lot of difficult words, so I thought I had to help.""",-1
C-2021-1_U12,"""
Simple rules and conventions for sending information""","""It is important that the code can be restored uniquely and quickly, and the arrangement of white and black is important for returning to the first place. For speed, it is as short as possible, and it is an array that can be deciphered without looking ahead. need to think about
""","""1MG bytes was not 10000 bytes""",,"""There were a lot of difficult words, so I thought I had to help.""",-1
C-2021-1_U12,"""
Simple rules and conventions for sending information""","""It is important that the code can be restored uniquely and quickly, and the arrangement of white and black is important for returning to the first place. For speed, it is as short as possible, and it is an array that can be deciphered without looking ahead. need to think about
""","""1MG bytes was not 10000 bytes""",,"""There were a lot of difficult words, so I thought I had to help.""",-1
C-2021-1_U13,,"""In addition to the specialized knowledge, I was able to understand the meaning of the codes, and I was able to step into ""information science"" more deeply than last time. ""","""I feel like I haven't made the effort yet to understand the exact meaning.""","""Nothing in particular.""",,-2
C-2021-1_U13,,"""In addition to the specialized knowledge, I was able to understand the meaning of the codes, and I was able to step into ""information science"" more deeply than last time. ""","""I feel like I haven't made the effort yet to understand the exact meaning.""","""Nothing in particular.""",,-2
C-2021-1_U13,,"""In addition to the specialized knowledge, I was able to understand the meaning of the codes, and I was able to step into ""information science"" more deeply than last time. ""","""I feel like I haven't made the effort yet to understand the exact meaning.""","""Nothing in particular.""",,-2
C-2021-1_U15,"""It was a content that seemed to have become a professional content.""","""I could also calculate things like entropy""",,,"""I had fun this time, so I'm looking forward to the next time""",-2
C-2021-1_U15,"""It was a content that seemed to have become a professional content.""","""I could also calculate things like entropy""",,,"""I had fun this time, so I'm looking forward to the next time""",-2
C-2021-1_U15,"""It was a content that seemed to have become a professional content.""","""I could also calculate things like entropy""",,,"""I had fun this time, so I'm looking forward to the next time""",-2
C-2021-1_U16,"""The entropy function is used to measure the amount of information and ambiguity. More information means less ambiguity.
""",,,,,-2
C-2021-1_U17,"""A unique and shortest possible way of describing information transfer""",,,,,-2
C-2021-1_U18,"""A simple explanation of how source coding works and the purpose of source coding.""","""How to use LGC. I clearly understood the contents of the first half of the class, such as the difference between things that are uniquely combinable and things that are not possible.""","""There was a part I didn't understand in the latter half of the story about entropy and about the optimal code.""",,,-2
C-2021-1_U18,"""A simple explanation of how source coding works and the purpose of source coding.""","""How to use LGC. I clearly understood the contents of the first half of the class, such as the difference between things that are uniquely combinable and things that are not possible.""","""There was a part I didn't understand in the latter half of the story about entropy and about the optimal code.""",,,-2
C-2021-1_U18,"""A simple explanation of how source coding works and the purpose of source coding.""","""How to use LGC. I clearly understood the contents of the first half of the class, such as the difference between things that are uniquely combinable and things that are not possible.""","""There was a part I didn't understand in the latter half of the story about entropy and about the optimal code.""",,,-2
C-2021-1_U19,"""The key to source encoding is to express it briefly and undo it uniquely and quickly.""","""The entropy must be less than or equal to the average codeword length.""",,,,-3
C-2021-1_U19,"""The key to source encoding is to express it briefly and undo it uniquely and quickly.""","""The entropy must be less than or equal to the average codeword length.""",,,,-3
C-2021-1_U2,,"""It is now possible to determine whether unique decryption is possible.""","""I lost track of the average codeword length.""",,"""Having examples made it easier to visualize.""",-3
C-2021-1_U2,,"""It is now possible to determine whether unique decryption is possible.""","""I lost track of the average codeword length.""",,"""Having examples made it easier to visualize.""",-3
C-2021-1_U2,,"""It is now possible to determine whether unique decryption is possible.""","""I lost track of the average codeword length.""",,"""Having examples made it easier to visualize.""",-3
C-2021-1_U20,,,,"""Is it correct to assume that only the optimal code has an average word length greater than or equal to entropy and less than entropy + 1?""",,-3
C-2021-1_U21,"""In this lecture, we learned in detail about the encoding of information that we learned last time, 'what is necessary to generate the optimal code'.
・Conditions necessary for encoding information sources using binary numbers
・It is necessary to design a code with a short average codeword length considering probability.
・Properties related to the above probability (entropy)
・Necessity of being uniquely decodable and instantaneously decodable
・Method of encoding in the above format
learned. ""","""I think I have understood most of what I wrote in today's content, and can now understand what an optimal code is and what methods should be used to generate it. ""","""Not particularly.""",,"""I'm glad that this time I didn't miss the class start time like I did last time.
Also, I thought it was a good idea to ask questions about the quiz.
Thank you for your kind reply. """,-1
C-2021-1_U21,"""In this lecture, we learned in detail about the encoding of information that we learned last time, 'what is necessary to generate the optimal code'.
・Conditions necessary for encoding information sources using binary numbers
・It is necessary to design a code with a short average codeword length considering probability.
・Properties related to the above probability (entropy)
・Necessity of being uniquely decodable and instantaneously decodable
・Method of encoding in the above format
learned. ""","""I think I have understood most of what I wrote in today's content, and can now understand what an optimal code is and what methods should be used to generate it. ""","""Not particularly.""",,"""I'm glad that this time I didn't miss the class start time like I did last time.
Also, I thought it was a good idea to ask questions about the quiz.
Thank you for your kind reply. """,-1
C-2021-1_U21,"""In this lecture, we learned in detail about the encoding of information that we learned last time, 'what is necessary to generate the optimal code'.
・Conditions necessary for encoding information sources using binary numbers
・It is necessary to design a code with a short average codeword length considering probability.
・Properties related to the above probability (entropy)
・Necessity of being uniquely decodable and instantaneously decodable
・Method of encoding in the above format
learned. ""","""I think I have understood most of what I wrote in today's content, and can now understand what an optimal code is and what methods should be used to generate it. ""","""Not particularly.""",,"""I'm glad that this time I didn't miss the class start time like I did last time.
Also, I thought it was a good idea to ask questions about the quiz.
Thank you for your kind reply. """,-1
C-2021-1_U21,"""In this lecture, we learned in detail about the encoding of information that we learned last time, 'what is necessary to generate the optimal code'.
・Conditions necessary for encoding information sources using binary numbers
・It is necessary to design a code with a short average codeword length considering probability.
・Properties related to the above probability (entropy)
・Necessity of being uniquely decodable and instantaneously decodable
・Method of encoding in the above format
learned. ""","""I think I have understood most of what I wrote in today's content, and can now understand what an optimal code is and what methods should be used to generate it. ""","""Not particularly.""",,"""I'm glad that this time I didn't miss the class start time like I did last time.
Also, I thought it was a good idea to ask questions about the quiz.
Thank you for your kind reply. """,-1
C-2021-1_U23,,"""In the previous class, when I was thinking about deciphering Morse code, I wondered if there was any concern that different divisions would result in multiple words or sentences. I learned that they are thinking about what to do to avoid such things.""",,,"""I had many doubts during the lecture, but after reviewing it again, I understood it well. The main idea was how to efficiently and accurately encode the information source. I wanted to revisit the theorems and definitions several times later to keep them in my head.""",-3
C-2021-1_U23,,"""In the previous class, when I was thinking about deciphering Morse code, I wondered if there was any concern that different divisions would result in multiple words or sentences. I learned that they are thinking about what to do to avoid such things.""",,,"""I had many doubts during the lecture, but after reviewing it again, I understood it well. The main idea was how to efficiently and accurately encode the information source. I wanted to revisit the theorems and definitions several times later to keep them in my head.""",-3
C-2021-1_U24,"""I learned about sources, source encoding, unique decodability, average codeword length, instantaneous decodability, prefixes, and entropy.""","""I was able to understand what a desirable code is. I was confused at first because there were many similar words such as initial code and average code word length, but I was able to organize them through the lecture.""",,,"""For us humans, we feel that the symbols before encoding are easier to understand than the list of white and black circles, so we once again realized the high information processing ability of the human brain. Just as a computer converts symbols into two types of characters to make them easier to process, we also need to improve our ability to break down difficult matters in our own way so that we can understand them. I thought.""",-1
C-2021-1_U24,"""I learned about sources, source encoding, unique decodability, average codeword length, instantaneous decodability, prefixes, and entropy.""","""I was able to understand what a desirable code is. I was confused at first because there were many similar words such as initial code and average code word length, but I was able to organize them through the lecture.""",,,"""For us humans, we feel that the symbols before encoding are easier to understand than the list of white and black circles, so we once again realized the high information processing ability of the human brain. Just as a computer converts symbols into two types of characters to make them easier to process, we also need to improve our ability to break down difficult matters in our own way so that we can understand them. I thought.""",-1
C-2021-1_U24,"""I learned about sources, source encoding, unique decodability, average codeword length, instantaneous decodability, prefixes, and entropy.""","""I was able to understand what a desirable code is. I was confused at first because there were many similar words such as initial code and average code word length, but I was able to organize them through the lecture.""",,,"""For us humans, we feel that the symbols before encoding are easier to understand than the list of white and black circles, so we once again realized the high information processing ability of the human brain. Just as a computer converts symbols into two types of characters to make them easier to process, we also need to improve our ability to break down difficult matters in our own way so that we can understand them. I thought.""",-1
C-2021-1_U25,"""Source encoding, encoding, how to encode uniquely and instantaneously""","""Initial codes have instantaneous decodability and unique decodability""","""Entropy calculation method, source coding theorem""",,,-2
C-2021-1_U25,"""Source encoding, encoding, how to encode uniquely and instantaneously""","""Initial codes have instantaneous decodability and unique decodability""","""Entropy calculation method, source coding theorem""",,,-2
C-2021-1_U25,"""Source encoding, encoding, how to encode uniquely and instantaneously""","""Initial codes have instantaneous decodability and unique decodability""","""Entropy calculation method, source coding theorem""",,,-2
C-2021-1_U26,"""source encoding
 Points to note when converting information into codes""","""Accuracy of information, speed, and as short as possible, I learned about these three points.
We calculated the probability and found the one with the least information. ""","""I didn't know the sign of the bytes in the quiz.""",,"""I want to review and not forget today's calculations and words.""",0
C-2021-1_U26,"""source encoding
 Points to note when converting information into codes""","""Accuracy of information, speed, and as short as possible, I learned about these three points.
We calculated the probability and found the one with the least information. ""","""I didn't know the sign of the bytes in the quiz.""",,"""I want to review and not forget today's calculations and words.""",0
C-2021-1_U26,"""source encoding
 Points to note when converting information into codes""","""Accuracy of information, speed, and as short as possible, I learned about these three points.
We calculated the probability and found the one with the least information. ""","""I didn't know the sign of the bytes in the quiz.""",,"""I want to review and not forget today's calculations and words.""",0
C-2021-1_U26,"""source encoding
 Points to note when converting information into codes""","""Accuracy of information, speed, and as short as possible, I learned about these three points.
We calculated the probability and found the one with the least information. ""","""I didn't know the sign of the bytes in the quiz.""",,"""I want to review and not forget today's calculations and words.""",0
C-2021-1_U27,,,"""・initial condition
・Initial sign
A code tree (like a code tree diagram?)
・Theorem 1 on page 32
・I don't really understand entropy. ""","""Is entropy a kind of average codeword length?
・I saw the word entropy in a chemistry or physics textbook, but is it the same thing?
・Is enthalpy similar to entropy? """,,-3
C-2021-1_U27,,,"""・initial condition
・Initial sign
A code tree (like a code tree diagram?)
・Theorem 1 on page 32
・I don't really understand entropy. ""","""Is entropy a kind of average codeword length?
・I saw the word entropy in a chemistry or physics textbook, but is it the same thing?
・Is enthalpy similar to entropy? """,,-3
C-2021-1_U28,,,"""Explanation of theorems using entropy""",,,-2
C-2021-1_U29,"""I learned what the information sources, source encodings, unique decodability, instantaneous decodability, desirable codes, lower bounds on average codeword length, and optimal codes are.""","""I learned how to find the average codeword length and how to determine whether or not it can be uniquely restored.""","""Entropy was a bit difficult to understand.""",,"""Entropy is difficult and I don't understand it very well, so I would like to review it by solving problems and try to understand it.""",-1
C-2021-1_U29,"""I learned what the information sources, source encodings, unique decodability, instantaneous decodability, desirable codes, lower bounds on average codeword length, and optimal codes are.""","""I learned how to find the average codeword length and how to determine whether or not it can be uniquely restored.""","""Entropy was a bit difficult to understand.""",,"""Entropy is difficult and I don't understand it very well, so I would like to review it by solving problems and try to understand it.""",-1
C-2021-1_U29,"""I learned what the information sources, source encodings, unique decodability, instantaneous decodability, desirable codes, lower bounds on average codeword length, and optimal codes are.""","""I learned how to find the average codeword length and how to determine whether or not it can be uniquely restored.""","""Entropy was a bit difficult to understand.""",,"""Entropy is difficult and I don't understand it very well, so I would like to review it by solving problems and try to understand it.""",-1
C-2021-1_U29,"""I learned what the information sources, source encodings, unique decodability, instantaneous decodability, desirable codes, lower bounds on average codeword length, and optimal codes are.""","""I learned how to find the average codeword length and how to determine whether or not it can be uniquely restored.""","""Entropy was a bit difficult to understand.""",,"""Entropy is difficult and I don't understand it very well, so I would like to review it by solving problems and try to understand it.""",-1
C-2021-1_U3,,,,,"""I know what the best encoding is, how to find the code length, and how to find the minimum length.""",0
C-2021-1_U30,,,"""Optimal Code Definition""","""It is quite amazing that the average codeword length can be sandwiched between the entropy and the entropy plus 1, so is it okay to recognize that the code at that time is the optimal code?""",,-1
C-2021-1_U30,,,"""Optimal Code Definition""","""It is quite amazing that the average codeword length can be sandwiched between the entropy and the entropy plus 1, so is it okay to recognize that the code at that time is the optimal code?""",,-1
C-2021-1_U31,,"""When sending information, I found that the initial code is used so that the decoding can be done instantaneously, and the entropy and other factors are taken into consideration when encoding so that the average code word tone is shorter.""",,"""Is it unlikely that the average word length of the optimal code matches the entropy?""","""It was a class that was easy to understand, although technical terms were coming out little by little.""",-2
C-2021-1_U31,,"""When sending information, I found that the initial code is used so that the decoding can be done instantaneously, and the entropy and other factors are taken into consideration when encoding so that the average code word tone is shorter.""",,"""Is it unlikely that the average word length of the optimal code matches the entropy?""","""It was a class that was easy to understand, although technical terms were coming out little by little.""",-2
C-2021-1_U31,,"""When sending information, I found that the initial code is used so that the decoding can be done instantaneously, and the entropy and other factors are taken into consideration when encoding so that the average code word tone is shorter.""",,"""Is it unlikely that the average word length of the optimal code matches the entropy?""","""It was a class that was easy to understand, although technical terms were coming out little by little.""",-2
C-2021-1_U32,"""Information is sent after being converted into various forms, but there are many things that need to be taken care of, as it is not just a matter of blind conversion.""",,"""Regarding the previous content, I didn't understand MB in the quiz, so I'd like to review it.""",,"""It took me a long time to understand entropy. Even if it gets difficult, I want to keep up with the class.""",-1
C-2021-1_U32,"""Information is sent after being converted into various forms, but there are many things that need to be taken care of, as it is not just a matter of blind conversion.""",,"""Regarding the previous content, I didn't understand MB in the quiz, so I'd like to review it.""",,"""It took me a long time to understand entropy. Even if it gets difficult, I want to keep up with the class.""",-1
C-2021-1_U32,"""Information is sent after being converted into various forms, but there are many things that need to be taken care of, as it is not just a matter of blind conversion.""",,"""Regarding the previous content, I didn't understand MB in the quiz, so I'd like to review it.""",,"""It took me a long time to understand entropy. Even if it gets difficult, I want to keep up with the class.""",-1
C-2021-1_U33,,"""I found that I could find out if the generated code is correct by applying it to the inequality without finding the average codeword length.""","""I didn't quite understand what the prefix was.""",,,-1
C-2021-1_U33,,"""I found that I could find out if the generated code is correct by applying it to the inequality without finding the average codeword length.""","""I didn't quite understand what the prefix was.""",,,-1
C-2021-1_U34,"""I learned what I needed to do to accurately and quickly decipher the information conveyed by ● and ○, which I learned in the previous lesson.""","""I was able to learn and confirm the calculation of entropy and average code length. However, there were some words that I didn't fully understand the meaning of, so I would like to review them so that I can understand them accurately.""",,,,-1
C-2021-1_U34,"""I learned what I needed to do to accurately and quickly decipher the information conveyed by ● and ○, which I learned in the previous lesson.""","""I was able to learn and confirm the calculation of entropy and average code length. However, there were some words that I didn't fully understand the meaning of, so I would like to review them so that I can understand them accurately.""",,,,-1
C-2021-1_U35,,"""I was able to understand the mechanism behind the encoding of information, which I had vaguely grasped.""",,,"""I would like to work with my own hands to confirm things like calculations where I feel ``Really?'' """,-1
C-2021-1_U35,,"""I was able to understand the mechanism behind the encoding of information, which I had vaguely grasped.""",,,"""I would like to work with my own hands to confirm things like calculations where I feel ``Really?'' """,-1
C-2021-1_U36,"""・ What is an information source?
・Information source coding How can it be shortened?
・What is a word prefix?
・
""","""・Those that output information at regular time intervals
・It is assumed that it can be restored uniquely (unique decryption is possible) and quickly restored.
Those that appear easily → short, those that do not appear easily → long
・Initial code → Unique decodable code that can be instantaneously decodable?
Shorten this
・The lower limit of the length is the entropy
All average codeword lengths are greater than entropy
　The average codeword length of the optimal code is between entropy and entropy + 1
""","""I don't know the best code.""",,"""I made a mistake with the materials I was preparing for, so next time I will check the information carefully before preparing for class.
I was surprised when the log suddenly appeared. I'm trying to find out why this formula works, but it seems difficult. It is interesting that the method of expressing information in a short way can be narrowed down to some extent by calculation rather than fumbling. """,-2
C-2021-1_U36,"""・ What is an information source?
・Information source coding How can it be shortened?
・What is a word prefix?
・
""","""・Those that output information at regular time intervals
・It is assumed that it can be restored uniquely (unique decryption is possible) and quickly restored.
Those that appear easily → short, those that do not appear easily → long
・Initial code → Unique decodable code that can be instantaneously decodable?
Shorten this
・The lower limit of the length is the entropy
All average codeword lengths are greater than entropy
　The average codeword length of the optimal code is between entropy and entropy + 1
""","""I don't know the best code.""",,"""I made a mistake with the materials I was preparing for, so next time I will check the information carefully before preparing for class.
I was surprised when the log suddenly appeared. I'm trying to find out why this formula works, but it seems difficult. It is interesting that the method of expressing information in a short way can be narrowed down to some extent by calculation rather than fumbling. """,-2
C-2021-1_U36,"""・ What is an information source?
・Information source coding How can it be shortened?
・What is a word prefix?
・
""","""・Those that output information at regular time intervals
・It is assumed that it can be restored uniquely (unique decryption is possible) and quickly restored.
Those that appear easily → short, those that do not appear easily → long
・Initial code → Unique decodable code that can be instantaneously decodable?
Shorten this
・The lower limit of the length is the entropy
All average codeword lengths are greater than entropy
　The average codeword length of the optimal code is between entropy and entropy + 1
""","""I don't know the best code.""",,"""I made a mistake with the materials I was preparing for, so next time I will check the information carefully before preparing for class.
I was surprised when the log suddenly appeared. I'm trying to find out why this formula works, but it seems difficult. It is interesting that the method of expressing information in a short way can be narrowed down to some extent by calculation rather than fumbling. """,-2
C-2021-1_U36,"""・ What is an information source?
・Information source coding How can it be shortened?
・What is a word prefix?
・
""","""・Those that output information at regular time intervals
・It is assumed that it can be restored uniquely (unique decryption is possible) and quickly restored.
Those that appear easily → short, those that do not appear easily → long
・Initial code → Unique decodable code that can be instantaneously decodable?
Shorten this
・The lower limit of the length is the entropy
All average codeword lengths are greater than entropy
　The average codeword length of the optimal code is between entropy and entropy + 1
""","""I don't know the best code.""",,"""I made a mistake with the materials I was preparing for, so next time I will check the information carefully before preparing for class.
I was surprised when the log suddenly appeared. I'm trying to find out why this formula works, but it seems difficult. It is interesting that the method of expressing information in a short way can be narrowed down to some extent by calculation rather than fumbling. """,-2
C-2021-1_U37,,,,,"""At first, I could understand it, but my head gradually became confused, so I want to review it again.""",-2
C-2021-1_U38,"""On the relationship between entropy and mathematical probability.""",,,"""nothing especially.
""","""I didn't study much about the n-adic system, so I had a hard time keeping up with the class.""",0
C-2021-1_U38,"""On the relationship between entropy and mathematical probability.""",,,"""nothing especially.
""","""I didn't study much about the n-adic system, so I had a hard time keeping up with the class.""",0
C-2021-1_U38,"""On the relationship between entropy and mathematical probability.""",,,"""nothing especially.
""","""I didn't study much about the n-adic system, so I had a hard time keeping up with the class.""",0
C-2021-1_U39,,"""I understand that the code evaluation criteria are: 1) uniquely undoable, 2) quickly undoable, and 3) express as short as possible.""","""I didn't understand entropy.""",,"""I haven't fully understood it yet, so I thought I'd review it carefully. It was difficult.""",-1
C-2021-1_U39,,"""I understand that the code evaluation criteria are: 1) uniquely undoable, 2) quickly undoable, and 3) express as short as possible.""","""I didn't understand entropy.""",,"""I haven't fully understood it yet, so I thought I'd review it carefully. It was difficult.""",-1
C-2021-1_U39,,"""I understand that the code evaluation criteria are: 1) uniquely undoable, 2) quickly undoable, and 3) express as short as possible.""","""I didn't understand entropy.""",,"""I haven't fully understood it yet, so I thought I'd review it carefully. It was difficult.""",-1
C-2021-1_U40,"""The purpose of source coding is to be uniquely and quickly reversible. Find the shortest average codeword length by narrowing down the initial codes that satisfy this. As a result, the optimal code is obtained.""","""It turns out that entropy is a lower bound on the average codeword length.""","""H(S)+1""",,"""There were so many types of symbols that I got confused.""",-2
C-2021-1_U40,"""The purpose of source coding is to be uniquely and quickly reversible. Find the shortest average codeword length by narrowing down the initial codes that satisfy this. As a result, the optimal code is obtained.""","""It turns out that entropy is a lower bound on the average codeword length.""","""H(S)+1""",,"""There were so many types of symbols that I got confused.""",-2
C-2021-1_U40,"""The purpose of source coding is to be uniquely and quickly reversible. Find the shortest average codeword length by narrowing down the initial codes that satisfy this. As a result, the optimal code is obtained.""","""It turns out that entropy is a lower bound on the average codeword length.""","""H(S)+1""",,"""There were so many types of symbols that I got confused.""",-2
C-2021-1_U40,"""The purpose of source coding is to be uniquely and quickly reversible. Find the shortest average codeword length by narrowing down the initial codes that satisfy this. As a result, the optimal code is obtained.""","""It turns out that entropy is a lower bound on the average codeword length.""","""H(S)+1""",,"""There were so many types of symbols that I got confused.""",-2
C-2021-1_U41,,,,,"""By symbolizing information, a huge amount of information is organized, but I learned that there is a very complicated mechanism and ingenuity behind it.""",-1
C-2021-1_U43,"""I learned about uniquely decodable codes and prefixes.""",,,,,-2
C-2021-1_U44,"""On Source Coding, Codeword Length, and Average Codeword Length""","""It turns out that you can't just decode information by simply encoding it.
I just learned about entropy.
""",,,,0
C-2021-1_U44,"""On Source Coding, Codeword Length, and Average Codeword Length""","""It turns out that you can't just decode information by simply encoding it.
I just learned about entropy.
""",,,,0
C-2021-1_U45,"""Source coding is done on the condition that it can be returned to uniqueness quickly.
If there are two or more ways of decomposing into codewords, it is not uniquely decodable, and the initial code is uniquely decodable. (A prefix is ​​one in which no code can be a prefix of another code.)
The prefix code is also instantaneously decodable. If the prefix code has the smallest average codeword length, then there exists a uniquely decodable symbol with the smallest average codeword length.
The prefix code with the smallest average codeword length is called the optimal code. ""","""It turns out that if there is a symbol only at the end of the code tree, it is a prefix.
I understood it before entropy. ""","""I didn't quite understand the entropy part.
""","""Why is log suddenly appearing at entropy?""","""It was simpler and easier to understand than I expected, but I didn't understand it until I saw the entropy log.
""",-1
C-2021-1_U45,"""Source coding is done on the condition that it can be returned to uniqueness quickly.
If there are two or more ways of decomposing into codewords, it is not uniquely decodable, and the initial code is uniquely decodable. (A prefix is ​​one in which no code can be a prefix of another code.)
The prefix code is also instantaneously decodable. If the prefix code has the smallest average codeword length, then there exists a uniquely decodable symbol with the smallest average codeword length.
The prefix code with the smallest average codeword length is called the optimal code. ""","""It turns out that if there is a symbol only at the end of the code tree, it is a prefix.
I understood it before entropy. ""","""I didn't quite understand the entropy part.
""","""Why is log suddenly appearing at entropy?""","""It was simpler and easier to understand than I expected, but I didn't understand it until I saw the entropy log.
""",-1
C-2021-1_U45,"""Source coding is done on the condition that it can be returned to uniqueness quickly.
If there are two or more ways of decomposing into codewords, it is not uniquely decodable, and the initial code is uniquely decodable. (A prefix is ​​one in which no code can be a prefix of another code.)
The prefix code is also instantaneously decodable. If the prefix code has the smallest average codeword length, then there exists a uniquely decodable symbol with the smallest average codeword length.
The prefix code with the smallest average codeword length is called the optimal code. ""","""It turns out that if there is a symbol only at the end of the code tree, it is a prefix.
I understood it before entropy. ""","""I didn't quite understand the entropy part.
""","""Why is log suddenly appearing at entropy?""","""It was simpler and easier to understand than I expected, but I didn't understand it until I saw the entropy log.
""",-1
C-2021-1_U45,"""Source coding is done on the condition that it can be returned to uniqueness quickly.
If there are two or more ways of decomposing into codewords, it is not uniquely decodable, and the initial code is uniquely decodable. (A prefix is ​​one in which no code can be a prefix of another code.)
The prefix code is also instantaneously decodable. If the prefix code has the smallest average codeword length, then there exists a uniquely decodable symbol with the smallest average codeword length.
The prefix code with the smallest average codeword length is called the optimal code. ""","""It turns out that if there is a symbol only at the end of the code tree, it is a prefix.
I understood it before entropy. ""","""I didn't quite understand the entropy part.
""","""Why is log suddenly appearing at entropy?""","""It was simpler and easier to understand than I expected, but I didn't understand it until I saw the entropy log.
""",-1
C-2021-1_U45,"""Source coding is done on the condition that it can be returned to uniqueness quickly.
If there are two or more ways of decomposing into codewords, it is not uniquely decodable, and the initial code is uniquely decodable. (A prefix is ​​one in which no code can be a prefix of another code.)
The prefix code is also instantaneously decodable. If the prefix code has the smallest average codeword length, then there exists a uniquely decodable symbol with the smallest average codeword length.
The prefix code with the smallest average codeword length is called the optimal code. ""","""It turns out that if there is a symbol only at the end of the code tree, it is a prefix.
I understood it before entropy. ""","""I didn't quite understand the entropy part.
""","""Why is log suddenly appearing at entropy?""","""It was simpler and easier to understand than I expected, but I didn't understand it until I saw the entropy log.
""",-1
C-2021-1_U46,"""There are two types of information sources: stationary and memoryless.
The source encoding must be uniquely reversible quickly. ""","""I understand the purpose of source encoding.""",,,"""I couldn't understand it the first time, so I think I'll review it.""",-2
C-2021-1_U46,"""There are two types of information sources: stationary and memoryless.
The source encoding must be uniquely reversible quickly. ""","""I understand the purpose of source encoding.""",,,"""I couldn't understand it the first time, so I think I'll review it.""",-2
C-2021-1_U46,"""There are two types of information sources: stationary and memoryless.
The source encoding must be uniquely reversible quickly. ""","""I understand the purpose of source encoding.""",,,"""I couldn't understand it the first time, so I think I'll review it.""",-2
C-2021-1_U47,"""There are some information source encodings that cannot be uniquely encoded, so we need to be careful about that. Also, it is important to represent the information in as short a millionaire as possible.""",,,,"""I thought that information technology has been devised in various ways.""",-2
C-2021-1_U47,"""There are some information source encodings that cannot be uniquely encoded, so we need to be careful about that. Also, it is important to represent the information in as short a millionaire as possible.""",,,,"""I thought that information technology has been devised in various ways.""",-2
C-2021-1_U48,"""When encoding information, it is desirable to be able to represent it in the shortest possible time, uniquely and quickly reversible. Sources and code variations will change the average average code length.""","""We found that encoding can be performed efficiently by changing the type of code according to the information to be expressed.""",,,"""I couldn't understand how to calculate the optimal code, so I felt my skills were lacking. However, I was glad that I was able to grasp the image of coding. I was uncomfortable because the chat interfered with my concentration.""",-3
C-2021-1_U48,"""When encoding information, it is desirable to be able to represent it in the shortest possible time, uniquely and quickly reversible. Sources and code variations will change the average average code length.""","""We found that encoding can be performed efficiently by changing the type of code according to the information to be expressed.""",,,"""I couldn't understand how to calculate the optimal code, so I felt my skills were lacking. However, I was glad that I was able to grasp the image of coding. I was uncomfortable because the chat interfered with my concentration.""",-3
C-2021-1_U48,"""When encoding information, it is desirable to be able to represent it in the shortest possible time, uniquely and quickly reversible. Sources and code variations will change the average average code length.""","""We found that encoding can be performed efficiently by changing the type of code according to the information to be expressed.""",,,"""I couldn't understand how to calculate the optimal code, so I felt my skills were lacking. However, I was glad that I was able to grasp the image of coding. I was uncomfortable because the chat interfered with my concentration.""",-3
C-2021-1_U49,"""・Stationary memoryless information source・・・The occurrence probability of the symbol is always the same, and the occurrence probability of the symbol is not affected by the previous expression symbol
A symbol output from a source is represented by only 0s and 1s (source encoding), which is then decoded back to a symbol
・It is desirable to have a code that can only be viewed in one way (unique decodability), can be immediately converted back to a symbol (instantaneous decodability), and is as short as possible (average codeword length is short).
・In order to make it as short as possible, shorten the code of items with high occurrence probability.""","""・The output contents are changed to two types of codes and sent
・In order to shorten the code as much as possible, it is necessary to change the code of each symbol according to the occurrence probability.
・When arranging the codes, it must be possible to interpret only one way, and the word length must be short, but it seems difficult.
・ I thought that the word prefix could be immediately converted back to a symbol, but the word length would be long.""","""I didn't understand the entropy passage at all, and I didn't understand what I didn't understand.
""",,"""By the next time, I hope to improve my understanding and interpretation of entropy.""",-2
C-2021-1_U49,"""・Stationary memoryless information source・・・The occurrence probability of the symbol is always the same, and the occurrence probability of the symbol is not affected by the previous expression symbol
A symbol output from a source is represented by only 0s and 1s (source encoding), which is then decoded back to a symbol
・It is desirable to have a code that can only be viewed in one way (unique decodability), can be immediately converted back to a symbol (instantaneous decodability), and is as short as possible (average codeword length is short).
・In order to make it as short as possible, shorten the code of items with high occurrence probability.""","""・The output contents are changed to two types of codes and sent
・In order to shorten the code as much as possible, it is necessary to change the code of each symbol according to the occurrence probability.
・When arranging the codes, it must be possible to interpret only one way, and the word length must be short, but it seems difficult.
・ I thought that the word prefix could be immediately converted back to a symbol, but the word length would be long.""","""I didn't understand the entropy passage at all, and I didn't understand what I didn't understand.
""",,"""By the next time, I hope to improve my understanding and interpretation of entropy.""",-2
C-2021-1_U49,"""・Stationary memoryless information source・・・The occurrence probability of the symbol is always the same, and the occurrence probability of the symbol is not affected by the previous expression symbol
A symbol output from a source is represented by only 0s and 1s (source encoding), which is then decoded back to a symbol
・It is desirable to have a code that can only be viewed in one way (unique decodability), can be immediately converted back to a symbol (instantaneous decodability), and is as short as possible (average codeword length is short).
・In order to make it as short as possible, shorten the code of items with high occurrence probability.""","""・The output contents are changed to two types of codes and sent
・In order to shorten the code as much as possible, it is necessary to change the code of each symbol according to the occurrence probability.
・When arranging the codes, it must be possible to interpret only one way, and the word length must be short, but it seems difficult.
・ I thought that the word prefix could be immediately converted back to a symbol, but the word length would be long.""","""I didn't understand the entropy passage at all, and I didn't understand what I didn't understand.
""",,"""By the next time, I hope to improve my understanding and interpretation of entropy.""",-2
C-2021-1_U49,"""・Stationary memoryless information source・・・The occurrence probability of the symbol is always the same, and the occurrence probability of the symbol is not affected by the previous expression symbol
A symbol output from a source is represented by only 0s and 1s (source encoding), which is then decoded back to a symbol
・It is desirable to have a code that can only be viewed in one way (unique decodability), can be immediately converted back to a symbol (instantaneous decodability), and is as short as possible (average codeword length is short).
・In order to make it as short as possible, shorten the code of items with high occurrence probability.""","""・The output contents are changed to two types of codes and sent
・In order to shorten the code as much as possible, it is necessary to change the code of each symbol according to the occurrence probability.
・When arranging the codes, it must be possible to interpret only one way, and the word length must be short, but it seems difficult.
・ I thought that the word prefix could be immediately converted back to a symbol, but the word length would be long.""","""I didn't understand the entropy passage at all, and I didn't understand what I didn't understand.
""",,"""By the next time, I hope to improve my understanding and interpretation of entropy.""",-2
C-2021-1_U50,,"""We've found that a good encoding should be uniquely reversible, be reversible quickly, and be as short as possible.""","""I was confused about how many bytes are in 1GB of the quiz. Also, entropy was difficult.""",,"""I learned that it is important to use methods such as prefixes and entropy to achieve desirable encoding. I would like to deepen my understanding by doing actual calculation problems.""",0
C-2021-1_U50,,"""We've found that a good encoding should be uniquely reversible, be reversible quickly, and be as short as possible.""","""I was confused about how many bytes are in 1GB of the quiz. Also, entropy was difficult.""",,"""I learned that it is important to use methods such as prefixes and entropy to achieve desirable encoding. I would like to deepen my understanding by doing actual calculation problems.""",0
C-2021-1_U50,,"""We've found that a good encoding should be uniquely reversible, be reversible quickly, and be as short as possible.""","""I was confused about how many bytes are in 1GB of the quiz. Also, entropy was difficult.""",,"""I learned that it is important to use methods such as prefixes and entropy to achieve desirable encoding. I would like to deepen my understanding by doing actual calculation problems.""",0
C-2021-1_U51,,"""I found that as I pursued the encoding of 'short' information, multiple ways of perceiving that information would eventually arise. ""","""I didn't understand why you could find the entropy by taking the logarithm (even if that's the definition).
""",,"""I thought it was necessary to have the ability to discern whether multiple events were occurring when encoding information or doing similar work.""",-2
C-2021-1_U51,,"""I found that as I pursued the encoding of 'short' information, multiple ways of perceiving that information would eventually arise. ""","""I didn't understand why you could find the entropy by taking the logarithm (even if that's the definition).
""",,"""I thought it was necessary to have the ability to discern whether multiple events were occurring when encoding information or doing similar work.""",-2
C-2021-1_U51,,"""I found that as I pursued the encoding of 'short' information, multiple ways of perceiving that information would eventually arise. ""","""I didn't understand why you could find the entropy by taking the logarithm (even if that's the definition).
""",,"""I thought it was necessary to have the ability to discern whether multiple events were occurring when encoding information or doing similar work.""",-2
C-2021-1_U52,"""About Encoded Information""","""How to calculate the average code length, etc.""","""The prefix code must not be a code with a short average code length""",,"""Sometimes there were things I didn't understand. I think that the method of calculating the average code length will be questioned in the future, so I want to learn it well.""",0
C-2021-1_U52,"""About Encoded Information""","""How to calculate the average code length, etc.""","""The prefix code must not be a code with a short average code length""",,"""Sometimes there were things I didn't understand. I think that the method of calculating the average code length will be questioned in the future, so I want to learn it well.""",0
C-2021-1_U52,"""About Encoded Information""","""How to calculate the average code length, etc.""","""The prefix code must not be a code with a short average code length""",,"""Sometimes there were things I didn't understand. I think that the method of calculating the average code length will be questioned in the future, so I want to learn it well.""",0
C-2021-1_U52,"""About Encoded Information""","""How to calculate the average code length, etc.""","""The prefix code must not be a code with a short average code length""",,"""Sometimes there were things I didn't understand. I think that the method of calculating the average code length will be questioned in the future, so I want to learn it well.""",0
C-2021-1_U53,,,"""Converting kilobytes to bytes isn't perfect yet, so I'd like to do some research myself.""","""Not particularly.""","""It was very interesting to see how many symbols and probabilities are used in weather forecasts and Sazae-san's rock-paper-scissors, which we often see. In terms of how to reduce the number of bits in weather forecasts, white circles and black circles are used. It was very interesting to see how they would line up.""",-2
C-2021-1_U53,,,"""Converting kilobytes to bytes isn't perfect yet, so I'd like to do some research myself.""","""Not particularly.""","""It was very interesting to see how many symbols and probabilities are used in weather forecasts and Sazae-san's rock-paper-scissors, which we often see. In terms of how to reduce the number of bits in weather forecasts, white circles and black circles are used. It was very interesting to see how they would line up.""",-2
C-2021-1_U53,,,"""Converting kilobytes to bytes isn't perfect yet, so I'd like to do some research myself.""","""Not particularly.""","""It was very interesting to see how many symbols and probabilities are used in weather forecasts and Sazae-san's rock-paper-scissors, which we often see. In terms of how to reduce the number of bits in weather forecasts, white circles and black circles are used. It was very interesting to see how they would line up.""",-2
C-2021-1_U54,"""We learned about the encoding of information sources using the weather forecast as an example. It uses black and white circles as codes, and is represented by a string of combinations. The purpose of this source coding is to design the information as a sequence of shorter codes that can be decoded uniquely and instantaneously. What is called a word prefix code.More desirable is to express it as short as possible.For that reason, by considering the word length and entropy of the code, the lower limit of the word length is calculated and the optimum encoding is achieved. .""","""How is information encoded and how is it better encoded?""",,,,-2
C-2021-1_U54,"""We learned about the encoding of information sources using the weather forecast as an example. It uses black and white circles as codes, and is represented by a string of combinations. The purpose of this source coding is to design the information as a sequence of shorter codes that can be decoded uniquely and instantaneously. What is called a word prefix code.More desirable is to express it as short as possible.For that reason, by considering the word length and entropy of the code, the lower limit of the word length is calculated and the optimum encoding is achieved. .""","""How is information encoded and how is it better encoded?""",,,,-2
C-2021-1_U56,"""Entropy is what we need when encoding information sources: unique decodability, instantaneous decodability, and short average codeword length.""","""It turns out that it's not just a matter of the information being encoded as short as possible, but that it must be uniquely and quickly encoded, and that they maintain the accuracy of the information.""","""I couldn't understand why the average codeword length of the optimal code for S satisfies 'H[S]≤L[C*]<H[S]+1' when S is an arbitrary information source. """,,"""Since this was the second class, I was able to use the electronic textbook better than the last time.""",-1
C-2021-1_U56,"""Entropy is what we need when encoding information sources: unique decodability, instantaneous decodability, and short average codeword length.""","""It turns out that it's not just a matter of the information being encoded as short as possible, but that it must be uniquely and quickly encoded, and that they maintain the accuracy of the information.""","""I couldn't understand why the average codeword length of the optimal code for S satisfies 'H[S]≤L[C*]<H[S]+1' when S is an arbitrary information source. """,,"""Since this was the second class, I was able to use the electronic textbook better than the last time.""",-1
C-2021-1_U56,"""Entropy is what we need when encoding information sources: unique decodability, instantaneous decodability, and short average codeword length.""","""It turns out that it's not just a matter of the information being encoded as short as possible, but that it must be uniquely and quickly encoded, and that they maintain the accuracy of the information.""","""I couldn't understand why the average codeword length of the optimal code for S satisfies 'H[S]≤L[C*]<H[S]+1' when S is an arbitrary information source. """,,"""Since this was the second class, I was able to use the electronic textbook better than the last time.""",-1
C-2021-1_U56,"""Entropy is what we need when encoding information sources: unique decodability, instantaneous decodability, and short average codeword length.""","""It turns out that it's not just a matter of the information being encoded as short as possible, but that it must be uniquely and quickly encoded, and that they maintain the accuracy of the information.""","""I couldn't understand why the average codeword length of the optimal code for S satisfies 'H[S]≤L[C*]<H[S]+1' when S is an arbitrary information source. """,,"""Since this was the second class, I was able to use the electronic textbook better than the last time.""",-1
C-2021-1_U57,"""In source coding, codes with short average codeword length must be designed according to the probability distribution
Also, as a premise, it is important to be able to decrypt uniquely and quickly.""","""The advantages of prefix codes are unique decodability and instantaneous decodability""",,,,0
C-2021-1_U57,"""In source coding, codes with short average codeword length must be designed according to the probability distribution
Also, as a premise, it is important to be able to decrypt uniquely and quickly.""","""The advantages of prefix codes are unique decodability and instantaneous decodability""",,,,0
C-2021-1_U58,,,"""There were many definitions of words I heard for the first time, and I got a little mixed up in the second half. It was good because I understood it after reviewing the textbook.""",,"""For the unfamiliar term average codeword length, I was able to think from multiple perspectives such as entropy and optimal code.""",-3
C-2021-1_U58,,,"""There were many definitions of words I heard for the first time, and I got a little mixed up in the second half. It was good because I understood it after reviewing the textbook.""",,"""For the unfamiliar term average codeword length, I was able to think from multiple perspectives such as entropy and optimal code.""",-3
C-2021-1_U59,"""A string of symbols generated from an information source is represented by a string of ○ and ● by source encoding, and the string is decoded to return to the original symbol string. Decodability (uniquely reversible), instantaneous decodability (quick reversal), and average codeword length (expressed as short as possible) are important.""","""Initial codes are uniquely decodable and instantaneously decodable.
Entropy is a lower bound on the average codeword length.
Of the initial codes C for any information source S, the one with the smallest average code length is called the optimum code. """,,,"""It was the first time I learned about source coding in detail and it was difficult, but I'm glad I learned a lot.
There are some theorems that I didn't fully understand, so in the next class, I wanted to work harder so that I could understand what I had learned. """,-1
C-2021-1_U59,"""A string of symbols generated from an information source is represented by a string of ○ and ● by source encoding, and the string is decoded to return to the original symbol string. Decodability (uniquely reversible), instantaneous decodability (quick reversal), and average codeword length (expressed as short as possible) are important.""","""Initial codes are uniquely decodable and instantaneously decodable.
Entropy is a lower bound on the average codeword length.
Of the initial codes C for any information source S, the one with the smallest average code length is called the optimum code. """,,,"""It was the first time I learned about source coding in detail and it was difficult, but I'm glad I learned a lot.
There are some theorems that I didn't fully understand, so in the next class, I wanted to work harder so that I could understand what I had learned. """,-1
C-2021-1_U59,"""A string of symbols generated from an information source is represented by a string of ○ and ● by source encoding, and the string is decoded to return to the original symbol string. Decodability (uniquely reversible), instantaneous decodability (quick reversal), and average codeword length (expressed as short as possible) are important.""","""Initial codes are uniquely decodable and instantaneously decodable.
Entropy is a lower bound on the average codeword length.
Of the initial codes C for any information source S, the one with the smallest average code length is called the optimum code. """,,,"""It was the first time I learned about source coding in detail and it was difficult, but I'm glad I learned a lot.
There are some theorems that I didn't fully understand, so in the next class, I wanted to work harder so that I could understand what I had learned. """,-1
C-2021-1_U6,"""Method of setting codewords for appropriate codes Relationship between average codeword length and entropy""",,,,,-3
C-2021-1_U60,,,,,"""Was funny.""",-1
C-2021-1_U61,"""There are various methods of encoding an information source, and we find the probability of occurrence so that the encoding of the entire information is as short as possible and the one that makes it easy to return to the original information.
Depending on the encoding method, there may be two ways to restore the original information. ""","""I'm trying to describe the source of the information in the simplest and shortest possible way. I didn't know what kind of code was called a prefix, but I figured it out by looking at an example of a non-initial.""","""There are many types of codes when encoding information sources, and it is difficult to distinguish between the types of codes.""",,,-2
C-2021-1_U61,"""There are various methods of encoding an information source, and we find the probability of occurrence so that the encoding of the entire information is as short as possible and the one that makes it easy to return to the original information.
Depending on the encoding method, there may be two ways to restore the original information. ""","""I'm trying to describe the source of the information in the simplest and shortest possible way. I didn't know what kind of code was called a prefix, but I figured it out by looking at an example of a non-initial.""","""There are many types of codes when encoding information sources, and it is difficult to distinguish between the types of codes.""",,,-2
C-2021-1_U61,"""There are various methods of encoding an information source, and we find the probability of occurrence so that the encoding of the entire information is as short as possible and the one that makes it easy to return to the original information.
Depending on the encoding method, there may be two ways to restore the original information. ""","""I'm trying to describe the source of the information in the simplest and shortest possible way. I didn't know what kind of code was called a prefix, but I figured it out by looking at an example of a non-initial.""","""There are many types of codes when encoding information sources, and it is difficult to distinguish between the types of codes.""",,,-2
C-2021-1_U62,"""I learned how 0's and 1's convey a lot of information concisely and accurately.""","""I found a concrete way to find the optimal code.""",,,,-1
C-2021-1_U62,"""I learned how 0's and 1's convey a lot of information concisely and accurately.""","""I found a concrete way to find the optimal code.""",,,,-1
C-2021-1_U63,"""When considering the decoding of the information source, it is important to consider how to shorten the code and how quickly it can be returned to the information source. Also, even if there is only one (=uniquely decodable code), it is assumed that it will take time if it cannot be decoded without prefetching (≠instantaneously decodable code). A prefix code is a codeword that is not prefixed by another code, is instantly decodable, and the prefix code with the smallest average codeword tone is the smallest uniquely decodable code. The average codeword tone has a lower bound called the entropy determined by the formula.""","""For any uniquely decodable code, there must be a prefix with the same codeword tone. At first I didn't understand what you were saying, but after listening to the explanation, I understood.""","""I couldn't keep up with the average codeword tone and entropy (p40~). (Added on 4/20 I understand a little)""",,"""I couldn't keep up with the last one, but I'll review it by next week and check it slowly. I didn't do the exercises last week, so I'll definitely do it this week.""",-1
C-2021-1_U63,"""When considering the decoding of the information source, it is important to consider how to shorten the code and how quickly it can be returned to the information source. Also, even if there is only one (=uniquely decodable code), it is assumed that it will take time if it cannot be decoded without prefetching (≠instantaneously decodable code). A prefix code is a codeword that is not prefixed by another code, is instantly decodable, and the prefix code with the smallest average codeword tone is the smallest uniquely decodable code. The average codeword tone has a lower bound called the entropy determined by the formula.""","""For any uniquely decodable code, there must be a prefix with the same codeword tone. At first I didn't understand what you were saying, but after listening to the explanation, I understood.""","""I couldn't keep up with the average codeword tone and entropy (p40~). (Added on 4/20 I understand a little)""",,"""I couldn't keep up with the last one, but I'll review it by next week and check it slowly. I didn't do the exercises last week, so I'll definitely do it this week.""",-1
C-2021-1_U63,"""When considering the decoding of the information source, it is important to consider how to shorten the code and how quickly it can be returned to the information source. Also, even if there is only one (=uniquely decodable code), it is assumed that it will take time if it cannot be decoded without prefetching (≠instantaneously decodable code). A prefix code is a codeword that is not prefixed by another code, is instantly decodable, and the prefix code with the smallest average codeword tone is the smallest uniquely decodable code. The average codeword tone has a lower bound called the entropy determined by the formula.""","""For any uniquely decodable code, there must be a prefix with the same codeword tone. At first I didn't understand what you were saying, but after listening to the explanation, I understood.""","""I couldn't keep up with the average codeword tone and entropy (p40~). (Added on 4/20 I understand a little)""",,"""I couldn't keep up with the last one, but I'll review it by next week and check it slowly. I didn't do the exercises last week, so I'll definitely do it this week.""",-1
C-2021-1_U63,"""When considering the decoding of the information source, it is important to consider how to shorten the code and how quickly it can be returned to the information source. Also, even if there is only one (=uniquely decodable code), it is assumed that it will take time if it cannot be decoded without prefetching (≠instantaneously decodable code). A prefix code is a codeword that is not prefixed by another code, is instantly decodable, and the prefix code with the smallest average codeword tone is the smallest uniquely decodable code. The average codeword tone has a lower bound called the entropy determined by the formula.""","""For any uniquely decodable code, there must be a prefix with the same codeword tone. At first I didn't understand what you were saying, but after listening to the explanation, I understood.""","""I couldn't keep up with the average codeword tone and entropy (p40~). (Added on 4/20 I understand a little)""",,"""I couldn't keep up with the last one, but I'll review it by next week and check it slowly. I didn't do the exercises last week, so I'll definitely do it this week.""",-1
C-2021-1_U64,"""There is more than one type of code that can transmit information, and the speed changes depending on what type of code is used.""",,,,"""It was interesting to learn that shortening the individual lengths (C1 example) may not be the fastest transfer, depending on the probability.""",0
C-2021-1_U64,"""There is more than one type of code that can transmit information, and the speed changes depending on what type of code is used.""",,,,"""It was interesting to learn that shortening the individual lengths (C1 example) may not be the fastest transfer, depending on the probability.""",0
C-2021-1_U65,"""It's important to be uniquely quick and short.""",,,,,-1
C-2021-1_U66,,,,,"""I regret that I got stuck in terms like entropy and that I failed one question in the test.""",-1
C-2021-1_U67,"""Encoding of information source　Calculation of average code length　The codeword length is as short as possible, unique and can be returned quickly　Definition of average codeword length L(C)　Definition of entropy H(S)　　
""","""L(C)=p1l1+…+pnln
H(S)=p1(-log2p1)+...+pn(-log2pn)
L(C) less than H(S)
H(C) L(C*) H(S)+1""",,,,-2
C-2021-1_U67,"""Encoding of information source　Calculation of average code length　The codeword length is as short as possible, unique and can be returned quickly　Definition of average codeword length L(C)　Definition of entropy H(S)　　
""","""L(C)=p1l1+…+pnln
H(S)=p1(-log2p1)+...+pn(-log2pn)
L(C) less than H(S)
H(C) L(C*) H(S)+1""",,,,-2
C-2021-1_U68,"""In source coding, multiple codewords can be considered, but in order to be efficient, it is important to be uniquely combinable, to be instantaneously combinable, and to be as short as possible.""","""Because codewords are used, it is possible to reduce the amount of data and shorten the time it takes to read data by determining the optimal one. Therefore, it is important to use prefixes and the like.""","""I'm a little uneasy about understanding parts that involve calculations, such as entropy.""",,"""I thought that the way the codewords are combined becomes more important as the data gets bigger.""",-2
C-2021-1_U68,"""In source coding, multiple codewords can be considered, but in order to be efficient, it is important to be uniquely combinable, to be instantaneously combinable, and to be as short as possible.""","""Because codewords are used, it is possible to reduce the amount of data and shorten the time it takes to read data by determining the optimal one. Therefore, it is important to use prefixes and the like.""","""I'm a little uneasy about understanding parts that involve calculations, such as entropy.""",,"""I thought that the way the codewords are combined becomes more important as the data gets bigger.""",-2
C-2021-1_U68,"""In source coding, multiple codewords can be considered, but in order to be efficient, it is important to be uniquely combinable, to be instantaneously combinable, and to be as short as possible.""","""Because codewords are used, it is possible to reduce the amount of data and shorten the time it takes to read data by determining the optimal one. Therefore, it is important to use prefixes and the like.""","""I'm a little uneasy about understanding parts that involve calculations, such as entropy.""",,"""I thought that the way the codewords are combined becomes more important as the data gets bigger.""",-2
C-2021-1_U68,"""In source coding, multiple codewords can be considered, but in order to be efficient, it is important to be uniquely combinable, to be instantaneously combinable, and to be as short as possible.""","""Because codewords are used, it is possible to reduce the amount of data and shorten the time it takes to read data by determining the optimal one. Therefore, it is important to use prefixes and the like.""","""I'm a little uneasy about understanding parts that involve calculations, such as entropy.""",,"""I thought that the way the codewords are combined becomes more important as the data gets bigger.""",-2
C-2021-1_U69,"""In encoding the information source, short codes are assigned to codes that are likely to occur, and relatively long codes are assigned to codes that are less likely to occur, in order to represent the information source with as short codes as possible. Initial codes are used to uniquely and quickly decode the codes. Average The concept of entropy is used to shorten the code length.""","""It just so happens that 1 byte is 8 bits. The reason there are no signals other than 0 or 1 is that it is difficult to receive complex signals. I learned for the first time that it is necessary to be able to decode instantaneously without being ahead of the curve. Average code The lower bound of the length can be roughly calculated.""","""Why is the entropy formula that way?
Why do prefix codes have the same length as arbitrary unique recoverable codes? ""","""Nothing in particular.""","""This time I entered with an account that was not a guest. It's easy to use a few patterns of symbols like the ones we learned in class, but I thought it would be difficult to think of codes that correspond to many symbols such as letters. Signals other than 0 and 1. If it becomes possible to use it, it will be extremely convenient.""",-3
C-2021-1_U69,"""In encoding the information source, short codes are assigned to codes that are likely to occur, and relatively long codes are assigned to codes that are less likely to occur, in order to represent the information source with as short codes as possible. Initial codes are used to uniquely and quickly decode the codes. Average The concept of entropy is used to shorten the code length.""","""It just so happens that 1 byte is 8 bits. The reason there are no signals other than 0 or 1 is that it is difficult to receive complex signals. I learned for the first time that it is necessary to be able to decode instantaneously without being ahead of the curve. Average code The lower bound of the length can be roughly calculated.""","""Why is the entropy formula that way?
Why do prefix codes have the same length as arbitrary unique recoverable codes? ""","""Nothing in particular.""","""This time I entered with an account that was not a guest. It's easy to use a few patterns of symbols like the ones we learned in class, but I thought it would be difficult to think of codes that correspond to many symbols such as letters. Signals other than 0 and 1. If it becomes possible to use it, it will be extremely convenient.""",-3
C-2021-1_U69,"""In encoding the information source, short codes are assigned to codes that are likely to occur, and relatively long codes are assigned to codes that are less likely to occur, in order to represent the information source with as short codes as possible. Initial codes are used to uniquely and quickly decode the codes. Average The concept of entropy is used to shorten the code length.""","""It just so happens that 1 byte is 8 bits. The reason there are no signals other than 0 or 1 is that it is difficult to receive complex signals. I learned for the first time that it is necessary to be able to decode instantaneously without being ahead of the curve. Average code The lower bound of the length can be roughly calculated.""","""Why is the entropy formula that way?
Why do prefix codes have the same length as arbitrary unique recoverable codes? ""","""Nothing in particular.""","""This time I entered with an account that was not a guest. It's easy to use a few patterns of symbols like the ones we learned in class, but I thought it would be difficult to think of codes that correspond to many symbols such as letters. Signals other than 0 and 1. If it becomes possible to use it, it will be extremely convenient.""",-3
C-2021-1_U69,"""In encoding the information source, short codes are assigned to codes that are likely to occur, and relatively long codes are assigned to codes that are less likely to occur, in order to represent the information source with as short codes as possible. Initial codes are used to uniquely and quickly decode the codes. Average The concept of entropy is used to shorten the code length.""","""It just so happens that 1 byte is 8 bits. The reason there are no signals other than 0 or 1 is that it is difficult to receive complex signals. I learned for the first time that it is necessary to be able to decode instantaneously without being ahead of the curve. Average code The lower bound of the length can be roughly calculated.""","""Why is the entropy formula that way?
Why do prefix codes have the same length as arbitrary unique recoverable codes? ""","""Nothing in particular.""","""This time I entered with an account that was not a guest. It's easy to use a few patterns of symbols like the ones we learned in class, but I thought it would be difficult to think of codes that correspond to many symbols such as letters. Signals other than 0 and 1. If it becomes possible to use it, it will be extremely convenient.""",-3
C-2021-1_U69,"""In encoding the information source, short codes are assigned to codes that are likely to occur, and relatively long codes are assigned to codes that are less likely to occur, in order to represent the information source with as short codes as possible. Initial codes are used to uniquely and quickly decode the codes. Average The concept of entropy is used to shorten the code length.""","""It just so happens that 1 byte is 8 bits. The reason there are no signals other than 0 or 1 is that it is difficult to receive complex signals. I learned for the first time that it is necessary to be able to decode instantaneously without being ahead of the curve. Average code The lower bound of the length can be roughly calculated.""","""Why is the entropy formula that way?
Why do prefix codes have the same length as arbitrary unique recoverable codes? ""","""Nothing in particular.""","""This time I entered with an account that was not a guest. It's easy to use a few patterns of symbols like the ones we learned in class, but I thought it would be difficult to think of codes that correspond to many symbols such as letters. Signals other than 0 and 1. If it becomes possible to use it, it will be extremely convenient.""",-3
C-2021-1_U7,"""I want to convey information by making the arrangement of ○ and ● as short as possible, but depending on how they are arranged, it is not possible to specify the information I want to convey.
For example, when A:○, B:●, C:○●, D:●○　, you want to say ABCD(○/●/○●/●○), but CCBA(○●/○●/●/ ○), etc.
""","""I understand what you wrote in (1)""",,,,0
C-2021-1_U7,"""I want to convey information by making the arrangement of ○ and ● as short as possible, but depending on how they are arranged, it is not possible to specify the information I want to convey.
For example, when A:○, B:●, C:○●, D:●○　, you want to say ABCD(○/●/○●/●○), but CCBA(○●/○●/●/ ○), etc.
""","""I understand what you wrote in (1)""",,,,0
C-2021-1_U70,"""A rough overview of codes and combinations, how to determine uniqueness or non-uniqueness, comparison of lengths of encodings, prefix codes can be uniquely and instantaneously combined, calculation of average codeword length and entropy""",,,,,-1
C-2021-1_U71,"""I learned about source coding.
A prefix code is a code that can be uniquely and instantaneously decoded and that can minimize the average codeword length.
We learned to evaluate using entropy as a measure of the minimum average codeword length. ""","""I was able to learn the criteria for judging how a source should be encoded.""","""Nothing in particular.""","""For some information, is it possible to make the shortest codeword length smaller than the original information by considering some pairs of the information as new information?
For example, in the case of fine weather, cloudy weather, rainy weather, and snowy weather this time, the question is whether the average codeword length can be reduced by defining codes for fine weather, sunny cloudy weather, sunny rain, ..., snow and snow.
When the probability of occurrence does not depend on the previous state, as in this example, I feel that it will not be small, but I wondered what would happen if the probability of occurrence is not independent, such as in general weather. """,,-2
C-2021-1_U71,"""I learned about source coding.
A prefix code is a code that can be uniquely and instantaneously decoded and that can minimize the average codeword length.
We learned to evaluate using entropy as a measure of the minimum average codeword length. ""","""I was able to learn the criteria for judging how a source should be encoded.""","""Nothing in particular.""","""For some information, is it possible to make the shortest codeword length smaller than the original information by considering some pairs of the information as new information?
For example, in the case of fine weather, cloudy weather, rainy weather, and snowy weather this time, the question is whether the average codeword length can be reduced by defining codes for fine weather, sunny cloudy weather, sunny rain, ..., snow and snow.
When the probability of occurrence does not depend on the previous state, as in this example, I feel that it will not be small, but I wondered what would happen if the probability of occurrence is not independent, such as in general weather. """,,-2
C-2021-1_U71,"""I learned about source coding.
A prefix code is a code that can be uniquely and instantaneously decoded and that can minimize the average codeword length.
We learned to evaluate using entropy as a measure of the minimum average codeword length. ""","""I was able to learn the criteria for judging how a source should be encoded.""","""Nothing in particular.""","""For some information, is it possible to make the shortest codeword length smaller than the original information by considering some pairs of the information as new information?
For example, in the case of fine weather, cloudy weather, rainy weather, and snowy weather this time, the question is whether the average codeword length can be reduced by defining codes for fine weather, sunny cloudy weather, sunny rain, ..., snow and snow.
When the probability of occurrence does not depend on the previous state, as in this example, I feel that it will not be small, but I wondered what would happen if the probability of occurrence is not independent, such as in general weather. """,,-2
C-2021-1_U71,"""I learned about source coding.
A prefix code is a code that can be uniquely and instantaneously decoded and that can minimize the average codeword length.
We learned to evaluate using entropy as a measure of the minimum average codeword length. ""","""I was able to learn the criteria for judging how a source should be encoded.""","""Nothing in particular.""","""For some information, is it possible to make the shortest codeword length smaller than the original information by considering some pairs of the information as new information?
For example, in the case of fine weather, cloudy weather, rainy weather, and snowy weather this time, the question is whether the average codeword length can be reduced by defining codes for fine weather, sunny cloudy weather, sunny rain, ..., snow and snow.
When the probability of occurrence does not depend on the previous state, as in this example, I feel that it will not be small, but I wondered what would happen if the probability of occurrence is not independent, such as in general weather. """,,-2
C-2021-1_U72,"""Source encoding. Unique code possibilities. Initial codes and code trees.""","""I learned that even if codewords are created arbitrarily, they will never work. If they are created well, they can be instantaneously combined.","""I couldn't keep up with the class when entropy came out.""",,"I was surprised because I didn't expect the explanation in ""What is an information source?"" I thought we didn't need a system where stamps flow from the left to the right.""",-3
C-2021-1_U72,"""Source encoding. Unique code possibilities. Initial codes and code trees.""","""I learned that even if codewords are created arbitrarily, they will never work. If they are created well, they can be instantaneously combined.","""I couldn't keep up with the class when entropy came out.""",,"I was surprised because I didn't expect the explanation in ""What is an information source?"" I thought we didn't need a system where stamps flow from the left to the right.""",-3
C-2021-1_U72,"""Source encoding. Unique code possibilities. Initial codes and code trees.""","""I learned that even if codewords are created arbitrarily, they will never work. If they are created well, they can be instantaneously combined.","""I couldn't keep up with the class when entropy came out.""",,"I was surprised because I didn't expect the explanation in ""What is an information source?"" I thought we didn't need a system where stamps flow from the left to the right.""",-3
C-2021-1_U72,"""Source encoding. Unique code possibilities. Initial codes and code trees.""","""I learned that even if codewords are created arbitrarily, they will never work. If they are created well, they can be instantaneously combined.","""I couldn't keep up with the class when entropy came out.""",,"I was surprised because I didn't expect the explanation in ""What is an information source?"" I thought we didn't need a system where stamps flow from the left to the right.""",-3
C-2021-1_U75,,,,,"""It was very interesting to learn the process of transforming information into a form that computers can understand in an easy-to-understand manner. There were new words and formulas, and I felt it was difficult. While listening to the lecture with some examples of codes, I found myself switching codes. I wondered if multiple decryptions could be possible, but after that, there was a talk about the concept of unique decodability, which cleared my doubts. """,-1
C-2021-1_U76,"""What kind of symbol should be used to convey information in a short and easy-to-understand manner?""","""It turns out that for encoding information, we can find the optimal code from the average codeword length and entropy to make it short and easy to understand at a glance.""","""Entropy and word-answer signs were a little confusing.""",,"""I was surprised to learn that only ○ and ● can represent a variety of information, and that information can be shortened or made easier to understand by combining them.
""",-2
C-2021-1_U76,"""What kind of symbol should be used to convey information in a short and easy-to-understand manner?""","""It turns out that for encoding information, we can find the optimal code from the average codeword length and entropy to make it short and easy to understand at a glance.""","""Entropy and word-answer signs were a little confusing.""",,"""I was surprised to learn that only ○ and ● can represent a variety of information, and that information can be shortened or made easier to understand by combining them.
""",-2
C-2021-1_U76,"""What kind of symbol should be used to convey information in a short and easy-to-understand manner?""","""It turns out that for encoding information, we can find the optimal code from the average codeword length and entropy to make it short and easy to understand at a glance.""","""Entropy and word-answer signs were a little confusing.""",,"""I was surprised to learn that only ○ and ● can represent a variety of information, and that information can be shortened or made easier to understand by combining them.
""",-2
C-2021-1_U76,"""What kind of symbol should be used to convey information in a short and easy-to-understand manner?""","""It turns out that for encoding information, we can find the optimal code from the average codeword length and entropy to make it short and easy to understand at a glance.""","""Entropy and word-answer signs were a little confusing.""",,"""I was surprised to learn that only ○ and ● can represent a variety of information, and that information can be shortened or made easier to understand by combining them.
""",-2
C-2021-1_U77,"""By encoding information, it is possible to communicate and transmit information with a smaller amount of information.In addition, the state can also be expressed as a numerical value by using entropy and information encoding theorem.""","""I learned that quantum cryptography is an intermediate code between ``0 or 1'' and ``whether or not''. """,,,"""I didn't really know what entropy was, but now I know it's a number.
""",-1
C-2021-1_U77,"""By encoding information, it is possible to communicate and transmit information with a smaller amount of information.In addition, the state can also be expressed as a numerical value by using entropy and information encoding theorem.""","""I learned that quantum cryptography is an intermediate code between ``0 or 1'' and ``whether or not''. """,,,"""I didn't really know what entropy was, but now I know it's a number.
""",-1
C-2021-1_U77,"""By encoding information, it is possible to communicate and transmit information with a smaller amount of information.In addition, the state can also be expressed as a numerical value by using entropy and information encoding theorem.""","""I learned that quantum cryptography is an intermediate code between ``0 or 1'' and ``whether or not''. """,,,"""I didn't really know what entropy was, but now I know it's a number.
""",-1
C-2021-1_U78,,,,,"""It was good to be able to see the actual weather from a familiar perspective.""",-1
C-2021-1_U79,"""We encode the information emitted from the information source and visualize the information by decoding it. There are many ways to encode information. Things that can be combined without thinking about the possibilities and that can be expressed in a short way are considered the best.""",,"""I didn't understand a little about the initial code and the possibility of instantaneous combination. Also, I didn't understand the relationship between the initial code and the code that can be uniquely combined.""",,,-2
C-2021-1_U79,"""We encode the information emitted from the information source and visualize the information by decoding it. There are many ways to encode information. Things that can be combined without thinking about the possibilities and that can be expressed in a short way are considered the best.""",,"""I didn't understand a little about the initial code and the possibility of instantaneous combination. Also, I didn't understand the relationship between the initial code and the code that can be uniquely combined.""",,,-2
C-2021-1_U8,"""In order to reduce the total size of the information, we considered a code that can be uniquely restored and instantly decoded.""","""It turns out that readability and the size of the overall information are taken into consideration, rather than simply applying a code.""","""As with all slide lectures, it was so fast that I couldn't keep up with my notes.""",,,-3
C-2021-1_U8,"""In order to reduce the total size of the information, we considered a code that can be uniquely restored and instantly decoded.""","""It turns out that readability and the size of the overall information are taken into consideration, rather than simply applying a code.""","""As with all slide lectures, it was so fast that I couldn't keep up with my notes.""",,,-3
C-2021-1_U8,"""In order to reduce the total size of the information, we considered a code that can be uniquely restored and instantly decoded.""","""It turns out that readability and the size of the overall information are taken into consideration, rather than simply applying a code.""","""As with all slide lectures, it was so fast that I couldn't keep up with my notes.""",,,-3
C-2021-1_U80,,,"""I have heard about entropy in chemistry, but I don't know what it is in the first place.""",,,-2
C-2021-1_U82,,"""There are various arrangements in a bit string, and even for the same codeword, the bit string can be shortened by considering the arrangement of black and white circles and the probability.""",,,,-1
C-2021-1_U83,"""I learned about information source coding. There is no fixed order for the weather every day. There are many patterns for expressing weather symbols with 〇 and ●, but the average codeword length changes depending on the time. In order to shorten the average codeword length as much as possible, it is necessary to determine the probability of symbols appearing and assign codewords.""",,,,"""Personally, I'm not familiar with this type of story, and I often felt it was difficult. However, I thought the content of the story itself was interesting. I felt refreshed at the time. I'll do my best to understand properly.""",-2
C-2021-1_U83,"""I learned about information source coding. There is no fixed order for the weather every day. There are many patterns for expressing weather symbols with 〇 and ●, but the average codeword length changes depending on the time. In order to shorten the average codeword length as much as possible, it is necessary to determine the probability of symbols appearing and assign codewords.""",,,,"""Personally, I'm not familiar with this type of story, and I often felt it was difficult. However, I thought the content of the story itself was interesting. I felt refreshed at the time. I'll do my best to understand properly.""",-2
C-2021-1_U84,,"""I learned what kind of code is best when converting information into code and sending it.""",,,,-2
C-2021-1_U85,"""When information is represented by 1s and 0s, it is necessary to send and receive the desired information with a small amount of information. To do this, it is best to reduce the information that is frequently used. This entropy is called entropy.In addition, codes are required to be uniquely reversible and to be able to restore information instantaneously.""","""How to generate and define entropy, what is the best way to send and receive information, and what method is used?""",,,"""I thought I needed a complicated method to reduce the amount of information, but I was a little relieved that the content itself was easy to understand. I thought that if I could easily grasp what I was doing, I wouldn't be afraid of information classes in the future.""",-1
C-2021-1_U85,"""When information is represented by 1s and 0s, it is necessary to send and receive the desired information with a small amount of information. To do this, it is best to reduce the information that is frequently used. This entropy is called entropy.In addition, codes are required to be uniquely reversible and to be able to restore information instantaneously.""","""How to generate and define entropy, what is the best way to send and receive information, and what method is used?""",,,"""I thought I needed a complicated method to reduce the amount of information, but I was a little relieved that the content itself was easy to understand. I thought that if I could easily grasp what I was doing, I wouldn't be afraid of information classes in the future.""",-1
C-2021-1_U85,"""When information is represented by 1s and 0s, it is necessary to send and receive the desired information with a small amount of information. To do this, it is best to reduce the information that is frequently used. This entropy is called entropy.In addition, codes are required to be uniquely reversible and to be able to restore information instantaneously.""","""How to generate and define entropy, what is the best way to send and receive information, and what method is used?""",,,"""I thought I needed a complicated method to reduce the amount of information, but I was a little relieved that the content itself was easy to understand. I thought that if I could easily grasp what I was doing, I wouldn't be afraid of information classes in the future.""",-1
C-2021-1_U87,"""Source encoding must be unique and quickly reversible
A unique compound number means that there is only one
Instantaneous decoding means that the decoded word can be read without prefetching.
The shortest average codeword length represented by entropy is called the optimal code.",,"""For probabilities and average codeword lengths""",,"""The mathematics were hard to understand, but that gave me an idea of ​​what they were trying to say.""",-1
C-2021-1_U87,"""Source encoding must be unique and quickly reversible
A unique compound number means that there is only one
Instantaneous decoding means that the decoded word can be read without prefetching.
The shortest average codeword length represented by entropy is called the optimal code.",,"""For probabilities and average codeword lengths""",,"""The mathematics were hard to understand, but that gave me an idea of ​​what they were trying to say.""",-1
C-2021-1_U87,"""Source encoding must be unique and quickly reversible
A unique compound number means that there is only one
Instantaneous decoding means that the decoded word can be read without prefetching.
The shortest average codeword length represented by entropy is called the optimal code.",,"""For probabilities and average codeword lengths""",,"""The mathematics were hard to understand, but that gave me an idea of ​​what they were trying to say.""",-1
C-2021-1_U88,"""An information source is a source that outputs symbols at regular time intervals. A steady-state non-memory information source is one that has the same probability of occurrence of a symbol string no matter what time it is started, and is not affected by the output before or after it. Forecasts are different.
Representing a string of symbols generated from an information source with ○ and ● is called information source coding, and restoring the original string of symbols is called decoding. The average code length is obtained based on the occurrence probability, and the code length is made as short as possible.
""Uniquely decodable"" means that there is only one decoding method for the same bit string, and ""instantaneously decodable"" means that decoding can be performed without prefetching. A code that satisfies both can be said to be a desirable code.
The lower limit of the average code length is called entropy. ""","""We have found the desired code. We have found that entropy is the lower bound of the average code length.""","""I don't quite understand pages 32 and 33. I don't understand why the entropy formula shows the addition and subtraction.""",,"""I think I was able to make more use of it than the last time, such as bookmarking the assignment pages and pages that needed review.""",-3
C-2021-1_U88,"""An information source is a source that outputs symbols at regular time intervals. A steady-state non-memory information source is one that has the same probability of occurrence of a symbol string no matter what time it is started, and is not affected by the output before or after it. Forecasts are different.
Representing a string of symbols generated from an information source with ○ and ● is called information source coding, and restoring the original string of symbols is called decoding. The average code length is obtained based on the occurrence probability, and the code length is made as short as possible.
""Uniquely decodable"" means that there is only one decoding method for the same bit string, and ""instantaneously decodable"" means that decoding can be performed without prefetching. A code that satisfies both can be said to be a desirable code.
The lower limit of the average code length is called entropy. ""","""We have found the desired code. We have found that entropy is the lower bound of the average code length.""","""I don't quite understand pages 32 and 33. I don't understand why the entropy formula shows the addition and subtraction.""",,"""I think I was able to make more use of it than the last time, such as bookmarking the assignment pages and pages that needed review.""",-3
C-2021-1_U88,"""An information source is a source that outputs symbols at regular time intervals. A steady-state non-memory information source is one that has the same probability of occurrence of a symbol string no matter what time it is started, and is not affected by the output before or after it. Forecasts are different.
Representing a string of symbols generated from an information source with ○ and ● is called information source coding, and restoring the original string of symbols is called decoding. The average code length is obtained based on the occurrence probability, and the code length is made as short as possible.
""Uniquely decodable"" means that there is only one decoding method for the same bit string, and ""instantaneously decodable"" means that decoding can be performed without prefetching. A code that satisfies both can be said to be a desirable code.
The lower limit of the average code length is called entropy. ""","""We have found the desired code. We have found that entropy is the lower bound of the average code length.""","""I don't quite understand pages 32 and 33. I don't understand why the entropy formula shows the addition and subtraction.""",,"""I think I was able to make more use of it than the last time, such as bookmarking the assignment pages and pages that needed review.""",-3
C-2021-1_U88,"""An information source is a source that outputs symbols at regular time intervals. A steady-state non-memory information source is one that has the same probability of occurrence of a symbol string no matter what time it is started, and is not affected by the output before or after it. Forecasts are different.
Representing a string of symbols generated from an information source with ○ and ● is called information source coding, and restoring the original string of symbols is called decoding. The average code length is obtained based on the occurrence probability, and the code length is made as short as possible.
""Uniquely decodable"" means that there is only one decoding method for the same bit string, and ""instantaneously decodable"" means that decoding can be performed without prefetching. A code that satisfies both can be said to be a desirable code.
The lower limit of the average code length is called entropy. ""","""We have found the desired code. We have found that entropy is the lower bound of the average code length.""","""I don't quite understand pages 32 and 33. I don't understand why the entropy formula shows the addition and subtraction.""",,"""I think I was able to make more use of it than the last time, such as bookmarking the assignment pages and pages that needed review.""",-3
C-2021-1_U89,"""Information encoding is to represent the symbols generated from the information source with ○ and ●.
Decryption restores it.
""","""To shorten the code length, shorten the symbols that are likely to appear.
Understand source coding. """,,,,-2
C-2021-1_U89,"""Information encoding is to represent the symbols generated from the information source with ○ and ●.
Decryption restores it.
""","""To shorten the code length, shorten the symbols that are likely to appear.
Understand source coding. """,,,,-2
C-2021-1_U9,"""Stationary memoryless information sources are those that are not affected by previous and subsequent results. Information is converted into symbols and transmitted, and then restored to the original information. Uniquely decodable, instantaneously decodable. Since the symbols they represent do not overlap with the beginnings of symbols that represent other information, the information can be understood without reading to the end. Initials have both properties.""","""Uniquely decodable codes refer to cases in which there are absolutely two circles representing information, or those in which the delimiter can be identified. Among the initial codes, pursue shorter ones. Lengthen the codes for those with a low probability of occurrence. The average codeword length can be shortened if",,,,-1
C-2021-1_U9,"""Stationary memoryless information sources are those that are not affected by previous and subsequent results. Information is converted into symbols and transmitted, and then restored to the original information. Uniquely decodable, instantaneously decodable. Since the symbols they represent do not overlap with the beginnings of symbols that represent other information, the information can be understood without reading to the end. Initials have both properties.""","""Uniquely decodable codes refer to cases in which there are absolutely two circles representing information, or those in which the delimiter can be identified. Among the initial codes, pursue shorter ones. Lengthen the codes for those with a low probability of occurrence. The average codeword length can be shortened if",,,,-1
C-2021-1_U91,"""Symbolization of Information, Representation Using Codewords, and Methods for Finding Probabilities""","""How to Represent Symbols Using Codewords""","""Calculation method using entropy was difficult""",,"""Today's class was very difficult because it involved entropy.""",-3
C-2021-1_U91,"""Symbolization of Information, Representation Using Codewords, and Methods for Finding Probabilities""","""How to Represent Symbols Using Codewords""","""Calculation method using entropy was difficult""",,"""Today's class was very difficult because it involved entropy.""",-3
C-2021-1_U91,"""Symbolization of Information, Representation Using Codewords, and Methods for Finding Probabilities""","""How to Represent Symbols Using Codewords""","""Calculation method using entropy was difficult""",,"""Today's class was very difficult because it involved entropy.""",-3
C-2021-1_U91,"""Symbolization of Information, Representation Using Codewords, and Methods for Finding Probabilities""","""How to Represent Symbols Using Codewords""","""Calculation method using entropy was difficult""",,"""Today's class was very difficult because it involved entropy.""",-3
C-2021-1_U92,"""Today's class was about what information is, one of the three pillars of information science from last time.
It was about thinking about how to present the information in the most concise way. ""","""I now know what prefixes, optimal signs, and entropy mean.
It was easy to understand, so I think I can do practice problems. ""","""I didn't understand the log part of the entropy formula.
If it's the latter, I'm worried if it's okay if I can understand the theorem in this information science class, or if I have to prove it myself in the future. ""","""When I listened to today's class and watched the movie TENET, I remembered that when entropy decreased, time would run backwards. Of course, I know it's fiction, but this time, I wondered if the retrogression of time could be theoretically proven by extending the entropy that was mentioned in the class.""","""When the example of Sazae-san and the general formula for finding the optimal code came out, the example of the weather forecast was brought nearby, so it was easy to understand.""",-1
C-2021-1_U92,"""Today's class was about what information is, one of the three pillars of information science from last time.
It was about thinking about how to present the information in the most concise way. ""","""I now know what prefixes, optimal signs, and entropy mean.
It was easy to understand, so I think I can do practice problems. ""","""I didn't understand the log part of the entropy formula.
If it's the latter, I'm worried if it's okay if I can understand the theorem in this information science class, or if I have to prove it myself in the future. ""","""When I listened to today's class and watched the movie TENET, I remembered that when entropy decreased, time would run backwards. Of course, I know it's fiction, but this time, I wondered if the retrogression of time could be theoretically proven by extending the entropy that was mentioned in the class.""","""When the example of Sazae-san and the general formula for finding the optimal code came out, the example of the weather forecast was brought nearby, so it was easy to understand.""",-1
C-2021-1_U92,"""Today's class was about what information is, one of the three pillars of information science from last time.
It was about thinking about how to present the information in the most concise way. ""","""I now know what prefixes, optimal signs, and entropy mean.
It was easy to understand, so I think I can do practice problems. ""","""I didn't understand the log part of the entropy formula.
If it's the latter, I'm worried if it's okay if I can understand the theorem in this information science class, or if I have to prove it myself in the future. ""","""When I listened to today's class and watched the movie TENET, I remembered that when entropy decreased, time would run backwards. Of course, I know it's fiction, but this time, I wondered if the retrogression of time could be theoretically proven by extending the entropy that was mentioned in the class.""","""When the example of Sazae-san and the general formula for finding the optimal code came out, the example of the weather forecast was brought nearby, so it was easy to understand.""",-1
C-2021-1_U92,"""Today's class was about what information is, one of the three pillars of information science from last time.
It was about thinking about how to present the information in the most concise way. ""","""I now know what prefixes, optimal signs, and entropy mean.
It was easy to understand, so I think I can do practice problems. ""","""I didn't understand the log part of the entropy formula.
If it's the latter, I'm worried if it's okay if I can understand the theorem in this information science class, or if I have to prove it myself in the future. ""","""When I listened to today's class and watched the movie TENET, I remembered that when entropy decreased, time would run backwards. Of course, I know it's fiction, but this time, I wondered if the retrogression of time could be theoretically proven by extending the entropy that was mentioned in the class.""","""When the example of Sazae-san and the general formula for finding the optimal code came out, the example of the weather forecast was brought nearby, so it was easy to understand.""",-1
C-2021-1_U92,"""Today's class was about what information is, one of the three pillars of information science from last time.
It was about thinking about how to present the information in the most concise way. ""","""I now know what prefixes, optimal signs, and entropy mean.
It was easy to understand, so I think I can do practice problems. ""","""I didn't understand the log part of the entropy formula.
If it's the latter, I'm worried if it's okay if I can understand the theorem in this information science class, or if I have to prove it myself in the future. ""","""When I listened to today's class and watched the movie TENET, I remembered that when entropy decreased, time would run backwards. Of course, I know it's fiction, but this time, I wondered if the retrogression of time could be theoretically proven by extending the entropy that was mentioned in the class.""","""When the example of Sazae-san and the general formula for finding the optimal code came out, the example of the weather forecast was brought nearby, so it was easy to understand.""",-1
C-2021-1_U94,"""Codes suitable for information source decoding satisfy three conditions: unique decoding possibility, instantaneous decoding possibility, and short average codeword length.""",,,,"""In the first half, I was able to learn things I didn't know, such as what is information source combination and what is good, but in the second half, calculations became complicated and difficult.""",-2
C-2021-1_U94,"""Codes suitable for information source decoding satisfy three conditions: unique decoding possibility, instantaneous decoding possibility, and short average codeword length.""",,,,"""In the first half, I was able to learn things I didn't know, such as what is information source combination and what is good, but in the second half, calculations became complicated and difficult.""",-2
C-2021-1_U96,"""When encoding the information source, it is important that it is unique and short enough to be reversible without looking ahead. Also, it is effective to calculate the entropy to check whether the average codeword length is the shortest.""","""Understanding what is important in source coding. Understanding entropy.""","""Understanding why entropy is a lower bound. Understanding what H(S)≤L(C*)≤H(S)+1 implies.""","""H(S) ≤ L(C*) ≤ H(S)+1 means that the minimum value of the average codeword length does not necessarily match the entropy, and H(S) ≤ L(C*) ≤ H( Does that mean there is only one value of L(C*) that satisfies S)+1?""","""I forgot to do my homework this time, so I'll do it next time.""",0
C-2021-1_U96,"""When encoding the information source, it is important that it is unique and short enough to be reversible without looking ahead. Also, it is effective to calculate the entropy to check whether the average codeword length is the shortest.""","""Understanding what is important in source coding. Understanding entropy.""","""Understanding why entropy is a lower bound. Understanding what H(S)≤L(C*)≤H(S)+1 implies.""","""H(S) ≤ L(C*) ≤ H(S)+1 means that the minimum value of the average codeword length does not necessarily match the entropy, and H(S) ≤ L(C*) ≤ H( Does that mean there is only one value of L(C*) that satisfies S)+1?""","""I forgot to do my homework this time, so I'll do it next time.""",0
C-2021-1_U96,"""When encoding the information source, it is important that it is unique and short enough to be reversible without looking ahead. Also, it is effective to calculate the entropy to check whether the average codeword length is the shortest.""","""Understanding what is important in source coding. Understanding entropy.""","""Understanding why entropy is a lower bound. Understanding what H(S)≤L(C*)≤H(S)+1 implies.""","""H(S) ≤ L(C*) ≤ H(S)+1 means that the minimum value of the average codeword length does not necessarily match the entropy, and H(S) ≤ L(C*) ≤ H( Does that mean there is only one value of L(C*) that satisfies S)+1?""","""I forgot to do my homework this time, so I'll do it next time.""",0
C-2021-1_U96,"""When encoding the information source, it is important that it is unique and short enough to be reversible without looking ahead. Also, it is effective to calculate the entropy to check whether the average codeword length is the shortest.""","""Understanding what is important in source coding. Understanding entropy.""","""Understanding why entropy is a lower bound. Understanding what H(S)≤L(C*)≤H(S)+1 implies.""","""H(S) ≤ L(C*) ≤ H(S)+1 means that the minimum value of the average codeword length does not necessarily match the entropy, and H(S) ≤ L(C*) ≤ H( Does that mean there is only one value of L(C*) that satisfies S)+1?""","""I forgot to do my homework this time, so I'll do it next time.""",0
C-2021-1_U96,"""When encoding the information source, it is important that it is unique and short enough to be reversible without looking ahead. Also, it is effective to calculate the entropy to check whether the average codeword length is the shortest.""","""Understanding what is important in source coding. Understanding entropy.""","""Understanding why entropy is a lower bound. Understanding what H(S)≤L(C*)≤H(S)+1 implies.""","""H(S) ≤ L(C*) ≤ H(S)+1 means that the minimum value of the average codeword length does not necessarily match the entropy, and H(S) ≤ L(C*) ≤ H( Does that mean there is only one value of L(C*) that satisfies S)+1?""","""I forgot to do my homework this time, so I'll do it next time.""",0
C-2021-1_U97,,"""Information turns out to be closely related to the world of probability.""",,,,-1
C-2021-1_U98,,"""I was able to understand how information is transmitted and how it is received.""","""I understand how entropy is calculated, but I'm still not used to it.""",,"""It was interesting to learn how information is normally exchanged.""",0
C-2021-1_U98,,"""I was able to understand how information is transmitted and how it is received.""","""I understand how entropy is calculated, but I'm still not used to it.""",,"""It was interesting to learn how information is normally exchanged.""",0
C-2021-1_U98,,"""I was able to understand how information is transmitted and how it is received.""","""I understand how entropy is calculated, but I'm still not used to it.""",,"""It was interesting to learn how information is normally exchanged.""",0
C-2021-1_U99,"""Information is exchanged through encoding and reconstruction. There are also types of information source coding, and it becomes possible to exchange information efficiently by considering the probability of occurrence.""","""I learned how information is encoded and how to efficiently exchange information with the minimum amount of information.""","""Even though the types of data used for entropy and average codeword length are different, it still doesn't feel right to specify the range of data, so I'll review it.""",,"""I didn't prepare enough, so I'll try to do better next time.""",-3
C-2021-1_U99,"""Information is exchanged through encoding and reconstruction. There are also types of information source coding, and it becomes possible to exchange information efficiently by considering the probability of occurrence.""","""I learned how information is encoded and how to efficiently exchange information with the minimum amount of information.""","""Even though the types of data used for entropy and average codeword length are different, it still doesn't feel right to specify the range of data, so I'll review it.""",,"""I didn't prepare enough, so I'll try to do better next time.""",-3
C-2021-1_U99,"""Information is exchanged through encoding and reconstruction. There are also types of information source coding, and it becomes possible to exchange information efficiently by considering the probability of occurrence.""","""I learned how information is encoded and how to efficiently exchange information with the minimum amount of information.""","""Even though the types of data used for entropy and average codeword length are different, it still doesn't feel right to specify the range of data, so I'll review it.""",,"""I didn't prepare enough, so I'll try to do better next time.""",-3
C-2021-1_U99,"""Information is exchanged through encoding and reconstruction. There are also types of information source coding, and it becomes possible to exchange information efficiently by considering the probability of occurrence.""","""I learned how information is encoded and how to efficiently exchange information with the minimum amount of information.""","""Even though the types of data used for entropy and average codeword length are different, it still doesn't feel right to specify the range of data, so I'll review it.""",,"""I didn't prepare enough, so I'll try to do better next time.""",-3
C-2021-2_U1,"""In order to transmit information sources efficiently, it is important to design a unique instantaneous decoding code with a length corresponding to the probability of occurrence.""","""We now have an understanding of the average codeword length and that the entropy is the minimum length.""","""When I first heard that it was the shortest among the prefix codes and the shortest among the codes that could be compounded, I felt strange.""",,"""I want to study hard for the quiz.""",-3
C-2021-2_U1,"""In order to transmit information sources efficiently, it is important to design a unique instantaneous decoding code with a length corresponding to the probability of occurrence.""","""We now have an understanding of the average codeword length and that the entropy is the minimum length.""","""When I first heard that it was the shortest among the prefix codes and the shortest among the codes that could be compounded, I felt strange.""",,"""I want to study hard for the quiz.""",-3
C-2021-2_U1,"""In order to transmit information sources efficiently, it is important to design a unique instantaneous decoding code with a length corresponding to the probability of occurrence.""","""We now have an understanding of the average codeword length and that the entropy is the minimum length.""","""When I first heard that it was the shortest among the prefix codes and the shortest among the codes that could be compounded, I felt strange.""",,"""I want to study hard for the quiz.""",-3
C-2021-2_U1,"""In order to transmit information sources efficiently, it is important to design a unique instantaneous decoding code with a length corresponding to the probability of occurrence.""","""We now have an understanding of the average codeword length and that the entropy is the minimum length.""","""When I first heard that it was the shortest among the prefix codes and the shortest among the codes that could be compounded, I felt strange.""",,"""I want to study hard for the quiz.""",-3
C-2021-2_U100,"""Codes have three properties: uniquely reversible combination possibility, instantaneous reversible instantaneous combination possibility, and average codeword length to be expressed as short as possible. In order to satisfy the two elements, if the former two are too conscious, it may end up being longer, so it is better to think mainly about the average code length, and there is a lower limit to the length.""","""I knew that bits consisted of 0s and 1s, but I found out that the combination there was optimized from the entanglement of various elements.""",,,"""I was able to understand it to some extent during the class, and I found it very interesting to learn that optimization was carried out after various considerations regarding information transmission.""",-1
C-2021-2_U100,"""Codes have three properties: uniquely reversible combination possibility, instantaneous reversible instantaneous combination possibility, and average codeword length to be expressed as short as possible. In order to satisfy the two elements, if the former two are too conscious, it may end up being longer, so it is better to think mainly about the average code length, and there is a lower limit to the length.""","""I knew that bits consisted of 0s and 1s, but I found out that the combination there was optimized from the entanglement of various elements.""",,,"""I was able to understand it to some extent during the class, and I found it very interesting to learn that optimization was carried out after various considerations regarding information transmission.""",-1
C-2021-2_U100,"""Codes have three properties: uniquely reversible combination possibility, instantaneous reversible instantaneous combination possibility, and average codeword length to be expressed as short as possible. In order to satisfy the two elements, if the former two are too conscious, it may end up being longer, so it is better to think mainly about the average code length, and there is a lower limit to the length.""","""I knew that bits consisted of 0s and 1s, but I found out that the combination there was optimized from the entanglement of various elements.""",,,"""I was able to understand it to some extent during the class, and I found it very interesting to learn that optimization was carried out after various considerations regarding information transmission.""",-1
C-2021-2_U101,"""An information source is one that outputs information at regular intervals and the probability of occurrence of each symbol is determined. When encoding this information, it must be possible to decode uniquely, quickly, and average as much as possible. By considering 3 points of shortening the codeword length, we can find a better way to apply the code.From the theorem that there exists a uniquely decodable codeword with the same average codeword length, When considering the optimal code, which is the most desirable code, the initial code should be considered.In addition, the average codeword length of the optimal code is in the range of entropy or more and entropy + 1 or less.""","""In this lecture, I was able to understand the three elements that should be taken into consideration when encoding information. Regarding this, I learned how to decode information accurately and quickly through concrete examples and exercises. I also learned about the usefulness of prefixes.""","""Nothing in particular.""",,"""This class was very easy to understand because there were familiar examples and specific practice problems. I was surprised at the high potential of word prefixes, and my interest in related theorems increased. I understood by looking at the materials. I wanted to not only deepen my understanding of the concept, but also try to encode it for a certain symbol and verify whether it was good.I also wanted to understand the origin of the entropy formula next time.""",-1
C-2021-2_U101,"""An information source is one that outputs information at regular intervals and the probability of occurrence of each symbol is determined. When encoding this information, it must be possible to decode uniquely, quickly, and average as much as possible. By considering 3 points of shortening the codeword length, we can find a better way to apply the code.From the theorem that there exists a uniquely decodable codeword with the same average codeword length, When considering the optimal code, which is the most desirable code, the initial code should be considered.In addition, the average codeword length of the optimal code is in the range of entropy or more and entropy + 1 or less.""","""In this lecture, I was able to understand the three elements that should be taken into consideration when encoding information. Regarding this, I learned how to decode information accurately and quickly through concrete examples and exercises. I also learned about the usefulness of prefixes.""","""Nothing in particular.""",,"""This class was very easy to understand because there were familiar examples and specific practice problems. I was surprised at the high potential of word prefixes, and my interest in related theorems increased. I understood by looking at the materials. I wanted to not only deepen my understanding of the concept, but also try to encode it for a certain symbol and verify whether it was good.I also wanted to understand the origin of the entropy formula next time.""",-1
C-2021-2_U101,"""An information source is one that outputs information at regular intervals and the probability of occurrence of each symbol is determined. When encoding this information, it must be possible to decode uniquely, quickly, and average as much as possible. By considering 3 points of shortening the codeword length, we can find a better way to apply the code.From the theorem that there exists a uniquely decodable codeword with the same average codeword length, When considering the optimal code, which is the most desirable code, the initial code should be considered.In addition, the average codeword length of the optimal code is in the range of entropy or more and entropy + 1 or less.""","""In this lecture, I was able to understand the three elements that should be taken into consideration when encoding information. Regarding this, I learned how to decode information accurately and quickly through concrete examples and exercises. I also learned about the usefulness of prefixes.""","""Nothing in particular.""",,"""This class was very easy to understand because there were familiar examples and specific practice problems. I was surprised at the high potential of word prefixes, and my interest in related theorems increased. I understood by looking at the materials. I wanted to not only deepen my understanding of the concept, but also try to encode it for a certain symbol and verify whether it was good.I also wanted to understand the origin of the entropy formula next time.""",-1
C-2021-2_U101,"""An information source is one that outputs information at regular intervals and the probability of occurrence of each symbol is determined. When encoding this information, it must be possible to decode uniquely, quickly, and average as much as possible. By considering 3 points of shortening the codeword length, we can find a better way to apply the code.From the theorem that there exists a uniquely decodable codeword with the same average codeword length, When considering the optimal code, which is the most desirable code, the initial code should be considered.In addition, the average codeword length of the optimal code is in the range of entropy or more and entropy + 1 or less.""","""In this lecture, I was able to understand the three elements that should be taken into consideration when encoding information. Regarding this, I learned how to decode information accurately and quickly through concrete examples and exercises. I also learned about the usefulness of prefixes.""","""Nothing in particular.""",,"""This class was very easy to understand because there were familiar examples and specific practice problems. I was surprised at the high potential of word prefixes, and my interest in related theorems increased. I understood by looking at the materials. I wanted to not only deepen my understanding of the concept, but also try to encode it for a certain symbol and verify whether it was good.I also wanted to understand the origin of the entropy formula next time.""",-1
C-2021-2_U102,"""I learned about encoding information sources. I learned how to create short codes with a small amount of data, and codes that can be uniquely and instantaneously restored. The length of a code can be roughly determined by using entropy. Have learned.""","""By creating a prefix code, we can create a short code, and we can restore it instantly, so we found that the prefix code is the most suitable code.""",,,"""In today's class, I thought about codes that are efficient and easy to reconstruct, but I was impressed to hear that word prefixes meet all the requirements. I want to learn more about word prefixes from now on. """,0
C-2021-2_U102,"""I learned about encoding information sources. I learned how to create short codes with a small amount of data, and codes that can be uniquely and instantaneously restored. The length of a code can be roughly determined by using entropy. Have learned.""","""By creating a prefix code, we can create a short code, and we can restore it instantly, so we found that the prefix code is the most suitable code.""",,,"""In today's class, I thought about codes that are efficient and easy to reconstruct, but I was impressed to hear that word prefixes meet all the requirements. I want to learn more about word prefixes from now on. """,0
C-2021-2_U102,"""I learned about encoding information sources. I learned how to create short codes with a small amount of data, and codes that can be uniquely and instantaneously restored. The length of a code can be roughly determined by using entropy. Have learned.""","""By creating a prefix code, we can create a short code, and we can restore it instantly, so we found that the prefix code is the most suitable code.""",,,"""In today's class, I thought about codes that are efficient and easy to reconstruct, but I was impressed to hear that word prefixes meet all the requirements. I want to learn more about word prefixes from now on. """,0
C-2021-2_U103,"""There are various information sources in the world. Information from information sources is encoded and decoded, but the encoding must be correct, unique, and can be decoded quickly, and the average codeword length must be as low as possible. It should be coded to be short, prefix codes are very useful because they have unique decodability and instantaneous decodability, and have the smallest average codeword length among uniquely decodable codes. The minimum average codeword length is represented by an index called entropy.""","""Even though it's called ""encoding,"" I realized that it's not that simple when you consider the convenience of decoding.""",,"""I'm curious about the proof of the theorem about entropy.""","""It was very interesting to see that ideal coding was investigated using various perspectives and indicators, such as average codeword length and entropy. do.""",-1
C-2021-2_U103,"""There are various information sources in the world. Information from information sources is encoded and decoded, but the encoding must be correct, unique, and can be decoded quickly, and the average codeword length must be as low as possible. It should be coded to be short, prefix codes are very useful because they have unique decodability and instantaneous decodability, and have the smallest average codeword length among uniquely decodable codes. The minimum average codeword length is represented by an index called entropy.""","""Even though it's called ""encoding,"" I realized that it's not that simple when you consider the convenience of decoding.""",,"""I'm curious about the proof of the theorem about entropy.""","""It was very interesting to see that ideal coding was investigated using various perspectives and indicators, such as average codeword length and entropy. do.""",-1
C-2021-2_U103,"""There are various information sources in the world. Information from information sources is encoded and decoded, but the encoding must be correct, unique, and can be decoded quickly, and the average codeword length must be as low as possible. It should be coded to be short, prefix codes are very useful because they have unique decodability and instantaneous decodability, and have the smallest average codeword length among uniquely decodable codes. The minimum average codeword length is represented by an index called entropy.""","""Even though it's called ""encoding,"" I realized that it's not that simple when you consider the convenience of decoding.""",,"""I'm curious about the proof of the theorem about entropy.""","""It was very interesting to see that ideal coding was investigated using various perspectives and indicators, such as average codeword length and entropy. do.""",-1
C-2021-2_U103,"""There are various information sources in the world. Information from information sources is encoded and decoded, but the encoding must be correct, unique, and can be decoded quickly, and the average codeword length must be as low as possible. It should be coded to be short, prefix codes are very useful because they have unique decodability and instantaneous decodability, and have the smallest average codeword length among uniquely decodable codes. The minimum average codeword length is represented by an index called entropy.""","""Even though it's called ""encoding,"" I realized that it's not that simple when you consider the convenience of decoding.""",,"""I'm curious about the proof of the theorem about entropy.""","""It was very interesting to see that ideal coding was investigated using various perspectives and indicators, such as average codeword length and entropy. do.""",-1
C-2021-2_U104,"""In order to convey information more quickly and accurately, we should consider a code that has a unique combination possibility, an instantaneous combination possibility, and a short average codeword length. In addition, by calculating the entropy, we can determine whether it is the optimal code or not. You can see what it is.""",,"""I want to review entropy calculations.""",,,0
C-2021-2_U104,"""In order to convey information more quickly and accurately, we should consider a code that has a unique combination possibility, an instantaneous combination possibility, and a short average codeword length. In addition, by calculating the entropy, we can determine whether it is the optimal code or not. You can see what it is.""",,"""I want to review entropy calculations.""",,,0
C-2021-2_U105,"""Source encoding is the representation of a sequence of symbols generated from the source by a sequence of ● and ○, whereas decoding is the reverse. The average codeword tone is shortened in consideration of probability. A code that has the characteristics of being instantly decodable and uniquely decodable is called a prefix code. Entropy is the lower limit of the average codeword tone.""","""You can now source encode and decode with black and white circles.""","""I couldn't tell with my own eyes if the columns of ● and ○ could be uniquely reversed.""",,"""Sazae-san's rock-paper-scissors, weather forecasts, etc., I was surprised because I didn't think that things I saw in my daily life were so full of information.""",-1
C-2021-2_U105,"""Source encoding is the representation of a sequence of symbols generated from the source by a sequence of ● and ○, whereas decoding is the reverse. The average codeword tone is shortened in consideration of probability. A code that has the characteristics of being instantly decodable and uniquely decodable is called a prefix code. Entropy is the lower limit of the average codeword tone.""","""You can now source encode and decode with black and white circles.""","""I couldn't tell with my own eyes if the columns of ● and ○ could be uniquely reversed.""",,"""Sazae-san's rock-paper-scissors, weather forecasts, etc., I was surprised because I didn't think that things I saw in my daily life were so full of information.""",-1
C-2021-2_U105,"""Source encoding is the representation of a sequence of symbols generated from the source by a sequence of ● and ○, whereas decoding is the reverse. The average codeword tone is shortened in consideration of probability. A code that has the characteristics of being instantly decodable and uniquely decodable is called a prefix code. Entropy is the lower limit of the average codeword tone.""","""You can now source encode and decode with black and white circles.""","""I couldn't tell with my own eyes if the columns of ● and ○ could be uniquely reversed.""",,"""Sazae-san's rock-paper-scissors, weather forecasts, etc., I was surprised because I didn't think that things I saw in my daily life were so full of information.""",-1
C-2021-2_U105,"""Source encoding is the representation of a sequence of symbols generated from the source by a sequence of ● and ○, whereas decoding is the reverse. The average codeword tone is shortened in consideration of probability. A code that has the characteristics of being instantly decodable and uniquely decodable is called a prefix code. Entropy is the lower limit of the average codeword tone.""","""You can now source encode and decode with black and white circles.""","""I couldn't tell with my own eyes if the columns of ● and ○ could be uniquely reversed.""",,"""Sazae-san's rock-paper-scissors, weather forecasts, etc., I was surprised because I didn't think that things I saw in my daily life were so full of information.""",-1
C-2021-2_U106,"""I learned about types of information sources, coding of information sources, things to be careful about when coding, uniquely combinable symbols, instantaneous combinable codes, initial codes, average codeword length, and the relationship between entropy.""","""I was able to understand how information is encoded and how to find the conditional average codeword length and enthalpy for decoding the encoded information.""","""I couldn't really tell at first glance whether a prefix or uniquely composable code was true or not.""",,"""I enjoyed learning more about how information is encoded and how it works.""",-1
C-2021-2_U106,"""I learned about types of information sources, coding of information sources, things to be careful about when coding, uniquely combinable symbols, instantaneous combinable codes, initial codes, average codeword length, and the relationship between entropy.""","""I was able to understand how information is encoded and how to find the conditional average codeword length and enthalpy for decoding the encoded information.""","""I couldn't really tell at first glance whether a prefix or uniquely composable code was true or not.""",,"""I enjoyed learning more about how information is encoded and how it works.""",-1
C-2021-2_U106,"""I learned about types of information sources, coding of information sources, things to be careful about when coding, uniquely combinable symbols, instantaneous combinable codes, initial codes, average codeword length, and the relationship between entropy.""","""I was able to understand how information is encoded and how to find the conditional average codeword length and enthalpy for decoding the encoded information.""","""I couldn't really tell at first glance whether a prefix or uniquely composable code was true or not.""",,"""I enjoyed learning more about how information is encoded and how it works.""",-1
C-2021-2_U106,"""I learned about types of information sources, coding of information sources, things to be careful about when coding, uniquely combinable symbols, instantaneous combinable codes, initial codes, average codeword length, and the relationship between entropy.""","""I was able to understand how information is encoded and how to find the conditional average codeword length and enthalpy for decoding the encoded information.""","""I couldn't really tell at first glance whether a prefix or uniquely composable code was true or not.""",,"""I enjoyed learning more about how information is encoded and how it works.""",-1
C-2021-2_U107,"""Innovation of a system that conveys information in a shorter and more accurate manner in information transmission.""","""It is necessary to pay attention to prefixes and prefixes to decode uniquely. Also, to convey the same information with shorter content, we need to pay attention to the average codeword length and find a theorem to find its lower bound. Calculations can be complicated, but the idea itself is simple and the theorem is easy to use.""",,,,-1
C-2021-2_U107,"""Innovation of a system that conveys information in a shorter and more accurate manner in information transmission.""","""It is necessary to pay attention to prefixes and prefixes to decode uniquely. Also, to convey the same information with shorter content, we need to pay attention to the average codeword length and find a theorem to find its lower bound. Calculations can be complicated, but the idea itself is simple and the theorem is easy to use.""",,,,-1
C-2021-2_U108,"""This time, I learned what kind of code representation is preferable when information is represented by code. There are two major conditions for that: uniqueness and instant decodability, and the addition of simplicity Depends on conditions. The former absolute condition can be solved by using a code called the initial code, and after all, only the initial code needs to be considered for brevity, and the simplest code pattern can be extracted by calculating the entropy. """,,,"""I have a question about (3) above. Regarding code representation when pursuing brevity, is it 'simply expressed uniformly with a short average codeword length' or 'using the simplest code pattern in each case?' Is it a case-by-case basis? ""","""The explanations were very thorough. They explained difficult words by breaking them down and gave examples using diagrams and tables.",0
C-2021-2_U108,"""This time, I learned what kind of code representation is preferable when information is represented by code. There are two major conditions for that: uniqueness and instant decodability, and the addition of simplicity Depends on conditions. The former absolute condition can be solved by using a code called the initial code, and after all, only the initial code needs to be considered for brevity, and the simplest code pattern can be extracted by calculating the entropy. """,,,"""I have a question about (3) above. Regarding code representation when pursuing brevity, is it 'simply expressed uniformly with a short average codeword length' or 'using the simplest code pattern in each case?' Is it a case-by-case basis? ""","""The explanations were very thorough. They explained difficult words by breaking them down and gave examples using diagrams and tables.",0
C-2021-2_U108,"""This time, I learned what kind of code representation is preferable when information is represented by code. There are two major conditions for that: uniqueness and instant decodability, and the addition of simplicity Depends on conditions. The former absolute condition can be solved by using a code called the initial code, and after all, only the initial code needs to be considered for brevity, and the simplest code pattern can be extracted by calculating the entropy. """,,,"""I have a question about (3) above. Regarding code representation when pursuing brevity, is it 'simply expressed uniformly with a short average codeword length' or 'using the simplest code pattern in each case?' Is it a case-by-case basis? ""","""The explanations were very thorough. They explained difficult words by breaking them down and gave examples using diagrams and tables.",0
C-2021-2_U109,,,,"""Is it possible that entropy has a base other than 2?""","""It's becoming more like a computer science class (with mathematical formulas, etc.), and I found it fun.""",-1
C-2021-2_U109,,,,"""Is it possible that entropy has a base other than 2?""","""It's becoming more like a computer science class (with mathematical formulas, etc.), and I found it fun.""",-1
C-2021-2_U11,"""How to encode information, how to reduce the number of bits in the encoded version, and how to easily restore the encoded information to the original information.""","""I was able to gain a good understanding of desirable encoding, such as how to encode to reduce the amount of space used, and what kind of code can be used to restore the original information.
Entropy can now be calculated.
""","""No.""","""No.""","""I knew that information was expressed in binary, but I had never thought about how to reduce the size, so I was interested in looking at it.""",-1
C-2021-2_U11,"""How to encode information, how to reduce the number of bits in the encoded version, and how to easily restore the encoded information to the original information.""","""I was able to gain a good understanding of desirable encoding, such as how to encode to reduce the amount of space used, and what kind of code can be used to restore the original information.
Entropy can now be calculated.
""","""No.""","""No.""","""I knew that information was expressed in binary, but I had never thought about how to reduce the size, so I was interested in looking at it.""",-1
C-2021-2_U11,"""How to encode information, how to reduce the number of bits in the encoded version, and how to easily restore the encoded information to the original information.""","""I was able to gain a good understanding of desirable encoding, such as how to encode to reduce the amount of space used, and what kind of code can be used to restore the original information.
Entropy can now be calculated.
""","""No.""","""No.""","""I knew that information was expressed in binary, but I had never thought about how to reduce the size, so I was interested in looking at it.""",-1
C-2021-2_U11,"""How to encode information, how to reduce the number of bits in the encoded version, and how to easily restore the encoded information to the original information.""","""I was able to gain a good understanding of desirable encoding, such as how to encode to reduce the amount of space used, and what kind of code can be used to restore the original information.
Entropy can now be calculated.
""","""No.""","""No.""","""I knew that information was expressed in binary, but I had never thought about how to reduce the size, so I was interested in looking at it.""",-1
C-2021-2_U11,"""How to encode information, how to reduce the number of bits in the encoded version, and how to easily restore the encoded information to the original information.""","""I was able to gain a good understanding of desirable encoding, such as how to encode to reduce the amount of space used, and what kind of code can be used to restore the original information.
Entropy can now be calculated.
""","""No.""","""No.""","""I knew that information was expressed in binary, but I had never thought about how to reduce the size, so I was interested in looking at it.""",-1
C-2021-2_U110,,"""I understood well the conditions and the way of thinking in coding.""","""I forgot how to calculate entropy and how to calculate log, so I felt it was difficult. I want to review it.""","""is not.""",,-1
C-2021-2_U110,,"""I understood well the conditions and the way of thinking in coding.""","""I forgot how to calculate entropy and how to calculate log, so I felt it was difficult. I want to review it.""","""is not.""",,-1
C-2021-2_U110,,"""I understood well the conditions and the way of thinking in coding.""","""I forgot how to calculate entropy and how to calculate log, so I felt it was difficult. I want to review it.""","""is not.""",,-1
C-2021-2_U111,,"""I learned the relationship between the initial code and the uniquely combinable code. I learned the definition of entropy and how to obtain it. I learned that the initial code and entropy are important in information encoding.""",,,,-1
C-2021-2_U112,"""Information is represented by two symbols with the shortest possible code, with the goal of being unique and quickly reversible, and this is called source coding. Converting this to the original symbol is called decoding. The encoding method is There are many, and the length can be varied. To shorten it, you can make the frequently occurring symbols short codewords.In order to make them unique, various tricks are necessary.""","""I understood how information can be represented by two symbols. I also understood the need for uniqueness in the encoding and the need for quick reversibility."" We were able to calculate the length of the average codeword length.""","""There were some concepts that I found difficult, such as prefixes and entropy, so I would like to review them properly.""","""Nothing in particular.""","""I have often heard that information can be represented by 0 and 1, but I had no idea what it meant until now. and 1. I felt that it would be difficult to encode while paying attention to the fact that it is unique.The idea of ​​mathematics is used more than I imagined. I was so surprised.""",-1
C-2021-2_U112,"""Information is represented by two symbols with the shortest possible code, with the goal of being unique and quickly reversible, and this is called source coding. Converting this to the original symbol is called decoding. The encoding method is There are many, and the length can be varied. To shorten it, you can make the frequently occurring symbols short codewords.In order to make them unique, various tricks are necessary.""","""I understood how information can be represented by two symbols. I also understood the need for uniqueness in the encoding and the need for quick reversibility."" We were able to calculate the length of the average codeword length.""","""There were some concepts that I found difficult, such as prefixes and entropy, so I would like to review them properly.""","""Nothing in particular.""","""I have often heard that information can be represented by 0 and 1, but I had no idea what it meant until now. and 1. I felt that it would be difficult to encode while paying attention to the fact that it is unique.The idea of ​​mathematics is used more than I imagined. I was so surprised.""",-1
C-2021-2_U112,"""Information is represented by two symbols with the shortest possible code, with the goal of being unique and quickly reversible, and this is called source coding. Converting this to the original symbol is called decoding. The encoding method is There are many, and the length can be varied. To shorten it, you can make the frequently occurring symbols short codewords.In order to make them unique, various tricks are necessary.""","""I understood how information can be represented by two symbols. I also understood the need for uniqueness in the encoding and the need for quick reversibility."" We were able to calculate the length of the average codeword length.""","""There were some concepts that I found difficult, such as prefixes and entropy, so I would like to review them properly.""","""Nothing in particular.""","""I have often heard that information can be represented by 0 and 1, but I had no idea what it meant until now. and 1. I felt that it would be difficult to encode while paying attention to the fact that it is unique.The idea of ​​mathematics is used more than I imagined. I was so surprised.""",-1
C-2021-2_U112,"""Information is represented by two symbols with the shortest possible code, with the goal of being unique and quickly reversible, and this is called source coding. Converting this to the original symbol is called decoding. The encoding method is There are many, and the length can be varied. To shorten it, you can make the frequently occurring symbols short codewords.In order to make them unique, various tricks are necessary.""","""I understood how information can be represented by two symbols. I also understood the need for uniqueness in the encoding and the need for quick reversibility."" We were able to calculate the length of the average codeword length.""","""There were some concepts that I found difficult, such as prefixes and entropy, so I would like to review them properly.""","""Nothing in particular.""","""I have often heard that information can be represented by 0 and 1, but I had no idea what it meant until now. and 1. I felt that it would be difficult to encode while paying attention to the fact that it is unique.The idea of ​​mathematics is used more than I imagined. I was so surprised.""",-1
C-2021-2_U112,"""Information is represented by two symbols with the shortest possible code, with the goal of being unique and quickly reversible, and this is called source coding. Converting this to the original symbol is called decoding. The encoding method is There are many, and the length can be varied. To shorten it, you can make the frequently occurring symbols short codewords.In order to make them unique, various tricks are necessary.""","""I understood how information can be represented by two symbols. I also understood the need for uniqueness in the encoding and the need for quick reversibility."" We were able to calculate the length of the average codeword length.""","""There were some concepts that I found difficult, such as prefixes and entropy, so I would like to review them properly.""","""Nothing in particular.""","""I have often heard that information can be represented by 0 and 1, but I had no idea what it meant until now. and 1. I felt that it would be difficult to encode while paying attention to the fact that it is unique.The idea of ​​mathematics is used more than I imagined. I was so surprised.""",-1
C-2021-2_U113,"""In order to convert information into code, it's better to do it in a quick, accurate, and short conversion.""","""The purpose of encoding the source is to design a code with as short an average codeword length as possible while still meeting the objective of uniquely and quickly decomposing.""","""I didn't understand that entropy is the lower bound of the average codeword length. I'd like to review it.""","""is not.""","""This time, I prepared well, and I think I was able to understand the difficult content. I want to keep doing this.""",-2
C-2021-2_U113,"""In order to convert information into code, it's better to do it in a quick, accurate, and short conversion.""","""The purpose of encoding the source is to design a code with as short an average codeword length as possible while still meeting the objective of uniquely and quickly decomposing.""","""I didn't understand that entropy is the lower bound of the average codeword length. I'd like to review it.""","""is not.""","""This time, I prepared well, and I think I was able to understand the difficult content. I want to keep doing this.""",-2
C-2021-2_U113,"""In order to convert information into code, it's better to do it in a quick, accurate, and short conversion.""","""The purpose of encoding the source is to design a code with as short an average codeword length as possible while still meeting the objective of uniquely and quickly decomposing.""","""I didn't understand that entropy is the lower bound of the average codeword length. I'd like to review it.""","""is not.""","""This time, I prepared well, and I think I was able to understand the difficult content. I want to keep doing this.""",-2
C-2021-2_U113,"""In order to convert information into code, it's better to do it in a quick, accurate, and short conversion.""","""The purpose of encoding the source is to design a code with as short an average codeword length as possible while still meeting the objective of uniquely and quickly decomposing.""","""I didn't understand that entropy is the lower bound of the average codeword length. I'd like to review it.""","""is not.""","""This time, I prepared well, and I think I was able to understand the difficult content. I want to keep doing this.""",-2
C-2021-2_U113,"""In order to convert information into code, it's better to do it in a quick, accurate, and short conversion.""","""The purpose of encoding the source is to design a code with as short an average codeword length as possible while still meeting the objective of uniquely and quickly decomposing.""","""I didn't understand that entropy is the lower bound of the average codeword length. I'd like to review it.""","""is not.""","""This time, I prepared well, and I think I was able to understand the difficult content. I want to keep doing this.""",-2
C-2021-2_U114,"""Representing a sequence of symbols generated from an information source with a sequence of ○ and ● is called information source coding. In order to facilitate information transmission, it is necessary to consider the probability of occurrence of symbols so that they can be expressed as short as possible. The coding condition is to be uniquely and quickly restored, and the prefix code satisfies both.In addition, among the prefix codes, the one with the smallest average codeword length is called the optimal code.""","""I was able to understand the meaning of the words in the stationary memoryless information source. I understood that the average codeword length should be calculated up to the sum of the product of the number of codewords and the probability of occurrence of the symbol.""","""None in particular.""",,"""I thought it would be complicated, but it was very easy to understand with lots of examples. I learned that there are many ways to simplify and speed up the communication of information. The entropy part is as follows. I would like to hear more about it in class.""",-2
C-2021-2_U114,"""Representing a sequence of symbols generated from an information source with a sequence of ○ and ● is called information source coding. In order to facilitate information transmission, it is necessary to consider the probability of occurrence of symbols so that they can be expressed as short as possible. The coding condition is to be uniquely and quickly restored, and the prefix code satisfies both.In addition, among the prefix codes, the one with the smallest average codeword length is called the optimal code.""","""I was able to understand the meaning of the words in the stationary memoryless information source. I understood that the average codeword length should be calculated up to the sum of the product of the number of codewords and the probability of occurrence of the symbol.""","""None in particular.""",,"""I thought it would be complicated, but it was very easy to understand with lots of examples. I learned that there are many ways to simplify and speed up the communication of information. The entropy part is as follows. I would like to hear more about it in class.""",-2
C-2021-2_U114,"""Representing a sequence of symbols generated from an information source with a sequence of ○ and ● is called information source coding. In order to facilitate information transmission, it is necessary to consider the probability of occurrence of symbols so that they can be expressed as short as possible. The coding condition is to be uniquely and quickly restored, and the prefix code satisfies both.In addition, among the prefix codes, the one with the smallest average codeword length is called the optimal code.""","""I was able to understand the meaning of the words in the stationary memoryless information source. I understood that the average codeword length should be calculated up to the sum of the product of the number of codewords and the probability of occurrence of the symbol.""","""None in particular.""",,"""I thought it would be complicated, but it was very easy to understand with lots of examples. I learned that there are many ways to simplify and speed up the communication of information. The entropy part is as follows. I would like to hear more about it in class.""",-2
C-2021-2_U114,"""Representing a sequence of symbols generated from an information source with a sequence of ○ and ● is called information source coding. In order to facilitate information transmission, it is necessary to consider the probability of occurrence of symbols so that they can be expressed as short as possible. The coding condition is to be uniquely and quickly restored, and the prefix code satisfies both.In addition, among the prefix codes, the one with the smallest average codeword length is called the optimal code.""","""I was able to understand the meaning of the words in the stationary memoryless information source. I understood that the average codeword length should be calculated up to the sum of the product of the number of codewords and the probability of occurrence of the symbol.""","""None in particular.""",,"""I thought it would be complicated, but it was very easy to understand with lots of examples. I learned that there are many ways to simplify and speed up the communication of information. The entropy part is as follows. I would like to hear more about it in class.""",-2
C-2021-2_U115,"""I learned how to use information and probability to determine the length of a code and whether it can be made unique again.""","""I was able to understand that whether or not it is possible to combine is determined by how the ○ and ● are arranged. It seems difficult to decode if you are not aware of the partition symbols.""",,,"""It was easy to understand""",-1
C-2021-2_U115,"""I learned how to use information and probability to determine the length of a code and whether it can be made unique again.""","""I was able to understand that whether or not it is possible to combine is determined by how the ○ and ● are arranged. It seems difficult to decode if you are not aware of the partition symbols.""",,,"""It was easy to understand""",-1
C-2021-2_U115,"""I learned how to use information and probability to determine the length of a code and whether it can be made unique again.""","""I was able to understand that whether or not it is possible to combine is determined by how the ○ and ● are arranged. It seems difficult to decode if you are not aware of the partition symbols.""",,,"""It was easy to understand""",-1
C-2021-2_U116,"""When information is sent, it is sent as data using codes. You must set something that does not exist in more than one way.""","""A lower bound on the average codeword length can be found by finding the entropy.""","""Why can entropy be calculated using logarithms?""",,"""I thought I'd try to prove p32's theorem 1.""",-1
C-2021-2_U116,"""When information is sent, it is sent as data using codes. You must set something that does not exist in more than one way.""","""A lower bound on the average codeword length can be found by finding the entropy.""","""Why can entropy be calculated using logarithms?""",,"""I thought I'd try to prove p32's theorem 1.""",-1
C-2021-2_U116,"""When information is sent, it is sent as data using codes. You must set something that does not exist in more than one way.""","""A lower bound on the average codeword length can be found by finding the entropy.""","""Why can entropy be calculated using logarithms?""",,"""I thought I'd try to prove p32's theorem 1.""",-1
C-2021-2_U116,"""When information is sent, it is sent as data using codes. You must set something that does not exist in more than one way.""","""A lower bound on the average codeword length can be found by finding the entropy.""","""Why can entropy be calculated using logarithms?""",,"""I thought I'd try to prove p32's theorem 1.""",-1
C-2021-2_U117,"""Information source coding is performed with the aim of designing a code whose average codeword length is as short as possible. However, it is assumed that it has unique decodability and instantaneous decodability. The shorter the average codeword length, the better."" Okay, but the lower bound is determined by entropy. The average codeword length of the optimal code is between entropy and entropy plus one.""","""The average codeword length can now be obtained. Also, until the previous time, I thought that in order to decode a symbol string by looking at it, I had to look ahead and think about the break while comparing it with the codeword. I was convinced that it was not necessary as long as it was satisfied.""","""I don't really understand why entropy is a lower bound on the average codeword length.""","""It's just a matter of language, but I want to know if it's the average codeword length or the average codelength.""","""I think this class was the first time I was able to learn about what the field of information science is going to pursue. I could understand it easily at the beginning, but I lost track of it around entropy. I will pay attention to it and listen to it in the next and subsequent classes.""",-2
C-2021-2_U117,"""Information source coding is performed with the aim of designing a code whose average codeword length is as short as possible. However, it is assumed that it has unique decodability and instantaneous decodability. The shorter the average codeword length, the better."" Okay, but the lower bound is determined by entropy. The average codeword length of the optimal code is between entropy and entropy plus one.""","""The average codeword length can now be obtained. Also, until the previous time, I thought that in order to decode a symbol string by looking at it, I had to look ahead and think about the break while comparing it with the codeword. I was convinced that it was not necessary as long as it was satisfied.""","""I don't really understand why entropy is a lower bound on the average codeword length.""","""It's just a matter of language, but I want to know if it's the average codeword length or the average codelength.""","""I think this class was the first time I was able to learn about what the field of information science is going to pursue. I could understand it easily at the beginning, but I lost track of it around entropy. I will pay attention to it and listen to it in the next and subsequent classes.""",-2
C-2021-2_U117,"""Information source coding is performed with the aim of designing a code whose average codeword length is as short as possible. However, it is assumed that it has unique decodability and instantaneous decodability. The shorter the average codeword length, the better."" Okay, but the lower bound is determined by entropy. The average codeword length of the optimal code is between entropy and entropy plus one.""","""The average codeword length can now be obtained. Also, until the previous time, I thought that in order to decode a symbol string by looking at it, I had to look ahead and think about the break while comparing it with the codeword. I was convinced that it was not necessary as long as it was satisfied.""","""I don't really understand why entropy is a lower bound on the average codeword length.""","""It's just a matter of language, but I want to know if it's the average codeword length or the average codelength.""","""I think this class was the first time I was able to learn about what the field of information science is going to pursue. I could understand it easily at the beginning, but I lost track of it around entropy. I will pay attention to it and listen to it in the next and subsequent classes.""",-2
C-2021-2_U117,"""Information source coding is performed with the aim of designing a code whose average codeword length is as short as possible. However, it is assumed that it has unique decodability and instantaneous decodability. The shorter the average codeword length, the better."" Okay, but the lower bound is determined by entropy. The average codeword length of the optimal code is between entropy and entropy plus one.""","""The average codeword length can now be obtained. Also, until the previous time, I thought that in order to decode a symbol string by looking at it, I had to look ahead and think about the break while comparing it with the codeword. I was convinced that it was not necessary as long as it was satisfied.""","""I don't really understand why entropy is a lower bound on the average codeword length.""","""It's just a matter of language, but I want to know if it's the average codeword length or the average codelength.""","""I think this class was the first time I was able to learn about what the field of information science is going to pursue. I could understand it easily at the beginning, but I lost track of it around entropy. I will pay attention to it and listen to it in the next and subsequent classes.""",-2
C-2021-2_U117,"""Information source coding is performed with the aim of designing a code whose average codeword length is as short as possible. However, it is assumed that it has unique decodability and instantaneous decodability. The shorter the average codeword length, the better."" Okay, but the lower bound is determined by entropy. The average codeword length of the optimal code is between entropy and entropy plus one.""","""The average codeword length can now be obtained. Also, until the previous time, I thought that in order to decode a symbol string by looking at it, I had to look ahead and think about the break while comparing it with the codeword. I was convinced that it was not necessary as long as it was satisfied.""","""I don't really understand why entropy is a lower bound on the average codeword length.""","""It's just a matter of language, but I want to know if it's the average codeword length or the average codelength.""","""I think this class was the first time I was able to learn about what the field of information science is going to pursue. I could understand it easily at the beginning, but I lost track of it around entropy. I will pay attention to it and listen to it in the next and subsequent classes.""",-2
C-2021-2_U118,,"""I didn't know why we bothered to encode, but it's true that if we didn't encode it, the amount of data sent would be large, and even if we encoded it, the total amount would change too much, so I thought we had to carefully examine the symbols. .""","""I didn't fully understand entropy, so I thought I'd review it by looking at the material in detail.""","""Nothing in particular.""","""It's the first time I've learned about it, but there were so many interesting things that I wanted to know more. I took notes in my notebook, but there were some things I couldn't keep up with, so I'd like to cover that with a review.""",0
C-2021-2_U118,,"""I didn't know why we bothered to encode, but it's true that if we didn't encode it, the amount of data sent would be large, and even if we encoded it, the total amount would change too much, so I thought we had to carefully examine the symbols. .""","""I didn't fully understand entropy, so I thought I'd review it by looking at the material in detail.""","""Nothing in particular.""","""It's the first time I've learned about it, but there were so many interesting things that I wanted to know more. I took notes in my notebook, but there were some things I couldn't keep up with, so I'd like to cover that with a review.""",0
C-2021-2_U118,,"""I didn't know why we bothered to encode, but it's true that if we didn't encode it, the amount of data sent would be large, and even if we encoded it, the total amount would change too much, so I thought we had to carefully examine the symbols. .""","""I didn't fully understand entropy, so I thought I'd review it by looking at the material in detail.""","""Nothing in particular.""","""It's the first time I've learned about it, but there were so many interesting things that I wanted to know more. I took notes in my notebook, but there were some things I couldn't keep up with, so I'd like to cover that with a review.""",0
C-2021-2_U118,,"""I didn't know why we bothered to encode, but it's true that if we didn't encode it, the amount of data sent would be large, and even if we encoded it, the total amount would change too much, so I thought we had to carefully examine the symbols. .""","""I didn't fully understand entropy, so I thought I'd review it by looking at the material in detail.""","""Nothing in particular.""","""It's the first time I've learned about it, but there were so many interesting things that I wanted to know more. I took notes in my notebook, but there were some things I couldn't keep up with, so I'd like to cover that with a review.""",0
C-2021-2_U119,,"""I was able to understand the mechanism of information source coding, how to calculate the average code length, the meaning of unique decodability, and the prefix code.
""","""The entropy calculation didn't go very well""","""When I open the slide, there is a flickering cloud mark on the top right of the slide. Is there something wrong with this?""","""In this lecture, I was able to feel how important it is to use information well (express it concisely) and how amazing it is. In particular, there are various processes just for expressing the weather using codes. I was surprised at this.I thought that the beginning code and its code tree were very efficient.Instead of using ``○○'' to express it, if you add some ingenuity, the amount of information can be changed considerably. It was easy to realize that it was.""",-1
C-2021-2_U119,,"""I was able to understand the mechanism of information source coding, how to calculate the average code length, the meaning of unique decodability, and the prefix code.
""","""The entropy calculation didn't go very well""","""When I open the slide, there is a flickering cloud mark on the top right of the slide. Is there something wrong with this?""","""In this lecture, I was able to feel how important it is to use information well (express it concisely) and how amazing it is. In particular, there are various processes just for expressing the weather using codes. I was surprised at this.I thought that the beginning code and its code tree were very efficient.Instead of using ``○○'' to express it, if you add some ingenuity, the amount of information can be changed considerably. It was easy to realize that it was.""",-1
C-2021-2_U119,,"""I was able to understand the mechanism of information source coding, how to calculate the average code length, the meaning of unique decodability, and the prefix code.
""","""The entropy calculation didn't go very well""","""When I open the slide, there is a flickering cloud mark on the top right of the slide. Is there something wrong with this?""","""In this lecture, I was able to feel how important it is to use information well (express it concisely) and how amazing it is. In particular, there are various processes just for expressing the weather using codes. I was surprised at this.I thought that the beginning code and its code tree were very efficient.Instead of using ``○○'' to express it, if you add some ingenuity, the amount of information can be changed considerably. It was easy to realize that it was.""",-1
C-2021-2_U119,,"""I was able to understand the mechanism of information source coding, how to calculate the average code length, the meaning of unique decodability, and the prefix code.
""","""The entropy calculation didn't go very well""","""When I open the slide, there is a flickering cloud mark on the top right of the slide. Is there something wrong with this?""","""In this lecture, I was able to feel how important it is to use information well (express it concisely) and how amazing it is. In particular, there are various processes just for expressing the weather using codes. I was surprised at this.I thought that the beginning code and its code tree were very efficient.Instead of using ``○○'' to express it, if you add some ingenuity, the amount of information can be changed considerably. It was easy to realize that it was.""",-1
C-2021-2_U12,"""By encoding information, information can be conveyed in a shorter time.""","""It is better to simplify the code of frequently displayed information as much as possible.""",,,,-1
C-2021-2_U12,"""By encoding information, information can be conveyed in a shorter time.""","""It is better to simplify the code of frequently displayed information as much as possible.""",,,,-1
C-2021-2_U120,"""In order to efficiently encode and decode a certain information source, a unique prefix code that can be decoded instantaneously is effective. This average codeword length is greater than or equal to the entropy.""","""We found that the prefix code is unique and can be instantaneously decoded. To obtain the average codeword length, we need the probability of occurrence of the information source.""","""I didn't know whether it was possible to know at a glance if it was possible to instantly decode a code, or whether it was better to try using a code tree.""",,"""Even though I'm not familiar with how computers work, I'm relieved that I can understand the contents of this article fairly well.""",0
C-2021-2_U120,"""In order to efficiently encode and decode a certain information source, a unique prefix code that can be decoded instantaneously is effective. This average codeword length is greater than or equal to the entropy.""","""We found that the prefix code is unique and can be instantaneously decoded. To obtain the average codeword length, we need the probability of occurrence of the information source.""","""I didn't know whether it was possible to know at a glance if it was possible to instantly decode a code, or whether it was better to try using a code tree.""",,"""Even though I'm not familiar with how computers work, I'm relieved that I can understand the contents of this article fairly well.""",0
C-2021-2_U120,"""In order to efficiently encode and decode a certain information source, a unique prefix code that can be decoded instantaneously is effective. This average codeword length is greater than or equal to the entropy.""","""We found that the prefix code is unique and can be instantaneously decoded. To obtain the average codeword length, we need the probability of occurrence of the information source.""","""I didn't know whether it was possible to know at a glance if it was possible to instantly decode a code, or whether it was better to try using a code tree.""",,"""Even though I'm not familiar with how computers work, I'm relieved that I can understand the contents of this article fairly well.""",0
C-2021-2_U120,"""In order to efficiently encode and decode a certain information source, a unique prefix code that can be decoded instantaneously is effective. This average codeword length is greater than or equal to the entropy.""","""We found that the prefix code is unique and can be instantaneously decoded. To obtain the average codeword length, we need the probability of occurrence of the information source.""","""I didn't know whether it was possible to know at a glance if it was possible to instantly decode a code, or whether it was better to try using a code tree.""",,"""Even though I'm not familiar with how computers work, I'm relieved that I can understand the contents of this article fairly well.""",0
C-2021-2_U121,,"""I learned that when encoding information, it is important to emphasize three points: 'uniquely reversible', 'quickly reversible', and 'expressed as short as possible'. ""","""I was able to understand the calculation of the entropy value in my head, but when I actually tried to solve the exercises, I couldn't solve them without looking at the materials.""",,"""I'm glad I was able to learn more about information encoding than I did last time. Also, I didn't get lost in the screens, so it was very easy to understand because I had a lesson with teams showing the screen. It's just.""",-2
C-2021-2_U121,,"""I learned that when encoding information, it is important to emphasize three points: 'uniquely reversible', 'quickly reversible', and 'expressed as short as possible'. ""","""I was able to understand the calculation of the entropy value in my head, but when I actually tried to solve the exercises, I couldn't solve them without looking at the materials.""",,"""I'm glad I was able to learn more about information encoding than I did last time. Also, I didn't get lost in the screens, so it was very easy to understand because I had a lesson with teams showing the screen. It's just.""",-2
C-2021-2_U121,,"""I learned that when encoding information, it is important to emphasize three points: 'uniquely reversible', 'quickly reversible', and 'expressed as short as possible'. ""","""I was able to understand the calculation of the entropy value in my head, but when I actually tried to solve the exercises, I couldn't solve them without looking at the materials.""",,"""I'm glad I was able to learn more about information encoding than I did last time. Also, I didn't get lost in the screens, so it was very easy to understand because I had a lesson with teams showing the screen. It's just.""",-2
C-2021-2_U122,"""Occurrence Probability of Information Source
Encode and decode a sequence of symbols originating from an information source
Source Length""","""How to find the average codeword length
Desired Sign""",,,"""Anyway, it's the first time I've heard it, and it feels difficult, but I want to do my best.""",-3
C-2021-2_U122,"""Occurrence Probability of Information Source
Encode and decode a sequence of symbols originating from an information source
Source Length""","""How to find the average codeword length
Desired Sign""",,,"""Anyway, it's the first time I've heard it, and it feels difficult, but I want to do my best.""",-3
C-2021-2_U122,"""Occurrence Probability of Information Source
Encode and decode a sequence of symbols originating from an information source
Source Length""","""How to find the average codeword length
Desired Sign""",,,"""Anyway, it's the first time I've heard it, and it feels difficult, but I want to do my best.""",-3
C-2021-2_U124,"""In information source coding, a sequence of symbols generated from the information source is represented by a sequence of 0 and ●, and the occurrence probability of the symbols must be considered. is related to the prefix code, and the entropy is the lower bound of the average codeword length.
""","""I was able to understand the definitions of various terms (average codeword length, entropy, optimal code) and the theorems using them.""","""The code tree part of the non-initial code was not immediately understood in my brain.""","""is not""","""I was surprised that it suddenly became like mathematics. There were a lot of difficult words I had never heard before, so I would like to carefully review them one by one.""",-3
C-2021-2_U124,"""In information source coding, a sequence of symbols generated from the information source is represented by a sequence of 0 and ●, and the occurrence probability of the symbols must be considered. is related to the prefix code, and the entropy is the lower bound of the average codeword length.
""","""I was able to understand the definitions of various terms (average codeword length, entropy, optimal code) and the theorems using them.""","""The code tree part of the non-initial code was not immediately understood in my brain.""","""is not""","""I was surprised that it suddenly became like mathematics. There were a lot of difficult words I had never heard before, so I would like to carefully review them one by one.""",-3
C-2021-2_U124,"""In information source coding, a sequence of symbols generated from the information source is represented by a sequence of 0 and ●, and the occurrence probability of the symbols must be considered. is related to the prefix code, and the entropy is the lower bound of the average codeword length.
""","""I was able to understand the definitions of various terms (average codeword length, entropy, optimal code) and the theorems using them.""","""The code tree part of the non-initial code was not immediately understood in my brain.""","""is not""","""I was surprised that it suddenly became like mathematics. There were a lot of difficult words I had never heard before, so I would like to carefully review them one by one.""",-3
C-2021-2_U124,"""In information source coding, a sequence of symbols generated from the information source is represented by a sequence of 0 and ●, and the occurrence probability of the symbols must be considered. is related to the prefix code, and the entropy is the lower bound of the average codeword length.
""","""I was able to understand the definitions of various terms (average codeword length, entropy, optimal code) and the theorems using them.""","""The code tree part of the non-initial code was not immediately understood in my brain.""","""is not""","""I was surprised that it suddenly became like mathematics. There were a lot of difficult words I had never heard before, so I would like to carefully review them one by one.""",-3
C-2021-2_U124,"""In information source coding, a sequence of symbols generated from the information source is represented by a sequence of 0 and ●, and the occurrence probability of the symbols must be considered. is related to the prefix code, and the entropy is the lower bound of the average codeword length.
""","""I was able to understand the definitions of various terms (average codeword length, entropy, optimal code) and the theorems using them.""","""The code tree part of the non-initial code was not immediately understood in my brain.""","""is not""","""I was surprised that it suddenly became like mathematics. There were a lot of difficult words I had never heard before, so I would like to carefully review them one by one.""",-3
C-2021-2_U125,"""Regarding information source coding. The purpose is to design a code with a short average code tone. In doing so, the unique decodability and instantaneous decodability of the code must be satisfied. The above three conditions are satisfied. A code with a prefix is ​​desirable. The prefix code is excellent because it has both uniqueness and instantaneous decodability.""","""Method to determine whether encoded information is uniquely decodable or instantaneously decodable. Excellence of initial code. Optimal code. How to find average code length and entropy.""","""The prefix code with the smallest average word length shall match the uniquely decodable code with the smallest average code length.""","""Regarding the diary, has the check been completed even if the teacher's comment has not been posted? In the diary last week, I posted it on the same day as class ended, but today's class still has comments from the teacher. was not posted. I was worried if my journal was properly checked, so I asked.""","""I learned a lot about source coding. I saw how to tell if it's a uniquely decodable code in the later material with more details, which was interesting. I also enjoyed the exercises.""",-2
C-2021-2_U125,"""Regarding information source coding. The purpose is to design a code with a short average code tone. In doing so, the unique decodability and instantaneous decodability of the code must be satisfied. The above three conditions are satisfied. A code with a prefix is ​​desirable. The prefix code is excellent because it has both uniqueness and instantaneous decodability.""","""Method to determine whether encoded information is uniquely decodable or instantaneously decodable. Excellence of initial code. Optimal code. How to find average code length and entropy.""","""The prefix code with the smallest average word length shall match the uniquely decodable code with the smallest average code length.""","""Regarding the diary, has the check been completed even if the teacher's comment has not been posted? In the diary last week, I posted it on the same day as class ended, but today's class still has comments from the teacher. was not posted. I was worried if my journal was properly checked, so I asked.""","""I learned a lot about source coding. I saw how to tell if it's a uniquely decodable code in the later material with more details, which was interesting. I also enjoyed the exercises.""",-2
C-2021-2_U125,"""Regarding information source coding. The purpose is to design a code with a short average code tone. In doing so, the unique decodability and instantaneous decodability of the code must be satisfied. The above three conditions are satisfied. A code with a prefix is ​​desirable. The prefix code is excellent because it has both uniqueness and instantaneous decodability.""","""Method to determine whether encoded information is uniquely decodable or instantaneously decodable. Excellence of initial code. Optimal code. How to find average code length and entropy.""","""The prefix code with the smallest average word length shall match the uniquely decodable code with the smallest average code length.""","""Regarding the diary, has the check been completed even if the teacher's comment has not been posted? In the diary last week, I posted it on the same day as class ended, but today's class still has comments from the teacher. was not posted. I was worried if my journal was properly checked, so I asked.""","""I learned a lot about source coding. I saw how to tell if it's a uniquely decodable code in the later material with more details, which was interesting. I also enjoyed the exercises.""",-2
C-2021-2_U125,"""Regarding information source coding. The purpose is to design a code with a short average code tone. In doing so, the unique decodability and instantaneous decodability of the code must be satisfied. The above three conditions are satisfied. A code with a prefix is ​​desirable. The prefix code is excellent because it has both uniqueness and instantaneous decodability.""","""Method to determine whether encoded information is uniquely decodable or instantaneously decodable. Excellence of initial code. Optimal code. How to find average code length and entropy.""","""The prefix code with the smallest average word length shall match the uniquely decodable code with the smallest average code length.""","""Regarding the diary, has the check been completed even if the teacher's comment has not been posted? In the diary last week, I posted it on the same day as class ended, but today's class still has comments from the teacher. was not posted. I was worried if my journal was properly checked, so I asked.""","""I learned a lot about source coding. I saw how to tell if it's a uniquely decodable code in the later material with more details, which was interesting. I also enjoyed the exercises.""",-2
C-2021-2_U125,"""Regarding information source coding. The purpose is to design a code with a short average code tone. In doing so, the unique decodability and instantaneous decodability of the code must be satisfied. The above three conditions are satisfied. A code with a prefix is ​​desirable. The prefix code is excellent because it has both uniqueness and instantaneous decodability.""","""Method to determine whether encoded information is uniquely decodable or instantaneously decodable. Excellence of initial code. Optimal code. How to find average code length and entropy.""","""The prefix code with the smallest average word length shall match the uniquely decodable code with the smallest average code length.""","""Regarding the diary, has the check been completed even if the teacher's comment has not been posted? In the diary last week, I posted it on the same day as class ended, but today's class still has comments from the teacher. was not posted. I was worried if my journal was properly checked, so I asked.""","""I learned a lot about source coding. I saw how to tell if it's a uniquely decodable code in the later material with more details, which was interesting. I also enjoyed the exercises.""",-2
C-2021-2_U126,,"""I learned the points that should be considered as conditions and ingenuity when encoding information sources.""",,"""I would like you to explain entropy again.""","""As an effective condition for ensuring unique decodability and instantaneous decodability, I found it interesting to pay attention to the fact that no codeword is a prefix of another codeword.""",-1
C-2021-2_U126,,"""I learned the points that should be considered as conditions and ingenuity when encoding information sources.""",,"""I would like you to explain entropy again.""","""As an effective condition for ensuring unique decodability and instantaneous decodability, I found it interesting to pay attention to the fact that no codeword is a prefix of another codeword.""",-1
C-2021-2_U126,,"""I learned the points that should be considered as conditions and ingenuity when encoding information sources.""",,"""I would like you to explain entropy again.""","""As an effective condition for ensuring unique decodability and instantaneous decodability, I found it interesting to pay attention to the fact that no codeword is a prefix of another codeword.""",-1
C-2021-2_U127,"""Information source coding is to convert and notate a string of symbols obtained from an information source simply with only two marks. The reverse operation of this information source coding is called decoding. The average codeword length is the product of the generation probability of the information represented by the code and the average codeword length. Proper source coding cannot be said to be proper unless it is accompanied by both accuracy and immediacy.In light of this, the initial condition of instantaneous and unique decodability (any codeword can be a prefix of another codeword It would be beneficial to take advantage of


""","""In source coding, I found that three things are very important: succinct representation, immediate reversibility, and unique reversibility. Through this lecture, I was able to understand that it is good to be aware of the product of the average codeword length and the probability distribution, as well as the word beginning condition, although there are many detailed restrictions when trying to implement source coding in . ""","""I still didn't fully understand the entropy talk at the end of the lecture, so I'll do my best to master it in the next and subsequent lectures.""",,,-2
C-2021-2_U127,"""Information source coding is to convert and notate a string of symbols obtained from an information source simply with only two marks. The reverse operation of this information source coding is called decoding. The average codeword length is the product of the generation probability of the information represented by the code and the average codeword length. Proper source coding cannot be said to be proper unless it is accompanied by both accuracy and immediacy.In light of this, the initial condition of instantaneous and unique decodability (any codeword can be a prefix of another codeword It would be beneficial to take advantage of


""","""In source coding, I found that three things are very important: succinct representation, immediate reversibility, and unique reversibility. Through this lecture, I was able to understand that it is good to be aware of the product of the average codeword length and the probability distribution, as well as the word beginning condition, although there are many detailed restrictions when trying to implement source coding in . ""","""I still didn't fully understand the entropy talk at the end of the lecture, so I'll do my best to master it in the next and subsequent lectures.""",,,-2
C-2021-2_U127,"""Information source coding is to convert and notate a string of symbols obtained from an information source simply with only two marks. The reverse operation of this information source coding is called decoding. The average codeword length is the product of the generation probability of the information represented by the code and the average codeword length. Proper source coding cannot be said to be proper unless it is accompanied by both accuracy and immediacy.In light of this, the initial condition of instantaneous and unique decodability (any codeword can be a prefix of another codeword It would be beneficial to take advantage of


""","""In source coding, I found that three things are very important: succinct representation, immediate reversibility, and unique reversibility. Through this lecture, I was able to understand that it is good to be aware of the product of the average codeword length and the probability distribution, as well as the word beginning condition, although there are many detailed restrictions when trying to implement source coding in . ""","""I still didn't fully understand the entropy talk at the end of the lecture, so I'll do my best to master it in the next and subsequent lectures.""",,,-2
C-2021-2_U128,,,"""There were a few math-related problems that made it look a bit confusing. Other than that, there was nothing I didn't understand or couldn't do.""","""How fast and how long would it take to decrypt the information?
""","""I think this class was quite easy to understand and I was able to deepen my understanding of information throughout.
At first, I was a little impatient because there was no sound in teams, but after that I was able to watch the lecture without difficulty, so it was good.
We hope to see you next week. """,-1
C-2021-2_U128,,,"""There were a few math-related problems that made it look a bit confusing. Other than that, there was nothing I didn't understand or couldn't do.""","""How fast and how long would it take to decrypt the information?
""","""I think this class was quite easy to understand and I was able to deepen my understanding of information throughout.
At first, I was a little impatient because there was no sound in teams, but after that I was able to watch the lecture without difficulty, so it was good.
We hope to see you next week. """,-1
C-2021-2_U128,,,"""There were a few math-related problems that made it look a bit confusing. Other than that, there was nothing I didn't understand or couldn't do.""","""How fast and how long would it take to decrypt the information?
""","""I think this class was quite easy to understand and I was able to deepen my understanding of information throughout.
At first, I was a little impatient because there was no sound in teams, but after that I was able to watch the lecture without difficulty, so it was good.
We hope to see you next week. """,-1
C-2021-2_U129,,,,,"""I felt that it was quite difficult because of the technical content, but I thought it would be interesting to think about the logic of prefixes to make source coding as efficient as possible. I could not deepen my understanding of the entropy part. I think it's a point to reflect on, so I'd like to understand it before the next lecture.""",0
C-2021-2_U130,"""I learned what is the most efficient way to convey information, and how to simplify and convey a lot of data. I also learned about the advantages and limitations of encoding.""","""There were some difficult words in each unit, and it took me a while to understand them at first, but I was able to understand many of them as I looked more closely.""","""It was a little difficult to understand the contents of the second half in particular. I didn't really understand the specifics of the relationship with other fields, so I would like to review it.""",,"""The content was somehow related to everyday life, so I was able to understand it somehow, but there were many difficult parts, so I would like to review it properly for the next time.""",0
C-2021-2_U130,"""I learned what is the most efficient way to convey information, and how to simplify and convey a lot of data. I also learned about the advantages and limitations of encoding.""","""There were some difficult words in each unit, and it took me a while to understand them at first, but I was able to understand many of them as I looked more closely.""","""It was a little difficult to understand the contents of the second half in particular. I didn't really understand the specifics of the relationship with other fields, so I would like to review it.""",,"""The content was somehow related to everyday life, so I was able to understand it somehow, but there were many difficult parts, so I would like to review it properly for the next time.""",0
C-2021-2_U130,"""I learned what is the most efficient way to convey information, and how to simplify and convey a lot of data. I also learned about the advantages and limitations of encoding.""","""There were some difficult words in each unit, and it took me a while to understand them at first, but I was able to understand many of them as I looked more closely.""","""It was a little difficult to understand the contents of the second half in particular. I didn't really understand the specifics of the relationship with other fields, so I would like to review it.""",,"""The content was somehow related to everyday life, so I was able to understand it somehow, but there were many difficult parts, so I would like to review it properly for the next time.""",0
C-2021-2_U130,"""I learned what is the most efficient way to convey information, and how to simplify and convey a lot of data. I also learned about the advantages and limitations of encoding.""","""There were some difficult words in each unit, and it took me a while to understand them at first, but I was able to understand many of them as I looked more closely.""","""It was a little difficult to understand the contents of the second half in particular. I didn't really understand the specifics of the relationship with other fields, so I would like to review it.""",,"""The content was somehow related to everyday life, so I was able to understand it somehow, but there were many difficult parts, so I would like to review it properly for the next time.""",0
C-2021-2_U131,,"""To find the average codeword length and entropy values ​​by calculation. Especially, I was able to understand the reason why the calculation formula for the average codeword length is like that.""",,,"""Thanks to screen sharing, it became easier to understand which page I was studying, and I was able to concentrate more in class than last time. I was able to study more effectively using markers and notes. I thought that if I could understand the meaning of the equations as much as possible instead of memorizing them by heart, I would be able to improve my retention rate. """,-2
C-2021-2_U131,,"""To find the average codeword length and entropy values ​​by calculation. Especially, I was able to understand the reason why the calculation formula for the average codeword length is like that.""",,,"""Thanks to screen sharing, it became easier to understand which page I was studying, and I was able to concentrate more in class than last time. I was able to study more effectively using markers and notes. I thought that if I could understand the meaning of the equations as much as possible instead of memorizing them by heart, I would be able to improve my retention rate. """,-2
C-2021-2_U132,"""I learned techniques to express symbols and other objects as efficiently as possible so as not to overload the computer.""","""We found that it is easier to express frequently used codewords (for example, the weather symbol for fine weather) with as few characters as possible.""","""I didn't quite understand the initial conditions.""",,"""It was a difficult but practical and very meaningful class.""",-1
C-2021-2_U132,"""I learned techniques to express symbols and other objects as efficiently as possible so as not to overload the computer.""","""We found that it is easier to express frequently used codewords (for example, the weather symbol for fine weather) with as few characters as possible.""","""I didn't quite understand the initial conditions.""",,"""It was a difficult but practical and very meaningful class.""",-1
C-2021-2_U132,"""I learned techniques to express symbols and other objects as efficiently as possible so as not to overload the computer.""","""We found that it is easier to express frequently used codewords (for example, the weather symbol for fine weather) with as few characters as possible.""","""I didn't quite understand the initial conditions.""",,"""It was a difficult but practical and very meaningful class.""",-1
C-2021-2_U132,"""I learned techniques to express symbols and other objects as efficiently as possible so as not to overload the computer.""","""We found that it is easier to express frequently used codewords (for example, the weather symbol for fine weather) with as few characters as possible.""","""I didn't quite understand the initial conditions.""",,"""It was a difficult but practical and very meaningful class.""",-1
C-2021-2_U133,"""The information source can be output as a symbol, and the probability of occurrence of that symbol is fixed. By using this, the length of the code can be shortened, etc., and the length can be changed. Also, there is a prefix code, which allows instantaneous There are codes that can be made decodable.""","""We found that the average code length can be shortened by devising the use of symbols. We also found the average code length by calculation.""","""I didn't really understand why entropy is a lower bound on the average code length.""","""Why are you logging in entropy?""","""There were some things that were difficult to understand, such as initial symbols, but I was able to make an effort to understand them by checking the contents of the materials. good.""",-2
C-2021-2_U133,"""The information source can be output as a symbol, and the probability of occurrence of that symbol is fixed. By using this, the length of the code can be shortened, etc., and the length can be changed. Also, there is a prefix code, which allows instantaneous There are codes that can be made decodable.""","""We found that the average code length can be shortened by devising the use of symbols. We also found the average code length by calculation.""","""I didn't really understand why entropy is a lower bound on the average code length.""","""Why are you logging in entropy?""","""There were some things that were difficult to understand, such as initial symbols, but I was able to make an effort to understand them by checking the contents of the materials. good.""",-2
C-2021-2_U133,"""The information source can be output as a symbol, and the probability of occurrence of that symbol is fixed. By using this, the length of the code can be shortened, etc., and the length can be changed. Also, there is a prefix code, which allows instantaneous There are codes that can be made decodable.""","""We found that the average code length can be shortened by devising the use of symbols. We also found the average code length by calculation.""","""I didn't really understand why entropy is a lower bound on the average code length.""","""Why are you logging in entropy?""","""There were some things that were difficult to understand, such as initial symbols, but I was able to make an effort to understand them by checking the contents of the materials. good.""",-2
C-2021-2_U133,"""The information source can be output as a symbol, and the probability of occurrence of that symbol is fixed. By using this, the length of the code can be shortened, etc., and the length can be changed. Also, there is a prefix code, which allows instantaneous There are codes that can be made decodable.""","""We found that the average code length can be shortened by devising the use of symbols. We also found the average code length by calculation.""","""I didn't really understand why entropy is a lower bound on the average code length.""","""Why are you logging in entropy?""","""There were some things that were difficult to understand, such as initial symbols, but I was able to make an effort to understand them by checking the contents of the materials. good.""",-2
C-2021-2_U133,"""The information source can be output as a symbol, and the probability of occurrence of that symbol is fixed. By using this, the length of the code can be shortened, etc., and the length can be changed. Also, there is a prefix code, which allows instantaneous There are codes that can be made decodable.""","""We found that the average code length can be shortened by devising the use of symbols. We also found the average code length by calculation.""","""I didn't really understand why entropy is a lower bound on the average code length.""","""Why are you logging in entropy?""","""There were some things that were difficult to understand, such as initial symbols, but I was able to make an effort to understand them by checking the contents of the materials. good.""",-2
C-2021-2_U134,"""Learned a detailed example of source coding
It was found that by changing the sequence of codewords, it is possible to express with a shorter number of bits. For that purpose, I found that it is necessary to consider the normal probability of symbols.

I learned that there are unique decodability and instantaneous decodability. In relation to this, there is a word prefix code, and it has been found that it has the property of being instantly decodable.

I was able to know various codes and the evaluation criteria for them. ""","""I was able to do a concrete method of encoding and a simplification of it.""","""I didn't quite understand the last calculation.""",,"""Beginning with a review of the previous class, I was happy to learn the specifics of coding this time.""",-1
C-2021-2_U134,"""Learned a detailed example of source coding
It was found that by changing the sequence of codewords, it is possible to express with a shorter number of bits. For that purpose, I found that it is necessary to consider the normal probability of symbols.

I learned that there are unique decodability and instantaneous decodability. In relation to this, there is a word prefix code, and it has been found that it has the property of being instantly decodable.

I was able to know various codes and the evaluation criteria for them. ""","""I was able to do a concrete method of encoding and a simplification of it.""","""I didn't quite understand the last calculation.""",,"""Beginning with a review of the previous class, I was happy to learn the specifics of coding this time.""",-1
C-2021-2_U134,"""Learned a detailed example of source coding
It was found that by changing the sequence of codewords, it is possible to express with a shorter number of bits. For that purpose, I found that it is necessary to consider the normal probability of symbols.

I learned that there are unique decodability and instantaneous decodability. In relation to this, there is a word prefix code, and it has been found that it has the property of being instantly decodable.

I was able to know various codes and the evaluation criteria for them. ""","""I was able to do a concrete method of encoding and a simplification of it.""","""I didn't quite understand the last calculation.""",,"""Beginning with a review of the previous class, I was happy to learn the specifics of coding this time.""",-1
C-2021-2_U134,"""Learned a detailed example of source coding
It was found that by changing the sequence of codewords, it is possible to express with a shorter number of bits. For that purpose, I found that it is necessary to consider the normal probability of symbols.

I learned that there are unique decodability and instantaneous decodability. In relation to this, there is a word prefix code, and it has been found that it has the property of being instantly decodable.

I was able to know various codes and the evaluation criteria for them. ""","""I was able to do a concrete method of encoding and a simplification of it.""","""I didn't quite understand the last calculation.""",,"""Beginning with a review of the previous class, I was happy to learn the specifics of coding this time.""",-1
C-2021-2_U135,"""Efficiency of decoding can be improved by changing the code creation method according to the frequency of the symbols.""","""I found that it is possible to expect considerable ease of decoding just by adding rules to how to create codes.""",,,"""I don't use Bookroll's colored pens very often, so I decided to write important things in a separate notebook. I felt that this was more efficient.""",-3
C-2021-2_U135,"""Efficiency of decoding can be improved by changing the code creation method according to the frequency of the symbols.""","""I found that it is possible to expect considerable ease of decoding just by adding rules to how to create codes.""",,,"""I don't use Bookroll's colored pens very often, so I decided to write important things in a separate notebook. I felt that this was more efficient.""",-3
C-2021-2_U135,"""Efficiency of decoding can be improved by changing the code creation method according to the frequency of the symbols.""","""I found that it is possible to expect considerable ease of decoding just by adding rules to how to create codes.""",,,"""I don't use Bookroll's colored pens very often, so I decided to write important things in a separate notebook. I felt that this was more efficient.""",-3
C-2021-2_U137,"""When encoding information, it is necessary to encode it uniquely and so that it can be quickly combined. It is necessary to set the code so that the average code word tone is short. At this time, the establishment of each information Considering , it can be encoded well. Anyway, the prefix is ​​convenient!""","""I was able to understand how to calculate the average codeword tone and some important points when encoding. I found prefixes to be useful.""","""The content of entropy was difficult and difficult to understand. Especially, I couldn't understand the meaning of the theorem. I felt that preparation and review are really important.""","""I'm thinking about optimal coding, such as the Teikun code word tone, but if a quantum computer is completed, will it be possible to code more efficiently?""","""When I heard that encoding should be done so that it can be quickly decoded, I thought that any code with uniqueness could be quickly decoded. When I saw it, the diagram was so complicated that I thought it would not be possible to combine it instantly, and I was convinced.I was also impressed by the existence of a theorem in the lecture on information.It's mathematical and very interesting. It was the content.""",-2
C-2021-2_U137,"""When encoding information, it is necessary to encode it uniquely and so that it can be quickly combined. It is necessary to set the code so that the average code word tone is short. At this time, the establishment of each information Considering , it can be encoded well. Anyway, the prefix is ​​convenient!""","""I was able to understand how to calculate the average codeword tone and some important points when encoding. I found prefixes to be useful.""","""The content of entropy was difficult and difficult to understand. Especially, I couldn't understand the meaning of the theorem. I felt that preparation and review are really important.""","""I'm thinking about optimal coding, such as the Teikun code word tone, but if a quantum computer is completed, will it be possible to code more efficiently?""","""When I heard that encoding should be done so that it can be quickly decoded, I thought that any code with uniqueness could be quickly decoded. When I saw it, the diagram was so complicated that I thought it would not be possible to combine it instantly, and I was convinced.I was also impressed by the existence of a theorem in the lecture on information.It's mathematical and very interesting. It was the content.""",-2
C-2021-2_U137,"""When encoding information, it is necessary to encode it uniquely and so that it can be quickly combined. It is necessary to set the code so that the average code word tone is short. At this time, the establishment of each information Considering , it can be encoded well. Anyway, the prefix is ​​convenient!""","""I was able to understand how to calculate the average codeword tone and some important points when encoding. I found prefixes to be useful.""","""The content of entropy was difficult and difficult to understand. Especially, I couldn't understand the meaning of the theorem. I felt that preparation and review are really important.""","""I'm thinking about optimal coding, such as the Teikun code word tone, but if a quantum computer is completed, will it be possible to code more efficiently?""","""When I heard that encoding should be done so that it can be quickly decoded, I thought that any code with uniqueness could be quickly decoded. When I saw it, the diagram was so complicated that I thought it would not be possible to combine it instantly, and I was convinced.I was also impressed by the existence of a theorem in the lecture on information.It's mathematical and very interesting. It was the content.""",-2
C-2021-2_U137,"""When encoding information, it is necessary to encode it uniquely and so that it can be quickly combined. It is necessary to set the code so that the average code word tone is short. At this time, the establishment of each information Considering , it can be encoded well. Anyway, the prefix is ​​convenient!""","""I was able to understand how to calculate the average codeword tone and some important points when encoding. I found prefixes to be useful.""","""The content of entropy was difficult and difficult to understand. Especially, I couldn't understand the meaning of the theorem. I felt that preparation and review are really important.""","""I'm thinking about optimal coding, such as the Teikun code word tone, but if a quantum computer is completed, will it be possible to code more efficiently?""","""When I heard that encoding should be done so that it can be quickly decoded, I thought that any code with uniqueness could be quickly decoded. When I saw it, the diagram was so complicated that I thought it would not be possible to combine it instantly, and I was convinced.I was also impressed by the existence of a theorem in the lecture on information.It's mathematical and very interesting. It was the content.""",-2
C-2021-2_U137,"""When encoding information, it is necessary to encode it uniquely and so that it can be quickly combined. It is necessary to set the code so that the average code word tone is short. At this time, the establishment of each information Considering , it can be encoded well. Anyway, the prefix is ​​convenient!""","""I was able to understand how to calculate the average codeword tone and some important points when encoding. I found prefixes to be useful.""","""The content of entropy was difficult and difficult to understand. Especially, I couldn't understand the meaning of the theorem. I felt that preparation and review are really important.""","""I'm thinking about optimal coding, such as the Teikun code word tone, but if a quantum computer is completed, will it be possible to code more efficiently?""","""When I heard that encoding should be done so that it can be quickly decoded, I thought that any code with uniqueness could be quickly decoded. When I saw it, the diagram was so complicated that I thought it would not be possible to combine it instantly, and I was convinced.I was also impressed by the existence of a theorem in the lecture on information.It's mathematical and very interesting. It was the content.""",-2
C-2021-2_U138,"""In today's lecture, we will start by reviewing what we learned in the previous lecture, then we will learn about ``information source coding,'' which represents a string of symbols generated from an information source by a string of ○ and ●, and then we will learn about We learned about ""decoding"" that converts the obtained sequence of ●○ to the original symbol string, then we learned about ""unique decodability"", then we learned about ""instantaneous decodability"", and finally we learned about entropy. ""","""I didn't understand entropy at the preparatory stage, but I was able to understand it after taking the lecture.""",,,,-1
C-2021-2_U138,"""In today's lecture, we will start by reviewing what we learned in the previous lecture, then we will learn about ``information source coding,'' which represents a string of symbols generated from an information source by a string of ○ and ●, and then we will learn about We learned about ""decoding"" that converts the obtained sequence of ●○ to the original symbol string, then we learned about ""unique decodability"", then we learned about ""instantaneous decodability"", and finally we learned about entropy. ""","""I didn't understand entropy at the preparatory stage, but I was able to understand it after taking the lecture.""",,,,-1
C-2021-2_U139,"""Signs are determined based on various rational rules, such as the ability to uniquely convert and initial signs, and can be easily converted.""","""I was able to understand the code conversion method and code rules.""",,,,-1
C-2021-2_U139,"""Signs are determined based on various rational rules, such as the ability to uniquely convert and initial signs, and can be easily converted.""","""I was able to understand the code conversion method and code rules.""",,,,-1
C-2021-2_U14,"""Representing a string of symbols generated from an information source with a separate string (0,1) is called source coding, and conversely, converting the string obtained by encoding into the original string of symbols is called source coding. The purpose of information source coding is to design a code with the shortest possible average codeword length according to the probability distribution of symbols, so that it can be decoded uniquely and quickly (uniquely decodable, instantaneously decodable). It is a precondition. In other words, any initial code is acceptable. Also, among the initial codes for any given information source, the code with the smallest average codeword length is called the optimal code.""","""Information source coding does not simply blindly replace symbol strings, but considers whether it is uniquely decodable or instantaneously decodable, so that information can be transmitted efficiently. I understood.""","""I couldn't calculate entropy well, so I want to review it.""","""Regarding stationarity, is it correct to interpret that the probability of occurrence of a symbol string is the same from any point, even if you extract a part of the symbol string that continues for a long time?""",,-1
C-2021-2_U14,"""Representing a string of symbols generated from an information source with a separate string (0,1) is called source coding, and conversely, converting the string obtained by encoding into the original string of symbols is called source coding. The purpose of information source coding is to design a code with the shortest possible average codeword length according to the probability distribution of symbols, so that it can be decoded uniquely and quickly (uniquely decodable, instantaneously decodable). It is a precondition. In other words, any initial code is acceptable. Also, among the initial codes for any given information source, the code with the smallest average codeword length is called the optimal code.""","""Information source coding does not simply blindly replace symbol strings, but considers whether it is uniquely decodable or instantaneously decodable, so that information can be transmitted efficiently. I understood.""","""I couldn't calculate entropy well, so I want to review it.""","""Regarding stationarity, is it correct to interpret that the probability of occurrence of a symbol string is the same from any point, even if you extract a part of the symbol string that continues for a long time?""",,-1
C-2021-2_U14,"""Representing a string of symbols generated from an information source with a separate string (0,1) is called source coding, and conversely, converting the string obtained by encoding into the original string of symbols is called source coding. The purpose of information source coding is to design a code with the shortest possible average codeword length according to the probability distribution of symbols, so that it can be decoded uniquely and quickly (uniquely decodable, instantaneously decodable). It is a precondition. In other words, any initial code is acceptable. Also, among the initial codes for any given information source, the code with the smallest average codeword length is called the optimal code.""","""Information source coding does not simply blindly replace symbol strings, but considers whether it is uniquely decodable or instantaneously decodable, so that information can be transmitted efficiently. I understood.""","""I couldn't calculate entropy well, so I want to review it.""","""Regarding stationarity, is it correct to interpret that the probability of occurrence of a symbol string is the same from any point, even if you extract a part of the symbol string that continues for a long time?""",,-1
C-2021-2_U14,"""Representing a string of symbols generated from an information source with a separate string (0,1) is called source coding, and conversely, converting the string obtained by encoding into the original string of symbols is called source coding. The purpose of information source coding is to design a code with the shortest possible average codeword length according to the probability distribution of symbols, so that it can be decoded uniquely and quickly (uniquely decodable, instantaneously decodable). It is a precondition. In other words, any initial code is acceptable. Also, among the initial codes for any given information source, the code with the smallest average codeword length is called the optimal code.""","""Information source coding does not simply blindly replace symbol strings, but considers whether it is uniquely decodable or instantaneously decodable, so that information can be transmitted efficiently. I understood.""","""I couldn't calculate entropy well, so I want to review it.""","""Regarding stationarity, is it correct to interpret that the probability of occurrence of a symbol string is the same from any point, even if you extract a part of the symbol string that continues for a long time?""",,-1
C-2021-2_U140,"""Conditions for Signs and Conditions for Ideal Signs.""","""For a code to hold, two conditions must be met: the code must be uniquely restored, and the code can be quickly restored.
A desirable code must meet the condition that it can be expressed as short as possible in addition to the above conditions. ""","""The description of entropy was difficult to understand.""","""Nothing in particular.""","""Even though the information code is represented by only two symbols, there are various mathematical formulas, and I thought it was profound.""",-3
C-2021-2_U140,"""Conditions for Signs and Conditions for Ideal Signs.""","""For a code to hold, two conditions must be met: the code must be uniquely restored, and the code can be quickly restored.
A desirable code must meet the condition that it can be expressed as short as possible in addition to the above conditions. ""","""The description of entropy was difficult to understand.""","""Nothing in particular.""","""Even though the information code is represented by only two symbols, there are various mathematical formulas, and I thought it was profound.""",-3
C-2021-2_U140,"""Conditions for Signs and Conditions for Ideal Signs.""","""For a code to hold, two conditions must be met: the code must be uniquely restored, and the code can be quickly restored.
A desirable code must meet the condition that it can be expressed as short as possible in addition to the above conditions. ""","""The description of entropy was difficult to understand.""","""Nothing in particular.""","""Even though the information code is represented by only two symbols, there are various mathematical formulas, and I thought it was profound.""",-3
C-2021-2_U140,"""Conditions for Signs and Conditions for Ideal Signs.""","""For a code to hold, two conditions must be met: the code must be uniquely restored, and the code can be quickly restored.
A desirable code must meet the condition that it can be expressed as short as possible in addition to the above conditions. ""","""The description of entropy was difficult to understand.""","""Nothing in particular.""","""Even though the information code is represented by only two symbols, there are various mathematical formulas, and I thought it was profound.""",-3
C-2021-2_U140,"""Conditions for Signs and Conditions for Ideal Signs.""","""For a code to hold, two conditions must be met: the code must be uniquely restored, and the code can be quickly restored.
A desirable code must meet the condition that it can be expressed as short as possible in addition to the above conditions. ""","""The description of entropy was difficult to understand.""","""Nothing in particular.""","""Even though the information code is represented by only two symbols, there are various mathematical formulas, and I thought it was profound.""",-3
C-2021-2_U141,"""I explained encoding and decoding of information sources, unique decoding, initial decoding, etc. as examples, and explained how to obtain the shortest representation from the probability of the code.""","""How to decrypt and what indication is not unambiguous decryption.""","""I didn't quite understand how to find the average codeword length and the entropy part.""","""Nothing in particular.""","""In the example weather forecast, there are only four weather forecasts, but I was surprised by the number of ways to display them. On the other hand, it wasn't that complicated, so I thought it was interesting. I will continue to use LGC, which the teacher introduced. I would like to make use of it.""",-1
C-2021-2_U141,"""I explained encoding and decoding of information sources, unique decoding, initial decoding, etc. as examples, and explained how to obtain the shortest representation from the probability of the code.""","""How to decrypt and what indication is not unambiguous decryption.""","""I didn't quite understand how to find the average codeword length and the entropy part.""","""Nothing in particular.""","""In the example weather forecast, there are only four weather forecasts, but I was surprised by the number of ways to display them. On the other hand, it wasn't that complicated, so I thought it was interesting. I will continue to use LGC, which the teacher introduced. I would like to make use of it.""",-1
C-2021-2_U141,"""I explained encoding and decoding of information sources, unique decoding, initial decoding, etc. as examples, and explained how to obtain the shortest representation from the probability of the code.""","""How to decrypt and what indication is not unambiguous decryption.""","""I didn't quite understand how to find the average codeword length and the entropy part.""","""Nothing in particular.""","""In the example weather forecast, there are only four weather forecasts, but I was surprised by the number of ways to display them. On the other hand, it wasn't that complicated, so I thought it was interesting. I will continue to use LGC, which the teacher introduced. I would like to make use of it.""",-1
C-2021-2_U141,"""I explained encoding and decoding of information sources, unique decoding, initial decoding, etc. as examples, and explained how to obtain the shortest representation from the probability of the code.""","""How to decrypt and what indication is not unambiguous decryption.""","""I didn't quite understand how to find the average codeword length and the entropy part.""","""Nothing in particular.""","""In the example weather forecast, there are only four weather forecasts, but I was surprised by the number of ways to display them. On the other hand, it wasn't that complicated, so I thought it was interesting. I will continue to use LGC, which the teacher introduced. I would like to make use of it.""",-1
C-2021-2_U141,"""I explained encoding and decoding of information sources, unique decoding, initial decoding, etc. as examples, and explained how to obtain the shortest representation from the probability of the code.""","""How to decrypt and what indication is not unambiguous decryption.""","""I didn't quite understand how to find the average codeword length and the entropy part.""","""Nothing in particular.""","""In the example weather forecast, there are only four weather forecasts, but I was surprised by the number of ways to display them. On the other hand, it wasn't that complicated, so I thought it was interesting. I will continue to use LGC, which the teacher introduced. I would like to make use of it.""",-1
C-2021-2_U142,"""Information can be encoded, and codes can reduce the average codeword length.
There are things that can be uniquely combined and things that cannot be combined, and prefixes can definitely be combined.
A prefix code is also called an instantaneously combinable code.
The average codeword length cannot be shorter than the entropy. ""","""Some codes are not uniquely combinable, and I found that prefixes are a sure way to avoid that.
I also learned that the initial code should aim for the optimal code. ""","""I had a vague idea of ​​what entropy meant, but I couldn't explain it well, and it was difficult to calculate.""",,"""I know how to summarize information in a concise way and make it possible to combine information, but I don't know exactly what it is useful for, so I'd like to investigate it.""",-1
C-2021-2_U142,"""Information can be encoded, and codes can reduce the average codeword length.
There are things that can be uniquely combined and things that cannot be combined, and prefixes can definitely be combined.
A prefix code is also called an instantaneously combinable code.
The average codeword length cannot be shorter than the entropy. ""","""Some codes are not uniquely combinable, and I found that prefixes are a sure way to avoid that.
I also learned that the initial code should aim for the optimal code. ""","""I had a vague idea of ​​what entropy meant, but I couldn't explain it well, and it was difficult to calculate.""",,"""I know how to summarize information in a concise way and make it possible to combine information, but I don't know exactly what it is useful for, so I'd like to investigate it.""",-1
C-2021-2_U142,"""Information can be encoded, and codes can reduce the average codeword length.
There are things that can be uniquely combined and things that cannot be combined, and prefixes can definitely be combined.
A prefix code is also called an instantaneously combinable code.
The average codeword length cannot be shorter than the entropy. ""","""Some codes are not uniquely combinable, and I found that prefixes are a sure way to avoid that.
I also learned that the initial code should aim for the optimal code. ""","""I had a vague idea of ​​what entropy meant, but I couldn't explain it well, and it was difficult to calculate.""",,"""I know how to summarize information in a concise way and make it possible to combine information, but I don't know exactly what it is useful for, so I'd like to investigate it.""",-1
C-2021-2_U142,"""Information can be encoded, and codes can reduce the average codeword length.
There are things that can be uniquely combined and things that cannot be combined, and prefixes can definitely be combined.
A prefix code is also called an instantaneously combinable code.
The average codeword length cannot be shorter than the entropy. ""","""Some codes are not uniquely combinable, and I found that prefixes are a sure way to avoid that.
I also learned that the initial code should aim for the optimal code. ""","""I had a vague idea of ​​what entropy meant, but I couldn't explain it well, and it was difficult to calculate.""",,"""I know how to summarize information in a concise way and make it possible to combine information, but I don't know exactly what it is useful for, so I'd like to investigate it.""",-1
C-2021-2_U143,,,"""Some non-initial codes are uniquely decodable and some are not, and it may take some time to tell them apart. I know how to calculate entropy, but why does that method give a lower bound?"" I don't quite understand why it's required.""",,,-2
C-2021-2_U144,,,"""The relationship between the initial code and the unique decodable symbol was ambiguous, so I will review it thoroughly.""",,"""I didn't know there were so many different symbols, and I found it very interesting that there are various relationships among them.""",0
C-2021-2_U144,,,"""The relationship between the initial code and the unique decodable symbol was ambiguous, so I will review it thoroughly.""",,"""I didn't know there were so many different symbols, and I found it very interesting that there are various relationships among them.""",0
C-2021-2_U145,,"""An information source is a source that outputs symbols at regular time intervals.
The importance of prefixes to satisfy instantaneous composability""","""I didn't understand why entropy was required in that formula""",,"""Because of the screen sharing, I was able to understand better than last time.
It's a reflection that I forgot my homework. """,0
C-2021-2_U145,,"""An information source is a source that outputs symbols at regular time intervals.
The importance of prefixes to satisfy instantaneous composability""","""I didn't understand why entropy was required in that formula""",,"""Because of the screen sharing, I was able to understand better than last time.
It's a reflection that I forgot my homework. """,0
C-2021-2_U145,,"""An information source is a source that outputs symbols at regular time intervals.
The importance of prefixes to satisfy instantaneous composability""","""I didn't understand why entropy was required in that formula""",,"""Because of the screen sharing, I was able to understand better than last time.
It's a reflection that I forgot my homework. """,0
C-2021-2_U146,"""When encoding information, it should be unique, quick, and as short as possible""",,,,,0
C-2021-2_U147,"""Information source coding is to represent a sequence of symbols generated from an information source with ○ and ●. The purpose of this is to design symbols with as short an average word length as possible according to the probability distribution of symbols. , must satisfy the possibility of unique decoding and instantaneous decoding.In addition, there is a lower bound on the average codeword length, expressed as entropy.""","""I understand the meaning of unique decoding, instantaneous decoding, and the method of entropy calculation.""",,,"""Information can be easily expressed with only ○ and ●, but if it is not unique decoding and instantaneous decoding, it may be difficult to read the wrong information.""",-2
C-2021-2_U147,"""Information source coding is to represent a sequence of symbols generated from an information source with ○ and ●. The purpose of this is to design symbols with as short an average word length as possible according to the probability distribution of symbols. , must satisfy the possibility of unique decoding and instantaneous decoding.In addition, there is a lower bound on the average codeword length, expressed as entropy.""","""I understand the meaning of unique decoding, instantaneous decoding, and the method of entropy calculation.""",,,"""Information can be easily expressed with only ○ and ●, but if it is not unique decoding and instantaneous decoding, it may be difficult to read the wrong information.""",-2
C-2021-2_U147,"""Information source coding is to represent a sequence of symbols generated from an information source with ○ and ●. The purpose of this is to design symbols with as short an average word length as possible according to the probability distribution of symbols. , must satisfy the possibility of unique decoding and instantaneous decoding.In addition, there is a lower bound on the average codeword length, expressed as entropy.""","""I understand the meaning of unique decoding, instantaneous decoding, and the method of entropy calculation.""",,,"""Information can be easily expressed with only ○ and ●, but if it is not unique decoding and instantaneous decoding, it may be difficult to read the wrong information.""",-2
C-2021-2_U148,"A source that outputs symbols at regular time intervals is called an information source, and a sequence of symbols output by the information source is represented by 0s and 1s is called information source coding. The average codeword length is called the average codeword length.Source coding is required to be short on the premise that it can only take one meaning and can be quickly reversed.If one codeword is included at the beginning of another codeword, A code that satisfies the condition is called a prefix condition, and a code that satisfies the condition is called a prefix code.The prefix code has the property of being instantaneously combinable.There is a value called entropy, and the average codeword length of the optimal code is greater than or equal to entropy and less than or equal to entropy + 1. .""","""We found that information can be read quickly because word prefixes can determine information without looking ahead in the sequence.""",,,"""There were parts that were difficult to understand along the way, but in the end I was able to understand""",-1
C-2021-2_U148,"A source that outputs symbols at regular time intervals is called an information source, and a sequence of symbols output by the information source is represented by 0s and 1s is called information source coding. The average codeword length is called the average codeword length.Source coding is required to be short on the premise that it can only take one meaning and can be quickly reversed.If one codeword is included at the beginning of another codeword, A code that satisfies the condition is called a prefix condition, and a code that satisfies the condition is called a prefix code.The prefix code has the property of being instantaneously combinable.There is a value called entropy, and the average codeword length of the optimal code is greater than or equal to entropy and less than or equal to entropy + 1. .""","""We found that information can be read quickly because word prefixes can determine information without looking ahead in the sequence.""",,,"""There were parts that were difficult to understand along the way, but in the end I was able to understand""",-1
C-2021-2_U148,"A source that outputs symbols at regular time intervals is called an information source, and a sequence of symbols output by the information source is represented by 0s and 1s is called information source coding. The average codeword length is called the average codeword length.Source coding is required to be short on the premise that it can only take one meaning and can be quickly reversed.If one codeword is included at the beginning of another codeword, A code that satisfies the condition is called a prefix condition, and a code that satisfies the condition is called a prefix code.The prefix code has the property of being instantaneously combinable.There is a value called entropy, and the average codeword length of the optimal code is greater than or equal to entropy and less than or equal to entropy + 1. .""","""We found that information can be read quickly because word prefixes can determine information without looking ahead in the sequence.""",,,"""There were parts that were difficult to understand along the way, but in the end I was able to understand""",-1
C-2021-2_U15,,,,,"""There were a lot of terms I didn't understand, so I couldn't understand clearly, so I would like to review it.""",-1
C-2021-2_U151,,"""I was able to understand the meaning of 'uniquely' and 'instantly', such as returning uniquely and instantly. ""","""Entropy and such took a while to make sense.""",,,-3
C-2021-2_U151,,"""I was able to understand the meaning of 'uniquely' and 'instantly', such as returning uniquely and instantly. ""","""Entropy and such took a while to make sense.""",,,-3
C-2021-2_U152,"""It has been proven that the optimal code lies between the entropy plus one.""",,,,,-1
C-2021-2_U153,"""I learned about what kind of ingenuity should be used in encoding the information source to achieve the desired encoding. Finally, I learned about average codeword length, entropy, and definitions and theorems of optimal codes. .""","""I was able to understand the contents of the unique decoding possibility and the instantaneous combining possibility necessary to make a desirable millionaire. I was also able to understand the definition of the initial code and distinguish between the initial code and the non-initial code. Now.""","""I was able to memorize the definitions and theorems of average codeword length, entropy, and optimal code, which I did towards the end, but I felt that I hadn't fully understood the content yet.""","""Nothing in particular.""","""I was able to understand the general content of information encoding, but there are parts of the content written in (3) that I do not understand, so I would like to deepen my understanding by researching it myself outside of class. rice field.""",-3
C-2021-2_U153,"""I learned about what kind of ingenuity should be used in encoding the information source to achieve the desired encoding. Finally, I learned about average codeword length, entropy, and definitions and theorems of optimal codes. .""","""I was able to understand the contents of the unique decoding possibility and the instantaneous combining possibility necessary to make a desirable millionaire. I was also able to understand the definition of the initial code and distinguish between the initial code and the non-initial code. Now.""","""I was able to memorize the definitions and theorems of average codeword length, entropy, and optimal code, which I did towards the end, but I felt that I hadn't fully understood the content yet.""","""Nothing in particular.""","""I was able to understand the general content of information encoding, but there are parts of the content written in (3) that I do not understand, so I would like to deepen my understanding by researching it myself outside of class. rice field.""",-3
C-2021-2_U153,"""I learned about what kind of ingenuity should be used in encoding the information source to achieve the desired encoding. Finally, I learned about average codeword length, entropy, and definitions and theorems of optimal codes. .""","""I was able to understand the contents of the unique decoding possibility and the instantaneous combining possibility necessary to make a desirable millionaire. I was also able to understand the definition of the initial code and distinguish between the initial code and the non-initial code. Now.""","""I was able to memorize the definitions and theorems of average codeword length, entropy, and optimal code, which I did towards the end, but I felt that I hadn't fully understood the content yet.""","""Nothing in particular.""","""I was able to understand the general content of information encoding, but there are parts of the content written in (3) that I do not understand, so I would like to deepen my understanding by researching it myself outside of class. rice field.""",-3
C-2021-2_U153,"""I learned about what kind of ingenuity should be used in encoding the information source to achieve the desired encoding. Finally, I learned about average codeword length, entropy, and definitions and theorems of optimal codes. .""","""I was able to understand the contents of the unique decoding possibility and the instantaneous combining possibility necessary to make a desirable millionaire. I was also able to understand the definition of the initial code and distinguish between the initial code and the non-initial code. Now.""","""I was able to memorize the definitions and theorems of average codeword length, entropy, and optimal code, which I did towards the end, but I felt that I hadn't fully understood the content yet.""","""Nothing in particular.""","""I was able to understand the general content of information encoding, but there are parts of the content written in (3) that I do not understand, so I would like to deepen my understanding by researching it myself outside of class. rice field.""",-3
C-2021-2_U153,"""I learned about what kind of ingenuity should be used in encoding the information source to achieve the desired encoding. Finally, I learned about average codeword length, entropy, and definitions and theorems of optimal codes. .""","""I was able to understand the contents of the unique decoding possibility and the instantaneous combining possibility necessary to make a desirable millionaire. I was also able to understand the definition of the initial code and distinguish between the initial code and the non-initial code. Now.""","""I was able to memorize the definitions and theorems of average codeword length, entropy, and optimal code, which I did towards the end, but I felt that I hadn't fully understood the content yet.""","""Nothing in particular.""","""I was able to understand the general content of information encoding, but there are parts of the content written in (3) that I do not understand, so I would like to deepen my understanding by researching it myself outside of class. rice field.""",-3
C-2021-2_U154,,,,"""Nothing in particular.""","""I understood how to find the optimal code when encoding information sources and the characteristics of each millionaire. I would like to try using markers and notes in the preparation stage. I also practice entropy calculations a lot. I want to be able to do it perfectly.""",-1
C-2021-2_U154,,,,"""Nothing in particular.""","""I understood how to find the optimal code when encoding information sources and the characteristics of each millionaire. I would like to try using markers and notes in the preparation stage. I also practice entropy calculations a lot. I want to be able to do it perfectly.""",-1
C-2021-2_U155,,,"""I didn't understand much from your explanation of entropy""",,,-1
C-2021-2_U156,"""Ingenuity to make information compact""","""Even with the same information, if you devise a method, you can convey it with a smaller amount of information.""","""How Entropy Helps with Code Length""","""Does thinking about entropy mean that we know the minimum length of information to be transmitted?""","""I had a hard time catching up with my understanding of the class because my preparation was just before the class.
I will be careful to draw a line in my preparation from the next time onwards. """,-3
C-2021-2_U156,"""Ingenuity to make information compact""","""Even with the same information, if you devise a method, you can convey it with a smaller amount of information.""","""How Entropy Helps with Code Length""","""Does thinking about entropy mean that we know the minimum length of information to be transmitted?""","""I had a hard time catching up with my understanding of the class because my preparation was just before the class.
I will be careful to draw a line in my preparation from the next time onwards. """,-3
C-2021-2_U156,"""Ingenuity to make information compact""","""Even with the same information, if you devise a method, you can convey it with a smaller amount of information.""","""How Entropy Helps with Code Length""","""Does thinking about entropy mean that we know the minimum length of information to be transmitted?""","""I had a hard time catching up with my understanding of the class because my preparation was just before the class.
I will be careful to draw a line in my preparation from the next time onwards. """,-3
C-2021-2_U156,"""Ingenuity to make information compact""","""Even with the same information, if you devise a method, you can convey it with a smaller amount of information.""","""How Entropy Helps with Code Length""","""Does thinking about entropy mean that we know the minimum length of information to be transmitted?""","""I had a hard time catching up with my understanding of the class because my preparation was just before the class.
I will be careful to draw a line in my preparation from the next time onwards. """,-3
C-2021-2_U156,"""Ingenuity to make information compact""","""Even with the same information, if you devise a method, you can convey it with a smaller amount of information.""","""How Entropy Helps with Code Length""","""Does thinking about entropy mean that we know the minimum length of information to be transmitted?""","""I had a hard time catching up with my understanding of the class because my preparation was just before the class.
I will be careful to draw a line in my preparation from the next time onwards. """,-3
C-2021-2_U157,"""When information is transmitted, it is expressed by encoding it with two symbols, and the receiving side decodes it. In order to shorten the symbol string, it is effective to assign short codes to those that have a high probability of occurrence.""","""I was able to understand the relationship between prefix codes and uniquely decodable codes in an easy-to-understand diagram. Also, there were examples of how to express various codes and their good points and bad points, so I understood well.""",,,,-2
C-2021-2_U157,"""When information is transmitted, it is expressed by encoding it with two symbols, and the receiving side decodes it. In order to shorten the symbol string, it is effective to assign short codes to those that have a high probability of occurrence.""","""I was able to understand the relationship between prefix codes and uniquely decodable codes in an easy-to-understand diagram. Also, there were examples of how to express various codes and their good points and bad points, so I understood well.""",,,,-2
C-2021-2_U158,"""Encoding the source of information and how to decipher it""","""There are things that can be done instantaneously and things that can't be done to distinguish codes.
Entropy is a lower bound on the average codeword length. ""","""How to calculate entropy
How to distinguish non-initial symbols""",,"""Today's class was more difficult than last time, and there were some things I couldn't keep up with, but I decided to do a thorough review.
Entropy was about to come out, so I thought I'd try to understand it. """,-1
C-2021-2_U158,"""Encoding the source of information and how to decipher it""","""There are things that can be done instantaneously and things that can't be done to distinguish codes.
Entropy is a lower bound on the average codeword length. ""","""How to calculate entropy
How to distinguish non-initial symbols""",,"""Today's class was more difficult than last time, and there were some things I couldn't keep up with, but I decided to do a thorough review.
Entropy was about to come out, so I thought I'd try to understand it. """,-1
C-2021-2_U158,"""Encoding the source of information and how to decipher it""","""There are things that can be done instantaneously and things that can't be done to distinguish codes.
Entropy is a lower bound on the average codeword length. ""","""How to calculate entropy
How to distinguish non-initial symbols""",,"""Today's class was more difficult than last time, and there were some things I couldn't keep up with, but I decided to do a thorough review.
Entropy was about to come out, so I thought I'd try to understand it. """,-1
C-2021-2_U158,"""Encoding the source of information and how to decipher it""","""There are things that can be done instantaneously and things that can't be done to distinguish codes.
Entropy is a lower bound on the average codeword length. ""","""How to calculate entropy
How to distinguish non-initial symbols""",,"""Today's class was more difficult than last time, and there were some things I couldn't keep up with, but I decided to do a thorough review.
Entropy was about to come out, so I thought I'd try to understand it. """,-1
C-2021-2_U159,"""In order to represent information in a shorter length, source coding is used, which should have unique decodability or instantaneous decodability, and the lower bound on the average code length is called entropy.""","""Overview of Source Coding and Understanding Entropy""","""I didn't understand the importance of entropy""",,"""The content was a little difficult.""",-1
C-2021-2_U159,"""In order to represent information in a shorter length, source coding is used, which should have unique decodability or instantaneous decodability, and the lower bound on the average code length is called entropy.""","""Overview of Source Coding and Understanding Entropy""","""I didn't understand the importance of entropy""",,"""The content was a little difficult.""",-1
C-2021-2_U159,"""In order to represent information in a shorter length, source coding is used, which should have unique decodability or instantaneous decodability, and the lower bound on the average code length is called entropy.""","""Overview of Source Coding and Understanding Entropy""","""I didn't understand the importance of entropy""",,"""The content was a little difficult.""",-1
C-2021-2_U159,"""In order to represent information in a shorter length, source coding is used, which should have unique decodability or instantaneous decodability, and the lower bound on the average code length is called entropy.""","""Overview of Source Coding and Understanding Entropy""","""I didn't understand the importance of entropy""",,"""The content was a little difficult.""",-1
C-2021-2_U16,"""The best way to encode information to convey it faster
""","""I was able to find out what the sources of information conveyed by ○ and ● are and what they mean.
It turns out that the use of prefixes is the most efficient way to encode information sources.""","""I had a hard time understanding the illumination part of the proof of Kraft's inequality.
I couldn't even understand the source coding theorem
""",,,-2
C-2021-2_U16,"""The best way to encode information to convey it faster
""","""I was able to find out what the sources of information conveyed by ○ and ● are and what they mean.
It turns out that the use of prefixes is the most efficient way to encode information sources.""","""I had a hard time understanding the illumination part of the proof of Kraft's inequality.
I couldn't even understand the source coding theorem
""",,,-2
C-2021-2_U16,"""The best way to encode information to convey it faster
""","""I was able to find out what the sources of information conveyed by ○ and ● are and what they mean.
It turns out that the use of prefixes is the most efficient way to encode information sources.""","""I had a hard time understanding the illumination part of the proof of Kraft's inequality.
I couldn't even understand the source coding theorem
""",,,-2
C-2021-2_U160,"""In order to shorten the average codeword length, it is better to represent easily appearing symbols with short codewords and less likely appearing symbols with long codewords.
For information coding, a code with an average codeword length as short as possible is designed. It is important to be able to return the sign to the sign uniquely and quickly.
Entropy is the lower bound of the average codeword length. The average codeword length is never less than the entropy. ""","""We were able to find the average codeword length.
We were able to identify whether it was uniquely decodable.
I was able to check whether the wrong answer condition was met. ""","""calculate log""",,"""I learned a lot about codes that convey information.
I want to make sure there are no calculation errors.
Information is conveyed as short, clear and understandable (unique) as possible.
LGC seems convenient, so I thought I'd try it. """,-3
C-2021-2_U160,"""In order to shorten the average codeword length, it is better to represent easily appearing symbols with short codewords and less likely appearing symbols with long codewords.
For information coding, a code with an average codeword length as short as possible is designed. It is important to be able to return the sign to the sign uniquely and quickly.
Entropy is the lower bound of the average codeword length. The average codeword length is never less than the entropy. ""","""We were able to find the average codeword length.
We were able to identify whether it was uniquely decodable.
I was able to check whether the wrong answer condition was met. ""","""calculate log""",,"""I learned a lot about codes that convey information.
I want to make sure there are no calculation errors.
Information is conveyed as short, clear and understandable (unique) as possible.
LGC seems convenient, so I thought I'd try it. """,-3
C-2021-2_U160,"""In order to shorten the average codeword length, it is better to represent easily appearing symbols with short codewords and less likely appearing symbols with long codewords.
For information coding, a code with an average codeword length as short as possible is designed. It is important to be able to return the sign to the sign uniquely and quickly.
Entropy is the lower bound of the average codeword length. The average codeword length is never less than the entropy. ""","""We were able to find the average codeword length.
We were able to identify whether it was uniquely decodable.
I was able to check whether the wrong answer condition was met. ""","""calculate log""",,"""I learned a lot about codes that convey information.
I want to make sure there are no calculation errors.
Information is conveyed as short, clear and understandable (unique) as possible.
LGC seems convenient, so I thought I'd try it. """,-3
C-2021-2_U160,"""In order to shorten the average codeword length, it is better to represent easily appearing symbols with short codewords and less likely appearing symbols with long codewords.
For information coding, a code with an average codeword length as short as possible is designed. It is important to be able to return the sign to the sign uniquely and quickly.
Entropy is the lower bound of the average codeword length. The average codeword length is never less than the entropy. ""","""We were able to find the average codeword length.
We were able to identify whether it was uniquely decodable.
I was able to check whether the wrong answer condition was met. ""","""calculate log""",,"""I learned a lot about codes that convey information.
I want to make sure there are no calculation errors.
Information is conveyed as short, clear and understandable (unique) as possible.
LGC seems convenient, so I thought I'd try it. """,-3
C-2021-2_U163,"""The purpose of source coding is to design a unique, quick-recoverable code with as short an average code length as possible according to the probability distribution of the symbol. The prefix code satisfies these two conditions and can be said to be effective. In this case, the optimal code is the prefix code with the smallest average code length.""","""I learned about the purpose and method of source coding.""","""I felt that it would be difficult to actually make it by myself""",,"""I felt that the idea of ​​prefixes could be used effectively when categorizing various phenomena.""",-1
C-2021-2_U163,"""The purpose of source coding is to design a unique, quick-recoverable code with as short an average code length as possible according to the probability distribution of the symbol. The prefix code satisfies these two conditions and can be said to be effective. In this case, the optimal code is the prefix code with the smallest average code length.""","""I learned about the purpose and method of source coding.""","""I felt that it would be difficult to actually make it by myself""",,"""I felt that the idea of ​​prefixes could be used effectively when categorizing various phenomena.""",-1
C-2021-2_U163,"""The purpose of source coding is to design a unique, quick-recoverable code with as short an average code length as possible according to the probability distribution of the symbol. The prefix code satisfies these two conditions and can be said to be effective. In this case, the optimal code is the prefix code with the smallest average code length.""","""I learned about the purpose and method of source coding.""","""I felt that it would be difficult to actually make it by myself""",,"""I felt that the idea of ​​prefixes could be used effectively when categorizing various phenomena.""",-1
C-2021-2_U163,"""The purpose of source coding is to design a unique, quick-recoverable code with as short an average code length as possible according to the probability distribution of the symbol. The prefix code satisfies these two conditions and can be said to be effective. In this case, the optimal code is the prefix code with the smallest average code length.""","""I learned about the purpose and method of source coding.""","""I felt that it would be difficult to actually make it by myself""",,"""I felt that the idea of ​​prefixes could be used effectively when categorizing various phenomena.""",-1
C-2021-2_U164,,,,,"""I was able to understand most of the things in the preparation stage.""",-2
C-2021-2_U165,"""Lecture on how to streamline the work of replacing and returning information with symbols.""","""I think I have understood the general flow of encoding, decoding, and streamlining information.""","""I learned new things such as entropy and was a little confused. I want to review it often.""",,"""I forgot to do my homework, so I'll try not to forget about it next time.""",-2
C-2021-2_U165,"""Lecture on how to streamline the work of replacing and returning information with symbols.""","""I think I have understood the general flow of encoding, decoding, and streamlining information.""","""I learned new things such as entropy and was a little confused. I want to review it often.""",,"""I forgot to do my homework, so I'll try not to forget about it next time.""",-2
C-2021-2_U165,"""Lecture on how to streamline the work of replacing and returning information with symbols.""","""I think I have understood the general flow of encoding, decoding, and streamlining information.""","""I learned new things such as entropy and was a little confused. I want to review it often.""",,"""I forgot to do my homework, so I'll try not to forget about it next time.""",-2
C-2021-2_U165,"""Lecture on how to streamline the work of replacing and returning information with symbols.""","""I think I have understood the general flow of encoding, decoding, and streamlining information.""","""I learned new things such as entropy and was a little confused. I want to review it often.""",,"""I forgot to do my homework, so I'll try not to forget about it next time.""",-2
C-2021-2_U167,"""On source coding with both unique decodability and instantaneous decodability. Touching on the concept of average codeword length, we confirm that the concept of entropy is involved for the shortest codeword length.""","""By designing a code with a short average codeword length according to the probability distribution of symbols, power consumption and decoding time can be shortened.""",,"""What is the [average] of the average codeword lengths?""",,-2
C-2021-2_U167,"""On source coding with both unique decodability and instantaneous decodability. Touching on the concept of average codeword length, we confirm that the concept of entropy is involved for the shortest codeword length.""","""By designing a code with a short average codeword length according to the probability distribution of symbols, power consumption and decoding time can be shortened.""",,"""What is the [average] of the average codeword lengths?""",,-2
C-2021-2_U167,"""On source coding with both unique decodability and instantaneous decodability. Touching on the concept of average codeword length, we confirm that the concept of entropy is involved for the shortest codeword length.""","""By designing a code with a short average codeword length according to the probability distribution of symbols, power consumption and decoding time can be shortened.""",,"""What is the [average] of the average codeword lengths?""",,-2
C-2021-2_U168,"""Information is expressed as a combination of 0s and 1s. When encoding, set the average codeword length to be as short as possible. To encode information, it must be possible to decode uniquely and quickly."" However, it is necessary that the code be unique, that it can be recovered quickly, and that it should be represented as short as possible. Entropy is the lower bound on the average codeword length.""","""We found that it is important to set the average codeword length as short as possible while recovering it accurately. By finding the entropy, we can find a method to find the lower bound of the average codeword length.""","""I didn't really understand the meaning of the prefix at first.""",,"""The content was a little difficult, so I couldn't understand it well just in class. I have a test next week, so I want to review it thoroughly and challenge myself.""",-1
C-2021-2_U168,"""Information is expressed as a combination of 0s and 1s. When encoding, set the average codeword length to be as short as possible. To encode information, it must be possible to decode uniquely and quickly."" However, it is necessary that the code be unique, that it can be recovered quickly, and that it should be represented as short as possible. Entropy is the lower bound on the average codeword length.""","""We found that it is important to set the average codeword length as short as possible while recovering it accurately. By finding the entropy, we can find a method to find the lower bound of the average codeword length.""","""I didn't really understand the meaning of the prefix at first.""",,"""The content was a little difficult, so I couldn't understand it well just in class. I have a test next week, so I want to review it thoroughly and challenge myself.""",-1
C-2021-2_U168,"""Information is expressed as a combination of 0s and 1s. When encoding, set the average codeword length to be as short as possible. To encode information, it must be possible to decode uniquely and quickly."" However, it is necessary that the code be unique, that it can be recovered quickly, and that it should be represented as short as possible. Entropy is the lower bound on the average codeword length.""","""We found that it is important to set the average codeword length as short as possible while recovering it accurately. By finding the entropy, we can find a method to find the lower bound of the average codeword length.""","""I didn't really understand the meaning of the prefix at first.""",,"""The content was a little difficult, so I couldn't understand it well just in class. I have a test next week, so I want to review it thoroughly and challenge myself.""",-1
C-2021-2_U168,"""Information is expressed as a combination of 0s and 1s. When encoding, set the average codeword length to be as short as possible. To encode information, it must be possible to decode uniquely and quickly."" However, it is necessary that the code be unique, that it can be recovered quickly, and that it should be represented as short as possible. Entropy is the lower bound on the average codeword length.""","""We found that it is important to set the average codeword length as short as possible while recovering it accurately. By finding the entropy, we can find a method to find the lower bound of the average codeword length.""","""I didn't really understand the meaning of the prefix at first.""",,"""The content was a little difficult, so I couldn't understand it well just in class. I have a test next week, so I want to review it thoroughly and challenge myself.""",-1
C-2021-2_U169,"""Information can be encoded, and when encoding, design an average codeword tone that is as short as possible according to the probability distribution of symbols. At that time, it is a condition that it can be uniquely and quickly restored. Codeword If there are not two or more ways to decompose into , it is said to be uniquely decodable. The fact that it can be decoded is called instantaneous decodability.A codeword in which no codeword is a prefix of another codeword is called a prefix code, and any prefix code is uniquely decodable and instantaneously decodable.Average codeword length The lower bound of is called entropy, and can be obtained by formula.""","""How to find the average codeword length. L(C)=p1l1+⋯+pmlm
How to find entropy. H(S)=p1(-log2p1)+⋯+pM(-log2pM)""","""About Optimal Codes""",,,-1
C-2021-2_U169,"""Information can be encoded, and when encoding, design an average codeword tone that is as short as possible according to the probability distribution of symbols. At that time, it is a condition that it can be uniquely and quickly restored. Codeword If there are not two or more ways to decompose into , it is said to be uniquely decodable. The fact that it can be decoded is called instantaneous decodability.A codeword in which no codeword is a prefix of another codeword is called a prefix code, and any prefix code is uniquely decodable and instantaneously decodable.Average codeword length The lower bound of is called entropy, and can be obtained by formula.""","""How to find the average codeword length. L(C)=p1l1+⋯+pmlm
How to find entropy. H(S)=p1(-log2p1)+⋯+pM(-log2pM)""","""About Optimal Codes""",,,-1
C-2021-2_U169,"""Information can be encoded, and when encoding, design an average codeword tone that is as short as possible according to the probability distribution of symbols. At that time, it is a condition that it can be uniquely and quickly restored. Codeword If there are not two or more ways to decompose into , it is said to be uniquely decodable. The fact that it can be decoded is called instantaneous decodability.A codeword in which no codeword is a prefix of another codeword is called a prefix code, and any prefix code is uniquely decodable and instantaneously decodable.Average codeword length The lower bound of is called entropy, and can be obtained by formula.""","""How to find the average codeword length. L(C)=p1l1+⋯+pmlm
How to find entropy. H(S)=p1(-log2p1)+⋯+pM(-log2pM)""","""About Optimal Codes""",,,-1
C-2021-2_U17,,"""I was able to solve practice problems other than entropy during the class. I had heard the word bit itself as a capacity for games, but I was able to understand the detailed concept of it.""","""I didn't really understand the meaning of the formula for entropy.""","""If you were actually reading a news article on your smartphone, how much information would you encode and convey?""",,-1
C-2021-2_U17,,"""I was able to solve practice problems other than entropy during the class. I had heard the word bit itself as a capacity for games, but I was able to understand the detailed concept of it.""","""I didn't really understand the meaning of the formula for entropy.""","""If you were actually reading a news article on your smartphone, how much information would you encode and convey?""",,-1
C-2021-2_U17,,"""I was able to solve practice problems other than entropy during the class. I had heard the word bit itself as a capacity for games, but I was able to understand the detailed concept of it.""","""I didn't really understand the meaning of the formula for entropy.""","""If you were actually reading a news article on your smartphone, how much information would you encode and convey?""",,-1
C-2021-2_U170,,,"""My understanding of instantaneous decodability in the second half of the class was vague.""","""On Instant Decodability""",,-2
C-2021-2_U170,,,"""My understanding of instantaneous decodability in the second half of the class was vague.""","""On Instant Decodability""",,-2
C-2021-2_U172,"""Optimize and send information by changing the sign.""","""best information""",,,"""I was surprised by the high versatility of mathematics, which is related to mathematics even in information science.""",-3
C-2021-2_U172,"""Optimize and send information by changing the sign.""","""best information""",,,"""I was surprised by the high versatility of mathematics, which is related to mathematics even in information science.""",-3
C-2021-2_U172,"""Optimize and send information by changing the sign.""","""best information""",,,"""I was surprised by the high versatility of mathematics, which is related to mathematics even in information science.""",-3
C-2021-2_U174,"""When encoding a source, what should the code satisfy?""",,,,"""I was able to understand what kind of thinking should be used to set the code when encoding the information source. Calculating things like average codeword length and entropy was mathematical and fun.""",-3
C-2021-2_U174,"""When encoding a source, what should the code satisfy?""",,,,"""I was able to understand what kind of thinking should be used to set the code when encoding the information source. Calculating things like average codeword length and entropy was mathematical and fun.""",-3
C-2021-2_U18,"""Information is identified by the combination of 2-bit white and black. The combination is more efficient considering various factors such as average codeword length, uniqueness, prefix code, entropy, etc.""","""I knew that information was encoded by combining 2 bits, but I knew in detail the conditions and methods for combining them.""",,,"""It was good to know the basics about the tool called information that I use casually every day.""",-1
C-2021-2_U18,"""Information is identified by the combination of 2-bit white and black. The combination is more efficient considering various factors such as average codeword length, uniqueness, prefix code, entropy, etc.""","""I knew that information was encoded by combining 2 bits, but I knew in detail the conditions and methods for combining them.""",,,"""It was good to know the basics about the tool called information that I use casually every day.""",-1
C-2021-2_U18,"""Information is identified by the combination of 2-bit white and black. The combination is more efficient considering various factors such as average codeword length, uniqueness, prefix code, entropy, etc.""","""I knew that information was encoded by combining 2 bits, but I knew in detail the conditions and methods for combining them.""",,,"""It was good to know the basics about the tool called information that I use casually every day.""",-1
C-2021-2_U19,"""Information emanating from sources is done by encoding and decoding. Encoding must be devised so that codes are shorter, and decoding must be quick and unique.""","""The black-and-white sphere representation allowed me to understand the encoding mechanism.""","""I didn't prepare for it, so I couldn't understand it right away.""",,"""I forgot to prepare for class this time, so from next time onwards, I want to prepare properly before attending class.""",-2
C-2021-2_U19,"""Information emanating from sources is done by encoding and decoding. Encoding must be devised so that codes are shorter, and decoding must be quick and unique.""","""The black-and-white sphere representation allowed me to understand the encoding mechanism.""","""I didn't prepare for it, so I couldn't understand it right away.""",,"""I forgot to prepare for class this time, so from next time onwards, I want to prepare properly before attending class.""",-2
C-2021-2_U19,"""Information emanating from sources is done by encoding and decoding. Encoding must be devised so that codes are shorter, and decoding must be quick and unique.""","""The black-and-white sphere representation allowed me to understand the encoding mechanism.""","""I didn't prepare for it, so I couldn't understand it right away.""",,"""I forgot to prepare for class this time, so from next time onwards, I want to prepare properly before attending class.""",-2
C-2021-2_U19,"""Information emanating from sources is done by encoding and decoding. Encoding must be devised so that codes are shorter, and decoding must be quick and unique.""","""The black-and-white sphere representation allowed me to understand the encoding mechanism.""","""I didn't prepare for it, so I couldn't understand it right away.""",,"""I forgot to prepare for class this time, so from next time onwards, I want to prepare properly before attending class.""",-2
C-2021-2_U20,"""Think academically about what you think about when you encode information in pairs of 0/1.
Specifically, we explored ways to efficiently and uniquely encode information with a smaller amount of information.


""","""I learned that codes are evaluated mainly from three viewpoints: unique decodability, instantaneous decodability, and average codeword length.
""",,,,-2
C-2021-2_U20,"""Think academically about what you think about when you encode information in pairs of 0/1.
Specifically, we explored ways to efficiently and uniquely encode information with a smaller amount of information.


""","""I learned that codes are evaluated mainly from three viewpoints: unique decodability, instantaneous decodability, and average codeword length.
""",,,,-2
C-2021-2_U21,,"""I was able to solve all three exercises.""",,,"""I couldn't concentrate for 90 minutes, and I was just listening towards the end. I spent a lot of time reviewing to understand that, so next time I will prepare a learning environment and take a solid lesson. I want to come.""",-3
C-2021-2_U21,,"""I was able to solve all three exercises.""",,,"""I couldn't concentrate for 90 minutes, and I was just listening towards the end. I spent a lot of time reviewing to understand that, so next time I will prepare a learning environment and take a solid lesson. I want to come.""",-3
C-2021-2_U24,"""A code that can be done quickly without incurring decoding is useful.""","""The prefix is ​​the ideal form""","""It's been a while since I calculated log, so I'll remember it again.""","""I was wondering how long the average codeword length of the codes that PCs and others are processing is.""","""I like the field of probability, so it was very interesting.""",-2
C-2021-2_U24,"""A code that can be done quickly without incurring decoding is useful.""","""The prefix is ​​the ideal form""","""It's been a while since I calculated log, so I'll remember it again.""","""I was wondering how long the average codeword length of the codes that PCs and others are processing is.""","""I like the field of probability, so it was very interesting.""",-2
C-2021-2_U24,"""A code that can be done quickly without incurring decoding is useful.""","""The prefix is ​​the ideal form""","""It's been a while since I calculated log, so I'll remember it again.""","""I was wondering how long the average codeword length of the codes that PCs and others are processing is.""","""I like the field of probability, so it was very interesting.""",-2
C-2021-2_U24,"""A code that can be done quickly without incurring decoding is useful.""","""The prefix is ​​the ideal form""","""It's been a while since I calculated log, so I'll remember it again.""","""I was wondering how long the average codeword length of the codes that PCs and others are processing is.""","""I like the field of probability, so it was very interesting.""",-2
C-2021-2_U24,"""A code that can be done quickly without incurring decoding is useful.""","""The prefix is ​​the ideal form""","""It's been a while since I calculated log, so I'll remember it again.""","""I was wondering how long the average codeword length of the codes that PCs and others are processing is.""","""I like the field of probability, so it was very interesting.""",-2
C-2021-2_U25,"""A mechanism for organizing and handling information quickly, easily, and concisely.""","""I learned terms such as initial code, unique decodability, and instantaneous decodability.""","""I can't use the formula for the lower bound of the average codeword length.""",,"""If I had done my homework, I should have been able to deepen my understanding. Next week, I will finish my homework and go to class.""",-3
C-2021-2_U25,"""A mechanism for organizing and handling information quickly, easily, and concisely.""","""I learned terms such as initial code, unique decodability, and instantaneous decodability.""","""I can't use the formula for the lower bound of the average codeword length.""",,"""If I had done my homework, I should have been able to deepen my understanding. Next week, I will finish my homework and go to class.""",-3
C-2021-2_U25,"""A mechanism for organizing and handling information quickly, easily, and concisely.""","""I learned terms such as initial code, unique decodability, and instantaneous decodability.""","""I can't use the formula for the lower bound of the average codeword length.""",,"""If I had done my homework, I should have been able to deepen my understanding. Next week, I will finish my homework and go to class.""",-3
C-2021-2_U25,"""A mechanism for organizing and handling information quickly, easily, and concisely.""","""I learned terms such as initial code, unique decodability, and instantaneous decodability.""","""I can't use the formula for the lower bound of the average codeword length.""",,"""If I had done my homework, I should have been able to deepen my understanding. Next week, I will finish my homework and go to class.""",-3
C-2021-2_U26,"""An information source outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed.
In order to more easily represent the information output from the information source, a task called source coding is required.
In source coding, the code is designed so that the average codeword length is as short as possible, that is, the amount of information is minimized. At this time, it is necessary to be able to restore the code uniquely and quickly.
The average codeword length has a lower bound, called entropy. ""","""We found that the probability of occurrence of each symbol should be considered in order to shorten the average codeword length.
Moreover, since the prefix code can be uniquely decoded and instantaneously decoded, it can be understood that it is very easy to handle when decoding the information source. ""","""Nothing in particular.""","""Nothing in particular.""","""I was surprised that the lower bound of the average codeword length can be mathematically determined according to the definition of entropy. Also, the code with the smallest average codeword length among the prefix codes has the lowest average codeword length among the uniquely decodable codes. I learned to be minimal and felt the usefulness of prefixes.
""",-2
C-2021-2_U26,"""An information source outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed.
In order to more easily represent the information output from the information source, a task called source coding is required.
In source coding, the code is designed so that the average codeword length is as short as possible, that is, the amount of information is minimized. At this time, it is necessary to be able to restore the code uniquely and quickly.
The average codeword length has a lower bound, called entropy. ""","""We found that the probability of occurrence of each symbol should be considered in order to shorten the average codeword length.
Moreover, since the prefix code can be uniquely decoded and instantaneously decoded, it can be understood that it is very easy to handle when decoding the information source. ""","""Nothing in particular.""","""Nothing in particular.""","""I was surprised that the lower bound of the average codeword length can be mathematically determined according to the definition of entropy. Also, the code with the smallest average codeword length among the prefix codes has the lowest average codeword length among the uniquely decodable codes. I learned to be minimal and felt the usefulness of prefixes.
""",-2
C-2021-2_U26,"""An information source outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed.
In order to more easily represent the information output from the information source, a task called source coding is required.
In source coding, the code is designed so that the average codeword length is as short as possible, that is, the amount of information is minimized. At this time, it is necessary to be able to restore the code uniquely and quickly.
The average codeword length has a lower bound, called entropy. ""","""We found that the probability of occurrence of each symbol should be considered in order to shorten the average codeword length.
Moreover, since the prefix code can be uniquely decoded and instantaneously decoded, it can be understood that it is very easy to handle when decoding the information source. ""","""Nothing in particular.""","""Nothing in particular.""","""I was surprised that the lower bound of the average codeword length can be mathematically determined according to the definition of entropy. Also, the code with the smallest average codeword length among the prefix codes has the lowest average codeword length among the uniquely decodable codes. I learned to be minimal and felt the usefulness of prefixes.
""",-2
C-2021-2_U26,"""An information source outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed.
In order to more easily represent the information output from the information source, a task called source coding is required.
In source coding, the code is designed so that the average codeword length is as short as possible, that is, the amount of information is minimized. At this time, it is necessary to be able to restore the code uniquely and quickly.
The average codeword length has a lower bound, called entropy. ""","""We found that the probability of occurrence of each symbol should be considered in order to shorten the average codeword length.
Moreover, since the prefix code can be uniquely decoded and instantaneously decoded, it can be understood that it is very easy to handle when decoding the information source. ""","""Nothing in particular.""","""Nothing in particular.""","""I was surprised that the lower bound of the average codeword length can be mathematically determined according to the definition of entropy. Also, the code with the smallest average codeword length among the prefix codes has the lowest average codeword length among the uniquely decodable codes. I learned to be minimal and felt the usefulness of prefixes.
""",-2
C-2021-2_U26,"""An information source outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed.
In order to more easily represent the information output from the information source, a task called source coding is required.
In source coding, the code is designed so that the average codeword length is as short as possible, that is, the amount of information is minimized. At this time, it is necessary to be able to restore the code uniquely and quickly.
The average codeword length has a lower bound, called entropy. ""","""We found that the probability of occurrence of each symbol should be considered in order to shorten the average codeword length.
Moreover, since the prefix code can be uniquely decoded and instantaneously decoded, it can be understood that it is very easy to handle when decoding the information source. ""","""Nothing in particular.""","""Nothing in particular.""","""I was surprised that the lower bound of the average codeword length can be mathematically determined according to the definition of entropy. Also, the code with the smallest average codeword length among the prefix codes has the lowest average codeword length among the uniquely decodable codes. I learned to be minimal and felt the usefulness of prefixes.
""",-2
C-2021-2_U27,,"""I learned that in the digital field, the amount of information is reduced and communicated. For that reason, I use indicators to judge whether it is easy to communicate.I felt that there was no problem in solving the exercises. So I thought we could think of an optimal signal even with our knowledge.""","""The entropy formula was difficult. Recently, I haven't had a chance to use logarithms, so I struggled with the calculations.""",,"""Today, I had trouble hearing the voice at first. From the next time, I would like to adjust it properly so that I can hear it from the beginning. Also, in terms of the content, research is progressing for optimal information transmission. In the future, I would like to be able to create the optimal signal myself.""",-3
C-2021-2_U27,,"""I learned that in the digital field, the amount of information is reduced and communicated. For that reason, I use indicators to judge whether it is easy to communicate.I felt that there was no problem in solving the exercises. So I thought we could think of an optimal signal even with our knowledge.""","""The entropy formula was difficult. Recently, I haven't had a chance to use logarithms, so I struggled with the calculations.""",,"""Today, I had trouble hearing the voice at first. From the next time, I would like to adjust it properly so that I can hear it from the beginning. Also, in terms of the content, research is progressing for optimal information transmission. In the future, I would like to be able to create the optimal signal myself.""",-3
C-2021-2_U27,,"""I learned that in the digital field, the amount of information is reduced and communicated. For that reason, I use indicators to judge whether it is easy to communicate.I felt that there was no problem in solving the exercises. So I thought we could think of an optimal signal even with our knowledge.""","""The entropy formula was difficult. Recently, I haven't had a chance to use logarithms, so I struggled with the calculations.""",,"""Today, I had trouble hearing the voice at first. From the next time, I would like to adjust it properly so that I can hear it from the beginning. Also, in terms of the content, research is progressing for optimal information transmission. In the future, I would like to be able to create the optimal signal myself.""",-3
C-2021-2_U28,,,,"""Nothing in particular.""",,-1
C-2021-2_U29,"""About sources and source encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About uniquely compoundable encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About unique combinable codes and instantaneous combinable codes
On the relationship between entropy and average codeword length""","""In order to shorten the average compound word length, the code words that are likely to appear should correspond to the code word tone. I understood the mechanism of the prefix code.
As for entropy, the average code word length is the lower limit of the average code length, and the optimal code is H(s)<=L(c)<H(s)+1. ""","""I didn't understand log2 in entropy""",,"""It was fun to learn a lot about information sources that I didn't know before. I also wanted to know more about the concept of entropy.""",-3
C-2021-2_U29,"""About sources and source encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About uniquely compoundable encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About unique combinable codes and instantaneous combinable codes
On the relationship between entropy and average codeword length""","""In order to shorten the average compound word length, the code words that are likely to appear should correspond to the code word tone. I understood the mechanism of the prefix code.
As for entropy, the average code word length is the lower limit of the average code length, and the optimal code is H(s)<=L(c)<H(s)+1. ""","""I didn't understand log2 in entropy""",,"""It was fun to learn a lot about information sources that I didn't know before. I also wanted to know more about the concept of entropy.""",-3
C-2021-2_U29,"""About sources and source encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About uniquely compoundable encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About unique combinable codes and instantaneous combinable codes
On the relationship between entropy and average codeword length""","""In order to shorten the average compound word length, the code words that are likely to appear should correspond to the code word tone. I understood the mechanism of the prefix code.
As for entropy, the average code word length is the lower limit of the average code length, and the optimal code is H(s)<=L(c)<H(s)+1. ""","""I didn't understand log2 in entropy""",,"""It was fun to learn a lot about information sources that I didn't know before. I also wanted to know more about the concept of entropy.""",-3
C-2021-2_U29,"""About sources and source encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About uniquely compoundable encodings.
How to shorten the average code length.
About uniquely composable encodings and encodings.
How to shorten the average code length.
About unique combinable codes and instantaneous combinable codes
On the relationship between entropy and average codeword length""","""In order to shorten the average compound word length, the code words that are likely to appear should correspond to the code word tone. I understood the mechanism of the prefix code.
As for entropy, the average code word length is the lower limit of the average code length, and the optimal code is H(s)<=L(c)<H(s)+1. ""","""I didn't understand log2 in entropy""",,"""It was fun to learn a lot about information sources that I didn't know before. I also wanted to know more about the concept of entropy.""",-3
C-2021-2_U3,"""・""Information source"" is one that outputs symbols at regular time intervals and has a fixed probability of occurrence.
・""Information source coding"" is to express the string of symbols generated from the information source by a string of ● and ◯, and the reverse process is called ""decoding"".
・In order to shorten the ""average codeword length"", the probability of occurrence of symbols is taken into consideration.
・The purpose of source coding is to be unique (there is only one way to decompose into codewords) and quickly reversible (prefix code: even after copper code, it is a prefix of another codeword). On the premise that there is no such thing as a symbol, the code is designed to have the shortest possible average codeword length according to the probability distribution of the symbol. In addition, since initial code ∈ uniquely combinable code ∈ information source code holds, it can be said that the average code word length is the smallest among the initial codes = the average code word length is the smallest among the uniquely combinable codes.
- The lower bound of the average codeword length is the entropy. ""","""In the information society, it is important to transmit information uniquely and quickly, and for that purpose, we found that we have devised whether it can be uniquely compounded or whether it is a prefix. I get a lot of information and disseminate it, but I didn't know how that process was done.I would like to deepen my knowledge of the mechanism through this class.""","""I didn't really understand the relationship between average codeword length, entropy, and optimal code.""",,"""Thanks for sharing, it's now easier for me to know which pages to focus on. Thank you.""",-3
C-2021-2_U3,"""・""Information source"" is one that outputs symbols at regular time intervals and has a fixed probability of occurrence.
・""Information source coding"" is to express the string of symbols generated from the information source by a string of ● and ◯, and the reverse process is called ""decoding"".
・In order to shorten the ""average codeword length"", the probability of occurrence of symbols is taken into consideration.
・The purpose of source coding is to be unique (there is only one way to decompose into codewords) and quickly reversible (prefix code: even after copper code, it is a prefix of another codeword). On the premise that there is no such thing as a symbol, the code is designed to have the shortest possible average codeword length according to the probability distribution of the symbol. In addition, since initial code ∈ uniquely combinable code ∈ information source code holds, it can be said that the average code word length is the smallest among the initial codes = the average code word length is the smallest among the uniquely combinable codes.
- The lower bound of the average codeword length is the entropy. ""","""In the information society, it is important to transmit information uniquely and quickly, and for that purpose, we found that we have devised whether it can be uniquely compounded or whether it is a prefix. I get a lot of information and disseminate it, but I didn't know how that process was done.I would like to deepen my knowledge of the mechanism through this class.""","""I didn't really understand the relationship between average codeword length, entropy, and optimal code.""",,"""Thanks for sharing, it's now easier for me to know which pages to focus on. Thank you.""",-3
C-2021-2_U3,"""・""Information source"" is one that outputs symbols at regular time intervals and has a fixed probability of occurrence.
・""Information source coding"" is to express the string of symbols generated from the information source by a string of ● and ◯, and the reverse process is called ""decoding"".
・In order to shorten the ""average codeword length"", the probability of occurrence of symbols is taken into consideration.
・The purpose of source coding is to be unique (there is only one way to decompose into codewords) and quickly reversible (prefix code: even after copper code, it is a prefix of another codeword). On the premise that there is no such thing as a symbol, the code is designed to have the shortest possible average codeword length according to the probability distribution of the symbol. In addition, since initial code ∈ uniquely combinable code ∈ information source code holds, it can be said that the average code word length is the smallest among the initial codes = the average code word length is the smallest among the uniquely combinable codes.
- The lower bound of the average codeword length is the entropy. ""","""In the information society, it is important to transmit information uniquely and quickly, and for that purpose, we found that we have devised whether it can be uniquely compounded or whether it is a prefix. I get a lot of information and disseminate it, but I didn't know how that process was done.I would like to deepen my knowledge of the mechanism through this class.""","""I didn't really understand the relationship between average codeword length, entropy, and optimal code.""",,"""Thanks for sharing, it's now easier for me to know which pages to focus on. Thank you.""",-3
C-2021-2_U3,"""・""Information source"" is one that outputs symbols at regular time intervals and has a fixed probability of occurrence.
・""Information source coding"" is to express the string of symbols generated from the information source by a string of ● and ◯, and the reverse process is called ""decoding"".
・In order to shorten the ""average codeword length"", the probability of occurrence of symbols is taken into consideration.
・The purpose of source coding is to be unique (there is only one way to decompose into codewords) and quickly reversible (prefix code: even after copper code, it is a prefix of another codeword). On the premise that there is no such thing as a symbol, the code is designed to have the shortest possible average codeword length according to the probability distribution of the symbol. In addition, since initial code ∈ uniquely combinable code ∈ information source code holds, it can be said that the average code word length is the smallest among the initial codes = the average code word length is the smallest among the uniquely combinable codes.
- The lower bound of the average codeword length is the entropy. ""","""In the information society, it is important to transmit information uniquely and quickly, and for that purpose, we found that we have devised whether it can be uniquely compounded or whether it is a prefix. I get a lot of information and disseminate it, but I didn't know how that process was done.I would like to deepen my knowledge of the mechanism through this class.""","""I didn't really understand the relationship between average codeword length, entropy, and optimal code.""",,"""Thanks for sharing, it's now easier for me to know which pages to focus on. Thank you.""",-3
C-2021-2_U30,"""Advantages of encoding information, and methods of encoding that maximize these advantages""","""By using prefixes, information can be expressed more succinctly""","""I didn't know about entropy the first time I heard it.""",,"""Rather than saying that this looks minimal, it was easy to understand because it was expressed using mathematical formulas. Also, in today's class, I used the learning dashboard's marker function for the first time, and everyone is important. I thought it was interesting to see with my own eyes what I was thinking.""",-1
C-2021-2_U30,"""Advantages of encoding information, and methods of encoding that maximize these advantages""","""By using prefixes, information can be expressed more succinctly""","""I didn't know about entropy the first time I heard it.""",,"""Rather than saying that this looks minimal, it was easy to understand because it was expressed using mathematical formulas. Also, in today's class, I used the learning dashboard's marker function for the first time, and everyone is important. I thought it was interesting to see with my own eyes what I was thinking.""",-1
C-2021-2_U30,"""Advantages of encoding information, and methods of encoding that maximize these advantages""","""By using prefixes, information can be expressed more succinctly""","""I didn't know about entropy the first time I heard it.""",,"""Rather than saying that this looks minimal, it was easy to understand because it was expressed using mathematical formulas. Also, in today's class, I used the learning dashboard's marker function for the first time, and everyone is important. I thought it was interesting to see with my own eyes what I was thinking.""",-1
C-2021-2_U30,"""Advantages of encoding information, and methods of encoding that maximize these advantages""","""By using prefixes, information can be expressed more succinctly""","""I didn't know about entropy the first time I heard it.""",,"""Rather than saying that this looks minimal, it was easy to understand because it was expressed using mathematical formulas. Also, in today's class, I used the learning dashboard's marker function for the first time, and everyone is important. I thought it was interesting to see with my own eyes what I was thinking.""",-1
C-2021-2_U31,"""It is important to design codes with a short average codeword length among those that are uniquely reversible in information coding.
A code in which no codeword is a prefix of another codeword is called a prefix code, and is instantaneously decodable and uniquely decodable. Also, there is a theorem that for any uniquely decodable code, there exists a prefix code with the same codeword length. Therefore, the prefix code with the smallest average codeword length has the smallest average codeword length among uniquely decodable codes. ""","""We found that the conditions for efficient information encoding and efficient codes include prefix codes.
It is now possible to calculate the average codeword length and its lower bound, the entropy. ""","""I didn't understand why such a formula for entropy gives a lower bound on the average code wavelength.""",,"""It was interesting to learn about the mechanism of efficient information encoding, which is often used in our daily life, but which we did not know. Especially, the mechanism of entropy and prefixes was very interesting.""",-2
C-2021-2_U31,"""It is important to design codes with a short average codeword length among those that are uniquely reversible in information coding.
A code in which no codeword is a prefix of another codeword is called a prefix code, and is instantaneously decodable and uniquely decodable. Also, there is a theorem that for any uniquely decodable code, there exists a prefix code with the same codeword length. Therefore, the prefix code with the smallest average codeword length has the smallest average codeword length among uniquely decodable codes. ""","""We found that the conditions for efficient information encoding and efficient codes include prefix codes.
It is now possible to calculate the average codeword length and its lower bound, the entropy. ""","""I didn't understand why such a formula for entropy gives a lower bound on the average code wavelength.""",,"""It was interesting to learn about the mechanism of efficient information encoding, which is often used in our daily life, but which we did not know. Especially, the mechanism of entropy and prefixes was very interesting.""",-2
C-2021-2_U31,"""It is important to design codes with a short average codeword length among those that are uniquely reversible in information coding.
A code in which no codeword is a prefix of another codeword is called a prefix code, and is instantaneously decodable and uniquely decodable. Also, there is a theorem that for any uniquely decodable code, there exists a prefix code with the same codeword length. Therefore, the prefix code with the smallest average codeword length has the smallest average codeword length among uniquely decodable codes. ""","""We found that the conditions for efficient information encoding and efficient codes include prefix codes.
It is now possible to calculate the average codeword length and its lower bound, the entropy. ""","""I didn't understand why such a formula for entropy gives a lower bound on the average code wavelength.""",,"""It was interesting to learn about the mechanism of efficient information encoding, which is often used in our daily life, but which we did not know. Especially, the mechanism of entropy and prefixes was very interesting.""",-2
C-2021-2_U31,"""It is important to design codes with a short average codeword length among those that are uniquely reversible in information coding.
A code in which no codeword is a prefix of another codeword is called a prefix code, and is instantaneously decodable and uniquely decodable. Also, there is a theorem that for any uniquely decodable code, there exists a prefix code with the same codeword length. Therefore, the prefix code with the smallest average codeword length has the smallest average codeword length among uniquely decodable codes. ""","""We found that the conditions for efficient information encoding and efficient codes include prefix codes.
It is now possible to calculate the average codeword length and its lower bound, the entropy. ""","""I didn't understand why such a formula for entropy gives a lower bound on the average code wavelength.""",,"""It was interesting to learn about the mechanism of efficient information encoding, which is often used in our daily life, but which we did not know. Especially, the mechanism of entropy and prefixes was very interesting.""",-2
C-2021-2_U33,"""Information source decoding is to represent the symbols generated from the information source as codes. The length of the decoded array is called the average codeword length. To improve efficiency, unique decodability and instantaneous decodability are considered. do.
Desirable codes are short expressions that can be quickly reversed. ""","""By looking at the code trees of prefixes, I was able to understand the advantages of prefixes.""","""When the concept of entropy came out, I was a little confused by the mathematical formulas.""",,"""I have a feeling it's going to get harder and harder, so I'll try not to neglect my preparation and review.""",-2
C-2021-2_U33,"""Information source decoding is to represent the symbols generated from the information source as codes. The length of the decoded array is called the average codeword length. To improve efficiency, unique decodability and instantaneous decodability are considered. do.
Desirable codes are short expressions that can be quickly reversed. ""","""By looking at the code trees of prefixes, I was able to understand the advantages of prefixes.""","""When the concept of entropy came out, I was a little confused by the mathematical formulas.""",,"""I have a feeling it's going to get harder and harder, so I'll try not to neglect my preparation and review.""",-2
C-2021-2_U33,"""Information source decoding is to represent the symbols generated from the information source as codes. The length of the decoded array is called the average codeword length. To improve efficiency, unique decodability and instantaneous decodability are considered. do.
Desirable codes are short expressions that can be quickly reversed. ""","""By looking at the code trees of prefixes, I was able to understand the advantages of prefixes.""","""When the concept of entropy came out, I was a little confused by the mathematical formulas.""",,"""I have a feeling it's going to get harder and harder, so I'll try not to neglect my preparation and review.""",-2
C-2021-2_U33,"""Information source decoding is to represent the symbols generated from the information source as codes. The length of the decoded array is called the average codeword length. To improve efficiency, unique decodability and instantaneous decodability are considered. do.
Desirable codes are short expressions that can be quickly reversed. ""","""By looking at the code trees of prefixes, I was able to understand the advantages of prefixes.""","""When the concept of entropy came out, I was a little confused by the mathematical formulas.""",,"""I have a feeling it's going to get harder and harder, so I'll try not to neglect my preparation and review.""",-2
C-2021-2_U34,,"""I was able to understand various laws about source coding.""","""I'm worried about whether the entropy calculation results are correct.""",,,-1
C-2021-2_U34,,"""I was able to understand various laws about source coding.""","""I'm worried about whether the entropy calculation results are correct.""",,,-1
C-2021-2_U35,"""It is necessary to reduce the number of bits when performing source coding. At that time, it is necessary to consider the probability of occurrence of symbols. As a prerequisite, it must be possible to recover uniquely. It should be possible to recover quickly. """,,,,"""In today's class, the first half of the lesson was relatively easy to understand, but it started to get difficult around the beginning of words.",-1
C-2021-2_U35,"""It is necessary to reduce the number of bits when performing source coding. At that time, it is necessary to consider the probability of occurrence of symbols. As a prerequisite, it must be possible to recover uniquely. It should be possible to recover quickly. """,,,,"""In today's class, the first half of the lesson was relatively easy to understand, but it started to get difficult around the beginning of words.",-1
C-2021-2_U36,"""Source coding should be designed so that the average codeword length is as short as possible on the assumption that it is uniquely reversible and quickly reversible. Every codeword is a prefix of another codeword. If the code satisfies the initial condition, it can be uniquely encoded, and it also has instantaneous decodability. There are also symbols in the middle. The lower bound on the average codeword length is the entropy.""","""It was found that the optimum code has the smallest average codeword length among the prefix codes. Since whether or not unique decoding is possible depends on the prefix conditions, the optimal code for information source coding is It turned out that the code was important. By calculating the entropy myself, I was able to find a lower bound on the average codeword length of the information.""","""It's given as a definition, but I think there's a more detailed proof, but I didn't understand the meaning of the formula that entropy expresses and why the average codeword length is not smaller than the entropy.""",,"""It was good to learn more about the mechanism of information source coding than in the last time. From those that cannot be uniquely decoded by the encoding method, we can find the optimum codeword that satisfies the initial conditions and has a short average codeword length."" It was interesting to learn about the mechanism for accurately and quickly delivering information in source encoding.""",-1
C-2021-2_U36,"""Source coding should be designed so that the average codeword length is as short as possible on the assumption that it is uniquely reversible and quickly reversible. Every codeword is a prefix of another codeword. If the code satisfies the initial condition, it can be uniquely encoded, and it also has instantaneous decodability. There are also symbols in the middle. The lower bound on the average codeword length is the entropy.""","""It was found that the optimum code has the smallest average codeword length among the prefix codes. Since whether or not unique decoding is possible depends on the prefix conditions, the optimal code for information source coding is It turned out that the code was important. By calculating the entropy myself, I was able to find a lower bound on the average codeword length of the information.""","""It's given as a definition, but I think there's a more detailed proof, but I didn't understand the meaning of the formula that entropy expresses and why the average codeword length is not smaller than the entropy.""",,"""It was good to learn more about the mechanism of information source coding than in the last time. From those that cannot be uniquely decoded by the encoding method, we can find the optimum codeword that satisfies the initial conditions and has a short average codeword length."" It was interesting to learn about the mechanism for accurately and quickly delivering information in source encoding.""",-1
C-2021-2_U36,"""Source coding should be designed so that the average codeword length is as short as possible on the assumption that it is uniquely reversible and quickly reversible. Every codeword is a prefix of another codeword. If the code satisfies the initial condition, it can be uniquely encoded, and it also has instantaneous decodability. There are also symbols in the middle. The lower bound on the average codeword length is the entropy.""","""It was found that the optimum code has the smallest average codeword length among the prefix codes. Since whether or not unique decoding is possible depends on the prefix conditions, the optimal code for information source coding is It turned out that the code was important. By calculating the entropy myself, I was able to find a lower bound on the average codeword length of the information.""","""It's given as a definition, but I think there's a more detailed proof, but I didn't understand the meaning of the formula that entropy expresses and why the average codeword length is not smaller than the entropy.""",,"""It was good to learn more about the mechanism of information source coding than in the last time. From those that cannot be uniquely decoded by the encoding method, we can find the optimum codeword that satisfies the initial conditions and has a short average codeword length."" It was interesting to learn about the mechanism for accurately and quickly delivering information in source encoding.""",-1
C-2021-2_U36,"""Source coding should be designed so that the average codeword length is as short as possible on the assumption that it is uniquely reversible and quickly reversible. Every codeword is a prefix of another codeword. If the code satisfies the initial condition, it can be uniquely encoded, and it also has instantaneous decodability. There are also symbols in the middle. The lower bound on the average codeword length is the entropy.""","""It was found that the optimum code has the smallest average codeword length among the prefix codes. Since whether or not unique decoding is possible depends on the prefix conditions, the optimal code for information source coding is It turned out that the code was important. By calculating the entropy myself, I was able to find a lower bound on the average codeword length of the information.""","""It's given as a definition, but I think there's a more detailed proof, but I didn't understand the meaning of the formula that entropy expresses and why the average codeword length is not smaller than the entropy.""",,"""It was good to learn more about the mechanism of information source coding than in the last time. From those that cannot be uniquely decoded by the encoding method, we can find the optimum codeword that satisfies the initial conditions and has a short average codeword length."" It was interesting to learn about the mechanism for accurately and quickly delivering information in source encoding.""",-1
C-2021-2_U37,"""The idea of ​​making information into an optimal code""","""Think of prefixes as a premise""","""I don't understand why the entropy is the shortest""",,"""I wanted a little practice time in the middle.""",0
C-2021-2_U37,"""The idea of ​​making information into an optimal code""","""Think of prefixes as a premise""","""I don't understand why the entropy is the shortest""",,"""I wanted a little practice time in the middle.""",0
C-2021-2_U37,"""The idea of ​​making information into an optimal code""","""Think of prefixes as a premise""","""I don't understand why the entropy is the shortest""",,"""I wanted a little practice time in the middle.""",0
C-2021-2_U37,"""The idea of ​​making information into an optimal code""","""Think of prefixes as a premise""","""I don't understand why the entropy is the shortest""",,"""I wanted a little practice time in the middle.""",0
C-2021-2_U38,,,"""I learned the definition of entropy, but I wondered why it was derived.""","""You taught me to use the logarithm to calculate entropy, but why is the base 2?""",,-2
C-2021-2_U38,,,"""I learned the definition of entropy, but I wondered why it was derived.""","""You taught me to use the logarithm to calculate entropy, but why is the base 2?""",,-2
C-2021-2_U39,"""Information source coding is to express the sequence of symbols generated from the information source as an arbitrary sequence. Decoding is to convert the sequence of black and white balls obtained by encoding into the original symbol sequence. We defined a new concept based on the type and number of balls, and proved that it can be used to explain the weather conditions.In addition, the length of the codeword differs depending on the symbol string.The average codeword length is It is the sum of all the results of the codeword length times the probability.Therefore, in order to shorten it, short symbol words should be used for symbols that are likely to appear, and long compound words should be used for those that are difficult to appear.
Also, the purpose of source coding is uniquely to design codes with as short an average codeword length as possible on the premise of quick reversal.
Also, a code string that satisfies unique codeability is a case where the delimiter is determined by a certain symbol, or a case where the length of the codeword is the same while looking at it. In other words, if there are two or more methods of decomposition into codewords, the code cannot be uniquely encoded.
The prefix code condition means that no codeword is a prefix of another codeword, and a code that satisfies this condition is called a prefix code. Also, the prefix code can be a unique code. The advantage of this prefix code is that it can be uniquely encoded and that it has the property of being temporarily decodable. It means that it can be combined. Prefix codes are also called temporary decodable codes. This can also be seen by some example code trees. ""","""I learned about what source coding is. Therefore, I encoded a simple weather forecast using black and white balls to find the average codeword length, determine whether or not it is uniquely signable, and It is now possible to write code trees for non-initial symbols.""","""I'm not sure if the rest of the entropy is for formulating.""",,"""I was going to write a journal as soon as the lecture was over, but I forgot and am posting it now. I'm sorry.""",-1
C-2021-2_U39,"""Information source coding is to express the sequence of symbols generated from the information source as an arbitrary sequence. Decoding is to convert the sequence of black and white balls obtained by encoding into the original symbol sequence. We defined a new concept based on the type and number of balls, and proved that it can be used to explain the weather conditions.In addition, the length of the codeword differs depending on the symbol string.The average codeword length is It is the sum of all the results of the codeword length times the probability.Therefore, in order to shorten it, short symbol words should be used for symbols that are likely to appear, and long compound words should be used for those that are difficult to appear.
Also, the purpose of source coding is uniquely to design codes with as short an average codeword length as possible on the premise of quick reversal.
Also, a code string that satisfies unique codeability is a case where the delimiter is determined by a certain symbol, or a case where the length of the codeword is the same while looking at it. In other words, if there are two or more methods of decomposition into codewords, the code cannot be uniquely encoded.
The prefix code condition means that no codeword is a prefix of another codeword, and a code that satisfies this condition is called a prefix code. Also, the prefix code can be a unique code. The advantage of this prefix code is that it can be uniquely encoded and that it has the property of being temporarily decodable. It means that it can be combined. Prefix codes are also called temporary decodable codes. This can also be seen by some example code trees. ""","""I learned about what source coding is. Therefore, I encoded a simple weather forecast using black and white balls to find the average codeword length, determine whether or not it is uniquely signable, and It is now possible to write code trees for non-initial symbols.""","""I'm not sure if the rest of the entropy is for formulating.""",,"""I was going to write a journal as soon as the lecture was over, but I forgot and am posting it now. I'm sorry.""",-1
C-2021-2_U39,"""Information source coding is to express the sequence of symbols generated from the information source as an arbitrary sequence. Decoding is to convert the sequence of black and white balls obtained by encoding into the original symbol sequence. We defined a new concept based on the type and number of balls, and proved that it can be used to explain the weather conditions.In addition, the length of the codeword differs depending on the symbol string.The average codeword length is It is the sum of all the results of the codeword length times the probability.Therefore, in order to shorten it, short symbol words should be used for symbols that are likely to appear, and long compound words should be used for those that are difficult to appear.
Also, the purpose of source coding is uniquely to design codes with as short an average codeword length as possible on the premise of quick reversal.
Also, a code string that satisfies unique codeability is a case where the delimiter is determined by a certain symbol, or a case where the length of the codeword is the same while looking at it. In other words, if there are two or more methods of decomposition into codewords, the code cannot be uniquely encoded.
The prefix code condition means that no codeword is a prefix of another codeword, and a code that satisfies this condition is called a prefix code. Also, the prefix code can be a unique code. The advantage of this prefix code is that it can be uniquely encoded and that it has the property of being temporarily decodable. It means that it can be combined. Prefix codes are also called temporary decodable codes. This can also be seen by some example code trees. ""","""I learned about what source coding is. Therefore, I encoded a simple weather forecast using black and white balls to find the average codeword length, determine whether or not it is uniquely signable, and It is now possible to write code trees for non-initial symbols.""","""I'm not sure if the rest of the entropy is for formulating.""",,"""I was going to write a journal as soon as the lecture was over, but I forgot and am posting it now. I'm sorry.""",-1
C-2021-2_U39,"""Information source coding is to express the sequence of symbols generated from the information source as an arbitrary sequence. Decoding is to convert the sequence of black and white balls obtained by encoding into the original symbol sequence. We defined a new concept based on the type and number of balls, and proved that it can be used to explain the weather conditions.In addition, the length of the codeword differs depending on the symbol string.The average codeword length is It is the sum of all the results of the codeword length times the probability.Therefore, in order to shorten it, short symbol words should be used for symbols that are likely to appear, and long compound words should be used for those that are difficult to appear.
Also, the purpose of source coding is uniquely to design codes with as short an average codeword length as possible on the premise of quick reversal.
Also, a code string that satisfies unique codeability is a case where the delimiter is determined by a certain symbol, or a case where the length of the codeword is the same while looking at it. In other words, if there are two or more methods of decomposition into codewords, the code cannot be uniquely encoded.
The prefix code condition means that no codeword is a prefix of another codeword, and a code that satisfies this condition is called a prefix code. Also, the prefix code can be a unique code. The advantage of this prefix code is that it can be uniquely encoded and that it has the property of being temporarily decodable. It means that it can be combined. Prefix codes are also called temporary decodable codes. This can also be seen by some example code trees. ""","""I learned about what source coding is. Therefore, I encoded a simple weather forecast using black and white balls to find the average codeword length, determine whether or not it is uniquely signable, and It is now possible to write code trees for non-initial symbols.""","""I'm not sure if the rest of the entropy is for formulating.""",,"""I was going to write a journal as soon as the lecture was over, but I forgot and am posting it now. I'm sorry.""",-1
C-2021-2_U40,,,,,"""Today, I was taking notes for the next quiz in class, but I felt that taking notes was overwhelmingly more memorable. Because I participated in the class using the moodle marker function. , I think I was able to approach the class with a better attitude than last time.At first, I thought that the real-time monitoring would only make my PC slow, but if I use it well, I feel like I'm studying with other people online. I thought it was good because it was easy to keep up with the class.""",-1
C-2021-2_U41,"""An information source is a source that outputs symbols with a fixed probability of occurrence at regular time intervals. In encoding the information output from the information source, the information to be sent must be as short as possible and can be expressed uniquely. It is important to be able to decode information.When encoding information, it is important to design the information into a short average codeword tone.To shorten the average codeword length, shorten the symbols that are likely to appear, The point is to use long codewords for symbols that are difficult to appear.It is also important to uniquely decode the original information.All codewords have the same length, there are symbols that match the roles of delimiters, etc. , it is possible to recover the correct information source.It is also important to decode the information quickly.The code that satisfies the condition that no codeword is a prefix of another codeword However, this is a uniquely recoverable code that can be decoded quickly on the information side.The average codeword tone is larger than the entropy, and in some cases it is smaller than the entropy plus 1. Desired value (optimal sign)""","""I learned what is important in encoding information, that depending on how information is expressed, it will be a variety of bits, and that the codeword tone will always be larger than the value of entropy. ""","""I forgot to draw a marker halfway through.
""","""Do I have to memorize the formula for entropy?""",,-1
C-2021-2_U41,"""An information source is a source that outputs symbols with a fixed probability of occurrence at regular time intervals. In encoding the information output from the information source, the information to be sent must be as short as possible and can be expressed uniquely. It is important to be able to decode information.When encoding information, it is important to design the information into a short average codeword tone.To shorten the average codeword length, shorten the symbols that are likely to appear, The point is to use long codewords for symbols that are difficult to appear.It is also important to uniquely decode the original information.All codewords have the same length, there are symbols that match the roles of delimiters, etc. , it is possible to recover the correct information source.It is also important to decode the information quickly.The code that satisfies the condition that no codeword is a prefix of another codeword However, this is a uniquely recoverable code that can be decoded quickly on the information side.The average codeword tone is larger than the entropy, and in some cases it is smaller than the entropy plus 1. Desired value (optimal sign)""","""I learned what is important in encoding information, that depending on how information is expressed, it will be a variety of bits, and that the codeword tone will always be larger than the value of entropy. ""","""I forgot to draw a marker halfway through.
""","""Do I have to memorize the formula for entropy?""",,-1
C-2021-2_U41,"""An information source is a source that outputs symbols with a fixed probability of occurrence at regular time intervals. In encoding the information output from the information source, the information to be sent must be as short as possible and can be expressed uniquely. It is important to be able to decode information.When encoding information, it is important to design the information into a short average codeword tone.To shorten the average codeword length, shorten the symbols that are likely to appear, The point is to use long codewords for symbols that are difficult to appear.It is also important to uniquely decode the original information.All codewords have the same length, there are symbols that match the roles of delimiters, etc. , it is possible to recover the correct information source.It is also important to decode the information quickly.The code that satisfies the condition that no codeword is a prefix of another codeword However, this is a uniquely recoverable code that can be decoded quickly on the information side.The average codeword tone is larger than the entropy, and in some cases it is smaller than the entropy plus 1. Desired value (optimal sign)""","""I learned what is important in encoding information, that depending on how information is expressed, it will be a variety of bits, and that the codeword tone will always be larger than the value of entropy. ""","""I forgot to draw a marker halfway through.
""","""Do I have to memorize the formula for entropy?""",,-1
C-2021-2_U41,"""An information source is a source that outputs symbols with a fixed probability of occurrence at regular time intervals. In encoding the information output from the information source, the information to be sent must be as short as possible and can be expressed uniquely. It is important to be able to decode information.When encoding information, it is important to design the information into a short average codeword tone.To shorten the average codeword length, shorten the symbols that are likely to appear, The point is to use long codewords for symbols that are difficult to appear.It is also important to uniquely decode the original information.All codewords have the same length, there are symbols that match the roles of delimiters, etc. , it is possible to recover the correct information source.It is also important to decode the information quickly.The code that satisfies the condition that no codeword is a prefix of another codeword However, this is a uniquely recoverable code that can be decoded quickly on the information side.The average codeword tone is larger than the entropy, and in some cases it is smaller than the entropy plus 1. Desired value (optimal sign)""","""I learned what is important in encoding information, that depending on how information is expressed, it will be a variety of bits, and that the codeword tone will always be larger than the value of entropy. ""","""I forgot to draw a marker halfway through.
""","""Do I have to memorize the formula for entropy?""",,-1
C-2021-2_U42,"""Information security is ensured by representing the original string of symbols with a different string of symbols, like source coding, and by restoring the string of symbols to the original string by decoding. increasing.
""","""The code evaluation criteria are uniquely reversible, quickly reversible, and expressed as short as possible. In addition, there is a system of prefix codes to satisfy unique decodability.""",,,"""I learned a little about the mechanism of replacing information with another symbol string in a high school class, but it was very interesting because it was the first time I had heard about the average codeword length and entropy.""",-1
C-2021-2_U42,"""Information security is ensured by representing the original string of symbols with a different string of symbols, like source coding, and by restoring the string of symbols to the original string by decoding. increasing.
""","""The code evaluation criteria are uniquely reversible, quickly reversible, and expressed as short as possible. In addition, there is a system of prefix codes to satisfy unique decodability.""",,,"""I learned a little about the mechanism of replacing information with another symbol string in a high school class, but it was very interesting because it was the first time I had heard about the average codeword length and entropy.""",-1
C-2021-2_U42,"""Information security is ensured by representing the original string of symbols with a different string of symbols, like source coding, and by restoring the string of symbols to the original string by decoding. increasing.
""","""The code evaluation criteria are uniquely reversible, quickly reversible, and expressed as short as possible. In addition, there is a system of prefix codes to satisfy unique decodability.""",,,"""I learned a little about the mechanism of replacing information with another symbol string in a high school class, but it was very interesting because it was the first time I had heard about the average codeword length and entropy.""",-1
C-2021-2_U43,"""The goal of source coding is to create a code that is uniquely and quickly reversible and has the shortest possible average codeword length.
The average codeword length can be calculated based on a formula, and entropy is the lower bound of the average codeword length. ""","""I was able to learn about the purpose of source coding and the best coding.""","""The part about entropy was a little tricky.""",,"""I still don't fully understand entropy, so I'd like to review it properly and take the next lecture.""",-1
C-2021-2_U43,"""The goal of source coding is to create a code that is uniquely and quickly reversible and has the shortest possible average codeword length.
The average codeword length can be calculated based on a formula, and entropy is the lower bound of the average codeword length. ""","""I was able to learn about the purpose of source coding and the best coding.""","""The part about entropy was a little tricky.""",,"""I still don't fully understand entropy, so I'd like to review it properly and take the next lecture.""",-1
C-2021-2_U43,"""The goal of source coding is to create a code that is uniquely and quickly reversible and has the shortest possible average codeword length.
The average codeword length can be calculated based on a formula, and entropy is the lower bound of the average codeword length. ""","""I was able to learn about the purpose of source coding and the best coding.""","""The part about entropy was a little tricky.""",,"""I still don't fully understand entropy, so I'd like to review it properly and take the next lecture.""",-1
C-2021-2_U43,"""The goal of source coding is to create a code that is uniquely and quickly reversible and has the shortest possible average codeword length.
The average codeword length can be calculated based on a formula, and entropy is the lower bound of the average codeword length. ""","""I was able to learn about the purpose of source coding and the best coding.""","""The part about entropy was a little tricky.""",,"""I still don't fully understand entropy, so I'd like to review it properly and take the next lecture.""",-1
C-2021-2_U44,"""A desirable condition when encoding information is that the code should be unique, quickly reversible, and represented as short as possible.""","""The procedure for obtaining the desired code is to first find the initial code and then search for the shortest possible one by entropy.""","""I didn't understand how the formula that yields the entropy was that formula.""",,"""I figured out what the desired code was, but thought it would be difficult to find one myself.""",-1
C-2021-2_U44,"""A desirable condition when encoding information is that the code should be unique, quickly reversible, and represented as short as possible.""","""The procedure for obtaining the desired code is to first find the initial code and then search for the shortest possible one by entropy.""","""I didn't understand how the formula that yields the entropy was that formula.""",,"""I figured out what the desired code was, but thought it would be difficult to find one myself.""",-1
C-2021-2_U44,"""A desirable condition when encoding information is that the code should be unique, quickly reversible, and represented as short as possible.""","""The procedure for obtaining the desired code is to first find the initial code and then search for the shortest possible one by entropy.""","""I didn't understand how the formula that yields the entropy was that formula.""",,"""I figured out what the desired code was, but thought it would be difficult to find one myself.""",-1
C-2021-2_U44,"""A desirable condition when encoding information is that the code should be unique, quickly reversible, and represented as short as possible.""","""The procedure for obtaining the desired code is to first find the initial code and then search for the shortest possible one by entropy.""","""I didn't understand how the formula that yields the entropy was that formula.""",,"""I figured out what the desired code was, but thought it would be difficult to find one myself.""",-1
C-2021-2_U45,"""Information can be encoded, but the length of the code string changes depending on how the code word is created. By devising encoding, the same information can be transmitted with a small amount of information. However, the code word Depending on how the code is created, it may not be possible to understand the information in one way from the code string.A code that has the same number of codes in a code word corresponding to a certain information, or a code that has the same last part of the code word ends with "", etc.","""Until now, I thought that all information was encoded in the same way, but I learned that there are various encoding methods. I thought that it would be important to use appropriate encoding depending on what kind of role you want the information to play after processing.""","""Nothing in particular""","""Nothing in particular.""","""I thought it was amazing that someone was thinking about what kind of code string to use for information encoding. Before the class, I didn't even know that such a role was necessary.""",-1
C-2021-2_U45,"""Information can be encoded, but the length of the code string changes depending on how the code word is created. By devising encoding, the same information can be transmitted with a small amount of information. However, the code word Depending on how the code is created, it may not be possible to understand the information in one way from the code string.A code that has the same number of codes in a code word corresponding to a certain information, or a code that has the same last part of the code word ends with "", etc.","""Until now, I thought that all information was encoded in the same way, but I learned that there are various encoding methods. I thought that it would be important to use appropriate encoding depending on what kind of role you want the information to play after processing.""","""Nothing in particular""","""Nothing in particular.""","""I thought it was amazing that someone was thinking about what kind of code string to use for information encoding. Before the class, I didn't even know that such a role was necessary.""",-1
C-2021-2_U45,"""Information can be encoded, but the length of the code string changes depending on how the code word is created. By devising encoding, the same information can be transmitted with a small amount of information. However, the code word Depending on how the code is created, it may not be possible to understand the information in one way from the code string.A code that has the same number of codes in a code word corresponding to a certain information, or a code that has the same last part of the code word ends with "", etc.","""Until now, I thought that all information was encoded in the same way, but I learned that there are various encoding methods. I thought that it would be important to use appropriate encoding depending on what kind of role you want the information to play after processing.""","""Nothing in particular""","""Nothing in particular.""","""I thought it was amazing that someone was thinking about what kind of code string to use for information encoding. Before the class, I didn't even know that such a role was necessary.""",-1
C-2021-2_U45,"""Information can be encoded, but the length of the code string changes depending on how the code word is created. By devising encoding, the same information can be transmitted with a small amount of information. However, the code word Depending on how the code is created, it may not be possible to understand the information in one way from the code string.A code that has the same number of codes in a code word corresponding to a certain information, or a code that has the same last part of the code word ends with "", etc.","""Until now, I thought that all information was encoded in the same way, but I learned that there are various encoding methods. I thought that it would be important to use appropriate encoding depending on what kind of role you want the information to play after processing.""","""Nothing in particular""","""Nothing in particular.""","""I thought it was amazing that someone was thinking about what kind of code string to use for information encoding. Before the class, I didn't even know that such a role was necessary.""",-1
C-2021-2_U45,"""Information can be encoded, but the length of the code string changes depending on how the code word is created. By devising encoding, the same information can be transmitted with a small amount of information. However, the code word Depending on how the code is created, it may not be possible to understand the information in one way from the code string.A code that has the same number of codes in a code word corresponding to a certain information, or a code that has the same last part of the code word ends with "", etc.","""Until now, I thought that all information was encoded in the same way, but I learned that there are various encoding methods. I thought that it would be important to use appropriate encoding depending on what kind of role you want the information to play after processing.""","""Nothing in particular""","""Nothing in particular.""","""I thought it was amazing that someone was thinking about what kind of code string to use for information encoding. Before the class, I didn't even know that such a role was necessary.""",-1
C-2021-2_U46,"""There are some rules for source encoding, and it must be possible to recover information accurately and quickly.
The shortest average codeword length that satisfies the conditions does not fall below the entropy. ""","""Handling signs, how to make them""","""What is entropy?""",,,-3
C-2021-2_U46,"""There are some rules for source encoding, and it must be possible to recover information accurately and quickly.
The shortest average codeword length that satisfies the conditions does not fall below the entropy. ""","""Handling signs, how to make them""","""What is entropy?""",,,-3
C-2021-2_U46,"""There are some rules for source encoding, and it must be possible to recover information accurately and quickly.
The shortest average codeword length that satisfies the conditions does not fall below the entropy. ""","""Handling signs, how to make them""","""What is entropy?""",,,-3
C-2021-2_U47,"""Information is transmitted not in its raw form, but in an encoded form. Encoded information must be uniquely reversible, quickly reversible, and expressed in the shortest possible time. Using prefixes, these conditions can be met.
""","""No matter how short I was able to express it, I found that it was a very big obstacle that I couldn't return it to the original. I was surprised that the problem was solved beautifully by using prefixes. """,,"""By encoding information, the start and end points of each information became unknown, and there were cases where it was not possible to recover uniquely or the speed of recovery was delayed. Will there be any inconvenience?""","""I would like to cherish the attitude of conveying information in a more complete and easy-to-understand manner, not only in encoding this information, but also in my daily learning.""",-3
C-2021-2_U47,"""Information is transmitted not in its raw form, but in an encoded form. Encoded information must be uniquely reversible, quickly reversible, and expressed in the shortest possible time. Using prefixes, these conditions can be met.
""","""No matter how short I was able to express it, I found that it was a very big obstacle that I couldn't return it to the original. I was surprised that the problem was solved beautifully by using prefixes. """,,"""By encoding information, the start and end points of each information became unknown, and there were cases where it was not possible to recover uniquely or the speed of recovery was delayed. Will there be any inconvenience?""","""I would like to cherish the attitude of conveying information in a more complete and easy-to-understand manner, not only in encoding this information, but also in my daily learning.""",-3
C-2021-2_U47,"""Information is transmitted not in its raw form, but in an encoded form. Encoded information must be uniquely reversible, quickly reversible, and expressed in the shortest possible time. Using prefixes, these conditions can be met.
""","""No matter how short I was able to express it, I found that it was a very big obstacle that I couldn't return it to the original. I was surprised that the problem was solved beautifully by using prefixes. """,,"""By encoding information, the start and end points of each information became unknown, and there were cases where it was not possible to recover uniquely or the speed of recovery was delayed. Will there be any inconvenience?""","""I would like to cherish the attitude of conveying information in a more complete and easy-to-understand manner, not only in encoding this information, but also in my daily learning.""",-3
C-2021-2_U47,"""Information is transmitted not in its raw form, but in an encoded form. Encoded information must be uniquely reversible, quickly reversible, and expressed in the shortest possible time. Using prefixes, these conditions can be met.
""","""No matter how short I was able to express it, I found that it was a very big obstacle that I couldn't return it to the original. I was surprised that the problem was solved beautifully by using prefixes. """,,"""By encoding information, the start and end points of each information became unknown, and there were cases where it was not possible to recover uniquely or the speed of recovery was delayed. Will there be any inconvenience?""","""I would like to cherish the attitude of conveying information in a more complete and easy-to-understand manner, not only in encoding this information, but also in my daily learning.""",-3
C-2021-2_U48,,"""We found the average codeword length, unique decodable code, initial code, and desirable code conditions.""",,,,-3
C-2021-2_U49,"""On Codeword Lengths and Optimal Codes""","""I was able to understand the conditions for thinking about the optimal code""",,,"""Currently, I am able to participate in classes without any problems, so I would like to continue as it is.""",-1
C-2021-2_U49,"""On Codeword Lengths and Optimal Codes""","""I was able to understand the conditions for thinking about the optimal code""",,,"""Currently, I am able to participate in classes without any problems, so I would like to continue as it is.""",-1
C-2021-2_U49,"""On Codeword Lengths and Optimal Codes""","""I was able to understand the conditions for thinking about the optimal code""",,,"""Currently, I am able to participate in classes without any problems, so I would like to continue as it is.""",-1
C-2021-2_U5,"""As digitization progressed, information came to be coded. When trying to express each phenomenon with a specific code, the length of the code changes depending on how the code is attached. It is designed to be rapidly compounded into , but its length never falls below entropy.""","""I was able to understand the meaning of the word entropy for the first time. I became more familiar with encoding data than I did last time.""","""It was difficult to change the codeword tone depending on the sequence of codes.""",,"""I didn't think I could understand humanities, but I was able to know the most basic part of data encoding, so my weak feeling has faded.""",-3
C-2021-2_U5,"""As digitization progressed, information came to be coded. When trying to express each phenomenon with a specific code, the length of the code changes depending on how the code is attached. It is designed to be rapidly compounded into , but its length never falls below entropy.""","""I was able to understand the meaning of the word entropy for the first time. I became more familiar with encoding data than I did last time.""","""It was difficult to change the codeword tone depending on the sequence of codes.""",,"""I didn't think I could understand humanities, but I was able to know the most basic part of data encoding, so my weak feeling has faded.""",-3
C-2021-2_U5,"""As digitization progressed, information came to be coded. When trying to express each phenomenon with a specific code, the length of the code changes depending on how the code is attached. It is designed to be rapidly compounded into , but its length never falls below entropy.""","""I was able to understand the meaning of the word entropy for the first time. I became more familiar with encoding data than I did last time.""","""It was difficult to change the codeword tone depending on the sequence of codes.""",,"""I didn't think I could understand humanities, but I was able to know the most basic part of data encoding, so my weak feeling has faded.""",-3
C-2021-2_U5,"""As digitization progressed, information came to be coded. When trying to express each phenomenon with a specific code, the length of the code changes depending on how the code is attached. It is designed to be rapidly compounded into , but its length never falls below entropy.""","""I was able to understand the meaning of the word entropy for the first time. I became more familiar with encoding data than I did last time.""","""It was difficult to change the codeword tone depending on the sequence of codes.""",,"""I didn't think I could understand humanities, but I was able to know the most basic part of data encoding, so my weak feeling has faded.""",-3
C-2021-2_U51,"""I learned the mechanism of source encoding. It's important to want something short, fast, and uniquely recoverable.""","""We found that the best source of information is the initial code that has the smallest average codeword length.""","""I understood roughly how to calculate entropy, but I didn't understand the mechanism why such a value came out.""",,"""I was confused when I saw the mathematical formula, but I wanted to be able to understand it properly through repeated trials.""",-2
C-2021-2_U51,"""I learned the mechanism of source encoding. It's important to want something short, fast, and uniquely recoverable.""","""We found that the best source of information is the initial code that has the smallest average codeword length.""","""I understood roughly how to calculate entropy, but I didn't understand the mechanism why such a value came out.""",,"""I was confused when I saw the mathematical formula, but I wanted to be able to understand it properly through repeated trials.""",-2
C-2021-2_U51,"""I learned the mechanism of source encoding. It's important to want something short, fast, and uniquely recoverable.""","""We found that the best source of information is the initial code that has the smallest average codeword length.""","""I understood roughly how to calculate entropy, but I didn't understand the mechanism why such a value came out.""",,"""I was confused when I saw the mathematical formula, but I wanted to be able to understand it properly through repeated trials.""",-2
C-2021-2_U51,"""I learned the mechanism of source encoding. It's important to want something short, fast, and uniquely recoverable.""","""We found that the best source of information is the initial code that has the smallest average codeword length.""","""I understood roughly how to calculate entropy, but I didn't understand the mechanism why such a value came out.""",,"""I was confused when I saw the mathematical formula, but I wanted to be able to understand it properly through repeated trials.""",-2
C-2021-2_U52,"""I learned about source coding. There are three things that must be met in source coding. Information should be represented as short as possible, decoded in the shortest possible time, and restored uniquely. One thing is important.""","""Information can be shortened to the limit if unique decodability is ignored, but there is a limit to the amount of information that can be shortened when unique decodability and instantaneous decodability are taken into account. is.""","""I didn't quite understand the unique decodability determination.""","""Nothing in particular.""","""Data science, like information science, is a field that I am very interested in, so it was interesting to listen to him.""",-1
C-2021-2_U52,"""I learned about source coding. There are three things that must be met in source coding. Information should be represented as short as possible, decoded in the shortest possible time, and restored uniquely. One thing is important.""","""Information can be shortened to the limit if unique decodability is ignored, but there is a limit to the amount of information that can be shortened when unique decodability and instantaneous decodability are taken into account. is.""","""I didn't quite understand the unique decodability determination.""","""Nothing in particular.""","""Data science, like information science, is a field that I am very interested in, so it was interesting to listen to him.""",-1
C-2021-2_U52,"""I learned about source coding. There are three things that must be met in source coding. Information should be represented as short as possible, decoded in the shortest possible time, and restored uniquely. One thing is important.""","""Information can be shortened to the limit if unique decodability is ignored, but there is a limit to the amount of information that can be shortened when unique decodability and instantaneous decodability are taken into account. is.""","""I didn't quite understand the unique decodability determination.""","""Nothing in particular.""","""Data science, like information science, is a field that I am very interested in, so it was interesting to listen to him.""",-1
C-2021-2_U52,"""I learned about source coding. There are three things that must be met in source coding. Information should be represented as short as possible, decoded in the shortest possible time, and restored uniquely. One thing is important.""","""Information can be shortened to the limit if unique decodability is ignored, but there is a limit to the amount of information that can be shortened when unique decodability and instantaneous decodability are taken into account. is.""","""I didn't quite understand the unique decodability determination.""","""Nothing in particular.""","""Data science, like information science, is a field that I am very interested in, so it was interesting to listen to him.""",-1
C-2021-2_U52,"""I learned about source coding. There are three things that must be met in source coding. Information should be represented as short as possible, decoded in the shortest possible time, and restored uniquely. One thing is important.""","""Information can be shortened to the limit if unique decodability is ignored, but there is a limit to the amount of information that can be shortened when unique decodability and instantaneous decodability are taken into account. is.""","""I didn't quite understand the unique decodability determination.""","""Nothing in particular.""","""Data science, like information science, is a field that I am very interested in, so it was interesting to listen to him.""",-1
C-2021-2_U53,"""This time, I was able to learn about source coding. Especially the part of initial code and instantaneous combinability was difficult, but it was interesting.""","""Through the lecture on information science, I was able to gain new knowledge about information source coding. There were many difficult words and parts that I had a hard time understanding, but I think I managed to keep up.""","""Nothing in particular.""",,"""It was a very interesting class. I'm glad that I was able to acquire new knowledge. I'm looking forward to the next class.""",-3
C-2021-2_U53,"""This time, I was able to learn about source coding. Especially the part of initial code and instantaneous combinability was difficult, but it was interesting.""","""Through the lecture on information science, I was able to gain new knowledge about information source coding. There were many difficult words and parts that I had a hard time understanding, but I think I managed to keep up.""","""Nothing in particular.""",,"""It was a very interesting class. I'm glad that I was able to acquire new knowledge. I'm looking forward to the next class.""",-3
C-2021-2_U53,"""This time, I was able to learn about source coding. Especially the part of initial code and instantaneous combinability was difficult, but it was interesting.""","""Through the lecture on information science, I was able to gain new knowledge about information source coding. There were many difficult words and parts that I had a hard time understanding, but I think I managed to keep up.""","""Nothing in particular.""",,"""It was a very interesting class. I'm glad that I was able to acquire new knowledge. I'm looking forward to the next class.""",-3
C-2021-2_U53,"""This time, I was able to learn about source coding. Especially the part of initial code and instantaneous combinability was difficult, but it was interesting.""","""Through the lecture on information science, I was able to gain new knowledge about information source coding. There were many difficult words and parts that I had a hard time understanding, but I think I managed to keep up.""","""Nothing in particular.""",,"""It was a very interesting class. I'm glad that I was able to acquire new knowledge. I'm looking forward to the next class.""",-3
C-2021-2_U54,"""Information can be represented by a series of 〇 and ●, and it can be converted into information again. The average codeword length varies considerably depending on how the code is set.""",,,,"""I understood up to 'what is the desirable code?', but after that, I couldn't keep up with my understanding because it was explained in terms I hadn't yet memorized. By the next time, I would like to review and prepare for lessons, and understand the terminology before coming to class. """,-1
C-2021-2_U54,"""Information can be represented by a series of 〇 and ●, and it can be converted into information again. The average codeword length varies considerably depending on how the code is set.""",,,,"""I understood up to 'what is the desirable code?', but after that, I couldn't keep up with my understanding because it was explained in terms I hadn't yet memorized. By the next time, I would like to review and prepare for lessons, and understand the terminology before coming to class. """,-1
C-2021-2_U55,"""By devising the placement of codewords during source coding, it is possible to shorten the length of the encoding. It is assumed that the information source coding can be returned uniquely and quickly, and the prefix code satisfies these requirements.In addition, the lower limit of the average codeword length is entropy.""","""I learned an efficient way to express information short.""","""There's nothing I couldn't understand, but I want to review it thoroughly.""",,"""Even though it is still simple, calculations have also appeared, and I felt that it was finally becoming more like information science. I was wondering how they were able to compactly summarize a huge amount of information, so I wanted to know the specific methods. I am very grateful to have been able to do it.""",-1
C-2021-2_U55,"""By devising the placement of codewords during source coding, it is possible to shorten the length of the encoding. It is assumed that the information source coding can be returned uniquely and quickly, and the prefix code satisfies these requirements.In addition, the lower limit of the average codeword length is entropy.""","""I learned an efficient way to express information short.""","""There's nothing I couldn't understand, but I want to review it thoroughly.""",,"""Even though it is still simple, calculations have also appeared, and I felt that it was finally becoming more like information science. I was wondering how they were able to compactly summarize a huge amount of information, so I wanted to know the specific methods. I am very grateful to have been able to do it.""",-1
C-2021-2_U55,"""By devising the placement of codewords during source coding, it is possible to shorten the length of the encoding. It is assumed that the information source coding can be returned uniquely and quickly, and the prefix code satisfies these requirements.In addition, the lower limit of the average codeword length is entropy.""","""I learned an efficient way to express information short.""","""There's nothing I couldn't understand, but I want to review it thoroughly.""",,"""Even though it is still simple, calculations have also appeared, and I felt that it was finally becoming more like information science. I was wondering how they were able to compactly summarize a huge amount of information, so I wanted to know the specific methods. I am very grateful to have been able to do it.""",-1
C-2021-2_U55,"""By devising the placement of codewords during source coding, it is possible to shorten the length of the encoding. It is assumed that the information source coding can be returned uniquely and quickly, and the prefix code satisfies these requirements.In addition, the lower limit of the average codeword length is entropy.""","""I learned an efficient way to express information short.""","""There's nothing I couldn't understand, but I want to review it thoroughly.""",,"""Even though it is still simple, calculations have also appeared, and I felt that it was finally becoming more like information science. I was wondering how they were able to compactly summarize a huge amount of information, so I wanted to know the specific methods. I am very grateful to have been able to do it.""",-1
C-2021-2_U56,"""The purpose of source coding is to design a code with the shortest possible average code length according to the probability distribution of the symbols, and it is premised on being able to recover it uniquely and quickly. Instantaneous decoding is possible. is the ability to recover the symbol without looking ahead at the end of reading one codeword when processing bit by bit from left to right. This is called prefix.""","""I learned how to find the average codeword length. I was able to understand the information coding theorem.""","""I didn't understand why you use log when finding entropy.""",,,-2
C-2021-2_U56,"""The purpose of source coding is to design a code with the shortest possible average code length according to the probability distribution of the symbols, and it is premised on being able to recover it uniquely and quickly. Instantaneous decoding is possible. is the ability to recover the symbol without looking ahead at the end of reading one codeword when processing bit by bit from left to right. This is called prefix.""","""I learned how to find the average codeword length. I was able to understand the information coding theorem.""","""I didn't understand why you use log when finding entropy.""",,,-2
C-2021-2_U56,"""The purpose of source coding is to design a code with the shortest possible average code length according to the probability distribution of the symbols, and it is premised on being able to recover it uniquely and quickly. Instantaneous decoding is possible. is the ability to recover the symbol without looking ahead at the end of reading one codeword when processing bit by bit from left to right. This is called prefix.""","""I learned how to find the average codeword length. I was able to understand the information coding theorem.""","""I didn't understand why you use log when finding entropy.""",,,-2
C-2021-2_U57,"""Information source coding is to express a string of symbols generated from the information source by a string of 〇 and ●, and it is important to be able to recover it uniquely and quickly. For that reason, unique decoding We are trying to create a desirable code by considering whether it is possible or whether it can be instantly decoded.""","""Even in the world of source coding, it is important to be able to proceed with things efficiently and accurately, and I learned that this is not a world where you can say ``anything is fine as long as it is conveyed''. ""","""I couldn't grasp how to understand ""entropy,"" which appears in the topic of the lower limit of the average codeword length, and how to use it. ""","""Nothing in particular.""","""I didn't prepare enough for class today, so I feel like I wasn't able to fully understand what I learned in class. I want to make sure this doesn't happen next time.""",-2
C-2021-2_U57,"""Information source coding is to express a string of symbols generated from the information source by a string of 〇 and ●, and it is important to be able to recover it uniquely and quickly. For that reason, unique decoding We are trying to create a desirable code by considering whether it is possible or whether it can be instantly decoded.""","""Even in the world of source coding, it is important to be able to proceed with things efficiently and accurately, and I learned that this is not a world where you can say ``anything is fine as long as it is conveyed''. ""","""I couldn't grasp how to understand ""entropy,"" which appears in the topic of the lower limit of the average codeword length, and how to use it. ""","""Nothing in particular.""","""I didn't prepare enough for class today, so I feel like I wasn't able to fully understand what I learned in class. I want to make sure this doesn't happen next time.""",-2
C-2021-2_U57,"""Information source coding is to express a string of symbols generated from the information source by a string of 〇 and ●, and it is important to be able to recover it uniquely and quickly. For that reason, unique decoding We are trying to create a desirable code by considering whether it is possible or whether it can be instantly decoded.""","""Even in the world of source coding, it is important to be able to proceed with things efficiently and accurately, and I learned that this is not a world where you can say ``anything is fine as long as it is conveyed''. ""","""I couldn't grasp how to understand ""entropy,"" which appears in the topic of the lower limit of the average codeword length, and how to use it. ""","""Nothing in particular.""","""I didn't prepare enough for class today, so I feel like I wasn't able to fully understand what I learned in class. I want to make sure this doesn't happen next time.""",-2
C-2021-2_U57,"""Information source coding is to express a string of symbols generated from the information source by a string of 〇 and ●, and it is important to be able to recover it uniquely and quickly. For that reason, unique decoding We are trying to create a desirable code by considering whether it is possible or whether it can be instantly decoded.""","""Even in the world of source coding, it is important to be able to proceed with things efficiently and accurately, and I learned that this is not a world where you can say ``anything is fine as long as it is conveyed''. ""","""I couldn't grasp how to understand ""entropy,"" which appears in the topic of the lower limit of the average codeword length, and how to use it. ""","""Nothing in particular.""","""I didn't prepare enough for class today, so I feel like I wasn't able to fully understand what I learned in class. I want to make sure this doesn't happen next time.""",-2
C-2021-2_U57,"""Information source coding is to express a string of symbols generated from the information source by a string of 〇 and ●, and it is important to be able to recover it uniquely and quickly. For that reason, unique decoding We are trying to create a desirable code by considering whether it is possible or whether it can be instantly decoded.""","""Even in the world of source coding, it is important to be able to proceed with things efficiently and accurately, and I learned that this is not a world where you can say ``anything is fine as long as it is conveyed''. ""","""I couldn't grasp how to understand ""entropy,"" which appears in the topic of the lower limit of the average codeword length, and how to use it. ""","""Nothing in particular.""","""I didn't prepare enough for class today, so I feel like I wasn't able to fully understand what I learned in class. I want to make sure this doesn't happen next time.""",-2
C-2021-2_U58,"""Decryption should be fast and unique.
A good code length is between entropy and entropy, but never shorter than entropy. ""","""I realized that information science is 'science'.
I didn't understand the meaning when I was preparing for class, but after listening to the lecture, I came to understand most of it. """,,"""I'm in trouble because I don't know where to submit assignments (exercises).""","""I was surprised that it was much more difficult than I thought.
I'm worried about whether I'll be able to keep up with classes and tests in the future. """,-1
C-2021-2_U58,"""Decryption should be fast and unique.
A good code length is between entropy and entropy, but never shorter than entropy. ""","""I realized that information science is 'science'.
I didn't understand the meaning when I was preparing for class, but after listening to the lecture, I came to understand most of it. """,,"""I'm in trouble because I don't know where to submit assignments (exercises).""","""I was surprised that it was much more difficult than I thought.
I'm worried about whether I'll be able to keep up with classes and tests in the future. """,-1
C-2021-2_U58,"""Decryption should be fast and unique.
A good code length is between entropy and entropy, but never shorter than entropy. ""","""I realized that information science is 'science'.
I didn't understand the meaning when I was preparing for class, but after listening to the lecture, I came to understand most of it. """,,"""I'm in trouble because I don't know where to submit assignments (exercises).""","""I was surprised that it was much more difficult than I thought.
I'm worried about whether I'll be able to keep up with classes and tests in the future. """,-1
C-2021-2_U58,"""Decryption should be fast and unique.
A good code length is between entropy and entropy, but never shorter than entropy. ""","""I realized that information science is 'science'.
I didn't understand the meaning when I was preparing for class, but after listening to the lecture, I came to understand most of it. """,,"""I'm in trouble because I don't know where to submit assignments (exercises).""","""I was surprised that it was much more difficult than I thought.
I'm worried about whether I'll be able to keep up with classes and tests in the future. """,-1
C-2021-2_U59,,"""I was able to understand the 'initial condition' that I could not understand in my preparation. ""","""I found the entropy calculation a bit difficult.""","""Nothing in particular.""",,-2
C-2021-2_U59,,"""I was able to understand the 'initial condition' that I could not understand in my preparation. ""","""I found the entropy calculation a bit difficult.""","""Nothing in particular.""",,-2
C-2021-2_U59,,"""I was able to understand the 'initial condition' that I could not understand in my preparation. ""","""I found the entropy calculation a bit difficult.""","""Nothing in particular.""",,-2
C-2021-2_U6,"""Information sources refer to things from which information can be extracted at a certain time and probability, and they are coded and handled in communication. Various patterns are conceivable for coding, but it is premised on being able to return to a unique and quick manner. A code that does not prefix any other code is called a prefix code, which can be uniquely and instantaneously decoded.In addition, for any uniquely decodable code, the There is a theorem that there is a prefix code, and in order to find the shortest code, it is necessary to know the lower bound of the average code length.","""I now know what an information source is and what it means to encode it. I understand what the average code length is and how to find it.""","""What is the entropy value? Why is log calculation necessary? If the lower limit of the average code length is known from the entropy value, and if it is within plus 1, it is meaningless if the code is not known in the first place. I was confused.""","""Even if we knew the lower limit of the average code length and found that there was a theoretically shortest code within +1, it would be meaningless unless we had a way to find it. are you asking for?""","""The contents of the first half were easy to understand and not unfamiliar, but the second half, especially the theorem and entropy, didn't make much sense, so I want to review them thoroughly.""",-2
C-2021-2_U6,"""Information sources refer to things from which information can be extracted at a certain time and probability, and they are coded and handled in communication. Various patterns are conceivable for coding, but it is premised on being able to return to a unique and quick manner. A code that does not prefix any other code is called a prefix code, which can be uniquely and instantaneously decoded.In addition, for any uniquely decodable code, the There is a theorem that there is a prefix code, and in order to find the shortest code, it is necessary to know the lower bound of the average code length.","""I now know what an information source is and what it means to encode it. I understand what the average code length is and how to find it.""","""What is the entropy value? Why is log calculation necessary? If the lower limit of the average code length is known from the entropy value, and if it is within plus 1, it is meaningless if the code is not known in the first place. I was confused.""","""Even if we knew the lower limit of the average code length and found that there was a theoretically shortest code within +1, it would be meaningless unless we had a way to find it. are you asking for?""","""The contents of the first half were easy to understand and not unfamiliar, but the second half, especially the theorem and entropy, didn't make much sense, so I want to review them thoroughly.""",-2
C-2021-2_U6,"""Information sources refer to things from which information can be extracted at a certain time and probability, and they are coded and handled in communication. Various patterns are conceivable for coding, but it is premised on being able to return to a unique and quick manner. A code that does not prefix any other code is called a prefix code, which can be uniquely and instantaneously decoded.In addition, for any uniquely decodable code, the There is a theorem that there is a prefix code, and in order to find the shortest code, it is necessary to know the lower bound of the average code length.","""I now know what an information source is and what it means to encode it. I understand what the average code length is and how to find it.""","""What is the entropy value? Why is log calculation necessary? If the lower limit of the average code length is known from the entropy value, and if it is within plus 1, it is meaningless if the code is not known in the first place. I was confused.""","""Even if we knew the lower limit of the average code length and found that there was a theoretically shortest code within +1, it would be meaningless unless we had a way to find it. are you asking for?""","""The contents of the first half were easy to understand and not unfamiliar, but the second half, especially the theorem and entropy, didn't make much sense, so I want to review them thoroughly.""",-2
C-2021-2_U6,"""Information sources refer to things from which information can be extracted at a certain time and probability, and they are coded and handled in communication. Various patterns are conceivable for coding, but it is premised on being able to return to a unique and quick manner. A code that does not prefix any other code is called a prefix code, which can be uniquely and instantaneously decoded.In addition, for any uniquely decodable code, the There is a theorem that there is a prefix code, and in order to find the shortest code, it is necessary to know the lower bound of the average code length.","""I now know what an information source is and what it means to encode it. I understand what the average code length is and how to find it.""","""What is the entropy value? Why is log calculation necessary? If the lower limit of the average code length is known from the entropy value, and if it is within plus 1, it is meaningless if the code is not known in the first place. I was confused.""","""Even if we knew the lower limit of the average code length and found that there was a theoretically shortest code within +1, it would be meaningless unless we had a way to find it. are you asking for?""","""The contents of the first half were easy to understand and not unfamiliar, but the second half, especially the theorem and entropy, didn't make much sense, so I want to review them thoroughly.""",-2
C-2021-2_U6,"""Information sources refer to things from which information can be extracted at a certain time and probability, and they are coded and handled in communication. Various patterns are conceivable for coding, but it is premised on being able to return to a unique and quick manner. A code that does not prefix any other code is called a prefix code, which can be uniquely and instantaneously decoded.In addition, for any uniquely decodable code, the There is a theorem that there is a prefix code, and in order to find the shortest code, it is necessary to know the lower bound of the average code length.","""I now know what an information source is and what it means to encode it. I understand what the average code length is and how to find it.""","""What is the entropy value? Why is log calculation necessary? If the lower limit of the average code length is known from the entropy value, and if it is within plus 1, it is meaningless if the code is not known in the first place. I was confused.""","""Even if we knew the lower limit of the average code length and found that there was a theoretically shortest code within +1, it would be meaningless unless we had a way to find it. are you asking for?""","""The contents of the first half were easy to understand and not unfamiliar, but the second half, especially the theorem and entropy, didn't make much sense, so I want to review them thoroughly.""",-2
C-2021-2_U60,"""An information source is a source that transmits information such as symbols at regular time intervals. Here, the occurrence probability is equal from any point, and the occurrence probability does not depend on the information before and after. think about.
Information originating from an information source is encoded and decoded at the destination of the information. At that time, what is emphasized is ""whether any combination can be decoded in only one way (unique decodability)"",
""Is it possible to decode immediately (instantaneous decodability)"", and ""Is the symbol string as short as possible (shortest average codeword length)"".
Of these, the code that satisfies the former two is called a prefix code (instantaneously decodable code), and the latter also has a theorem that ``there exists a prefix code that has the same codeword length as any unique decodable code''. For,
The code to be adopted is ``the one with the smallest average codeword length among the initial codes''.
Also, for the information source S(p1~pm), the entropy of S is H(S)=∑(t:1~m)pt*(-logpt), and the average codeword length of code C is L(C) , it satisfies H(S)≦L(C) and H(S)≦L(C)min≦H(S)+1 (the reason will be explained next time). ""","""It turns out that Morse code, which at first glance seems to be properly determined, is devised to reduce the amount of information transmitted as much as possible.""","""I didn't understand the relationship between entropy and average codeword length.""",,"""Compared to last time, I felt that the class content was relatively easy to understand, probably because I was able to use notes and markers.""",0
C-2021-2_U60,"""An information source is a source that transmits information such as symbols at regular time intervals. Here, the occurrence probability is equal from any point, and the occurrence probability does not depend on the information before and after. think about.
Information originating from an information source is encoded and decoded at the destination of the information. At that time, what is emphasized is ""whether any combination can be decoded in only one way (unique decodability)"",
""Is it possible to decode immediately (instantaneous decodability)"", and ""Is the symbol string as short as possible (shortest average codeword length)"".
Of these, the code that satisfies the former two is called a prefix code (instantaneously decodable code), and the latter also has a theorem that ``there exists a prefix code that has the same codeword length as any unique decodable code''. For,
The code to be adopted is ``the one with the smallest average codeword length among the initial codes''.
Also, for the information source S(p1~pm), the entropy of S is H(S)=∑(t:1~m)pt*(-logpt), and the average codeword length of code C is L(C) , it satisfies H(S)≦L(C) and H(S)≦L(C)min≦H(S)+1 (the reason will be explained next time). ""","""It turns out that Morse code, which at first glance seems to be properly determined, is devised to reduce the amount of information transmitted as much as possible.""","""I didn't understand the relationship between entropy and average codeword length.""",,"""Compared to last time, I felt that the class content was relatively easy to understand, probably because I was able to use notes and markers.""",0
C-2021-2_U60,"""An information source is a source that transmits information such as symbols at regular time intervals. Here, the occurrence probability is equal from any point, and the occurrence probability does not depend on the information before and after. think about.
Information originating from an information source is encoded and decoded at the destination of the information. At that time, what is emphasized is ""whether any combination can be decoded in only one way (unique decodability)"",
""Is it possible to decode immediately (instantaneous decodability)"", and ""Is the symbol string as short as possible (shortest average codeword length)"".
Of these, the code that satisfies the former two is called a prefix code (instantaneously decodable code), and the latter also has a theorem that ``there exists a prefix code that has the same codeword length as any unique decodable code''. For,
The code to be adopted is ``the one with the smallest average codeword length among the initial codes''.
Also, for the information source S(p1~pm), the entropy of S is H(S)=∑(t:1~m)pt*(-logpt), and the average codeword length of code C is L(C) , it satisfies H(S)≦L(C) and H(S)≦L(C)min≦H(S)+1 (the reason will be explained next time). ""","""It turns out that Morse code, which at first glance seems to be properly determined, is devised to reduce the amount of information transmitted as much as possible.""","""I didn't understand the relationship between entropy and average codeword length.""",,"""Compared to last time, I felt that the class content was relatively easy to understand, probably because I was able to use notes and markers.""",0
C-2021-2_U60,"""An information source is a source that transmits information such as symbols at regular time intervals. Here, the occurrence probability is equal from any point, and the occurrence probability does not depend on the information before and after. think about.
Information originating from an information source is encoded and decoded at the destination of the information. At that time, what is emphasized is ""whether any combination can be decoded in only one way (unique decodability)"",
""Is it possible to decode immediately (instantaneous decodability)"", and ""Is the symbol string as short as possible (shortest average codeword length)"".
Of these, the code that satisfies the former two is called a prefix code (instantaneously decodable code), and the latter also has a theorem that ``there exists a prefix code that has the same codeword length as any unique decodable code''. For,
The code to be adopted is ``the one with the smallest average codeword length among the initial codes''.
Also, for the information source S(p1~pm), the entropy of S is H(S)=∑(t:1~m)pt*(-logpt), and the average codeword length of code C is L(C) , it satisfies H(S)≦L(C) and H(S)≦L(C)min≦H(S)+1 (the reason will be explained next time). ""","""It turns out that Morse code, which at first glance seems to be properly determined, is devised to reduce the amount of information transmitted as much as possible.""","""I didn't understand the relationship between entropy and average codeword length.""",,"""Compared to last time, I felt that the class content was relatively easy to understand, probably because I was able to use notes and markers.""",0
C-2021-2_U62,"""Unique decodability of prefix code, average code length, instantaneous decodability, etc.""",,,,"""The content suddenly became difficult, so I was a little confused, but I managed to keep up. I think it will get even more difficult from now on, so I want to concentrate more than ever before.""",-3
C-2021-2_U62,"""Unique decodability of prefix code, average code length, instantaneous decodability, etc.""",,,,"""The content suddenly became difficult, so I was a little confused, but I managed to keep up. I think it will get even more difficult from now on, so I want to concentrate more than ever before.""",-3
C-2021-2_U63,,"""Mechanism of encoding and decoding""","""I thought I had to do a thorough entropy calculation.""",,,-3
C-2021-2_U63,,"""Mechanism of encoding and decoding""","""I thought I had to do a thorough entropy calculation.""",,,-3
C-2021-2_U64,"""An information source is a source that outputs symbols at regular time intervals, and is generally a stationary memoryless information source. Information source coding is the encoding of a string of symbols generated from an information source. Decoding is the act of restoring what has been obtained by encoding.Conventions have been made to design codes with a short average codeword length on the premise of being able to quickly return to a unique code. It was found that the code that is preferable for this is the prefix code that satisfies the prefix condition, and among them, the code with the smallest average codeword length is the optimal code.""","""In today's content, I first learned what an information source is. I also learned how to encode and decode information source encoding through examples of encoding. In addition, I learned that it is necessary to emphasize the three conditions of unique decodability, instantaneous decodability, and minimization of the average codeword length in encoding. , the code with the smallest average codeword length among the uniquely decodable codes has the smallest average codeword length. I found out that I should find something with.""","""I understood the entropy as a formula, but I didn't quite understand what it was. Also, the average codeword length of the optimal code is greater than the entropy and less than the entropy plus 1. I didn't understand much. I was told that entropy will be explained again in next week's class, so I'll make sure to listen carefully during next week's class, including preparation, so that I don't miss anything.""",,"""Today's class was more difficult than last week's first class. There were a lot of them, so when I was preparing for the next class, I decided to spend a little more time reading through the materials before I could take the next class.""",-2
C-2021-2_U64,"""An information source is a source that outputs symbols at regular time intervals, and is generally a stationary memoryless information source. Information source coding is the encoding of a string of symbols generated from an information source. Decoding is the act of restoring what has been obtained by encoding.Conventions have been made to design codes with a short average codeword length on the premise of being able to quickly return to a unique code. It was found that the code that is preferable for this is the prefix code that satisfies the prefix condition, and among them, the code with the smallest average codeword length is the optimal code.""","""In today's content, I first learned what an information source is. I also learned how to encode and decode information source encoding through examples of encoding. In addition, I learned that it is necessary to emphasize the three conditions of unique decodability, instantaneous decodability, and minimization of the average codeword length in encoding. , the code with the smallest average codeword length among the uniquely decodable codes has the smallest average codeword length. I found out that I should find something with.""","""I understood the entropy as a formula, but I didn't quite understand what it was. Also, the average codeword length of the optimal code is greater than the entropy and less than the entropy plus 1. I didn't understand much. I was told that entropy will be explained again in next week's class, so I'll make sure to listen carefully during next week's class, including preparation, so that I don't miss anything.""",,"""Today's class was more difficult than last week's first class. There were a lot of them, so when I was preparing for the next class, I decided to spend a little more time reading through the materials before I could take the next class.""",-2
C-2021-2_U64,"""An information source is a source that outputs symbols at regular time intervals, and is generally a stationary memoryless information source. Information source coding is the encoding of a string of symbols generated from an information source. Decoding is the act of restoring what has been obtained by encoding.Conventions have been made to design codes with a short average codeword length on the premise of being able to quickly return to a unique code. It was found that the code that is preferable for this is the prefix code that satisfies the prefix condition, and among them, the code with the smallest average codeword length is the optimal code.""","""In today's content, I first learned what an information source is. I also learned how to encode and decode information source encoding through examples of encoding. In addition, I learned that it is necessary to emphasize the three conditions of unique decodability, instantaneous decodability, and minimization of the average codeword length in encoding. , the code with the smallest average codeword length among the uniquely decodable codes has the smallest average codeword length. I found out that I should find something with.""","""I understood the entropy as a formula, but I didn't quite understand what it was. Also, the average codeword length of the optimal code is greater than the entropy and less than the entropy plus 1. I didn't understand much. I was told that entropy will be explained again in next week's class, so I'll make sure to listen carefully during next week's class, including preparation, so that I don't miss anything.""",,"""Today's class was more difficult than last week's first class. There were a lot of them, so when I was preparing for the next class, I decided to spend a little more time reading through the materials before I could take the next class.""",-2
C-2021-2_U64,"""An information source is a source that outputs symbols at regular time intervals, and is generally a stationary memoryless information source. Information source coding is the encoding of a string of symbols generated from an information source. Decoding is the act of restoring what has been obtained by encoding.Conventions have been made to design codes with a short average codeword length on the premise of being able to quickly return to a unique code. It was found that the code that is preferable for this is the prefix code that satisfies the prefix condition, and among them, the code with the smallest average codeword length is the optimal code.""","""In today's content, I first learned what an information source is. I also learned how to encode and decode information source encoding through examples of encoding. In addition, I learned that it is necessary to emphasize the three conditions of unique decodability, instantaneous decodability, and minimization of the average codeword length in encoding. , the code with the smallest average codeword length among the uniquely decodable codes has the smallest average codeword length. I found out that I should find something with.""","""I understood the entropy as a formula, but I didn't quite understand what it was. Also, the average codeword length of the optimal code is greater than the entropy and less than the entropy plus 1. I didn't understand much. I was told that entropy will be explained again in next week's class, so I'll make sure to listen carefully during next week's class, including preparation, so that I don't miss anything.""",,"""Today's class was more difficult than last week's first class. There were a lot of them, so when I was preparing for the next class, I decided to spend a little more time reading through the materials before I could take the next class.""",-2
C-2021-2_U65,"""Information source = something that emits symbols at regular time intervals
Information source coding = A string of symbols is represented by 〇 and ●.
Decoding = inverse of source encoding
Uniquely decodable code = same codeword length (fixed-length code)
Instantaneous decodability = initial condition (no codeword is a prefix of another codeword)
""","""I prefer codes that have a single meaning, can be decoded quickly, and are as short as possible.""","""It was difficult from around page 32.""","""Nothing in particular.""",,-1
C-2021-2_U65,"""Information source = something that emits symbols at regular time intervals
Information source coding = A string of symbols is represented by 〇 and ●.
Decoding = inverse of source encoding
Uniquely decodable code = same codeword length (fixed-length code)
Instantaneous decodability = initial condition (no codeword is a prefix of another codeword)
""","""I prefer codes that have a single meaning, can be decoded quickly, and are as short as possible.""","""It was difficult from around page 32.""","""Nothing in particular.""",,-1
C-2021-2_U65,"""Information source = something that emits symbols at regular time intervals
Information source coding = A string of symbols is represented by 〇 and ●.
Decoding = inverse of source encoding
Uniquely decodable code = same codeword length (fixed-length code)
Instantaneous decodability = initial condition (no codeword is a prefix of another codeword)
""","""I prefer codes that have a single meaning, can be decoded quickly, and are as short as possible.""","""It was difficult from around page 32.""","""Nothing in particular.""",,-1
C-2021-2_U65,"""Information source = something that emits symbols at regular time intervals
Information source coding = A string of symbols is represented by 〇 and ●.
Decoding = inverse of source encoding
Uniquely decodable code = same codeword length (fixed-length code)
Instantaneous decodability = initial condition (no codeword is a prefix of another codeword)
""","""I prefer codes that have a single meaning, can be decoded quickly, and are as short as possible.""","""It was difficult from around page 32.""","""Nothing in particular.""",,-1
C-2021-2_U66,"""I learned how to encode information and how to encode it. As for encoding, I used formulas to find the best code for the type and length of time it takes to decode.""","""I was able to understand the differences between the types of codes and their properties. Especially, I think the contents of unique decodability and instantaneous decodability are perfect.""","""I found it difficult to accept the definition of average codeword length and entropy. Also, I could only vaguely understand the explanation of the source coding theorem for optimal codes.""",,"""I was able to understand and calculate entropy to a certain extent (although I could only apply it to the formula), but I don't think I could say that I fully understood the source coding theorem. I will deepen my understanding in the next class. It's been a long time, so I can't hide my surprise because I forgot how to calculate log.""",-2
C-2021-2_U66,"""I learned how to encode information and how to encode it. As for encoding, I used formulas to find the best code for the type and length of time it takes to decode.""","""I was able to understand the differences between the types of codes and their properties. Especially, I think the contents of unique decodability and instantaneous decodability are perfect.""","""I found it difficult to accept the definition of average codeword length and entropy. Also, I could only vaguely understand the explanation of the source coding theorem for optimal codes.""",,"""I was able to understand and calculate entropy to a certain extent (although I could only apply it to the formula), but I don't think I could say that I fully understood the source coding theorem. I will deepen my understanding in the next class. It's been a long time, so I can't hide my surprise because I forgot how to calculate log.""",-2
C-2021-2_U66,"""I learned how to encode information and how to encode it. As for encoding, I used formulas to find the best code for the type and length of time it takes to decode.""","""I was able to understand the differences between the types of codes and their properties. Especially, I think the contents of unique decodability and instantaneous decodability are perfect.""","""I found it difficult to accept the definition of average codeword length and entropy. Also, I could only vaguely understand the explanation of the source coding theorem for optimal codes.""",,"""I was able to understand and calculate entropy to a certain extent (although I could only apply it to the formula), but I don't think I could say that I fully understood the source coding theorem. I will deepen my understanding in the next class. It's been a long time, so I can't hide my surprise because I forgot how to calculate log.""",-2
C-2021-2_U66,"""I learned how to encode information and how to encode it. As for encoding, I used formulas to find the best code for the type and length of time it takes to decode.""","""I was able to understand the differences between the types of codes and their properties. Especially, I think the contents of unique decodability and instantaneous decodability are perfect.""","""I found it difficult to accept the definition of average codeword length and entropy. Also, I could only vaguely understand the explanation of the source coding theorem for optimal codes.""",,"""I was able to understand and calculate entropy to a certain extent (although I could only apply it to the formula), but I don't think I could say that I fully understood the source coding theorem. I will deepen my understanding in the next class. It's been a long time, so I can't hide my surprise because I forgot how to calculate log.""",-2
C-2021-2_U67,"""When encoding a source, it is better not only to be short, but also to be able to quickly return to uniqueness. Those that can be returned to uniqueness are those of fixed length, those with a delimiting code at the end. Also, in order to return instantaneously, it is necessary to prevent the beginning from overlapping.The lower limit of the average codeword length can be found by calculating the entropy, and the optimum length is the entropy
and that number plus one. ""","""It's not just about encoding, you have to think about encoding so that you can decode it quickly.""",,,,-1
C-2021-2_U67,"""When encoding a source, it is better not only to be short, but also to be able to quickly return to uniqueness. Those that can be returned to uniqueness are those of fixed length, those with a delimiting code at the end. Also, in order to return instantaneously, it is necessary to prevent the beginning from overlapping.The lower limit of the average codeword length can be found by calculating the entropy, and the optimum length is the entropy
and that number plus one. ""","""It's not just about encoding, you have to think about encoding so that you can decode it quickly.""",,,,-1
C-2021-2_U68,"""Information sources often have many conditions that must be met. They must be uniquely decodable (they can be read in one way), they must be read quickly, and they must be short. The information source is wasteful and long. If this happens, there are disadvantages such as heavy processing.""","""It turns out that entropy is the minimum value of the average codeword length (the average length of one symbol).""","""Not particularly.""","""Not particularly.""","""If you don't devise ways to express the symbols, the information source will come up with multiple readings, but it was interesting that anything that satisfies the initial conditions can always be read uniquely.""",-3
C-2021-2_U68,"""Information sources often have many conditions that must be met. They must be uniquely decodable (they can be read in one way), they must be read quickly, and they must be short. The information source is wasteful and long. If this happens, there are disadvantages such as heavy processing.""","""It turns out that entropy is the minimum value of the average codeword length (the average length of one symbol).""","""Not particularly.""","""Not particularly.""","""If you don't devise ways to express the symbols, the information source will come up with multiple readings, but it was interesting that anything that satisfies the initial conditions can always be read uniquely.""",-3
C-2021-2_U68,"""Information sources often have many conditions that must be met. They must be uniquely decodable (they can be read in one way), they must be read quickly, and they must be short. The information source is wasteful and long. If this happens, there are disadvantages such as heavy processing.""","""It turns out that entropy is the minimum value of the average codeword length (the average length of one symbol).""","""Not particularly.""","""Not particularly.""","""If you don't devise ways to express the symbols, the information source will come up with multiple readings, but it was interesting that anything that satisfies the initial conditions can always be read uniquely.""",-3
C-2021-2_U68,"""Information sources often have many conditions that must be met. They must be uniquely decodable (they can be read in one way), they must be read quickly, and they must be short. The information source is wasteful and long. If this happens, there are disadvantages such as heavy processing.""","""It turns out that entropy is the minimum value of the average codeword length (the average length of one symbol).""","""Not particularly.""","""Not particularly.""","""If you don't devise ways to express the symbols, the information source will come up with multiple readings, but it was interesting that anything that satisfies the initial conditions can always be read uniquely.""",-3
C-2021-2_U68,"""Information sources often have many conditions that must be met. They must be uniquely decodable (they can be read in one way), they must be read quickly, and they must be short. The information source is wasteful and long. If this happens, there are disadvantages such as heavy processing.""","""It turns out that entropy is the minimum value of the average codeword length (the average length of one symbol).""","""Not particularly.""","""Not particularly.""","""If you don't devise ways to express the symbols, the information source will come up with multiple readings, but it was interesting that anything that satisfies the initial conditions can always be read uniquely.""",-3
C-2021-2_U69,"""The main content of this lecture was about coding, in which information symbols are represented by a white circle and a black circle. There are various rules to convey information more concisely and accurately, and the most important thing is to be unique and quickly return to the original symbol.""","""I learned why I should encode the source and what I should be careful about when doing so. I was also able to determine the average codeword length.""","""I didn't quite understand why the source coding theorem (1) worked.""",,,-1
C-2021-2_U69,"""The main content of this lecture was about coding, in which information symbols are represented by a white circle and a black circle. There are various rules to convey information more concisely and accurately, and the most important thing is to be unique and quickly return to the original symbol.""","""I learned why I should encode the source and what I should be careful about when doing so. I was also able to determine the average codeword length.""","""I didn't quite understand why the source coding theorem (1) worked.""",,,-1
C-2021-2_U69,"""The main content of this lecture was about coding, in which information symbols are represented by a white circle and a black circle. There are various rules to convey information more concisely and accurately, and the most important thing is to be unique and quickly return to the original symbol.""","""I learned why I should encode the source and what I should be careful about when doing so. I was also able to determine the average codeword length.""","""I didn't quite understand why the source coding theorem (1) worked.""",,,-1
C-2021-2_U7,"""source encoding
(1) What is an information source?
A source that outputs symbols at regular time intervals. Each symbol has an equal probability of occurrence.
　Stationary memoryless information source...The probability of occurrence is the same regardless of the preceding or succeeding symbols regardless of the starting point of the symbol string.
(2) What is source coding?
    Coding
　Symbol string　→The column represented by ○●
←
Decryption
In order to speed up decoding and encoding, it is necessary to shorten the average codeword length (sum of word length of each code×occurrence probability). In other words, it is better to shorten the word length of symbols with high occurrence probability and lengthen the word length of symbols with low occurrence probability. However, the condition is that it can be returned to uniqueness quickly (unique decodability, instantaneous decodability)
Unique decodability: The word length of each code is the same. There is a symbol to guide you. It is not acceptable when the symbol string after encoding different symbol strings is the same
Instantaneous decodability: Requires prefix condition (after any code is not a prefix of another code). A code with a prefix condition is called a prefix code, and the prefix code can be uniquely decoded.
Lower limit of average codeword length (entropy): sum of probability of each code × (-log2 probability)
Optimal codeword length is entropy to entropy + 1

""","""In the previous class, I didn't understand the initial conditions at all, but in this class, I understood.
I was able to complete all the practice problems. ""","""It's not because the class was easy to understand.""",,"""It was fun to calculate the logarithm for the first time in a long time. I thought it was interesting to see the result in the calculation.
I want to remember the formula. """,-1
C-2021-2_U7,"""source encoding
(1) What is an information source?
A source that outputs symbols at regular time intervals. Each symbol has an equal probability of occurrence.
　Stationary memoryless information source...The probability of occurrence is the same regardless of the preceding or succeeding symbols regardless of the starting point of the symbol string.
(2) What is source coding?
    Coding
　Symbol string　→The column represented by ○●
←
Decryption
In order to speed up decoding and encoding, it is necessary to shorten the average codeword length (sum of word length of each code×occurrence probability). In other words, it is better to shorten the word length of symbols with high occurrence probability and lengthen the word length of symbols with low occurrence probability. However, the condition is that it can be returned to uniqueness quickly (unique decodability, instantaneous decodability)
Unique decodability: The word length of each code is the same. There is a symbol to guide you. It is not acceptable when the symbol string after encoding different symbol strings is the same
Instantaneous decodability: Requires prefix condition (after any code is not a prefix of another code). A code with a prefix condition is called a prefix code, and the prefix code can be uniquely decoded.
Lower limit of average codeword length (entropy): sum of probability of each code × (-log2 probability)
Optimal codeword length is entropy to entropy + 1

""","""In the previous class, I didn't understand the initial conditions at all, but in this class, I understood.
I was able to complete all the practice problems. ""","""It's not because the class was easy to understand.""",,"""It was fun to calculate the logarithm for the first time in a long time. I thought it was interesting to see the result in the calculation.
I want to remember the formula. """,-1
C-2021-2_U7,"""source encoding
(1) What is an information source?
A source that outputs symbols at regular time intervals. Each symbol has an equal probability of occurrence.
　Stationary memoryless information source...The probability of occurrence is the same regardless of the preceding or succeeding symbols regardless of the starting point of the symbol string.
(2) What is source coding?
    Coding
　Symbol string　→The column represented by ○●
←
Decryption
In order to speed up decoding and encoding, it is necessary to shorten the average codeword length (sum of word length of each code×occurrence probability). In other words, it is better to shorten the word length of symbols with high occurrence probability and lengthen the word length of symbols with low occurrence probability. However, the condition is that it can be returned to uniqueness quickly (unique decodability, instantaneous decodability)
Unique decodability: The word length of each code is the same. There is a symbol to guide you. It is not acceptable when the symbol string after encoding different symbol strings is the same
Instantaneous decodability: Requires prefix condition (after any code is not a prefix of another code). A code with a prefix condition is called a prefix code, and the prefix code can be uniquely decoded.
Lower limit of average codeword length (entropy): sum of probability of each code × (-log2 probability)
Optimal codeword length is entropy to entropy + 1

""","""In the previous class, I didn't understand the initial conditions at all, but in this class, I understood.
I was able to complete all the practice problems. ""","""It's not because the class was easy to understand.""",,"""It was fun to calculate the logarithm for the first time in a long time. I thought it was interesting to see the result in the calculation.
I want to remember the formula. """,-1
C-2021-2_U7,"""source encoding
(1) What is an information source?
A source that outputs symbols at regular time intervals. Each symbol has an equal probability of occurrence.
　Stationary memoryless information source...The probability of occurrence is the same regardless of the preceding or succeeding symbols regardless of the starting point of the symbol string.
(2) What is source coding?
    Coding
　Symbol string　→The column represented by ○●
←
Decryption
In order to speed up decoding and encoding, it is necessary to shorten the average codeword length (sum of word length of each code×occurrence probability). In other words, it is better to shorten the word length of symbols with high occurrence probability and lengthen the word length of symbols with low occurrence probability. However, the condition is that it can be returned to uniqueness quickly (unique decodability, instantaneous decodability)
Unique decodability: The word length of each code is the same. There is a symbol to guide you. It is not acceptable when the symbol string after encoding different symbol strings is the same
Instantaneous decodability: Requires prefix condition (after any code is not a prefix of another code). A code with a prefix condition is called a prefix code, and the prefix code can be uniquely decoded.
Lower limit of average codeword length (entropy): sum of probability of each code × (-log2 probability)
Optimal codeword length is entropy to entropy + 1

""","""In the previous class, I didn't understand the initial conditions at all, but in this class, I understood.
I was able to complete all the practice problems. ""","""It's not because the class was easy to understand.""",,"""It was fun to calculate the logarithm for the first time in a long time. I thought it was interesting to see the result in the calculation.
I want to remember the formula. """,-1
C-2021-2_U71,"""Several steps are required to convey some information. First, source coding, where unique decodability is where the encoded information can be restored to a single piece of information. Another important factor here is instantaneous decodability.Then, what is a desirable code?Unique decodability, instantaneous decodability, average codeword It fulfills all the requirements.""","""I learned that many elements are required for just one process to transmit certain information, and that they are intricately intertwined, such as aiming to reduce the number of codes as much as possible.""",,,"""I felt that there were many technical formulas and terms in class, so I want to put more effort into my preparation.""",-1
C-2021-2_U71,"""Several steps are required to convey some information. First, source coding, where unique decodability is where the encoded information can be restored to a single piece of information. Another important factor here is instantaneous decodability.Then, what is a desirable code?Unique decodability, instantaneous decodability, average codeword It fulfills all the requirements.""","""I learned that many elements are required for just one process to transmit certain information, and that they are intricately intertwined, such as aiming to reduce the number of codes as much as possible.""",,,"""I felt that there were many technical formulas and terms in class, so I want to put more effort into my preparation.""",-1
C-2021-2_U71,"""Several steps are required to convey some information. First, source coding, where unique decodability is where the encoded information can be restored to a single piece of information. Another important factor here is instantaneous decodability.Then, what is a desirable code?Unique decodability, instantaneous decodability, average codeword It fulfills all the requirements.""","""I learned that many elements are required for just one process to transmit certain information, and that they are intricately intertwined, such as aiming to reduce the number of codes as much as possible.""",,,"""I felt that there were many technical formulas and terms in class, so I want to put more effort into my preparation.""",-1
C-2021-2_U72,"""A source that generates symbols with a constant sense of time is called an information source. The probability of generation for each symbol is constant. It does not change from any point in time (stationary), and does not change with previous or subsequent symbols (invariant). memory).Therefore, information can be transmitted with a smaller number of bits by performing information source coding that generates a symbol called a codeword that takes into account the generation probability. It is good if it can be decoded quickly.How can such a property be attached?A non-unique code is one that can be interpreted in two or more ways when decoding a code sequence.This is not suitable. Also, it is good to be able to stabilize the code by reading as few bits as possible.A code that has these two properties is called a prefix code.There is a lower limit to the average codeword length.This is called entropy, and it is algebraically There is also a formula to be found: for any source, there is a code with the smallest average codeword length, called the optimal code, which is close to entropy.""","""I pretty much understand everything but the meaning of the entropy formula.""","""I don't really understand why the entropy formula involves logarithms. I have a feeling that the fact that the base is 2 and that the bits are binary are related...""",,"""It took me a while to figure it out.""",-2
C-2021-2_U72,"""A source that generates symbols with a constant sense of time is called an information source. The probability of generation for each symbol is constant. It does not change from any point in time (stationary), and does not change with previous or subsequent symbols (invariant). memory).Therefore, information can be transmitted with a smaller number of bits by performing information source coding that generates a symbol called a codeword that takes into account the generation probability. It is good if it can be decoded quickly.How can such a property be attached?A non-unique code is one that can be interpreted in two or more ways when decoding a code sequence.This is not suitable. Also, it is good to be able to stabilize the code by reading as few bits as possible.A code that has these two properties is called a prefix code.There is a lower limit to the average codeword length.This is called entropy, and it is algebraically There is also a formula to be found: for any source, there is a code with the smallest average codeword length, called the optimal code, which is close to entropy.""","""I pretty much understand everything but the meaning of the entropy formula.""","""I don't really understand why the entropy formula involves logarithms. I have a feeling that the fact that the base is 2 and that the bits are binary are related...""",,"""It took me a while to figure it out.""",-2
C-2021-2_U72,"""A source that generates symbols with a constant sense of time is called an information source. The probability of generation for each symbol is constant. It does not change from any point in time (stationary), and does not change with previous or subsequent symbols (invariant). memory).Therefore, information can be transmitted with a smaller number of bits by performing information source coding that generates a symbol called a codeword that takes into account the generation probability. It is good if it can be decoded quickly.How can such a property be attached?A non-unique code is one that can be interpreted in two or more ways when decoding a code sequence.This is not suitable. Also, it is good to be able to stabilize the code by reading as few bits as possible.A code that has these two properties is called a prefix code.There is a lower limit to the average codeword length.This is called entropy, and it is algebraically There is also a formula to be found: for any source, there is a code with the smallest average codeword length, called the optimal code, which is close to entropy.""","""I pretty much understand everything but the meaning of the entropy formula.""","""I don't really understand why the entropy formula involves logarithms. I have a feeling that the fact that the base is 2 and that the bits are binary are related...""",,"""It took me a while to figure it out.""",-2
C-2021-2_U72,"""A source that generates symbols with a constant sense of time is called an information source. The probability of generation for each symbol is constant. It does not change from any point in time (stationary), and does not change with previous or subsequent symbols (invariant). memory).Therefore, information can be transmitted with a smaller number of bits by performing information source coding that generates a symbol called a codeword that takes into account the generation probability. It is good if it can be decoded quickly.How can such a property be attached?A non-unique code is one that can be interpreted in two or more ways when decoding a code sequence.This is not suitable. Also, it is good to be able to stabilize the code by reading as few bits as possible.A code that has these two properties is called a prefix code.There is a lower limit to the average codeword length.This is called entropy, and it is algebraically There is also a formula to be found: for any source, there is a code with the smallest average codeword length, called the optimal code, which is close to entropy.""","""I pretty much understand everything but the meaning of the entropy formula.""","""I don't really understand why the entropy formula involves logarithms. I have a feeling that the fact that the base is 2 and that the bits are binary are related...""",,"""It took me a while to figure it out.""",-2
C-2021-2_U73,"""A stationary memoryless information source is an information source that always has the same occurrence probability of symbols and does not depend on the symbols output before and after it.In information transmission, information is encoded and decoded. Since the purpose of information coding is to design codes with as short a codeword length as possible, it is desirable to use codes that can be uniquely reverted, quickly decompressed, and expressed in a short time.""",,,,,-3
C-2021-2_U74,"""There are various ways to express something electronically by combining symbols, which can be easily deciphered or can be expressed with less capacity.""",,,,"""The way of thinking is very simple, but it is very difficult to explain it in plain words, so I had a hard time understanding it.""",-2
C-2021-2_U74,"""There are various ways to express something electronically by combining symbols, which can be easily deciphered or can be expressed with less capacity.""",,,,"""The way of thinking is very simple, but it is very difficult to explain it in plain words, so I had a hard time understanding it.""",-2
C-2021-2_U75,"""Information source coding is to represent a string of symbols generated from the information source by a string of white and black circles, and decoding is to convert the encoded string of white and black circles into the original symbol string. When encoding the information source, the probability of occurrence of the symbol
Therefore, it is necessary to design a code with a short average codeword length as much as possible, and to consider unique decodability and instantaneous decodability of the code. The lower bound on the average codeword length is called entropy. The source coding theorem using average codeword length and entropy gives the optimal code for a given source. ""","""I was able to understand the three conditions that need to be considered when source coding and what they are. There were many words I heard for the first time, but I understood the meaning of each one properly. I'm glad I was able to do it.""","""I felt that I needed to be able to calculate the average codeword length and entropy by myself, so I would like to practice by myself and be able to calculate it by the next class. I got it.""",,"""I'm glad I was able to give you an overview of what's important when encoding a source. Do your own math to find the average codeword length, entropy, and try to understand the meaning of these words."" I would like to memorize it accurately and connect it to future classes.""",-2
C-2021-2_U75,"""Information source coding is to represent a string of symbols generated from the information source by a string of white and black circles, and decoding is to convert the encoded string of white and black circles into the original symbol string. When encoding the information source, the probability of occurrence of the symbol
Therefore, it is necessary to design a code with a short average codeword length as much as possible, and to consider unique decodability and instantaneous decodability of the code. The lower bound on the average codeword length is called entropy. The source coding theorem using average codeword length and entropy gives the optimal code for a given source. ""","""I was able to understand the three conditions that need to be considered when source coding and what they are. There were many words I heard for the first time, but I understood the meaning of each one properly. I'm glad I was able to do it.""","""I felt that I needed to be able to calculate the average codeword length and entropy by myself, so I would like to practice by myself and be able to calculate it by the next class. I got it.""",,"""I'm glad I was able to give you an overview of what's important when encoding a source. Do your own math to find the average codeword length, entropy, and try to understand the meaning of these words."" I would like to memorize it accurately and connect it to future classes.""",-2
C-2021-2_U75,"""Information source coding is to represent a string of symbols generated from the information source by a string of white and black circles, and decoding is to convert the encoded string of white and black circles into the original symbol string. When encoding the information source, the probability of occurrence of the symbol
Therefore, it is necessary to design a code with a short average codeword length as much as possible, and to consider unique decodability and instantaneous decodability of the code. The lower bound on the average codeword length is called entropy. The source coding theorem using average codeword length and entropy gives the optimal code for a given source. ""","""I was able to understand the three conditions that need to be considered when source coding and what they are. There were many words I heard for the first time, but I understood the meaning of each one properly. I'm glad I was able to do it.""","""I felt that I needed to be able to calculate the average codeword length and entropy by myself, so I would like to practice by myself and be able to calculate it by the next class. I got it.""",,"""I'm glad I was able to give you an overview of what's important when encoding a source. Do your own math to find the average codeword length, entropy, and try to understand the meaning of these words."" I would like to memorize it accurately and connect it to future classes.""",-2
C-2021-2_U75,"""Information source coding is to represent a string of symbols generated from the information source by a string of white and black circles, and decoding is to convert the encoded string of white and black circles into the original symbol string. When encoding the information source, the probability of occurrence of the symbol
Therefore, it is necessary to design a code with a short average codeword length as much as possible, and to consider unique decodability and instantaneous decodability of the code. The lower bound on the average codeword length is called entropy. The source coding theorem using average codeword length and entropy gives the optimal code for a given source. ""","""I was able to understand the three conditions that need to be considered when source coding and what they are. There were many words I heard for the first time, but I understood the meaning of each one properly. I'm glad I was able to do it.""","""I felt that I needed to be able to calculate the average codeword length and entropy by myself, so I would like to practice by myself and be able to calculate it by the next class. I got it.""",,"""I'm glad I was able to give you an overview of what's important when encoding a source. Do your own math to find the average codeword length, entropy, and try to understand the meaning of these words."" I would like to memorize it accurately and connect it to future classes.""",-2
C-2021-2_U76,"""The average decoded wordbook is the average of the codewords of the information source, and when decoding the information source, the codewords are determined so as to make it as small as possible. It is important to have a decoding that can be reverted: codes that are all the same length can be decoded uniquely, but codes of different lengths may not be uniquely decoded.
A code that satisfies the condition that no codeword is a prefix of another codeword is called a prefix code, which is uniquely decodable and instantaneously decodable.
The lower bound of the average decoded wordbook is called entropy. ""","""I was able to understand the meaning of H(S)<=L(C*)<H(S)+1, which the average decoded wordbook L(C*) satisfies.
""","""In today's class, there was a formula for calculating entropy for information sources, and I felt it was a little complicated.

""",,"""I found it interesting that academic research is being conducted to find out how efficient coding can be done. I realized it again.""",0
C-2021-2_U76,"""The average decoded wordbook is the average of the codewords of the information source, and when decoding the information source, the codewords are determined so as to make it as small as possible. It is important to have a decoding that can be reverted: codes that are all the same length can be decoded uniquely, but codes of different lengths may not be uniquely decoded.
A code that satisfies the condition that no codeword is a prefix of another codeword is called a prefix code, which is uniquely decodable and instantaneously decodable.
The lower bound of the average decoded wordbook is called entropy. ""","""I was able to understand the meaning of H(S)<=L(C*)<H(S)+1, which the average decoded wordbook L(C*) satisfies.
""","""In today's class, there was a formula for calculating entropy for information sources, and I felt it was a little complicated.

""",,"""I found it interesting that academic research is being conducted to find out how efficient coding can be done. I realized it again.""",0
C-2021-2_U76,"""The average decoded wordbook is the average of the codewords of the information source, and when decoding the information source, the codewords are determined so as to make it as small as possible. It is important to have a decoding that can be reverted: codes that are all the same length can be decoded uniquely, but codes of different lengths may not be uniquely decoded.
A code that satisfies the condition that no codeword is a prefix of another codeword is called a prefix code, which is uniquely decodable and instantaneously decodable.
The lower bound of the average decoded wordbook is called entropy. ""","""I was able to understand the meaning of H(S)<=L(C*)<H(S)+1, which the average decoded wordbook L(C*) satisfies.
""","""In today's class, there was a formula for calculating entropy for information sources, and I felt it was a little complicated.

""",,"""I found it interesting that academic research is being conducted to find out how efficient coding can be done. I realized it again.""",0
C-2021-2_U76,"""The average decoded wordbook is the average of the codewords of the information source, and when decoding the information source, the codewords are determined so as to make it as small as possible. It is important to have a decoding that can be reverted: codes that are all the same length can be decoded uniquely, but codes of different lengths may not be uniquely decoded.
A code that satisfies the condition that no codeword is a prefix of another codeword is called a prefix code, which is uniquely decodable and instantaneously decodable.
The lower bound of the average decoded wordbook is called entropy. ""","""I was able to understand the meaning of H(S)<=L(C*)<H(S)+1, which the average decoded wordbook L(C*) satisfies.
""","""In today's class, there was a formula for calculating entropy for information sources, and I felt it was a little complicated.

""",,"""I found it interesting that academic research is being conducted to find out how efficient coding can be done. I realized it again.""",0
C-2021-2_U77,"""An information source is something that outputs symbols at regular time intervals. Information is conveyed to humans by encoding and decoding, but what do you want to convey if you do not make it unique when encoding? I don't know what's going on.""","""We try to send information in as few bits as possible to save energy and effort. That's why we have the average codeword length.""","""I didn't understand why entropy was defined like that.""","""How many optimal codes exist?""","""Other than entropy, it was very easy to understand.""",-2
C-2021-2_U77,"""An information source is something that outputs symbols at regular time intervals. Information is conveyed to humans by encoding and decoding, but what do you want to convey if you do not make it unique when encoding? I don't know what's going on.""","""We try to send information in as few bits as possible to save energy and effort. That's why we have the average codeword length.""","""I didn't understand why entropy was defined like that.""","""How many optimal codes exist?""","""Other than entropy, it was very easy to understand.""",-2
C-2021-2_U77,"""An information source is something that outputs symbols at regular time intervals. Information is conveyed to humans by encoding and decoding, but what do you want to convey if you do not make it unique when encoding? I don't know what's going on.""","""We try to send information in as few bits as possible to save energy and effort. That's why we have the average codeword length.""","""I didn't understand why entropy was defined like that.""","""How many optimal codes exist?""","""Other than entropy, it was very easy to understand.""",-2
C-2021-2_U77,"""An information source is something that outputs symbols at regular time intervals. Information is conveyed to humans by encoding and decoding, but what do you want to convey if you do not make it unique when encoding? I don't know what's going on.""","""We try to send information in as few bits as possible to save energy and effort. That's why we have the average codeword length.""","""I didn't understand why entropy was defined like that.""","""How many optimal codes exist?""","""Other than entropy, it was very easy to understand.""",-2
C-2021-2_U77,"""An information source is something that outputs symbols at regular time intervals. Information is conveyed to humans by encoding and decoding, but what do you want to convey if you do not make it unique when encoding? I don't know what's going on.""","""We try to send information in as few bits as possible to save energy and effort. That's why we have the average codeword length.""","""I didn't understand why entropy was defined like that.""","""How many optimal codes exist?""","""Other than entropy, it was very easy to understand.""",-2
C-2021-2_U78,"""I learned how to encode and try to shorten the average codeword tone. However, the code's evaluation criteria are that it can be uniquely reverted, that it can be reverted quickly, and that it can be as short as possible. Also, the entropy leads to the optimal code. I learned.""","""I learned that entropy can be used to find the optimal code with average codeword length.""","""I didn't understand why the entropy calculation did that.""",,"""I'm glad I learned more about codes.""",-3
C-2021-2_U78,"""I learned how to encode and try to shorten the average codeword tone. However, the code's evaluation criteria are that it can be uniquely reverted, that it can be reverted quickly, and that it can be as short as possible. Also, the entropy leads to the optimal code. I learned.""","""I learned that entropy can be used to find the optimal code with average codeword length.""","""I didn't understand why the entropy calculation did that.""",,"""I'm glad I learned more about codes.""",-3
C-2021-2_U78,"""I learned how to encode and try to shorten the average codeword tone. However, the code's evaluation criteria are that it can be uniquely reverted, that it can be reverted quickly, and that it can be as short as possible. Also, the entropy leads to the optimal code. I learned.""","""I learned that entropy can be used to find the optimal code with average codeword length.""","""I didn't understand why the entropy calculation did that.""",,"""I'm glad I learned more about codes.""",-3
C-2021-2_U78,"""I learned how to encode and try to shorten the average codeword tone. However, the code's evaluation criteria are that it can be uniquely reverted, that it can be reverted quickly, and that it can be as short as possible. Also, the entropy leads to the optimal code. I learned.""","""I learned that entropy can be used to find the optimal code with average codeword length.""","""I didn't understand why the entropy calculation did that.""",,"""I'm glad I learned more about codes.""",-3
C-2021-2_U79,"""I learned what source coding is and its purpose. I also learned about unique decodability and instantaneous decodability, and considered desirable codes.""",,"""I thought I understood the source coding theorem while it was being explained to me, but after reviewing it, I wasn't sure if I understood it.""",,"""I understand the desired code.""",-1
C-2021-2_U79,"""I learned what source coding is and its purpose. I also learned about unique decodability and instantaneous decodability, and considered desirable codes.""",,"""I thought I understood the source coding theorem while it was being explained to me, but after reviewing it, I wasn't sure if I understood it.""",,"""I understand the desired code.""",-1
C-2021-2_U79,"""I learned what source coding is and its purpose. I also learned about unique decodability and instantaneous decodability, and considered desirable codes.""",,"""I thought I understood the source coding theorem while it was being explained to me, but after reviewing it, I wasn't sure if I understood it.""",,"""I understand the desired code.""",-1
C-2021-2_U8,"An information source is a source that outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed. Decoding is to restore the string obtained by the encoding to the original symbol string.The purpose of the encoding is to design a code with the shortest possible average code length.However, it must be uniquely decodable. For example, if there are two or more ways to decompose the same bit string into corresponding codes, or if it is a non-initial code, unique code possibility and instantaneous decodability are not satisfied. No. The desired code is one that is uniquely quickly reversible and has the shortest possible representation.For any uniquely decodable code there exists a prefix with the same codeword length.Therefore, among prefixes When the average code is the smallest, the uniquely decodable code has the smallest average word length, and the entropy is the lower bound of the average code word length, and the code with less than the entropy plus 1 is the optimal code for the source. It becomes.""","""In source coding, we found that a long average codeword length has a large impact on our daily life, such as an increase in the power consumption of equipment. Finding and using the optimal conversion method from an infinite number of conversion methods. I understood the rough method and its importance.""","""This time, there were only four codeword types, but I felt it was difficult to think about the optimal code when this number increased.""",,"""It was difficult this time. It took me a long time to figure it out because most of it was something I didn't know.""",-3
C-2021-2_U8,"An information source is a source that outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed. Decoding is to restore the string obtained by the encoding to the original symbol string.The purpose of the encoding is to design a code with the shortest possible average code length.However, it must be uniquely decodable. For example, if there are two or more ways to decompose the same bit string into corresponding codes, or if it is a non-initial code, unique code possibility and instantaneous decodability are not satisfied. No. The desired code is one that is uniquely quickly reversible and has the shortest possible representation.For any uniquely decodable code there exists a prefix with the same codeword length.Therefore, among prefixes When the average code is the smallest, the uniquely decodable code has the smallest average word length, and the entropy is the lower bound of the average code word length, and the code with less than the entropy plus 1 is the optimal code for the source. It becomes.""","""In source coding, we found that a long average codeword length has a large impact on our daily life, such as an increase in the power consumption of equipment. Finding and using the optimal conversion method from an infinite number of conversion methods. I understood the rough method and its importance.""","""This time, there were only four codeword types, but I felt it was difficult to think about the optimal code when this number increased.""",,"""It was difficult this time. It took me a long time to figure it out because most of it was something I didn't know.""",-3
C-2021-2_U8,"An information source is a source that outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed. Decoding is to restore the string obtained by the encoding to the original symbol string.The purpose of the encoding is to design a code with the shortest possible average code length.However, it must be uniquely decodable. For example, if there are two or more ways to decompose the same bit string into corresponding codes, or if it is a non-initial code, unique code possibility and instantaneous decodability are not satisfied. No. The desired code is one that is uniquely quickly reversible and has the shortest possible representation.For any uniquely decodable code there exists a prefix with the same codeword length.Therefore, among prefixes When the average code is the smallest, the uniquely decodable code has the smallest average word length, and the entropy is the lower bound of the average code word length, and the code with less than the entropy plus 1 is the optimal code for the source. It becomes.""","""In source coding, we found that a long average codeword length has a large impact on our daily life, such as an increase in the power consumption of equipment. Finding and using the optimal conversion method from an infinite number of conversion methods. I understood the rough method and its importance.""","""This time, there were only four codeword types, but I felt it was difficult to think about the optimal code when this number increased.""",,"""It was difficult this time. It took me a long time to figure it out because most of it was something I didn't know.""",-3
C-2021-2_U8,"An information source is a source that outputs symbols at regular time intervals, and the probability of occurrence of each symbol is fixed. Decoding is to restore the string obtained by the encoding to the original symbol string.The purpose of the encoding is to design a code with the shortest possible average code length.However, it must be uniquely decodable. For example, if there are two or more ways to decompose the same bit string into corresponding codes, or if it is a non-initial code, unique code possibility and instantaneous decodability are not satisfied. No. The desired code is one that is uniquely quickly reversible and has the shortest possible representation.For any uniquely decodable code there exists a prefix with the same codeword length.Therefore, among prefixes When the average code is the smallest, the uniquely decodable code has the smallest average word length, and the entropy is the lower bound of the average code word length, and the code with less than the entropy plus 1 is the optimal code for the source. It becomes.""","""In source coding, we found that a long average codeword length has a large impact on our daily life, such as an increase in the power consumption of equipment. Finding and using the optimal conversion method from an infinite number of conversion methods. I understood the rough method and its importance.""","""This time, there were only four codeword types, but I felt it was difficult to think about the optimal code when this number increased.""",,"""It was difficult this time. It took me a long time to figure it out because most of it was something I didn't know.""",-3
C-2021-2_U80,"""The source encoding started with an explanation of what a source is and its properties, followed by some know-how on how to encode and decode a source.""","""We know the average codeword length, unique decodability, instantaneous decodability, and prefixes.""","""My understanding of entropy is vague, partly because there wasn't much explanation this time.""","""Nothing in particular.""","""I didn't have any knowledge about how to encode information sources, so I learned for the first time that various methods have been cultivated in this class, and I was able to take the class fresh.""",-1
C-2021-2_U80,"""The source encoding started with an explanation of what a source is and its properties, followed by some know-how on how to encode and decode a source.""","""We know the average codeword length, unique decodability, instantaneous decodability, and prefixes.""","""My understanding of entropy is vague, partly because there wasn't much explanation this time.""","""Nothing in particular.""","""I didn't have any knowledge about how to encode information sources, so I learned for the first time that various methods have been cultivated in this class, and I was able to take the class fresh.""",-1
C-2021-2_U80,"""The source encoding started with an explanation of what a source is and its properties, followed by some know-how on how to encode and decode a source.""","""We know the average codeword length, unique decodability, instantaneous decodability, and prefixes.""","""My understanding of entropy is vague, partly because there wasn't much explanation this time.""","""Nothing in particular.""","""I didn't have any knowledge about how to encode information sources, so I learned for the first time that various methods have been cultivated in this class, and I was able to take the class fresh.""",-1
C-2021-2_U80,"""The source encoding started with an explanation of what a source is and its properties, followed by some know-how on how to encode and decode a source.""","""We know the average codeword length, unique decodability, instantaneous decodability, and prefixes.""","""My understanding of entropy is vague, partly because there wasn't much explanation this time.""","""Nothing in particular.""","""I didn't have any knowledge about how to encode information sources, so I learned for the first time that various methods have been cultivated in this class, and I was able to take the class fresh.""",-1
C-2021-2_U80,"""The source encoding started with an explanation of what a source is and its properties, followed by some know-how on how to encode and decode a source.""","""We know the average codeword length, unique decodability, instantaneous decodability, and prefixes.""","""My understanding of entropy is vague, partly because there wasn't much explanation this time.""","""Nothing in particular.""","""I didn't have any knowledge about how to encode information sources, so I learned for the first time that various methods have been cultivated in this class, and I was able to take the class fresh.""",-1
C-2021-2_U81,"""I learned about the encoding of sources, their types, their optimizations and their fundamental theorems.""","""I was able to understand the purpose of source coding, the mechanism of prefix codes, and their advantages.""","""I could not fully understand the entropy of the average codeword length, including the theorem.""","""Why base 2 for logarithms?""","""It was quite a complicated story, so I realized that I couldn't keep up without a certain amount of preparation.""",0
C-2021-2_U81,"""I learned about the encoding of sources, their types, their optimizations and their fundamental theorems.""","""I was able to understand the purpose of source coding, the mechanism of prefix codes, and their advantages.""","""I could not fully understand the entropy of the average codeword length, including the theorem.""","""Why base 2 for logarithms?""","""It was quite a complicated story, so I realized that I couldn't keep up without a certain amount of preparation.""",0
C-2021-2_U81,"""I learned about the encoding of sources, their types, their optimizations and their fundamental theorems.""","""I was able to understand the purpose of source coding, the mechanism of prefix codes, and their advantages.""","""I could not fully understand the entropy of the average codeword length, including the theorem.""","""Why base 2 for logarithms?""","""It was quite a complicated story, so I realized that I couldn't keep up without a certain amount of preparation.""",0
C-2021-2_U81,"""I learned about the encoding of sources, their types, their optimizations and their fundamental theorems.""","""I was able to understand the purpose of source coding, the mechanism of prefix codes, and their advantages.""","""I could not fully understand the entropy of the average codeword length, including the theorem.""","""Why base 2 for logarithms?""","""It was quite a complicated story, so I realized that I couldn't keep up without a certain amount of preparation.""",0
C-2021-2_U81,"""I learned about the encoding of sources, their types, their optimizations and their fundamental theorems.""","""I was able to understand the purpose of source coding, the mechanism of prefix codes, and their advantages.""","""I could not fully understand the entropy of the average codeword length, including the theorem.""","""Why base 2 for logarithms?""","""It was quite a complicated story, so I realized that I couldn't keep up without a certain amount of preparation.""",0
C-2021-2_U82,"""Types and desirability of information codes.""","""I was able to gain a firm understanding of what kind of information encoding is desirable.""","""Nothing in particular.""","""Nothing in particular.""","""There are various types of codes, and it was interesting to see how mathematics is involved in choosing the best one.""",-2
C-2021-2_U82,"""Types and desirability of information codes.""","""I was able to gain a firm understanding of what kind of information encoding is desirable.""","""Nothing in particular.""","""Nothing in particular.""","""There are various types of codes, and it was interesting to see how mathematics is involved in choosing the best one.""",-2
C-2021-2_U82,"""Types and desirability of information codes.""","""I was able to gain a firm understanding of what kind of information encoding is desirable.""","""Nothing in particular.""","""Nothing in particular.""","""There are various types of codes, and it was interesting to see how mathematics is involved in choosing the best one.""",-2
C-2021-2_U82,"""Types and desirability of information codes.""","""I was able to gain a firm understanding of what kind of information encoding is desirable.""","""Nothing in particular.""","""Nothing in particular.""","""There are various types of codes, and it was interesting to see how mathematics is involved in choosing the best one.""",-2
C-2021-2_U82,"""Types and desirability of information codes.""","""I was able to gain a firm understanding of what kind of information encoding is desirable.""","""Nothing in particular.""","""Nothing in particular.""","""There are various types of codes, and it was interesting to see how mathematics is involved in choosing the best one.""",-2
C-2021-2_U83,"""Explanation of source coding. Also, Theorem I on uniqueness of compounding and initial code. Finally, we learned about information content and entropy.""",,,,,-2
C-2021-2_U84,"""About Source Coding""","""I learned a lot about source coding. I was able to understand the examples very well, especially regarding the occurrence probability. did it.""","""I didn't find anything in particular that I didn't understand in class. I was late in filling out the diary this time, so next time I'll write it soon.""","""Nothing in particular""","""Today's examples were easy to understand, so I was able to grasp the contents of the class well. I didn't fully understand the Morse code from the previous lesson, so I think I'll review that as well.""",-1
C-2021-2_U84,"""About Source Coding""","""I learned a lot about source coding. I was able to understand the examples very well, especially regarding the occurrence probability. did it.""","""I didn't find anything in particular that I didn't understand in class. I was late in filling out the diary this time, so next time I'll write it soon.""","""Nothing in particular""","""Today's examples were easy to understand, so I was able to grasp the contents of the class well. I didn't fully understand the Morse code from the previous lesson, so I think I'll review that as well.""",-1
C-2021-2_U84,"""About Source Coding""","""I learned a lot about source coding. I was able to understand the examples very well, especially regarding the occurrence probability. did it.""","""I didn't find anything in particular that I didn't understand in class. I was late in filling out the diary this time, so next time I'll write it soon.""","""Nothing in particular""","""Today's examples were easy to understand, so I was able to grasp the contents of the class well. I didn't fully understand the Morse code from the previous lesson, so I think I'll review that as well.""",-1
C-2021-2_U84,"""About Source Coding""","""I learned a lot about source coding. I was able to understand the examples very well, especially regarding the occurrence probability. did it.""","""I didn't find anything in particular that I didn't understand in class. I was late in filling out the diary this time, so next time I'll write it soon.""","""Nothing in particular""","""Today's examples were easy to understand, so I was able to grasp the contents of the class well. I didn't fully understand the Morse code from the previous lesson, so I think I'll review that as well.""",-1
C-2021-2_U84,"""About Source Coding""","""I learned a lot about source coding. I was able to understand the examples very well, especially regarding the occurrence probability. did it.""","""I didn't find anything in particular that I didn't understand in class. I was late in filling out the diary this time, so next time I'll write it soon.""","""Nothing in particular""","""Today's examples were easy to understand, so I was able to grasp the contents of the class well. I didn't fully understand the Morse code from the previous lesson, so I think I'll review that as well.""",-1
C-2021-2_U85,"""I learned what an information source is using examples such as the weather and rock-paper-scissors, and learned about the mechanism of information source encoding and the desired code using mathematical formulas.""","""An information source is a source that outputs symbols at regular time intervals, and the occurrence probability of each symbol is fixed. A steady-state memoryless information source has a symbol string occurrence probability Similarly, the occurrence probability of a symbol at an arbitrary time is an information source that does not depend on the symbols output before and after it. It is called encoding, and converting the sequence of ◯⚫ obtained by encoding into the original symbol string is called decoding.The purpose of information encoding is to create a code with the shortest possible average codeword length according to the probability distribution of the symbol. The design is based on the assumption that it is uniquely reversible, so in order to reduce the average codeword length, we assign short codes to symbols with high probability and long codes to low probability symbols. However, unique decodability and instantaneous decodability must also be considered.The lower limit of the average codeword length is called entropy, and the optimum symbol average codeword length is equal to or greater than entropy and equal to or less than entropy plus 1. .""",,,"""I hadn't studied mathematics at all since I entered university, so when I first saw mathematical formulas, I almost had a reaction to rejection, but after listening carefully to what the teacher was saying, I was able to understand them properly. It was interesting, especially the problem of unique decodability, and I enjoyed thinking about it like a puzzle.""",-3
C-2021-2_U85,"""I learned what an information source is using examples such as the weather and rock-paper-scissors, and learned about the mechanism of information source encoding and the desired code using mathematical formulas.""","""An information source is a source that outputs symbols at regular time intervals, and the occurrence probability of each symbol is fixed. A steady-state memoryless information source has a symbol string occurrence probability Similarly, the occurrence probability of a symbol at an arbitrary time is an information source that does not depend on the symbols output before and after it. It is called encoding, and converting the sequence of ◯⚫ obtained by encoding into the original symbol string is called decoding.The purpose of information encoding is to create a code with the shortest possible average codeword length according to the probability distribution of the symbol. The design is based on the assumption that it is uniquely reversible, so in order to reduce the average codeword length, we assign short codes to symbols with high probability and long codes to low probability symbols. However, unique decodability and instantaneous decodability must also be considered.The lower limit of the average codeword length is called entropy, and the optimum symbol average codeword length is equal to or greater than entropy and equal to or less than entropy plus 1. .""",,,"""I hadn't studied mathematics at all since I entered university, so when I first saw mathematical formulas, I almost had a reaction to rejection, but after listening carefully to what the teacher was saying, I was able to understand them properly. It was interesting, especially the problem of unique decodability, and I enjoyed thinking about it like a puzzle.""",-3
C-2021-2_U85,"""I learned what an information source is using examples such as the weather and rock-paper-scissors, and learned about the mechanism of information source encoding and the desired code using mathematical formulas.""","""An information source is a source that outputs symbols at regular time intervals, and the occurrence probability of each symbol is fixed. A steady-state memoryless information source has a symbol string occurrence probability Similarly, the occurrence probability of a symbol at an arbitrary time is an information source that does not depend on the symbols output before and after it. It is called encoding, and converting the sequence of ◯⚫ obtained by encoding into the original symbol string is called decoding.The purpose of information encoding is to create a code with the shortest possible average codeword length according to the probability distribution of the symbol. The design is based on the assumption that it is uniquely reversible, so in order to reduce the average codeword length, we assign short codes to symbols with high probability and long codes to low probability symbols. However, unique decodability and instantaneous decodability must also be considered.The lower limit of the average codeword length is called entropy, and the optimum symbol average codeword length is equal to or greater than entropy and equal to or less than entropy plus 1. .""",,,"""I hadn't studied mathematics at all since I entered university, so when I first saw mathematical formulas, I almost had a reaction to rejection, but after listening carefully to what the teacher was saying, I was able to understand them properly. It was interesting, especially the problem of unique decodability, and I enjoyed thinking about it like a puzzle.""",-3
C-2021-2_U86,"""In source coding, it is important to be able to decode uniquely, to be able to decode quickly, and to encode short.""","""I've found a good encoding standard.""","""Entropy was difficult.""",,"""There are some parts that I don't fully understand, so I would like to review them thoroughly.""",-2
C-2021-2_U86,"""In source coding, it is important to be able to decode uniquely, to be able to decode quickly, and to encode short.""","""I've found a good encoding standard.""","""Entropy was difficult.""",,"""There are some parts that I don't fully understand, so I would like to review them thoroughly.""",-2
C-2021-2_U86,"""In source coding, it is important to be able to decode uniquely, to be able to decode quickly, and to encode short.""","""I've found a good encoding standard.""","""Entropy was difficult.""",,"""There are some parts that I don't fully understand, so I would like to review them thoroughly.""",-2
C-2021-2_U86,"""In source coding, it is important to be able to decode uniquely, to be able to decode quickly, and to encode short.""","""I've found a good encoding standard.""","""Entropy was difficult.""",,"""There are some parts that I don't fully understand, so I would like to review them thoroughly.""",-2
C-2021-2_U87,"""Information codes, decoding availability and efficiency, how to derive optimal codes after calculating entropy""","""How to calculate entropy""",,,,-1
C-2021-2_U87,"""Information codes, decoding availability and efficiency, how to derive optimal codes after calculating entropy""","""How to calculate entropy""",,,,-1
C-2021-2_U88,"""I learned about information encoding and average codeword lengths, and with it what is the most efficient information encoding on a computer.""","""It is now possible to calculate the average codeword length and find the optimum code. In addition, since the processing on the computer can be simplified as much as possible, the code with the minimum average codeword length is the optimum code. It turned out to be.""","""Not at the moment. It's been a long time since I've calculated log in the calculation method, so it seems to be wrong.""",,"""Because the class was based on theory, I was able to understand it very easily.""",-3
C-2021-2_U88,"""I learned about information encoding and average codeword lengths, and with it what is the most efficient information encoding on a computer.""","""It is now possible to calculate the average codeword length and find the optimum code. In addition, since the processing on the computer can be simplified as much as possible, the code with the minimum average codeword length is the optimum code. It turned out to be.""","""Not at the moment. It's been a long time since I've calculated log in the calculation method, so it seems to be wrong.""",,"""Because the class was based on theory, I was able to understand it very easily.""",-3
C-2021-2_U88,"""I learned about information encoding and average codeword lengths, and with it what is the most efficient information encoding on a computer.""","""It is now possible to calculate the average codeword length and find the optimum code. In addition, since the processing on the computer can be simplified as much as possible, the code with the minimum average codeword length is the optimum code. It turned out to be.""","""Not at the moment. It's been a long time since I've calculated log in the calculation method, so it seems to be wrong.""",,"""Because the class was based on theory, I was able to understand it very easily.""",-3
C-2021-2_U88,"""I learned about information encoding and average codeword lengths, and with it what is the most efficient information encoding on a computer.""","""It is now possible to calculate the average codeword length and find the optimum code. In addition, since the processing on the computer can be simplified as much as possible, the code with the minimum average codeword length is the optimum code. It turned out to be.""","""Not at the moment. It's been a long time since I've calculated log in the calculation method, so it seems to be wrong.""",,"""Because the class was based on theory, I was able to understand it very easily.""",-3
C-2021-2_U89,"""When encoding information, it is desirable to have prefix codes that are uniquely decodable (uniquely reversible) and instantaneously decodable (quickly reversible). Among the prefix codes, the average codeword length is the shortest, and by calculating the entropy we can find a lower bound on the average codeword length.""","""Until now, I thought it was too reckless to represent information with 0s and 1s, but after taking this class, I unexpectedly learned that if the framework is solid, even with two types of symbols, you can do something about it.""","""I didn't understand how the entropy is a lower bound on the average codeword length.""",,"""In this class, I felt a sign that the content of the future classes would become more profound and more interesting. In order to enjoy difficult classes, I want to make sure I do not forget to prepare and review.""",-2
C-2021-2_U89,"""When encoding information, it is desirable to have prefix codes that are uniquely decodable (uniquely reversible) and instantaneously decodable (quickly reversible). Among the prefix codes, the average codeword length is the shortest, and by calculating the entropy we can find a lower bound on the average codeword length.""","""Until now, I thought it was too reckless to represent information with 0s and 1s, but after taking this class, I unexpectedly learned that if the framework is solid, even with two types of symbols, you can do something about it.""","""I didn't understand how the entropy is a lower bound on the average codeword length.""",,"""In this class, I felt a sign that the content of the future classes would become more profound and more interesting. In order to enjoy difficult classes, I want to make sure I do not forget to prepare and review.""",-2
C-2021-2_U89,"""When encoding information, it is desirable to have prefix codes that are uniquely decodable (uniquely reversible) and instantaneously decodable (quickly reversible). Among the prefix codes, the average codeword length is the shortest, and by calculating the entropy we can find a lower bound on the average codeword length.""","""Until now, I thought it was too reckless to represent information with 0s and 1s, but after taking this class, I unexpectedly learned that if the framework is solid, even with two types of symbols, you can do something about it.""","""I didn't understand how the entropy is a lower bound on the average codeword length.""",,"""In this class, I felt a sign that the content of the future classes would become more profound and more interesting. In order to enjoy difficult classes, I want to make sure I do not forget to prepare and review.""",-2
C-2021-2_U89,"""When encoding information, it is desirable to have prefix codes that are uniquely decodable (uniquely reversible) and instantaneously decodable (quickly reversible). Among the prefix codes, the average codeword length is the shortest, and by calculating the entropy we can find a lower bound on the average codeword length.""","""Until now, I thought it was too reckless to represent information with 0s and 1s, but after taking this class, I unexpectedly learned that if the framework is solid, even with two types of symbols, you can do something about it.""","""I didn't understand how the entropy is a lower bound on the average codeword length.""",,"""In this class, I felt a sign that the content of the future classes would become more profound and more interesting. In order to enjoy difficult classes, I want to make sure I do not forget to prepare and review.""",-2
C-2021-2_U9,"""Information source coding is the representation of a string of symbols generated from an information source that outputs symbols at regular time intervals with 0s and 1s. It is based on the premise that the probability distribution of symbols can be uniquely and instantaneously restored. The average codeword length is shortened as much as possible according to .Conversely, converting the string to the original symbol string is called decoding.Here, each codeword is a prefix of another codeword A code that does not correspond to the initial code is called a prefix code, and it can be decoded uniquely and instantaneously.Therefore, when considering a desirable code, it is sufficient to narrow down to the prefix code and minimize the average codeword length. A code with the smallest average codeword length is called an optimal code, where the average codeword length is greater than or equal to entropy and less than ""entropy + 1"". ""","""I now know what to consider in order for information to be conveyed accurately and efficiently. I also understand the meaning of new words (e.g. average codeword length).""",,,,0
C-2021-2_U9,"""Information source coding is the representation of a string of symbols generated from an information source that outputs symbols at regular time intervals with 0s and 1s. It is based on the premise that the probability distribution of symbols can be uniquely and instantaneously restored. The average codeword length is shortened as much as possible according to .Conversely, converting the string to the original symbol string is called decoding.Here, each codeword is a prefix of another codeword A code that does not correspond to the initial code is called a prefix code, and it can be decoded uniquely and instantaneously.Therefore, when considering a desirable code, it is sufficient to narrow down to the prefix code and minimize the average codeword length. A code with the smallest average codeword length is called an optimal code, where the average codeword length is greater than or equal to entropy and less than ""entropy + 1"". ""","""I now know what to consider in order for information to be conveyed accurately and efficiently. I also understand the meaning of new words (e.g. average codeword length).""",,,,0
C-2021-2_U90,"""Learn the theorems about codes and think about how to make the best codes""","""I learned a new theorem about signs.""","""I didn't quite understand how to use the sign theorem.""",,"""My understanding wasn't perfect, so I'd like to review it thoroughly and eliminate the things I don't understand one by one.""",-1
C-2021-2_U90,"""Learn the theorems about codes and think about how to make the best codes""","""I learned a new theorem about signs.""","""I didn't quite understand how to use the sign theorem.""",,"""My understanding wasn't perfect, so I'd like to review it thoroughly and eliminate the things I don't understand one by one.""",-1
C-2021-2_U90,"""Learn the theorems about codes and think about how to make the best codes""","""I learned a new theorem about signs.""","""I didn't quite understand how to use the sign theorem.""",,"""My understanding wasn't perfect, so I'd like to review it thoroughly and eliminate the things I don't understand one by one.""",-1
C-2021-2_U90,"""Learn the theorems about codes and think about how to make the best codes""","""I learned a new theorem about signs.""","""I didn't quite understand how to use the sign theorem.""",,"""My understanding wasn't perfect, so I'd like to review it thoroughly and eliminate the things I don't understand one by one.""",-1
C-2021-2_U92,"""Information is transmitted by source coding, and the amount of information varies depending on the predetermined way of coding
・It is necessary to define the code so that it is “unique and can be returned quickly”, and it is desirable to express it as short as possible.
・The minimum average codeword length is called entropy.""","""In source coding, the necessary conditions are unique recoverability and instantaneous combinability, and these can be initial codes that satisfy the initial conditions.
A sufficient condition is to shorten the average codeword length, and the shortest one is called ""entropy"", which is obtained by a formula. ""","""I didn't quite understand how to find entropy.""",,,-3
C-2021-2_U92,"""Information is transmitted by source coding, and the amount of information varies depending on the predetermined way of coding
・It is necessary to define the code so that it is “unique and can be returned quickly”, and it is desirable to express it as short as possible.
・The minimum average codeword length is called entropy.""","""In source coding, the necessary conditions are unique recoverability and instantaneous combinability, and these can be initial codes that satisfy the initial conditions.
A sufficient condition is to shorten the average codeword length, and the shortest one is called ""entropy"", which is obtained by a formula. ""","""I didn't quite understand how to find entropy.""",,,-3
C-2021-2_U92,"""Information is transmitted by source coding, and the amount of information varies depending on the predetermined way of coding
・It is necessary to define the code so that it is “unique and can be returned quickly”, and it is desirable to express it as short as possible.
・The minimum average codeword length is called entropy.""","""In source coding, the necessary conditions are unique recoverability and instantaneous combinability, and these can be initial codes that satisfy the initial conditions.
A sufficient condition is to shorten the average codeword length, and the shortest one is called ""entropy"", which is obtained by a formula. ""","""I didn't quite understand how to find entropy.""",,,-3
C-2021-2_U93,"""Encoding is the conversion of information such as the weather into a combination of two symbols, a white circle and a black circle.
When converting, it is necessary to pay attention to various factors such as reducing the amount of information as much as possible, whether the information can be converted uniquely, and whether the converted information can be quickly restored to the original information. ""","""I was able to understand the meaning of new phrases such as uniquely decodable and stationary memoryless information sources.
I was able to understand the basic concept of entropy. ""","""I didn't understand the meaning of the initial condition.""",,"""I missed the first part of the class because of bad connection on Teams, so I want to pay attention to the communication environment next time.
""",-1
C-2021-2_U93,"""Encoding is the conversion of information such as the weather into a combination of two symbols, a white circle and a black circle.
When converting, it is necessary to pay attention to various factors such as reducing the amount of information as much as possible, whether the information can be converted uniquely, and whether the converted information can be quickly restored to the original information. ""","""I was able to understand the meaning of new phrases such as uniquely decodable and stationary memoryless information sources.
I was able to understand the basic concept of entropy. ""","""I didn't understand the meaning of the initial condition.""",,"""I missed the first part of the class because of bad connection on Teams, so I want to pay attention to the communication environment next time.
""",-1
C-2021-2_U93,"""Encoding is the conversion of information such as the weather into a combination of two symbols, a white circle and a black circle.
When converting, it is necessary to pay attention to various factors such as reducing the amount of information as much as possible, whether the information can be converted uniquely, and whether the converted information can be quickly restored to the original information. ""","""I was able to understand the meaning of new phrases such as uniquely decodable and stationary memoryless information sources.
I was able to understand the basic concept of entropy. ""","""I didn't understand the meaning of the initial condition.""",,"""I missed the first part of the class because of bad connection on Teams, so I want to pay attention to the communication environment next time.
""",-1
C-2021-2_U93,"""Encoding is the conversion of information such as the weather into a combination of two symbols, a white circle and a black circle.
When converting, it is necessary to pay attention to various factors such as reducing the amount of information as much as possible, whether the information can be converted uniquely, and whether the converted information can be quickly restored to the original information. ""","""I was able to understand the meaning of new phrases such as uniquely decodable and stationary memoryless information sources.
I was able to understand the basic concept of entropy. ""","""I didn't understand the meaning of the initial condition.""",,"""I missed the first part of the class because of bad connection on Teams, so I want to pay attention to the communication environment next time.
""",-1
C-2021-2_U94,"""After learning about the types of symbols, I learned how to decide which symbol is best. I concluded that it is best to look for the shortest symbol among prefixes.""","""Today, I was able to learn about the classification of codes and the conditions for optimal codes. I felt that this way of thinking could be applied to other things by understanding the fundamentals of each.""","""I'm curious as to why you use logarithms, so I'm looking forward to the next class.""",,"""It was interesting to organize in my head what I had only vaguely known about codes.""",-2
C-2021-2_U94,"""After learning about the types of symbols, I learned how to decide which symbol is best. I concluded that it is best to look for the shortest symbol among prefixes.""","""Today, I was able to learn about the classification of codes and the conditions for optimal codes. I felt that this way of thinking could be applied to other things by understanding the fundamentals of each.""","""I'm curious as to why you use logarithms, so I'm looking forward to the next class.""",,"""It was interesting to organize in my head what I had only vaguely known about codes.""",-2
C-2021-2_U94,"""After learning about the types of symbols, I learned how to decide which symbol is best. I concluded that it is best to look for the shortest symbol among prefixes.""","""Today, I was able to learn about the classification of codes and the conditions for optimal codes. I felt that this way of thinking could be applied to other things by understanding the fundamentals of each.""","""I'm curious as to why you use logarithms, so I'm looking forward to the next class.""",,"""It was interesting to organize in my head what I had only vaguely known about codes.""",-2
C-2021-2_U94,"""After learning about the types of symbols, I learned how to decide which symbol is best. I concluded that it is best to look for the shortest symbol among prefixes.""","""Today, I was able to learn about the classification of codes and the conditions for optimal codes. I felt that this way of thinking could be applied to other things by understanding the fundamentals of each.""","""I'm curious as to why you use logarithms, so I'm looking forward to the next class.""",,"""It was interesting to organize in my head what I had only vaguely known about codes.""",-2
C-2021-2_U95,"""It was about how to convey information quickly and accurately when conveying information. It is important to convey information quickly, but when restoring, it is important not to use multiple restoration methods. At this time, the prefix is ​​important. You have to be careful with words, and you need to be creative with suffixes in order to decipher the content more quickly.""","""Use fewer words to express more frequently used items.
""","""Calculating Entropy""",,"""It was really nice to be able to check it immediately by sharing the screen even if it wasn't loading in time.""",-3
C-2021-2_U95,"""It was about how to convey information quickly and accurately when conveying information. It is important to convey information quickly, but when restoring, it is important not to use multiple restoration methods. At this time, the prefix is ​​important. You have to be careful with words, and you need to be creative with suffixes in order to decipher the content more quickly.""","""Use fewer words to express more frequently used items.
""","""Calculating Entropy""",,"""It was really nice to be able to check it immediately by sharing the screen even if it wasn't loading in time.""",-3
C-2021-2_U95,"""It was about how to convey information quickly and accurately when conveying information. It is important to convey information quickly, but when restoring, it is important not to use multiple restoration methods. At this time, the prefix is ​​important. You have to be careful with words, and you need to be creative with suffixes in order to decipher the content more quickly.""","""Use fewer words to express more frequently used items.
""","""Calculating Entropy""",,"""It was really nice to be able to check it immediately by sharing the screen even if it wasn't loading in time.""",-3
C-2021-2_U95,"""It was about how to convey information quickly and accurately when conveying information. It is important to convey information quickly, but when restoring, it is important not to use multiple restoration methods. At this time, the prefix is ​​important. You have to be careful with words, and you need to be creative with suffixes in order to decipher the content more quickly.""","""Use fewer words to express more frequently used items.
""","""Calculating Entropy""",,"""It was really nice to be able to check it immediately by sharing the screen even if it wasn't loading in time.""",-3
C-2021-2_U96,"""Binary representation of information, encoding of information and its shortness, entropy, etc.""","""I was able to understand that it is necessary to consider code combinations in order to reduce the amount of information.""",,,,-3
C-2021-2_U96,"""Binary representation of information, encoding of information and its shortness, entropy, etc.""","""I was able to understand that it is necessary to consider code combinations in order to reduce the amount of information.""",,,,-3
C-2021-2_U97,"""・About source coding ・About unique compound symbols and initial codes ・About average codeword length""",,"""I don't quite understand the definition of prefixes.""",,"""I had heard the word ""entropy"" in high school physics, but I never thought I would hear it in an information science class. """,-3
C-2021-2_U97,"""・About source coding ・About unique compound symbols and initial codes ・About average codeword length""",,"""I don't quite understand the definition of prefixes.""",,"""I had heard the word ""entropy"" in high school physics, but I never thought I would hear it in an information science class. """,-3
C-2021-2_U97,"""・About source coding ・About unique compound symbols and initial codes ・About average codeword length""",,"""I don't quite understand the definition of prefixes.""",,"""I had heard the word ""entropy"" in high school physics, but I never thought I would hear it in an information science class. """,-3
C-2021-2_U99,"""Representing a sequence of symbols generated from an information source with a sequence of ● and 〇 is called encoding, and various encoding methods are conceivable. And codes that can be decoded quickly are limited. Examples of codes that make this possible are prefix codes.""","""I learned how to actually convert information into a sequence of two types of code, and what conditions the code must satisfy to be considered appropriate coding: average codeword length, instantaneous decodability, and unique decoding. It turns out that there is a prefix that can consider all possibilities.""","""I didn't quite understand the entropy story in the second half. I knew that the lower bound of the average codeword length was entropy, but I didn't understand why the entropy could be derived from that formula.""",,"""Considering that we know the specific method of converting the information source into only two types of code strings, and that all the vast amount of information that currently exists on the Internet is encoded in this way, it is very impressive. I thought it was a deep technology.""",-3
C-2021-2_U99,"""Representing a sequence of symbols generated from an information source with a sequence of ● and 〇 is called encoding, and various encoding methods are conceivable. And codes that can be decoded quickly are limited. Examples of codes that make this possible are prefix codes.""","""I learned how to actually convert information into a sequence of two types of code, and what conditions the code must satisfy to be considered appropriate coding: average codeword length, instantaneous decodability, and unique decoding. It turns out that there is a prefix that can consider all possibilities.""","""I didn't quite understand the entropy story in the second half. I knew that the lower bound of the average codeword length was entropy, but I didn't understand why the entropy could be derived from that formula.""",,"""Considering that we know the specific method of converting the information source into only two types of code strings, and that all the vast amount of information that currently exists on the Internet is encoded in this way, it is very impressive. I thought it was a deep technology.""",-3
C-2021-2_U99,"""Representing a sequence of symbols generated from an information source with a sequence of ● and 〇 is called encoding, and various encoding methods are conceivable. And codes that can be decoded quickly are limited. Examples of codes that make this possible are prefix codes.""","""I learned how to actually convert information into a sequence of two types of code, and what conditions the code must satisfy to be considered appropriate coding: average codeword length, instantaneous decodability, and unique decoding. It turns out that there is a prefix that can consider all possibilities.""","""I didn't quite understand the entropy story in the second half. I knew that the lower bound of the average codeword length was entropy, but I didn't understand why the entropy could be derived from that formula.""",,"""Considering that we know the specific method of converting the information source into only two types of code strings, and that all the vast amount of information that currently exists on the Internet is encoded in this way, it is very impressive. I thought it was a deep technology.""",-3
C-2021-2_U99,"""Representing a sequence of symbols generated from an information source with a sequence of ● and 〇 is called encoding, and various encoding methods are conceivable. And codes that can be decoded quickly are limited. Examples of codes that make this possible are prefix codes.""","""I learned how to actually convert information into a sequence of two types of code, and what conditions the code must satisfy to be considered appropriate coding: average codeword length, instantaneous decodability, and unique decoding. It turns out that there is a prefix that can consider all possibilities.""","""I didn't quite understand the entropy story in the second half. I knew that the lower bound of the average codeword length was entropy, but I didn't understand why the entropy could be derived from that formula.""",,"""Considering that we know the specific method of converting the information source into only two types of code strings, and that all the vast amount of information that currently exists on the Internet is encoded in this way, it is very impressive. I thought it was a deep technology.""",-3
C-2022-1_U10,,"""I thought I understood the word ""quantity of information"", but for the first time I learned that it is something that is calculated and sought.
In order to shorten the symbol string, it is good to consider the occurrence probability.
An example of entropy calculation was completed. """,,,,-3
C-2022-1_U11,"""A source is something that outputs symbols at regular time intervals, and the symbols are encoded by the source encoding and converted back to the original symbols by the source decoder. During the source encoding, there are as few symbols as possible. Since the symbol is represented by a code, a symbol with a short average codeword length is selected, but at this time, it is necessary to consider whether it is uniquely decodable and instantaneously decodable. A word must also satisfy the initial condition that it must not be a prefix of another codeword.""",,,,"""The codeword for information source coding was interesting. In the class example, there are four types of weather forecast symbols, so we were able to create a codeword that is uniquely decodable and satisfies the initial conditions. The information isn't that simple, so I was wondering how the codewords were created.""",-3
C-2022-1_U11,"""A source is something that outputs symbols at regular time intervals, and the symbols are encoded by the source encoding and converted back to the original symbols by the source decoder. During the source encoding, there are as few symbols as possible. Since the symbol is represented by a code, a symbol with a short average codeword length is selected, but at this time, it is necessary to consider whether it is uniquely decodable and instantaneously decodable. A word must also satisfy the initial condition that it must not be a prefix of another codeword.""",,,,"""The codeword for information source coding was interesting. In the class example, there are four types of weather forecast symbols, so we were able to create a codeword that is uniquely decodable and satisfies the initial conditions. The information isn't that simple, so I was wondering how the codewords were created.""",-3
C-2022-1_U12,"""When decoding information, make sure that unique decoding, instantaneous decoding, and average codeword length are the best.
The average codeword length is calculated using log as the expected value and the amount of information is log. ""","""For the first time, I properly understood the amount of information.
You have completed the calculations you learned today. """,,,"""Although it was a simple one, calculations were included, so I felt that I had finally entered the university's computer science, unlike the information I had in high school.""",-3
C-2022-1_U12,"""When decoding information, make sure that unique decoding, instantaneous decoding, and average codeword length are the best.
The average codeword length is calculated using log as the expected value and the amount of information is log. ""","""For the first time, I properly understood the amount of information.
You have completed the calculations you learned today. """,,,"""Although it was a simple one, calculations were included, so I felt that I had finally entered the university's computer science, unlike the information I had in high school.""",-3
C-2022-1_U12,"""When decoding information, make sure that unique decoding, instantaneous decoding, and average codeword length are the best.
The average codeword length is calculated using log as the expected value and the amount of information is log. ""","""For the first time, I properly understood the amount of information.
You have completed the calculations you learned today. """,,,"""Although it was a simple one, calculations were included, so I felt that I had finally entered the university's computer science, unlike the information I had in high school.""",-3
C-2022-1_U13,"""The points to be evaluated in encoding are unique combination possibility, instantaneous combination possibility, and short average codeword length.
Entropy is the shortest codeword length and cannot be expressed shorter than entropy.
The average word length of the optimal code must be between entropy and entropy+1. ""","""Calculate the length and entropy of the average codeword length.
The initial code is uniquely compoundable because there is no other code that starts with the same code.
""",,,,-3
C-2022-1_U13,"""The points to be evaluated in encoding are unique combination possibility, instantaneous combination possibility, and short average codeword length.
Entropy is the shortest codeword length and cannot be expressed shorter than entropy.
The average word length of the optimal code must be between entropy and entropy+1. ""","""Calculate the length and entropy of the average codeword length.
The initial code is uniquely compoundable because there is no other code that starts with the same code.
""",,,,-3
C-2022-1_U14,,"""We found that by changing the combination and order of black and white codewords, we could reduce the number of balls and receive information more quickly and accurately.
It was found that the code word can be uniquely and instantaneously restored, and that the shorter the code word, the better the code. ""","""Why did you decide to take log with entropy?""",,"""It was easy to understand because there were familiar examples such as housewives who like rock-paper-scissors on Sundays and itogon. I was surprised to learn that so many ideas were put into place so that we could receive information quickly. .""",-3
C-2022-1_U14,,"""We found that by changing the combination and order of black and white codewords, we could reduce the number of balls and receive information more quickly and accurately.
It was found that the code word can be uniquely and instantaneously restored, and that the shorter the code word, the better the code. ""","""Why did you decide to take log with entropy?""",,"""It was easy to understand because there were familiar examples such as housewives who like rock-paper-scissors on Sundays and itogon. I was surprised to learn that so many ideas were put into place so that we could receive information quickly. .""",-3
C-2022-1_U14,,"""We found that by changing the combination and order of black and white codewords, we could reduce the number of balls and receive information more quickly and accurately.
It was found that the code word can be uniquely and instantaneously restored, and that the shorter the code word, the better the code. ""","""Why did you decide to take log with entropy?""",,"""It was easy to understand because there were familiar examples such as housewives who like rock-paper-scissors on Sundays and itogon. I was surprised to learn that so many ideas were put into place so that we could receive information quickly. .""",-3
C-2022-1_U15,"An information source is a source that outputs symbols at regular time intervals, and the probability of occurrence of the symbols is constant. When encoding or decoding information sources, it is necessary to consider the probability of occurrence of symbols in order to reduce the amount of information. The average codeword length is called the average codeword length, and the average codeword length should be as short as possible. Both include prefixes where it is a necessary condition to have the possibility, and prefixes that include the prefix condition that any prefix does not match any other symbol. Here, the average codeword length has a lower chord, which is called entropy. The optimal code is the initial code for any source with the smallest average codeword length, and the average codeword length of the optimal code is greater than or equal to its entropy. will fall within a range less than the entropy plus 1.""",,"""I didn't understand why entropy is a lower bound on the average codeword length in that formula.""",,"""I had to clarify the parts I didn't know in advance and focus on studying them.
""",-3
C-2022-1_U15,"An information source is a source that outputs symbols at regular time intervals, and the probability of occurrence of the symbols is constant. When encoding or decoding information sources, it is necessary to consider the probability of occurrence of symbols in order to reduce the amount of information. The average codeword length is called the average codeword length, and the average codeword length should be as short as possible. Both include prefixes where it is a necessary condition to have the possibility, and prefixes that include the prefix condition that any prefix does not match any other symbol. Here, the average codeword length has a lower chord, which is called entropy. The optimal code is the initial code for any source with the smallest average codeword length, and the average codeword length of the optimal code is greater than or equal to its entropy. will fall within a range less than the entropy plus 1.""",,"""I didn't understand why entropy is a lower bound on the average codeword length in that formula.""",,"""I had to clarify the parts I didn't know in advance and focus on studying them.
""",-3
C-2022-1_U15,"An information source is a source that outputs symbols at regular time intervals, and the probability of occurrence of the symbols is constant. When encoding or decoding information sources, it is necessary to consider the probability of occurrence of symbols in order to reduce the amount of information. The average codeword length is called the average codeword length, and the average codeword length should be as short as possible. Both include prefixes where it is a necessary condition to have the possibility, and prefixes that include the prefix condition that any prefix does not match any other symbol. Here, the average codeword length has a lower chord, which is called entropy. The optimal code is the initial code for any source with the smallest average codeword length, and the average codeword length of the optimal code is greater than or equal to its entropy. will fall within a range less than the entropy plus 1.""",,"""I didn't understand why entropy is a lower bound on the average codeword length in that formula.""",,"""I had to clarify the parts I didn't know in advance and focus on studying them.
""",-3
C-2022-1_U16,"""There are many possible ways to arrange the white and black balls that convey information, but it is important to be able to combine them uniquely and instantaneously. Also, the disadvantage of using word prefixes is that the code becomes long. However, since there is a theorem that there is always a wrong answer code of the same word length for things that can be uniquely compounded, it is thought that there will be no inconvenience caused by making it a wrong answer code.""","""Until now, I didn't understand how binary numbers are combined, but today's lecture helped me understand a little. Also, I often see a message on the computer screen telling me to compress data. I couldn't figure out how to do it, but I found out that the method is to change the corresponding sign according to the probability.""",,"""Can two or more optimal codes exist in the range H(S)≤L(C)≤H(S)+1?""","""I had a vague image of the words 'source of information' and 'quantity of information', but I learned that there are solid definitions and mathematical formulas. From now on, I will study the words I know while thinking about their definitions and their meanings on the spot."" I want to.""",-3
C-2022-1_U16,"""There are many possible ways to arrange the white and black balls that convey information, but it is important to be able to combine them uniquely and instantaneously. Also, the disadvantage of using word prefixes is that the code becomes long. However, since there is a theorem that there is always a wrong answer code of the same word length for things that can be uniquely compounded, it is thought that there will be no inconvenience caused by making it a wrong answer code.""","""Until now, I didn't understand how binary numbers are combined, but today's lecture helped me understand a little. Also, I often see a message on the computer screen telling me to compress data. I couldn't figure out how to do it, but I found out that the method is to change the corresponding sign according to the probability.""",,"""Can two or more optimal codes exist in the range H(S)≤L(C)≤H(S)+1?""","""I had a vague image of the words 'source of information' and 'quantity of information', but I learned that there are solid definitions and mathematical formulas. From now on, I will study the words I know while thinking about their definitions and their meanings on the spot."" I want to.""",-3
C-2022-1_U16,"""There are many possible ways to arrange the white and black balls that convey information, but it is important to be able to combine them uniquely and instantaneously. Also, the disadvantage of using word prefixes is that the code becomes long. However, since there is a theorem that there is always a wrong answer code of the same word length for things that can be uniquely compounded, it is thought that there will be no inconvenience caused by making it a wrong answer code.""","""Until now, I didn't understand how binary numbers are combined, but today's lecture helped me understand a little. Also, I often see a message on the computer screen telling me to compress data. I couldn't figure out how to do it, but I found out that the method is to change the corresponding sign according to the probability.""",,"""Can two or more optimal codes exist in the range H(S)≤L(C)≤H(S)+1?""","""I had a vague image of the words 'source of information' and 'quantity of information', but I learned that there are solid definitions and mathematical formulas. From now on, I will study the words I know while thinking about their definitions and their meanings on the spot."" I want to.""",-3
C-2022-1_U16,"""There are many possible ways to arrange the white and black balls that convey information, but it is important to be able to combine them uniquely and instantaneously. Also, the disadvantage of using word prefixes is that the code becomes long. However, since there is a theorem that there is always a wrong answer code of the same word length for things that can be uniquely compounded, it is thought that there will be no inconvenience caused by making it a wrong answer code.""","""Until now, I didn't understand how binary numbers are combined, but today's lecture helped me understand a little. Also, I often see a message on the computer screen telling me to compress data. I couldn't figure out how to do it, but I found out that the method is to change the corresponding sign according to the probability.""",,"""Can two or more optimal codes exist in the range H(S)≤L(C)≤H(S)+1?""","""I had a vague image of the words 'source of information' and 'quantity of information', but I learned that there are solid definitions and mathematical formulas. From now on, I will study the words I know while thinking about their definitions and their meanings on the spot."" I want to.""",-3
C-2022-1_U17,"""What is a source? An explanation of the importance of source coding and how to calculate the lowest average code length.""",,,,"""I thought the word 'source' meant something else. I was able to learn more about source encoding and understand everything. It was a learning experience.""",-3
C-2022-1_U17,"""What is a source? An explanation of the importance of source coding and how to calculate the lowest average code length.""",,,,"""I thought the word 'source' meant something else. I was able to learn more about source encoding and understand everything. It was a learning experience.""",-3
C-2022-1_U19,"""When representing information sources with codes, it is important to be able to return them to uniqueness and to be able to return them quickly. Methods and conditions for evaluating which code is optimal.""","""When communicating information, I learned that it is possible to express information more quickly by examining whether the code is desirable, rather than just assigning codes to symbols. .""",,,,-3
C-2022-1_U19,"""When representing information sources with codes, it is important to be able to return them to uniqueness and to be able to return them quickly. Methods and conditions for evaluating which code is optimal.""","""When communicating information, I learned that it is possible to express information more quickly by examining whether the code is desirable, rather than just assigning codes to symbols. .""",,,,-3
C-2022-1_U20,"""How to use symbols that are more convenient and can be transmitted quickly. In this case, it is important not only to be fast, but also to be able to read instantly without being mistaken for other readings, and to be as short as possible. That is why we use prefixes. ""","""Basic rules that are also used in actual communication technology. I also learned how to read simple codes and the definition of how to create shorter codes.""",,,,-3
C-2022-1_U20,"""How to use symbols that are more convenient and can be transmitted quickly. In this case, it is important not only to be fast, but also to be able to read instantly without being mistaken for other readings, and to be as short as possible. That is why we use prefixes. ""","""Basic rules that are also used in actual communication technology. I also learned how to read simple codes and the definition of how to create shorter codes.""",,,,-3
C-2022-1_U21,,,"""I was a little confused about deciphering the initial code and its code tree, but after listening to the lecture, I was able to understand it.""",,"""I was perplexed when I saw new words such as uniquely compoundable codes and prefixes.
I'm glad I was able to do the entropy calculation myself.
I want to remember the words and theorems I learned today. """,-2
C-2022-1_U21,,,"""I was a little confused about deciphering the initial code and its code tree, but after listening to the lecture, I was able to understand it.""",,"""I was perplexed when I saw new words such as uniquely compoundable codes and prefixes.
I'm glad I was able to do the entropy calculation myself.
I want to remember the words and theorems I learned today. """,-2
C-2022-1_U22,"""We found that there are many methods of source encoding, and we are trying to use the best one among them.""","""I understood unique decodability and instantaneous decodability. I learned that the average codeword length has a lower bound and is expressed by a mathematical formula.""","""I couldn't keep up with the optimal code, so I want to review properly.""",,"""I thought I knew the word 'source of information', but it was completely different from what I thought, so I was a little surprised. I want to remember the words that came.""",-3
C-2022-1_U22,"""We found that there are many methods of source encoding, and we are trying to use the best one among them.""","""I understood unique decodability and instantaneous decodability. I learned that the average codeword length has a lower bound and is expressed by a mathematical formula.""","""I couldn't keep up with the optimal code, so I want to review properly.""",,"""I thought I knew the word 'source of information', but it was completely different from what I thought, so I was a little surprised. I want to remember the words that came.""",-3
C-2022-1_U22,"""We found that there are many methods of source encoding, and we are trying to use the best one among them.""","""I understood unique decodability and instantaneous decodability. I learned that the average codeword length has a lower bound and is expressed by a mathematical formula.""","""I couldn't keep up with the optimal code, so I want to review properly.""",,"""I thought I knew the word 'source of information', but it was completely different from what I thought, so I was a little surprised. I want to remember the words that came.""",-3
C-2022-1_U22,"""We found that there are many methods of source encoding, and we are trying to use the best one among them.""","""I understood unique decodability and instantaneous decodability. I learned that the average codeword length has a lower bound and is expressed by a mathematical formula.""","""I couldn't keep up with the optimal code, so I want to review properly.""",,"""I thought I knew the word 'source of information', but it was completely different from what I thought, so I was a little surprised. I want to remember the words that came.""",-3
C-2022-1_U24,"""I mainly learned about encoding and decoding of information sources, and the purpose of encoding. When exchanging data, the larger the data, the more time it takes to process it, so I decided to encode (shorten) the information source. I agree.""","""In order to encode the information source, it is necessary to be unique and to be able to quickly return to the original, and it was also found that when encoding, it is represented by ○ and ●. If there is something that acts as a codeword delimiter, it is possible to decode uniquely, but I found that it is impossible if there are two or more ways to decompose, and I am convinced. The code is also called an instantaneously decodable code, and we also found that it can be decoded without looking ahead once the codeword has been read.""","""I don't have anything in particular, but if you plan to prepare for class on the weekend, it will be impossible to prepare for class if the schedule suddenly becomes available, so I think I'll try to prepare for class during the free time on weekdays.""",,,-3
C-2022-1_U24,"""I mainly learned about encoding and decoding of information sources, and the purpose of encoding. When exchanging data, the larger the data, the more time it takes to process it, so I decided to encode (shorten) the information source. I agree.""","""In order to encode the information source, it is necessary to be unique and to be able to quickly return to the original, and it was also found that when encoding, it is represented by ○ and ●. If there is something that acts as a codeword delimiter, it is possible to decode uniquely, but I found that it is impossible if there are two or more ways to decompose, and I am convinced. The code is also called an instantaneously decodable code, and we also found that it can be decoded without looking ahead once the codeword has been read.""","""I don't have anything in particular, but if you plan to prepare for class on the weekend, it will be impossible to prepare for class if the schedule suddenly becomes available, so I think I'll try to prepare for class during the free time on weekdays.""",,,-3
C-2022-1_U24,"""I mainly learned about encoding and decoding of information sources, and the purpose of encoding. When exchanging data, the larger the data, the more time it takes to process it, so I decided to encode (shorten) the information source. I agree.""","""In order to encode the information source, it is necessary to be unique and to be able to quickly return to the original, and it was also found that when encoding, it is represented by ○ and ●. If there is something that acts as a codeword delimiter, it is possible to decode uniquely, but I found that it is impossible if there are two or more ways to decompose, and I am convinced. The code is also called an instantaneously decodable code, and we also found that it can be decoded without looking ahead once the codeword has been read.""","""I don't have anything in particular, but if you plan to prepare for class on the weekend, it will be impossible to prepare for class if the schedule suddenly becomes available, so I think I'll try to prepare for class during the free time on weekdays.""",,,-3
C-2022-1_U25,"""An information source is a source that outputs symbols at regular time intervals. Not outputting any symbols is also a symbol. The probability of occurrence of each symbol is assumed to be fixed.
A stationary memoryless information source is an information source in which the occurrence probability of a symbol string is the same from any time point, and the occurrence probability at an arbitrary time point does not depend on symbols before and after it.
Information source coding means that a string of symbols generated from an information source is represented by a sequence of ◯ and ● by an information source encoder. Compositing means converting the ●○ string obtained by combining into the original symbol string.
In order to shorten the average word length, short codewords are assigned to symbols that are likely to appear, and long codewords are assigned to symbols that are difficult to appear.
Information source coding aims at designing a code with the shortest possible average codeword length according to the probability distribution of symbols, and the condition is that it can be restored uniquely and quickly.
Unique combination possibility means that there is only one way to decompose a bit string into codewords.
Instantaneous combination possibility means that symbols can be combined without look-ahead when the codeword has been read.
A prefix condition is that no codeword is a prefix of another codeword. A code that satisfies the prefix condition is called a prefix code.
Prefixes are uniquely combinable and instantaneously combinable. A prefix code is also called an instantaneously combinable code.
For any uniquely combinable code C, there exists a prefix C' with the same codeword length.
For an information source S, the entropy H(S) of S is determined as follows. H(S) = sum of p(-log2p)
Let S be an arbitrary source. The average codeword length L(C) of any uniquely combinable code C for S satisfies the following inequality. H(S)≤L(C)
Entropy is a lower bound on the average codeword length.
The optimum code for S is the prefix code C for S that has the smallest average codeword length L(C).
The information source coding theorem states that the average codeword length L(C*) of the optimal code C* of S satisfies the following inequality. H(S) ≤ L(C*) < H(S) + 1""","""average codeword length = sum of (codeword length x probability)
A prefix code has a symbol only at the end of a path when a code tree of prefix codes is created.
The amount of information is -log2p. """,,,"""I found it interesting that it is necessary to consider the probability of occurrence, unique combination possibility, instantaneous combination possibility, etc. so that the number of bits is minimized when encoding a symbol string into ○ and ●.""",-3
C-2022-1_U25,"""An information source is a source that outputs symbols at regular time intervals. Not outputting any symbols is also a symbol. The probability of occurrence of each symbol is assumed to be fixed.
A stationary memoryless information source is an information source in which the occurrence probability of a symbol string is the same from any time point, and the occurrence probability at an arbitrary time point does not depend on symbols before and after it.
Information source coding means that a string of symbols generated from an information source is represented by a sequence of ◯ and ● by an information source encoder. Compositing means converting the ●○ string obtained by combining into the original symbol string.
In order to shorten the average word length, short codewords are assigned to symbols that are likely to appear, and long codewords are assigned to symbols that are difficult to appear.
Information source coding aims at designing a code with the shortest possible average codeword length according to the probability distribution of symbols, and the condition is that it can be restored uniquely and quickly.
Unique combination possibility means that there is only one way to decompose a bit string into codewords.
Instantaneous combination possibility means that symbols can be combined without look-ahead when the codeword has been read.
A prefix condition is that no codeword is a prefix of another codeword. A code that satisfies the prefix condition is called a prefix code.
Prefixes are uniquely combinable and instantaneously combinable. A prefix code is also called an instantaneously combinable code.
For any uniquely combinable code C, there exists a prefix C' with the same codeword length.
For an information source S, the entropy H(S) of S is determined as follows. H(S) = sum of p(-log2p)
Let S be an arbitrary source. The average codeword length L(C) of any uniquely combinable code C for S satisfies the following inequality. H(S)≤L(C)
Entropy is a lower bound on the average codeword length.
The optimum code for S is the prefix code C for S that has the smallest average codeword length L(C).
The information source coding theorem states that the average codeword length L(C*) of the optimal code C* of S satisfies the following inequality. H(S) ≤ L(C*) < H(S) + 1""","""average codeword length = sum of (codeword length x probability)
A prefix code has a symbol only at the end of a path when a code tree of prefix codes is created.
The amount of information is -log2p. """,,,"""I found it interesting that it is necessary to consider the probability of occurrence, unique combination possibility, instantaneous combination possibility, etc. so that the number of bits is minimized when encoding a symbol string into ○ and ●.""",-3
C-2022-1_U25,"""An information source is a source that outputs symbols at regular time intervals. Not outputting any symbols is also a symbol. The probability of occurrence of each symbol is assumed to be fixed.
A stationary memoryless information source is an information source in which the occurrence probability of a symbol string is the same from any time point, and the occurrence probability at an arbitrary time point does not depend on symbols before and after it.
Information source coding means that a string of symbols generated from an information source is represented by a sequence of ◯ and ● by an information source encoder. Compositing means converting the ●○ string obtained by combining into the original symbol string.
In order to shorten the average word length, short codewords are assigned to symbols that are likely to appear, and long codewords are assigned to symbols that are difficult to appear.
Information source coding aims at designing a code with the shortest possible average codeword length according to the probability distribution of symbols, and the condition is that it can be restored uniquely and quickly.
Unique combination possibility means that there is only one way to decompose a bit string into codewords.
Instantaneous combination possibility means that symbols can be combined without look-ahead when the codeword has been read.
A prefix condition is that no codeword is a prefix of another codeword. A code that satisfies the prefix condition is called a prefix code.
Prefixes are uniquely combinable and instantaneously combinable. A prefix code is also called an instantaneously combinable code.
For any uniquely combinable code C, there exists a prefix C' with the same codeword length.
For an information source S, the entropy H(S) of S is determined as follows. H(S) = sum of p(-log2p)
Let S be an arbitrary source. The average codeword length L(C) of any uniquely combinable code C for S satisfies the following inequality. H(S)≤L(C)
Entropy is a lower bound on the average codeword length.
The optimum code for S is the prefix code C for S that has the smallest average codeword length L(C).
The information source coding theorem states that the average codeword length L(C*) of the optimal code C* of S satisfies the following inequality. H(S) ≤ L(C*) < H(S) + 1""","""average codeword length = sum of (codeword length x probability)
A prefix code has a symbol only at the end of a path when a code tree of prefix codes is created.
The amount of information is -log2p. """,,,"""I found it interesting that it is necessary to consider the probability of occurrence, unique combination possibility, instantaneous combination possibility, etc. so that the number of bits is minimized when encoding a symbol string into ○ and ●.""",-3
C-2022-1_U26,"""In order to uniquely recover the symbol emitted from the information source, the codeword should not be the same as the beginning of other codewords.
To send a short symbol, the codeword with the highest probability should be the shortest.
""","""I learned that information transmitted from an information source cannot be communicated well unless it is not only encoded but also a symbol that can be instantly and uniquely decoded.""","""Entropy is not well understood yet, so I would like to take time to understand it while solving problems.""",,"""Signals are invisible and you can't experience them yourself, so it's interesting to learn how information is exchanged in the world.
I felt that it was difficult because there were various conditions in order not only to encode and decode, but also to process it accurately and quickly.""",-3
C-2022-1_U26,"""In order to uniquely recover the symbol emitted from the information source, the codeword should not be the same as the beginning of other codewords.
To send a short symbol, the codeword with the highest probability should be the shortest.
""","""I learned that information transmitted from an information source cannot be communicated well unless it is not only encoded but also a symbol that can be instantly and uniquely decoded.""","""Entropy is not well understood yet, so I would like to take time to understand it while solving problems.""",,"""Signals are invisible and you can't experience them yourself, so it's interesting to learn how information is exchanged in the world.
I felt that it was difficult because there were various conditions in order not only to encode and decode, but also to process it accurately and quickly.""",-3
C-2022-1_U26,"""In order to uniquely recover the symbol emitted from the information source, the codeword should not be the same as the beginning of other codewords.
To send a short symbol, the codeword with the highest probability should be the shortest.
""","""I learned that information transmitted from an information source cannot be communicated well unless it is not only encoded but also a symbol that can be instantly and uniquely decoded.""","""Entropy is not well understood yet, so I would like to take time to understand it while solving problems.""",,"""Signals are invisible and you can't experience them yourself, so it's interesting to learn how information is exchanged in the world.
I felt that it was difficult because there were various conditions in order not only to encode and decode, but also to process it accurately and quickly.""",-3
C-2022-1_U26,"""In order to uniquely recover the symbol emitted from the information source, the codeword should not be the same as the beginning of other codewords.
To send a short symbol, the codeword with the highest probability should be the shortest.
""","""I learned that information transmitted from an information source cannot be communicated well unless it is not only encoded but also a symbol that can be instantly and uniquely decoded.""","""Entropy is not well understood yet, so I would like to take time to understand it while solving problems.""",,"""Signals are invisible and you can't experience them yourself, so it's interesting to learn how information is exchanged in the world.
I felt that it was difficult because there were various conditions in order not only to encode and decode, but also to process it accurately and quickly.""",-3
C-2022-1_U27,"""Stationary information sources have the property that the probability of occurrence is the same regardless of the starting time point, and the property that the probability of occurrence does not depend on the symbols before and after it. A code that can be converted into a codeword in one way only is a code that can be converted into a codeword in one way, and a code that can be instantaneously combined is a code that can be converted into a codeword in order from the beginning without considering the previous code. A code that is both uniquely combinable and instantaneously combinable is a prefix code.""","""I learned about information sources, how to read prefixes, code trees, etc.""","""It was difficult to understand the relationship between prefixes and uniquely combinable codes.""",,,-3
C-2022-1_U27,"""Stationary information sources have the property that the probability of occurrence is the same regardless of the starting time point, and the property that the probability of occurrence does not depend on the symbols before and after it. A code that can be converted into a codeword in one way only is a code that can be converted into a codeword in one way, and a code that can be instantaneously combined is a code that can be converted into a codeword in order from the beginning without considering the previous code. A code that is both uniquely combinable and instantaneously combinable is a prefix code.""","""I learned about information sources, how to read prefixes, code trees, etc.""","""It was difficult to understand the relationship between prefixes and uniquely combinable codes.""",,,-3
C-2022-1_U27,"""Stationary information sources have the property that the probability of occurrence is the same regardless of the starting time point, and the property that the probability of occurrence does not depend on the symbols before and after it. A code that can be converted into a codeword in one way only is a code that can be converted into a codeword in one way, and a code that can be instantaneously combined is a code that can be converted into a codeword in order from the beginning without considering the previous code. A code that is both uniquely combinable and instantaneously combinable is a prefix code.""","""I learned about information sources, how to read prefixes, code trees, etc.""","""It was difficult to understand the relationship between prefixes and uniquely combinable codes.""",,,-3
C-2022-1_U28,"""On Source Coding and Instantaneous Decodability of Initial Codes""","""A prefix code is called an instantaneously decodable code
How to calculate the average codeword length""",,,,-3
C-2022-1_U28,"""On Source Coding and Instantaneous Decodability of Initial Codes""","""A prefix code is called an instantaneously decodable code
How to calculate the average codeword length""",,,,-3
C-2022-1_U29,,"""I was able to correctly understand ""information sources"" and ""information volume"" in this class. Also, I think that I can now explain the position of the initial sign, which I could not understand at the time of preparation. ""","""I'm worried if I'm understanding correctly about ``What is the desired code?'' ""","""In (1), I skipped over what can be said from Theorem 1, but I'm not sure if this understanding is correct. If it's completely different or if the words are not enough, I'd appreciate it if you could let me know.""",,-3
C-2022-1_U29,,"""I was able to correctly understand ""information sources"" and ""information volume"" in this class. Also, I think that I can now explain the position of the initial sign, which I could not understand at the time of preparation. ""","""I'm worried if I'm understanding correctly about ``What is the desired code?'' ""","""In (1), I skipped over what can be said from Theorem 1, but I'm not sure if this understanding is correct. If it's completely different or if the words are not enough, I'd appreciate it if you could let me know.""",,-3
C-2022-1_U29,,"""I was able to correctly understand ""information sources"" and ""information volume"" in this class. Also, I think that I can now explain the position of the initial sign, which I could not understand at the time of preparation. ""","""I'm worried if I'm understanding correctly about ``What is the desired code?'' ""","""In (1), I skipped over what can be said from Theorem 1, but I'm not sure if this understanding is correct. If it's completely different or if the words are not enough, I'd appreciate it if you could let me know.""",,-3
C-2022-1_U3,"""In the encoding of stationary memoryless information sources, the probability of occurrence is taken into consideration in order to shorten the average codeword length. As a prerequisite, it is necessary to be able to decode uniquely and instantaneously. “Uniquely decodable” means that the division between codewords is known, that is, the same bit string can be decomposed into codewords in one way. In order to satisfy instantaneous decodability, it is necessary to be a prefix code. If there is, it can be decoded uniquely.The average codeword length does not increase due to the prefix code.Entropy is the lower limit of the average codeword length, and the average codeword length is entropy and entropy The prefix that is between the additions of 1 is the optimal code.""","""When encoding an information source, it is necessary to satisfy unique decodability and instantaneous decodability as prerequisites. In order to satisfy these conditions and to perform desirable encoding with a short average codeword length, it is necessary to use a prefix code. , it turns out that the key is to consider the range of the optimal average codeword length from the entropy.""","""I didn't understand why the optimal code wasn't always the entropy.""","""I want the average codeword length to be as short as possible, so why isn't entropy = optimal code?""",,-3
C-2022-1_U3,"""In the encoding of stationary memoryless information sources, the probability of occurrence is taken into consideration in order to shorten the average codeword length. As a prerequisite, it is necessary to be able to decode uniquely and instantaneously. “Uniquely decodable” means that the division between codewords is known, that is, the same bit string can be decomposed into codewords in one way. In order to satisfy instantaneous decodability, it is necessary to be a prefix code. If there is, it can be decoded uniquely.The average codeword length does not increase due to the prefix code.Entropy is the lower limit of the average codeword length, and the average codeword length is entropy and entropy The prefix that is between the additions of 1 is the optimal code.""","""When encoding an information source, it is necessary to satisfy unique decodability and instantaneous decodability as prerequisites. In order to satisfy these conditions and to perform desirable encoding with a short average codeword length, it is necessary to use a prefix code. , it turns out that the key is to consider the range of the optimal average codeword length from the entropy.""","""I didn't understand why the optimal code wasn't always the entropy.""","""I want the average codeword length to be as short as possible, so why isn't entropy = optimal code?""",,-3
C-2022-1_U3,"""In the encoding of stationary memoryless information sources, the probability of occurrence is taken into consideration in order to shorten the average codeword length. As a prerequisite, it is necessary to be able to decode uniquely and instantaneously. “Uniquely decodable” means that the division between codewords is known, that is, the same bit string can be decomposed into codewords in one way. In order to satisfy instantaneous decodability, it is necessary to be a prefix code. If there is, it can be decoded uniquely.The average codeword length does not increase due to the prefix code.Entropy is the lower limit of the average codeword length, and the average codeword length is entropy and entropy The prefix that is between the additions of 1 is the optimal code.""","""When encoding an information source, it is necessary to satisfy unique decodability and instantaneous decodability as prerequisites. In order to satisfy these conditions and to perform desirable encoding with a short average codeword length, it is necessary to use a prefix code. , it turns out that the key is to consider the range of the optimal average codeword length from the entropy.""","""I didn't understand why the optimal code wasn't always the entropy.""","""I want the average codeword length to be as short as possible, so why isn't entropy = optimal code?""",,-3
C-2022-1_U3,"""In the encoding of stationary memoryless information sources, the probability of occurrence is taken into consideration in order to shorten the average codeword length. As a prerequisite, it is necessary to be able to decode uniquely and instantaneously. “Uniquely decodable” means that the division between codewords is known, that is, the same bit string can be decomposed into codewords in one way. In order to satisfy instantaneous decodability, it is necessary to be a prefix code. If there is, it can be decoded uniquely.The average codeword length does not increase due to the prefix code.Entropy is the lower limit of the average codeword length, and the average codeword length is entropy and entropy The prefix that is between the additions of 1 is the optimal code.""","""When encoding an information source, it is necessary to satisfy unique decodability and instantaneous decodability as prerequisites. In order to satisfy these conditions and to perform desirable encoding with a short average codeword length, it is necessary to use a prefix code. , it turns out that the key is to consider the range of the optimal average codeword length from the entropy.""","""I didn't understand why the optimal code wasn't always the entropy.""","""I want the average codeword length to be as short as possible, so why isn't entropy = optimal code?""",,-3
C-2022-1_U30,,,,,"""It was a field that I was interested in in my high school information class, so it was very interesting. Even in the encoding of a small number of events, such as rock-paper-scissors in class, all of unique decodability, instantaneous decodability, and average code length are considered. As a result, the code string becomes quite long, so I thought that the code string would be considerably long even if the optimal code was used in the scene where the information source coding was actually used. I thought it would be easy to transmit and restore information because all phenomena are represented by the code of .I think that not all information is coded and transmitted, so it is an information source suitable for coding. I would also like to find out about sources of information that are not suitable.""",-3
C-2022-1_U32,"""Optimal encoding of information, explanation and content of terms for uniqueness, instantaneousness, length of code length to reduce the amount of information as much as possible
How to use LGC, BR-MAP""",,,,"""In order to simplify the information as much as possible, I was surprised that by calculating the average code length and calculating the entropy, some theorems could be used to optimize the informationization.""",-3
C-2022-1_U32,"""Optimal encoding of information, explanation and content of terms for uniqueness, instantaneousness, length of code length to reduce the amount of information as much as possible
How to use LGC, BR-MAP""",,,,"""In order to simplify the information as much as possible, I was surprised that by calculating the average code length and calculating the entropy, some theorems could be used to optimize the informationization.""",-3
C-2022-1_U33,"""About Sources and Decryption""",,,,"""I came to class because I didn't have enough preparation, so from next time onwards, I'd like to prepare properly.""",-3
C-2022-1_U33,"""About Sources and Decryption""",,,,"""I came to class because I didn't have enough preparation, so from next time onwards, I'd like to prepare properly.""",-3
C-2022-1_U34,,,"""I managed to understand up to the average sign of 5 trillion, but after that, log came out for entropy and so on, and I couldn't quite understand what they were trying to think.""",,"""I would like to reflect on the fact that my understanding level was a little low because I hadn't prepared for it.
I would like to put aside the parts I don't understand and keep up with the class, focusing on reviewing the exercises. """,-3
C-2022-1_U34,,,"""I managed to understand up to the average sign of 5 trillion, but after that, log came out for entropy and so on, and I couldn't quite understand what they were trying to think.""",,"""I would like to reflect on the fact that my understanding level was a little low because I hadn't prepared for it.
I would like to put aside the parts I don't understand and keep up with the class, focusing on reviewing the exercises. """,-3
C-2022-1_U35,,"""When the code length is the shortest, there is a way to uniquely determine the length of the encoding that is the same as the code length.
There is a limit to the shortest code length, and the range can be calculated.
""",,,"""I thought it would be interesting because I didn't think Log would come up in the information class. I think that knowledge such as mathematics will be necessary in the future, so I thought it would be interesting.
Since there are various ways of encoding, I thought that I would like to think about better encoding by myself.
""",-3
C-2022-1_U35,,"""When the code length is the shortest, there is a way to uniquely determine the length of the encoding that is the same as the code length.
There is a limit to the shortest code length, and the range can be calculated.
""",,,"""I thought it would be interesting because I didn't think Log would come up in the information class. I think that knowledge such as mathematics will be necessary in the future, so I thought it would be interesting.
Since there are various ways of encoding, I thought that I would like to think about better encoding by myself.
""",-3
C-2022-1_U36,,"""Roughly speaking, I thought that a fixed amount of information was exchanged as long as the information was of the same type in terms of fixed-length coding, but in reality, the amount should be minimized based on the probability of occurrence. I learned that calculations were made to minimize the amount of information. I also learned that calculation methods for minimizing the amount of information had been established at the basic stage.""","""There's nothing in particular that I didn't understand, but I haven't learned how to calculate it yet, so I have to review it properly before coming next week.""",,"""Unlike the first lecture, which focused on explanations of concepts, calculations using logarithms also appeared, and I thought that I had to review and prepare properly before I could keep up. By learning the structure of information, the class deepened our understanding of how the Internet we use on a daily basis works, and it was a meaningful class.""",-3
C-2022-1_U36,,"""Roughly speaking, I thought that a fixed amount of information was exchanged as long as the information was of the same type in terms of fixed-length coding, but in reality, the amount should be minimized based on the probability of occurrence. I learned that calculations were made to minimize the amount of information. I also learned that calculation methods for minimizing the amount of information had been established at the basic stage.""","""There's nothing in particular that I didn't understand, but I haven't learned how to calculate it yet, so I have to review it properly before coming next week.""",,"""Unlike the first lecture, which focused on explanations of concepts, calculations using logarithms also appeared, and I thought that I had to review and prepare properly before I could keep up. By learning the structure of information, the class deepened our understanding of how the Internet we use on a daily basis works, and it was a meaningful class.""",-3
C-2022-1_U36,,"""Roughly speaking, I thought that a fixed amount of information was exchanged as long as the information was of the same type in terms of fixed-length coding, but in reality, the amount should be minimized based on the probability of occurrence. I learned that calculations were made to minimize the amount of information. I also learned that calculation methods for minimizing the amount of information had been established at the basic stage.""","""There's nothing in particular that I didn't understand, but I haven't learned how to calculate it yet, so I have to review it properly before coming next week.""",,"""Unlike the first lecture, which focused on explanations of concepts, calculations using logarithms also appeared, and I thought that I had to review and prepare properly before I could keep up. By learning the structure of information, the class deepened our understanding of how the Internet we use on a daily basis works, and it was a meaningful class.""",-3
C-2022-1_U37,"""When encoding sources, the more uniquely, quickly reversible, and shorter the average codeword length, the better.""",,,,,-3
C-2022-1_U38,"""When information is encoded, it should be easy to distinguish when it is decoded. Such codes are called uniquely decodable codes or instantaneously decodable codes. Initial codes have these properties. The code with the shortest average codeword length among the initial codes is called the optimal code.""",,"""The difference between uniquely decodable and instantaneously decodable""",,,-3
C-2022-1_U38,"""When information is encoded, it should be easy to distinguish when it is decoded. Such codes are called uniquely decodable codes or instantaneously decodable codes. Initial codes have these properties. The code with the shortest average codeword length among the initial codes is called the optimal code.""",,"""The difference between uniquely decodable and instantaneously decodable""",,,-3
C-2022-1_U39,,,,"""I read BookRoll's A-09-Information Volume and Entropy, but does entropy mean the sum of the ambiguity U(S) of each event? (I feel like I understand it somehow, but I don't understand it somehow .)""",,-3
C-2022-1_U4,"""Information source coding is a sequence of symbols output from an information source at regular intervals, represented by a sequence of ○ and ●. Information source codes include uniquely decodable codes that can be uniquely decoded to the original symbol string, There is a prefix code that satisfies the prefix condition that the code is not a prefix of another code, etc. The average codeword length is the sum of the product of the output probability of each symbol and the codeword length. The lower bound of the codeword length is equal to the entropy, and the optimal code is the one with the smallest average codeword length among the prefix codes for a given information source.
""","""I learned that the meaning of the information sources I've always thought about, which I often hear, is different from the meaning of the information sources I learned this time. I can now calculate the average codeword length and entropy.""",,,"""The explanation of encoding was very easy to understand with many examples and diagrams. The diagram of the detailed inclusion relationship of the source code was easy to understand, and it was useful for organizing the meaning of important words and phrases.""",-3
C-2022-1_U4,"""Information source coding is a sequence of symbols output from an information source at regular intervals, represented by a sequence of ○ and ●. Information source codes include uniquely decodable codes that can be uniquely decoded to the original symbol string, There is a prefix code that satisfies the prefix condition that the code is not a prefix of another code, etc. The average codeword length is the sum of the product of the output probability of each symbol and the codeword length. The lower bound of the codeword length is equal to the entropy, and the optimal code is the one with the smallest average codeword length among the prefix codes for a given information source.
""","""I learned that the meaning of the information sources I've always thought about, which I often hear, is different from the meaning of the information sources I learned this time. I can now calculate the average codeword length and entropy.""",,,"""The explanation of encoding was very easy to understand with many examples and diagrams. The diagram of the detailed inclusion relationship of the source code was easy to understand, and it was useful for organizing the meaning of important words and phrases.""",-3
C-2022-1_U4,"""Information source coding is a sequence of symbols output from an information source at regular intervals, represented by a sequence of ○ and ●. Information source codes include uniquely decodable codes that can be uniquely decoded to the original symbol string, There is a prefix code that satisfies the prefix condition that the code is not a prefix of another code, etc. The average codeword length is the sum of the product of the output probability of each symbol and the codeword length. The lower bound of the codeword length is equal to the entropy, and the optimal code is the one with the smallest average codeword length among the prefix codes for a given information source.
""","""I learned that the meaning of the information sources I've always thought about, which I often hear, is different from the meaning of the information sources I learned this time. I can now calculate the average codeword length and entropy.""",,,"""The explanation of encoding was very easy to understand with many examples and diagrams. The diagram of the detailed inclusion relationship of the source code was easy to understand, and it was useful for organizing the meaning of important words and phrases.""",-3
C-2022-1_U42,"""・What is an information source, and what is stationary and memoryless?
・What is source coding?
・What is unique and instantaneous composite possibility?
・What is the desirable sign?","""A source that outputs symbols at regular time intervals is called an information source.
Stationary means that the probability of occurrence is the same regardless of starting time, and memoryless means that the probability of occurrence does not depend on the symbols output before and after.
Source coding is the representation of a string of 0's and 1's generated from a source.
The unique combinability is the possibility that the output symbol string can be composed only in one way, and the instantaneous combinability is the possibility that it can be composed quickly.
It is desirable for the code to have both the above uniqueness and instantaneous combinability, and that the total number of bits be as small as possible.""",,"""・Regarding the coding of the weather, which was discussed in class, for example, during the rainy season, I think that the probability of rain and cloudiness is higher than that of clear weather, and in that case the codeword changes. mosquito
・Why do you use log when calculating entropy?""","""When encoding, I thought it would be good to just make it distinguishable from others, but I was very interested in having to think about uniqueness, instantaneous combinability, and the total number of bits.
Computers can only represent things with 0 and 1, but many things are represented with 0 and 1, such as the Japanese syllabary, the English alphabet from a to z, and other languages. I thought it was interesting to think about it.""",-3
C-2022-1_U42,"""・What is an information source, and what is stationary and memoryless?
・What is source coding?
・What is unique and instantaneous composite possibility?
・What is the desirable sign?","""A source that outputs symbols at regular time intervals is called an information source.
Stationary means that the probability of occurrence is the same regardless of starting time, and memoryless means that the probability of occurrence does not depend on the symbols output before and after.
Source coding is the representation of a string of 0's and 1's generated from a source.
The unique combinability is the possibility that the output symbol string can be composed only in one way, and the instantaneous combinability is the possibility that it can be composed quickly.
It is desirable for the code to have both the above uniqueness and instantaneous combinability, and that the total number of bits be as small as possible.""",,"""・Regarding the coding of the weather, which was discussed in class, for example, during the rainy season, I think that the probability of rain and cloudiness is higher than that of clear weather, and in that case the codeword changes. mosquito
・Why do you use log when calculating entropy?""","""When encoding, I thought it would be good to just make it distinguishable from others, but I was very interested in having to think about uniqueness, instantaneous combinability, and the total number of bits.
Computers can only represent things with 0 and 1, but many things are represented with 0 and 1, such as the Japanese syllabary, the English alphabet from a to z, and other languages. I thought it was interesting to think about it.""",-3
C-2022-1_U42,"""・What is an information source, and what is stationary and memoryless?
・What is source coding?
・What is unique and instantaneous composite possibility?
・What is the desirable sign?","""A source that outputs symbols at regular time intervals is called an information source.
Stationary means that the probability of occurrence is the same regardless of starting time, and memoryless means that the probability of occurrence does not depend on the symbols output before and after.
Source coding is the representation of a string of 0's and 1's generated from a source.
The unique combinability is the possibility that the output symbol string can be composed only in one way, and the instantaneous combinability is the possibility that it can be composed quickly.
It is desirable for the code to have both the above uniqueness and instantaneous combinability, and that the total number of bits be as small as possible.""",,"""・Regarding the coding of the weather, which was discussed in class, for example, during the rainy season, I think that the probability of rain and cloudiness is higher than that of clear weather, and in that case the codeword changes. mosquito
・Why do you use log when calculating entropy?""","""When encoding, I thought it would be good to just make it distinguishable from others, but I was very interested in having to think about uniqueness, instantaneous combinability, and the total number of bits.
Computers can only represent things with 0 and 1, but many things are represented with 0 and 1, such as the Japanese syllabary, the English alphabet from a to z, and other languages. I thought it was interesting to think about it.""",-3
C-2022-1_U42,"""・What is an information source, and what is stationary and memoryless?
・What is source coding?
・What is unique and instantaneous composite possibility?
・What is the desirable sign?","""A source that outputs symbols at regular time intervals is called an information source.
Stationary means that the probability of occurrence is the same regardless of starting time, and memoryless means that the probability of occurrence does not depend on the symbols output before and after.
Source coding is the representation of a string of 0's and 1's generated from a source.
The unique combinability is the possibility that the output symbol string can be composed only in one way, and the instantaneous combinability is the possibility that it can be composed quickly.
It is desirable for the code to have both the above uniqueness and instantaneous combinability, and that the total number of bits be as small as possible.""",,"""・Regarding the coding of the weather, which was discussed in class, for example, during the rainy season, I think that the probability of rain and cloudiness is higher than that of clear weather, and in that case the codeword changes. mosquito
・Why do you use log when calculating entropy?""","""When encoding, I thought it would be good to just make it distinguishable from others, but I was very interested in having to think about uniqueness, instantaneous combinability, and the total number of bits.
Computers can only represent things with 0 and 1, but many things are represented with 0 and 1, such as the Japanese syllabary, the English alphabet from a to z, and other languages. I thought it was interesting to think about it.""",-3
C-2022-1_U44,"""Information source coding is to express information in an array of ○ and ●. When coding, it is desirable to code as short and concise as possible in order to reduce the electrical burden. In addition, It is necessary to consider whether the code indicates something unique.For that reason, various mathematical knowledge and thinking are required in the information source.""",,"""Some of the theorems that appeared in the slides did not understand why they happened, so I would like to investigate the proofs and use them for learning.""",,"""It was very interesting because it was the first time for me to specifically learn how the log function and expected value concept, which I learned in high school mathematics IIB, is being used in real life. In the future, I will try to systematize my knowledge as much as possible. , I want to be able to use it.
""",-3
C-2022-1_U44,"""Information source coding is to express information in an array of ○ and ●. When coding, it is desirable to code as short and concise as possible in order to reduce the electrical burden. In addition, It is necessary to consider whether the code indicates something unique.For that reason, various mathematical knowledge and thinking are required in the information source.""",,"""Some of the theorems that appeared in the slides did not understand why they happened, so I would like to investigate the proofs and use them for learning.""",,"""It was very interesting because it was the first time for me to specifically learn how the log function and expected value concept, which I learned in high school mathematics IIB, is being used in real life. In the future, I will try to systematize my knowledge as much as possible. , I want to be able to use it.
""",-3
C-2022-1_U44,"""Information source coding is to express information in an array of ○ and ●. When coding, it is desirable to code as short and concise as possible in order to reduce the electrical burden. In addition, It is necessary to consider whether the code indicates something unique.For that reason, various mathematical knowledge and thinking are required in the information source.""",,"""Some of the theorems that appeared in the slides did not understand why they happened, so I would like to investigate the proofs and use them for learning.""",,"""It was very interesting because it was the first time for me to specifically learn how the log function and expected value concept, which I learned in high school mathematics IIB, is being used in real life. In the future, I will try to systematize my knowledge as much as possible. , I want to be able to use it.
""",-3
C-2022-1_U45,,,"""Nothing in particular.""","""Does the optimal code always exist between entropy and +1?""",,-3
C-2022-1_U45,,,"""Nothing in particular.""","""Does the optimal code always exist between entropy and +1?""",,-3
C-2022-1_U46,"""Desired code...1, Uniquely decodable: Uniquely decodable/2, Instantaneously decodable: Quickly decodable/3, Average codeword length: Express as short as possible
prefix...[initial condition] words where no codeword is a prefix of another codeword
Initial code can be instantly decoded/Uniquely decodable if it is initial code""","""I was able to understand how to find the average codeword length and the initial code that I didn't understand during the preparation.""",,"""Not yet.""","""I couldn't see the proofs of some theorems and properties in class, so I thought I'd check them out myself before I forget what I learned in class.""",-3
C-2022-1_U46,"""Desired code...1, Uniquely decodable: Uniquely decodable/2, Instantaneously decodable: Quickly decodable/3, Average codeword length: Express as short as possible
prefix...[initial condition] words where no codeword is a prefix of another codeword
Initial code can be instantly decoded/Uniquely decodable if it is initial code""","""I was able to understand how to find the average codeword length and the initial code that I didn't understand during the preparation.""",,"""Not yet.""","""I couldn't see the proofs of some theorems and properties in class, so I thought I'd check them out myself before I forget what I learned in class.""",-3
C-2022-1_U46,"""Desired code...1, Uniquely decodable: Uniquely decodable/2, Instantaneously decodable: Quickly decodable/3, Average codeword length: Express as short as possible
prefix...[initial condition] words where no codeword is a prefix of another codeword
Initial code can be instantly decoded/Uniquely decodable if it is initial code""","""I was able to understand how to find the average codeword length and the initial code that I didn't understand during the preparation.""",,"""Not yet.""","""I couldn't see the proofs of some theorems and properties in class, so I thought I'd check them out myself before I forget what I learned in class.""",-3
C-2022-1_U46,"""Desired code...1, Uniquely decodable: Uniquely decodable/2, Instantaneously decodable: Quickly decodable/3, Average codeword length: Express as short as possible
prefix...[initial condition] words where no codeword is a prefix of another codeword
Initial code can be instantly decoded/Uniquely decodable if it is initial code""","""I was able to understand how to find the average codeword length and the initial code that I didn't understand during the preparation.""",,"""Not yet.""","""I couldn't see the proofs of some theorems and properties in class, so I thought I'd check them out myself before I forget what I learned in class.""",-3
C-2022-1_U47,,,"""About LGC and BR-MAP""","""Nothing in particular.""","""I don't really understand how to use LGC and BR-MAP, so I'd like to review it well so that I can use it without problems when using it for assignments.""",-3
C-2022-1_U47,,,"""About LGC and BR-MAP""","""Nothing in particular.""","""I don't really understand how to use LGC and BR-MAP, so I'd like to review it well so that I can use it without problems when using it for assignments.""",-3
C-2022-1_U47,,,"""About LGC and BR-MAP""","""Nothing in particular.""","""I don't really understand how to use LGC and BR-MAP, so I'd like to review it well so that I can use it without problems when using it for assignments.""",-3
C-2022-1_U48,"""Today we mainly talked about codes. When sending information in codes, it is important to consider the probability of occurrence of each event and send it in the shortest possible code string. Decodability is a prerequisite, and this is called prefix code. It is desirable to satisfy these as much as possible.""",,,,,-3
C-2022-1_U49,"""Information can be easily represented by encoding, and by being aware of the average length of the code word tone and initial conditions, it is possible to reduce the waiting time required for the user to transfer information.
""","""In source coding, short codes are assigned to items that are likely to appear, and long codes are assigned to items that are difficult to appear. This should be done so that the average code word tone is as short as possible. The initial code should be unique. It satisfies the condition of ""quickly."" Also, the average codeword tone of the optimal code with the shortest average codeword tone is greater than entropy and less than entropy + 1.""","""is not""","""is not""","""It was easy to understand because you explained the invisible coding using formulas and diagrams.""",-3
C-2022-1_U49,"""Information can be easily represented by encoding, and by being aware of the average length of the code word tone and initial conditions, it is possible to reduce the waiting time required for the user to transfer information.
""","""In source coding, short codes are assigned to items that are likely to appear, and long codes are assigned to items that are difficult to appear. This should be done so that the average code word tone is as short as possible. The initial code should be unique. It satisfies the condition of ""quickly."" Also, the average codeword tone of the optimal code with the shortest average codeword tone is greater than entropy and less than entropy + 1.""","""is not""","""is not""","""It was easy to understand because you explained the invisible coding using formulas and diagrams.""",-3
C-2022-1_U49,"""Information can be easily represented by encoding, and by being aware of the average length of the code word tone and initial conditions, it is possible to reduce the waiting time required for the user to transfer information.
""","""In source coding, short codes are assigned to items that are likely to appear, and long codes are assigned to items that are difficult to appear. This should be done so that the average code word tone is as short as possible. The initial code should be unique. It satisfies the condition of ""quickly."" Also, the average codeword tone of the optimal code with the shortest average codeword tone is greater than entropy and less than entropy + 1.""","""is not""","""is not""","""It was easy to understand because you explained the invisible coding using formulas and diagrams.""",-3
C-2022-1_U49,"""Information can be easily represented by encoding, and by being aware of the average length of the code word tone and initial conditions, it is possible to reduce the waiting time required for the user to transfer information.
""","""In source coding, short codes are assigned to items that are likely to appear, and long codes are assigned to items that are difficult to appear. This should be done so that the average code word tone is as short as possible. The initial code should be unique. It satisfies the condition of ""quickly."" Also, the average codeword tone of the optimal code with the shortest average codeword tone is greater than entropy and less than entropy + 1.""","""is not""","""is not""","""It was easy to understand because you explained the invisible coding using formulas and diagrams.""",-3
C-2022-1_U49,"""Information can be easily represented by encoding, and by being aware of the average length of the code word tone and initial conditions, it is possible to reduce the waiting time required for the user to transfer information.
""","""In source coding, short codes are assigned to items that are likely to appear, and long codes are assigned to items that are difficult to appear. This should be done so that the average code word tone is as short as possible. The initial code should be unique. It satisfies the condition of ""quickly."" Also, the average codeword tone of the optimal code with the shortest average codeword tone is greater than entropy and less than entropy + 1.""","""is not""","""is not""","""It was easy to understand because you explained the invisible coding using formulas and diagrams.""",-3
C-2022-1_U5,"""Information difference in source coding and the most compact optimal code conceivable from it
Initial Conditions and Initial Signs""",,,,,-2
C-2022-1_U50,"""The code C1 can be represented by two binary digits, all four
Code C2 represents information with a black dot as an end mark.
Code C3 is even shorter (but due to probability of occurrence)
The purpose of source encoding is to be able to translate quickly and uniquely (some combinations are indeterminate or delay decoding).
prefix code = instantaneous decodable code
The ideal code is short and uniquely decipherable
Entropy is the lower bound of the average codeword length",,,,"""Wi-Fi was weak and intermittent, but I was surprised by the difference in information choices and accuracy that can be expressed with only 0 and 1.""",-3
C-2022-1_U50,"""The code C1 can be represented by two binary digits, all four
Code C2 represents information with a black dot as an end mark.
Code C3 is even shorter (but due to probability of occurrence)
The purpose of source encoding is to be able to translate quickly and uniquely (some combinations are indeterminate or delay decoding).
prefix code = instantaneous decodable code
The ideal code is short and uniquely decipherable
Entropy is the lower bound of the average codeword length",,,,"""Wi-Fi was weak and intermittent, but I was surprised by the difference in information choices and accuracy that can be expressed with only 0 and 1.""",-3
C-2022-1_U51,"""There are many ways to send ciphers""","""The amount sent increases or decreases depending on how the encryption is made.
""","""How to determine the code that sends the least amount""",,"""I was a little drowsy listening to it, so next time I want to listen with more concentration.""",-3
C-2022-1_U51,"""There are many ways to send ciphers""","""The amount sent increases or decreases depending on how the encryption is made.
""","""How to determine the code that sends the least amount""",,"""I was a little drowsy listening to it, so next time I want to listen with more concentration.""",-3
C-2022-1_U51,"""There are many ways to send ciphers""","""The amount sent increases or decreases depending on how the encryption is made.
""","""How to determine the code that sends the least amount""",,"""I was a little drowsy listening to it, so next time I want to listen with more concentration.""",-3
C-2022-1_U51,"""There are many ways to send ciphers""","""The amount sent increases or decreases depending on how the encryption is made.
""","""How to determine the code that sends the least amount""",,"""I was a little drowsy listening to it, so next time I want to listen with more concentration.""",-3
C-2022-1_U52,"""Information source: a source that outputs symbols at regular time intervals
→ stationary memoryless information source
　The occurrence probability of the symbol string is the same regardless of the starting point, and each occurrence probability is independent

source encoding
How can I send information appropriately when sending it in binary (○●)?

~Even if you send 4 types of information, it is not always the best to express it as 2 x 2 of ○●! ~

It is assumed that the size of the data is represented by the length of ○●. The average length of ○● used for information to be sent is called “average codeword length”. Information can be sent with less data as the average codeword length is shorter.
→In order to shorten the average codeword length, it is better to use short codewords for symbols that appear easily and long codewords for symbols that do not appear easily.

ex.
Symbol Probability Codeword Codeword length
😃　　0.2　○●　　　　2
🤗 0.3 ○○ 2
😂　　0.5　●　　　　　1
Average codeword length = 0.2 x 2 + 0.3 x 2 + 0.5 x 1 = 1.5 [bits]

* When source encoding, it is important to be unique and quickly reversible!
Uniquely restorable: For a certain bit string, there is only one way to return it to a codeword ←If there are two or more ways to decompose the same bit string, the information cannot be read correctly!

Instantaneous decodability: The ability to decode the symbol without looking ahead when the codeword has been read.
→ If a codeword is a prefix of another codeword, it will take time to restore the codeword, so care must be taken not to overlap the codewords.

Initial condition: no codeword is a prefix of another codeword
→ A code word that satisfies the prefix condition is called a ""initial code"".
*Clearly, prefix codes are uniquely decodable (instantaneously decodable codes)

Information source code ⊃ uniquely decodable code ⊃ prefix code

What is the desired sign?
(1) Uniquely reversible: unique decodability
(2) Quick recovery: Instantaneous decodability
(3) Express as short as possible: Average codeword length ➡︎ I want to pursue (3) while satisfying (1) and (2) (optimal code)

[Theorem 1]
For any uniquely decodable code C, there exists a prefix C' with the same codeword length

[Definition]
Assume a code C for a source S as follows
Symbol Probability Codeword Codeword length
a1 p1 C(a1) L1
a2 p2 C(a2) L2
: : : :
an pn C(an) Ln average codeword length L(C)=p1*L1+p2*L2+...+pn*Ln

entropy
[Definition]
Source S=
symbol probability
a1 p1
a2 p2
: :
an pn

, the entropy H(S) of S is
　H(S)=p1(-log2p1)＋…＋pn(-log2pn)

[Theorem 2]
Let S be an arbitrary source. The average codeword length L(C) of any uniquely decodable code C for S satisfies the inequality
　H(S) ≤ L(C) ≤ H(S) + 1
*Entropy is the lower bound of the average codeword length! ""","""I understand the above""",,,"""I'm keeping up so far, so I want to keep doing my best.""",-3
C-2022-1_U52,"""Information source: a source that outputs symbols at regular time intervals
→ stationary memoryless information source
　The occurrence probability of the symbol string is the same regardless of the starting point, and each occurrence probability is independent

source encoding
How can I send information appropriately when sending it in binary (○●)?

~Even if you send 4 types of information, it is not always the best to express it as 2 x 2 of ○●! ~

It is assumed that the size of the data is represented by the length of ○●. The average length of ○● used for information to be sent is called “average codeword length”. Information can be sent with less data as the average codeword length is shorter.
→In order to shorten the average codeword length, it is better to use short codewords for symbols that appear easily and long codewords for symbols that do not appear easily.

ex.
Symbol Probability Codeword Codeword length
😃　　0.2　○●　　　　2
🤗 0.3 ○○ 2
😂　　0.5　●　　　　　1
Average codeword length = 0.2 x 2 + 0.3 x 2 + 0.5 x 1 = 1.5 [bits]

* When source encoding, it is important to be unique and quickly reversible!
Uniquely restorable: For a certain bit string, there is only one way to return it to a codeword ←If there are two or more ways to decompose the same bit string, the information cannot be read correctly!

Instantaneous decodability: The ability to decode the symbol without looking ahead when the codeword has been read.
→ If a codeword is a prefix of another codeword, it will take time to restore the codeword, so care must be taken not to overlap the codewords.

Initial condition: no codeword is a prefix of another codeword
→ A code word that satisfies the prefix condition is called a ""initial code"".
*Clearly, prefix codes are uniquely decodable (instantaneously decodable codes)

Information source code ⊃ uniquely decodable code ⊃ prefix code

What is the desired sign?
(1) Uniquely reversible: unique decodability
(2) Quick recovery: Instantaneous decodability
(3) Express as short as possible: Average codeword length ➡︎ I want to pursue (3) while satisfying (1) and (2) (optimal code)

[Theorem 1]
For any uniquely decodable code C, there exists a prefix C' with the same codeword length

[Definition]
Assume a code C for a source S as follows
Symbol Probability Codeword Codeword length
a1 p1 C(a1) L1
a2 p2 C(a2) L2
: : : :
an pn C(an) Ln average codeword length L(C)=p1*L1+p2*L2+...+pn*Ln

entropy
[Definition]
Source S=
symbol probability
a1 p1
a2 p2
: :
an pn

, the entropy H(S) of S is
　H(S)=p1(-log2p1)＋…＋pn(-log2pn)

[Theorem 2]
Let S be an arbitrary source. The average codeword length L(C) of any uniquely decodable code C for S satisfies the inequality
　H(S) ≤ L(C) ≤ H(S) + 1
*Entropy is the lower bound of the average codeword length! ""","""I understand the above""",,,"""I'm keeping up so far, so I want to keep doing my best.""",-3
C-2022-1_U52,"""Information source: a source that outputs symbols at regular time intervals
→ stationary memoryless information source
　The occurrence probability of the symbol string is the same regardless of the starting point, and each occurrence probability is independent

source encoding
How can I send information appropriately when sending it in binary (○●)?

~Even if you send 4 types of information, it is not always the best to express it as 2 x 2 of ○●! ~

It is assumed that the size of the data is represented by the length of ○●. The average length of ○● used for information to be sent is called “average codeword length”. Information can be sent with less data as the average codeword length is shorter.
→In order to shorten the average codeword length, it is better to use short codewords for symbols that appear easily and long codewords for symbols that do not appear easily.

ex.
Symbol Probability Codeword Codeword length
😃　　0.2　○●　　　　2
🤗 0.3 ○○ 2
😂　　0.5　●　　　　　1
Average codeword length = 0.2 x 2 + 0.3 x 2 + 0.5 x 1 = 1.5 [bits]

* When source encoding, it is important to be unique and quickly reversible!
Uniquely restorable: For a certain bit string, there is only one way to return it to a codeword ←If there are two or more ways to decompose the same bit string, the information cannot be read correctly!

Instantaneous decodability: The ability to decode the symbol without looking ahead when the codeword has been read.
→ If a codeword is a prefix of another codeword, it will take time to restore the codeword, so care must be taken not to overlap the codewords.

Initial condition: no codeword is a prefix of another codeword
→ A code word that satisfies the prefix condition is called a ""initial code"".
*Clearly, prefix codes are uniquely decodable (instantaneously decodable codes)

Information source code ⊃ uniquely decodable code ⊃ prefix code

What is the desired sign?
(1) Uniquely reversible: unique decodability
(2) Quick recovery: Instantaneous decodability
(3) Express as short as possible: Average codeword length ➡︎ I want to pursue (3) while satisfying (1) and (2) (optimal code)

[Theorem 1]
For any uniquely decodable code C, there exists a prefix C' with the same codeword length

[Definition]
Assume a code C for a source S as follows
Symbol Probability Codeword Codeword length
a1 p1 C(a1) L1
a2 p2 C(a2) L2
: : : :
an pn C(an) Ln average codeword length L(C)=p1*L1+p2*L2+...+pn*Ln

entropy
[Definition]
Source S=
symbol probability
a1 p1
a2 p2
: :
an pn

, the entropy H(S) of S is
　H(S)=p1(-log2p1)＋…＋pn(-log2pn)

[Theorem 2]
Let S be an arbitrary source. The average codeword length L(C) of any uniquely decodable code C for S satisfies the inequality
　H(S) ≤ L(C) ≤ H(S) + 1
*Entropy is the lower bound of the average codeword length! ""","""I understand the above""",,,"""I'm keeping up so far, so I want to keep doing my best.""",-3
C-2022-1_U53,"""Information source: Something that continues to output information at a certain time interval and probability.
There are three evaluation criteria when encoding information: unique decodability, instantaneous decodability, and average decoded word length. ""","""I learned that encoding is done when information is transmitted, and I was able to find out that there are ways to convey information more concisely.""",,,"""I was impressed to learn about the mechanism that conveys the information that I usually see casually and the ingenuity hidden in it.""",-3
C-2022-1_U53,"""Information source: Something that continues to output information at a certain time interval and probability.
There are three evaluation criteria when encoding information: unique decodability, instantaneous decodability, and average decoded word length. ""","""I learned that encoding is done when information is transmitted, and I was able to find out that there are ways to convey information more concisely.""",,,"""I was impressed to learn about the mechanism that conveys the information that I usually see casually and the ingenuity hidden in it.""",-3
C-2022-1_U53,"""Information source: Something that continues to output information at a certain time interval and probability.
There are three evaluation criteria when encoding information: unique decodability, instantaneous decodability, and average decoded word length. ""","""I learned that encoding is done when information is transmitted, and I was able to find out that there are ways to convey information more concisely.""",,,"""I was impressed to learn about the mechanism that conveys the information that I usually see casually and the ingenuity hidden in it.""",-3
C-2022-1_U54,"""It's harder than you think to make the information you convey more accurate and easier.""",,,,,-3
C-2022-1_U56,"""An information source is a source that emits symbols at regular time intervals, and humans can also be an information source. In information, the probability of occurrence of symbols is the same regardless of the starting point of a constant memoryless information source, and To shorten the unique combinability, instantaneous combinability, and average codeword length for the purpose of encoding as short as possible according to the probability distribution of symbols. We will consider and encode.""","""I was able to understand the coding requirements very well.""","""I didn't quite understand the meaning of the initial condition.""",,"""I was surprised that the meanings of words such as information source and information amount that I thought I knew were different. I didn't know anything about information source coding, but I was able to understand a desirable code string that satisfies the three conditions. I'm glad I was able to do it. There were many things that were difficult to understand with just mathematical formulas and words, but it was very easy to understand with an example of a weather forecast.""",-3
C-2022-1_U56,"""An information source is a source that emits symbols at regular time intervals, and humans can also be an information source. In information, the probability of occurrence of symbols is the same regardless of the starting point of a constant memoryless information source, and To shorten the unique combinability, instantaneous combinability, and average codeword length for the purpose of encoding as short as possible according to the probability distribution of symbols. We will consider and encode.""","""I was able to understand the coding requirements very well.""","""I didn't quite understand the meaning of the initial condition.""",,"""I was surprised that the meanings of words such as information source and information amount that I thought I knew were different. I didn't know anything about information source coding, but I was able to understand a desirable code string that satisfies the three conditions. I'm glad I was able to do it. There were many things that were difficult to understand with just mathematical formulas and words, but it was very easy to understand with an example of a weather forecast.""",-3
C-2022-1_U56,"""An information source is a source that emits symbols at regular time intervals, and humans can also be an information source. In information, the probability of occurrence of symbols is the same regardless of the starting point of a constant memoryless information source, and To shorten the unique combinability, instantaneous combinability, and average codeword length for the purpose of encoding as short as possible according to the probability distribution of symbols. We will consider and encode.""","""I was able to understand the coding requirements very well.""","""I didn't quite understand the meaning of the initial condition.""",,"""I was surprised that the meanings of words such as information source and information amount that I thought I knew were different. I didn't know anything about information source coding, but I was able to understand a desirable code string that satisfies the three conditions. I'm glad I was able to do it. There were many things that were difficult to understand with just mathematical formulas and words, but it was very easy to understand with an example of a weather forecast.""",-3
C-2022-1_U56,"""An information source is a source that emits symbols at regular time intervals, and humans can also be an information source. In information, the probability of occurrence of symbols is the same regardless of the starting point of a constant memoryless information source, and To shorten the unique combinability, instantaneous combinability, and average codeword length for the purpose of encoding as short as possible according to the probability distribution of symbols. We will consider and encode.""","""I was able to understand the coding requirements very well.""","""I didn't quite understand the meaning of the initial condition.""",,"""I was surprised that the meanings of words such as information source and information amount that I thought I knew were different. I didn't know anything about information source coding, but I was able to understand a desirable code string that satisfies the three conditions. I'm glad I was able to do it. There were many things that were difficult to understand with just mathematical formulas and words, but it was very easy to understand with an example of a weather forecast.""",-3
C-2022-1_U58,"""An information source is something that outputs symbols at a constant time, and the probability of occurrence of symbols is the same. When encoding the information source, it is desirable to make it as short as possible on the condition that it can be returned to uniqueness quickly. Average The entropy, which is the lower bound of the codeword length, is calculated.""",,"""I still haven't learned all the terms.""",,,-3
C-2022-1_U58,"""An information source is something that outputs symbols at a constant time, and the probability of occurrence of symbols is the same. When encoding the information source, it is desirable to make it as short as possible on the condition that it can be returned to uniqueness quickly. Average The entropy, which is the lower bound of the codeword length, is calculated.""",,"""I still haven't learned all the terms.""",,,-3
C-2022-1_U59,,,"""entropy""","""-
""",,-3
C-2022-1_U59,,,"""entropy""","""-
""",,-3
C-2022-1_U6,"""Assuming that the probability of occurrence of the information source is fixed, and especially using a stationary memoryless information source. Information source coding is important for fast transmission of information. , that is, the probability of a symbol appearing must be taken into account, and it is also important to be able to return it uniquely (unique combinability) quickly (instantaneous combinability) in the source decoder afterwards. has the smallest average codeword length among prefix codes.This code is called the optimal code, and the average codeword length is the sum of the entropy of the information source and the probability times the log-2 probability.""",,,,,-3
C-2022-1_U60,"""Concerning the symbolic representation of information sources and the conditions for such representation.""","""Information source, I learned that it is to output a symbol at a constant time interval. Thanks to the illustration, it was very easy to understand how to quickly return to uniqueness and minimize the average codeword length.""",,,,-3
C-2022-1_U60,"""Concerning the symbolic representation of information sources and the conditions for such representation.""","""Information source, I learned that it is to output a symbol at a constant time interval. Thanks to the illustration, it was very easy to understand how to quickly return to uniqueness and minimize the average codeword length.""",,,,-3
C-2022-1_U61,,"""I've found that uniquely quick is the watchword in source encoding.""",,,"""Honestly, I wasn't sure what I ultimately wanted to do with the sign.""",-3
C-2022-1_U61,,"""I've found that uniquely quick is the watchword in source encoding.""",,,"""Honestly, I wasn't sure what I ultimately wanted to do with the sign.""",-3
C-2022-1_U62,"""Nowadays, it has become necessary to simplify information.""","""I was able to figure out the optimal code by finding the entropy""",,,"""It was fun to think of a postscript that would not only be concise, but could be uniquely compounded, like a puzzle.""",-3
C-2022-1_U62,"""Nowadays, it has become necessary to simplify information.""","""I was able to figure out the optimal code by finding the entropy""",,,"""It was fun to think of a postscript that would not only be concise, but could be uniquely compounded, like a puzzle.""",-3
C-2022-1_U62,"""Nowadays, it has become necessary to simplify information.""","""I was able to figure out the optimal code by finding the entropy""",,,"""It was fun to think of a postscript that would not only be concise, but could be uniquely compounded, like a puzzle.""",-3
C-2022-1_U63,"""Information sources can be shortened by devising code types and lengths according to the frequency of each piece of information.""",,,,,-3
C-2022-1_U64,"""For information sources, there are various patterns when converting to binary numbers.
""","""It is best to have unique and instantaneous decoding and a short average codeword length.""",,,,-3
C-2022-1_U64,"""For information sources, there are various patterns when converting to binary numbers.
""","""It is best to have unique and instantaneous decoding and a short average codeword length.""",,,,-3
C-2022-1_U65,,"""I was able to find the correct definition of a source.
I also learned that there are two types of information sources: stationary and memoryless. """,,,,-3
C-2022-1_U66,"""An information source is not just a source of information, but something that spits out some kind of information at regular intervals. Information source coding is performed to transmit information. Information is represented by 0s and 1s, and the information is made as short as possible. In source coding, it is necessary to consider unique decodability and instantaneous decodability, so that there are multiple ways of decomposing bit strings and decoding does not take much time. Therefore, the code evaluation criteria consist of three elements: unique decodability, instantaneous decodability, and average codeword length. It satisfies the decodability and instantaneous decodability.In addition, from the theorem that ``for any unique decodable code C, there exists a prefix code C' with the same codeword tone'', the prefix code has an average codeword length can also be minimized. The average codeword length varies by changing the information source and codeword. Also, since the entropy of the information source is equal to or less than the minimum value of the average codeword length, the entropy is the lower limit of the average codeword length. However, the entropy is not the optimal code, and the code is optimal if the average codeword length is between the entropy and the entropy+1. """,,,,,-3
C-2022-1_U67,"""Information sources are represented by codes so that they cannot be eavesdropped. A class on how to decide on codes for that purpose. Something short, uniquely decodable, and instantaneously decodable is suitable. Initial codes are excellent.""","""I learned that the information we use every day can be sent and received safely and quickly to some extent because smart people have invented the best code.""","""I didn't understand how the source coding theorem works.""","""Nothing in particular.""","""I felt that the person who first thought about how to find the best code and invented it was a genius.""",-3
C-2022-1_U67,"""Information sources are represented by codes so that they cannot be eavesdropped. A class on how to decide on codes for that purpose. Something short, uniquely decodable, and instantaneously decodable is suitable. Initial codes are excellent.""","""I learned that the information we use every day can be sent and received safely and quickly to some extent because smart people have invented the best code.""","""I didn't understand how the source coding theorem works.""","""Nothing in particular.""","""I felt that the person who first thought about how to find the best code and invented it was a genius.""",-3
C-2022-1_U67,"""Information sources are represented by codes so that they cannot be eavesdropped. A class on how to decide on codes for that purpose. Something short, uniquely decodable, and instantaneously decodable is suitable. Initial codes are excellent.""","""I learned that the information we use every day can be sent and received safely and quickly to some extent because smart people have invented the best code.""","""I didn't understand how the source coding theorem works.""","""Nothing in particular.""","""I felt that the person who first thought about how to find the best code and invented it was a genius.""",-3
C-2022-1_U67,"""Information sources are represented by codes so that they cannot be eavesdropped. A class on how to decide on codes for that purpose. Something short, uniquely decodable, and instantaneously decodable is suitable. Initial codes are excellent.""","""I learned that the information we use every day can be sent and received safely and quickly to some extent because smart people have invented the best code.""","""I didn't understand how the source coding theorem works.""","""Nothing in particular.""","""I felt that the person who first thought about how to find the best code and invented it was a genius.""",-3
C-2022-1_U67,"""Information sources are represented by codes so that they cannot be eavesdropped. A class on how to decide on codes for that purpose. Something short, uniquely decodable, and instantaneously decodable is suitable. Initial codes are excellent.""","""I learned that the information we use every day can be sent and received safely and quickly to some extent because smart people have invented the best code.""","""I didn't understand how the source coding theorem works.""","""Nothing in particular.""","""I felt that the person who first thought about how to find the best code and invented it was a genius.""",-3
C-2022-1_U68,,,"""Nothing in particular.""",,,-3
C-2022-1_U69,"""The conditions for a code suitable for transmitting information are (1) to be able to return uniquely, (2) to be able to return quickly, and (3) to be as short as possible.","""I became able to identify what kind of code can be instantly combined. Also, I found that the initial code can be easily created by writing a code tree.""","""is not.""",,,-3
C-2022-1_U69,"""The conditions for a code suitable for transmitting information are (1) to be able to return uniquely, (2) to be able to return quickly, and (3) to be as short as possible.","""I became able to identify what kind of code can be instantly combined. Also, I found that the initial code can be easily created by writing a code tree.""","""is not.""",,,-3
C-2022-1_U69,"""The conditions for a code suitable for transmitting information are (1) to be able to return uniquely, (2) to be able to return quickly, and (3) to be as short as possible.","""I became able to identify what kind of code can be instantly combined. Also, I found that the initial code can be easily created by writing a code tree.""","""is not.""",,,-3
C-2022-1_U7,"""When we encode symbols, we consider the average codeword length. The two conditions are that it must be unique and can be quickly restored. (Unique combination possibility/Instantaneous combination possibility) All codes with the same length It is called a fixed-length code.In addition, any code with a different prefix is ​​called a prefix code.The average compound word length is expressed using the occurrence probability and the length of the code, and the lower limit can be expressed by entropy.""","""Efficient way of encoding when transcoding""","""I still don't understand how to find entropy.""",,"""I vaguely knew the terms information volume and encoding, but I think I was able to understand the correct definition after listening to today's class.""",-3
C-2022-1_U7,"""When we encode symbols, we consider the average codeword length. The two conditions are that it must be unique and can be quickly restored. (Unique combination possibility/Instantaneous combination possibility) All codes with the same length It is called a fixed-length code.In addition, any code with a different prefix is ​​called a prefix code.The average compound word length is expressed using the occurrence probability and the length of the code, and the lower limit can be expressed by entropy.""","""Efficient way of encoding when transcoding""","""I still don't understand how to find entropy.""",,"""I vaguely knew the terms information volume and encoding, but I think I was able to understand the correct definition after listening to today's class.""",-3
C-2022-1_U7,"""When we encode symbols, we consider the average codeword length. The two conditions are that it must be unique and can be quickly restored. (Unique combination possibility/Instantaneous combination possibility) All codes with the same length It is called a fixed-length code.In addition, any code with a different prefix is ​​called a prefix code.The average compound word length is expressed using the occurrence probability and the length of the code, and the lower limit can be expressed by entropy.""","""Efficient way of encoding when transcoding""","""I still don't understand how to find entropy.""",,"""I vaguely knew the terms information volume and encoding, but I think I was able to understand the correct definition after listening to today's class.""",-3
C-2022-1_U7,"""When we encode symbols, we consider the average codeword length. The two conditions are that it must be unique and can be quickly restored. (Unique combination possibility/Instantaneous combination possibility) All codes with the same length It is called a fixed-length code.In addition, any code with a different prefix is ​​called a prefix code.The average compound word length is expressed using the occurrence probability and the length of the code, and the lower limit can be expressed by entropy.""","""Efficient way of encoding when transcoding""","""I still don't understand how to find entropy.""",,"""I vaguely knew the terms information volume and encoding, but I think I was able to understand the correct definition after listening to today's class.""",-3
C-2022-1_U70,,,"""There were so many definitions and so much new content that my head felt like it was going to explode. If explained, I could understand, but there are still some words that I haven't made my own, so I want to review them often.""",,,-3
C-2022-1_U72,,,,,"""At first glance, it looked like a simple rearrangement of black and white circles, but I found it interesting that mathematics was actually used. I wanted to join in.""",-3
C-2022-1_U73,,"""I was wondering how to convey information with only 0s and 1s, but today's lecture on coding gave me a good idea.
A shorter average code length is better. The prefix code with the smallest average codeword length has the smallest average codeword length among uniquely decodable codes.

""","""I didn't quite understand the meaning that entropy is the lower limit of the average codeword length. Does the base 2 of entropy mean 2, meaning 0 or 1?
Since the graph of logarithm has a limit, does entropy also have a lower limit? I don't quite understand the source coding theorem. """,,"""The source of information that I thought of was different from the true meaning. It is interesting that the information conveyed differs depending on how it is decomposed into codewords.
I learned how to send a huge amount of information quickly with only 0s and 1s, and learned a lot. """,-3
C-2022-1_U73,,"""I was wondering how to convey information with only 0s and 1s, but today's lecture on coding gave me a good idea.
A shorter average code length is better. The prefix code with the smallest average codeword length has the smallest average codeword length among uniquely decodable codes.

""","""I didn't quite understand the meaning that entropy is the lower limit of the average codeword length. Does the base 2 of entropy mean 2, meaning 0 or 1?
Since the graph of logarithm has a limit, does entropy also have a lower limit? I don't quite understand the source coding theorem. """,,"""The source of information that I thought of was different from the true meaning. It is interesting that the information conveyed differs depending on how it is decomposed into codewords.
I learned how to send a huge amount of information quickly with only 0s and 1s, and learned a lot. """,-3
C-2022-1_U73,,"""I was wondering how to convey information with only 0s and 1s, but today's lecture on coding gave me a good idea.
A shorter average code length is better. The prefix code with the smallest average codeword length has the smallest average codeword length among uniquely decodable codes.

""","""I didn't quite understand the meaning that entropy is the lower limit of the average codeword length. Does the base 2 of entropy mean 2, meaning 0 or 1?
Since the graph of logarithm has a limit, does entropy also have a lower limit? I don't quite understand the source coding theorem. """,,"""The source of information that I thought of was different from the true meaning. It is interesting that the information conveyed differs depending on how it is decomposed into codewords.
I learned how to send a huge amount of information quickly with only 0s and 1s, and learned a lot. """,-3
C-2022-1_U74,,,"""I'm not sure about the lower bound of the average codeword length, where log comes in...I'll take revenge on you with a practice problem.""","""Nothing in particular.""",,-3
C-2022-1_U74,,,"""I'm not sure about the lower bound of the average codeword length, where log comes in...I'll take revenge on you with a practice problem.""","""Nothing in particular.""",,-3
C-2022-1_U75,"""By information source coding, information is represented by a sequence of ●○, and compounding is to restore it. The length of the encoding changes depending on how the codeword is represented, and it also changes depending on how it is arranged. Symbols that are likely to appear It is sufficient to lengthen short symbols that are difficult to appear in. The initial condition is that a certain code is not a prefix of another code, which has the characteristics of first-order restoration and instant compounding.Also, the average code. The lower bound of the word length can be obtained by a formula.""",,"""Regarding the calculation, I understood the formula, but I thought it would be difficult to understand without a little more practice.""",,"""It was a bit difficult because of the odds and such. I don't think I can understand it just by memorizing, so I want to study hard.""",-3
C-2022-1_U75,"""By information source coding, information is represented by a sequence of ●○, and compounding is to restore it. The length of the encoding changes depending on how the codeword is represented, and it also changes depending on how it is arranged. Symbols that are likely to appear It is sufficient to lengthen short symbols that are difficult to appear in. The initial condition is that a certain code is not a prefix of another code, which has the characteristics of first-order restoration and instant compounding.Also, the average code. The lower bound of the word length can be obtained by a formula.""",,"""Regarding the calculation, I understood the formula, but I thought it would be difficult to understand without a little more practice.""",,"""It was a bit difficult because of the odds and such. I don't think I can understand it just by memorizing, so I want to study hard.""",-3
C-2022-1_U75,"""By information source coding, information is represented by a sequence of ●○, and compounding is to restore it. The length of the encoding changes depending on how the codeword is represented, and it also changes depending on how it is arranged. Symbols that are likely to appear It is sufficient to lengthen short symbols that are difficult to appear in. The initial condition is that a certain code is not a prefix of another code, which has the characteristics of first-order restoration and instant compounding.Also, the average code. The lower bound of the word length can be obtained by a formula.""",,"""Regarding the calculation, I understood the formula, but I thought it would be difficult to understand without a little more practice.""",,"""It was a bit difficult because of the odds and such. I don't think I can understand it just by memorizing, so I want to study hard.""",-3
C-2022-1_U76,"""What is an information source? What codewords are preferred when encoding an information source? On the features of prefixes that satisfy the condition that no codeword is a prefix of another codeword. Mean About minimum codeword length and optimal code.
""",,"""I searched for entropy proofs and proofs for narrowing down the range of optimal codes, but I couldn't understand them at all.""",,"""I was able to keep up with today's class, but from now on I will attend class without failing to prepare.""",-3
C-2022-1_U76,"""What is an information source? What codewords are preferred when encoding an information source? On the features of prefixes that satisfy the condition that no codeword is a prefix of another codeword. Mean About minimum codeword length and optimal code.
""",,"""I searched for entropy proofs and proofs for narrowing down the range of optimal codes, but I couldn't understand them at all.""",,"""I was able to keep up with today's class, but from now on I will attend class without failing to prepare.""",-3
C-2022-1_U76,"""What is an information source? What codewords are preferred when encoding an information source? On the features of prefixes that satisfy the condition that no codeword is a prefix of another codeword. Mean About minimum codeword length and optimal code.
""",,"""I searched for entropy proofs and proofs for narrowing down the range of optimal codes, but I couldn't understand them at all.""",,"""I was able to keep up with today's class, but from now on I will attend class without failing to prepare.""",-3
C-2022-1_U77,,,,"""I've learned that entropy in chemistry means randomness. Does it mean the same thing here?""","""I thought I had prepared for class, but in reality I was just looking at it and didn't remember anything. Next time, I will read the textbook properly and clarify what I don't understand before taking the class.""",-3
C-2022-1_U77,,,,"""I've learned that entropy in chemistry means randomness. Does it mean the same thing here?""","""I thought I had prepared for class, but in reality I was just looking at it and didn't remember anything. Next time, I will read the textbook properly and clarify what I don't understand before taking the class.""",-3
C-2022-1_U78,"""In order to keep the data as small as possible and make it easier to decode, it is good to use prefixes.
""","""Use binary concepts to source code.""","""I didn't quite understand the meaning of H(S)≤L(C).""",,"""I felt that I needed math skills.""",-3
C-2022-1_U78,"""In order to keep the data as small as possible and make it easier to decode, it is good to use prefixes.
""","""Use binary concepts to source code.""","""I didn't quite understand the meaning of H(S)≤L(C).""",,"""I felt that I needed math skills.""",-3
C-2022-1_U78,"""In order to keep the data as small as possible and make it easier to decode, it is good to use prefixes.
""","""Use binary concepts to source code.""","""I didn't quite understand the meaning of H(S)≤L(C).""",,"""I felt that I needed math skills.""",-3
C-2022-1_U78,"""In order to keep the data as small as possible and make it easier to decode, it is good to use prefixes.
""","""Use binary concepts to source code.""","""I didn't quite understand the meaning of H(S)≤L(C).""",,"""I felt that I needed math skills.""",-3
C-2022-1_U79,,"""When sending information by code, it is ideal to send data in a unique, quick, and short manner, and a prefix code can satisfy that. The shortest uniquely decodable code is a prefix of the same length. It means having a sign.I also learned that we can use mathematical formulas and probabilities to find the range of optimal signs.""","""I remembered the formula incorrectly in a calculation exercise, so I made a mistake. Also, when I listened to it once in class, the relationship between the uniquely decodable code, the instantly decodable code, and the initial code was ambiguous. However, I was able to sort it out after looking into it later.""",,,-3
C-2022-1_U79,,"""When sending information by code, it is ideal to send data in a unique, quick, and short manner, and a prefix code can satisfy that. The shortest uniquely decodable code is a prefix of the same length. It means having a sign.I also learned that we can use mathematical formulas and probabilities to find the range of optimal signs.""","""I remembered the formula incorrectly in a calculation exercise, so I made a mistake. Also, when I listened to it once in class, the relationship between the uniquely decodable code, the instantly decodable code, and the initial code was ambiguous. However, I was able to sort it out after looking into it later.""",,,-3
C-2022-1_U8,,,"""From around the time the final log came out, it was delayed.
Also, although I can do calculations, I felt like I couldn't understand the meaning somehow. """,,"""As a liberal arts student, I'm unfamiliar with this kind of thing, and I was surprised at the fact that it was required by calculations that weren't that difficult. The content of the class gradually became more difficult, so I want to prepare well before attending the class."" .""",-3
C-2022-1_U8,,,"""From around the time the final log came out, it was delayed.
Also, although I can do calculations, I felt like I couldn't understand the meaning somehow. """,,"""As a liberal arts student, I'm unfamiliar with this kind of thing, and I was surprised at the fact that it was required by calculations that weren't that difficult. The content of the class gradually became more difficult, so I want to prepare well before attending the class."" .""",-3
C-2022-1_U81,"""source""","""General Flow of Information Transmission""",,,"""It was easy to understand.""",-3
C-2022-1_U81,"""source""","""General Flow of Information Transmission""",,,"""It was easy to understand.""",-3
C-2022-1_U81,"""source""","""General Flow of Information Transmission""",,,"""It was easy to understand.""",-3
C-2022-1_U82,,,"""I thought the entropy and other calculations were a bit complicated. I'll check it again with a practice problem.""",,,-3
C-2022-1_U83,"""Electronic data is mainly represented by binary numbers, and various devices have been devised so that information can be identified quickly.
""","""Binary numbers can create multiple types of data depending on how the data is distributed""","""I didn't know the enthalpy""",,"""I thought it was amazing that a lot of data could be represented by a simple expression method called binary numbers.
""",-3
C-2022-1_U83,"""Electronic data is mainly represented by binary numbers, and various devices have been devised so that information can be identified quickly.
""","""Binary numbers can create multiple types of data depending on how the data is distributed""","""I didn't know the enthalpy""",,"""I thought it was amazing that a lot of data could be represented by a simple expression method called binary numbers.
""",-3
C-2022-1_U83,"""Electronic data is mainly represented by binary numbers, and various devices have been devised so that information can be identified quickly.
""","""Binary numbers can create multiple types of data depending on how the data is distributed""","""I didn't know the enthalpy""",,"""I thought it was amazing that a lot of data could be represented by a simple expression method called binary numbers.
""",-3
C-2022-1_U83,"""Electronic data is mainly represented by binary numbers, and various devices have been devised so that information can be identified quickly.
""","""Binary numbers can create multiple types of data depending on how the data is distributed""","""I didn't know the enthalpy""",,"""I thought it was amazing that a lot of data could be represented by a simple expression method called binary numbers.
""",-3
C-2022-1_U84,"""Today's topic was about source encoding. It seems to be a good idea to first think about whether it can be restored uniquely and quickly, and then try to express it as briefly as possible.""",,,,"""Today I learned how to calculate in information science.
I was glad that the calculation of log and the calculation of expected value that I learned in mathematics were useful.
I wonder what other calculations are used in information science. """,-3
C-2022-1_U84,"""Today's topic was about source encoding. It seems to be a good idea to first think about whether it can be restored uniquely and quickly, and then try to express it as briefly as possible.""",,,,"""Today I learned how to calculate in information science.
I was glad that the calculation of log and the calculation of expected value that I learned in mathematics were useful.
I wonder what other calculations are used in information science. """,-3
C-2022-1_U85,,"""Information source does not mean just a source of information as it is written in kanji, but it means that information is emitted at regular intervals, and the probability of occurrence of that information is fixed.
Source coding shall take into account probabilities of occurrence. Uniquely decodable if all codewords have the same length. ""","""Proof of source coding theorem""",,,-3
C-2022-1_U85,,"""Information source does not mean just a source of information as it is written in kanji, but it means that information is emitted at regular intervals, and the probability of occurrence of that information is fixed.
Source coding shall take into account probabilities of occurrence. Uniquely decodable if all codewords have the same length. ""","""Proof of source coding theorem""",,,-3
C-2022-1_U86,"""Relationship between Information Coding and Probability""","""When encoding a source, consider the probability of that happening and decide the length of the code.""","""The definition of entropy didn't feel right""",,"""I thought the system of encoding information was very rational.""",-3
C-2022-1_U86,"""Relationship between Information Coding and Probability""","""When encoding a source, consider the probability of that happening and decide the length of the code.""","""The definition of entropy didn't feel right""",,"""I thought the system of encoding information was very rational.""",-3
C-2022-1_U86,"""Relationship between Information Coding and Probability""","""When encoding a source, consider the probability of that happening and decide the length of the code.""","""The definition of entropy didn't feel right""",,"""I thought the system of encoding information was very rational.""",-3
C-2022-1_U86,"""Relationship between Information Coding and Probability""","""When encoding a source, consider the probability of that happening and decide the length of the code.""","""The definition of entropy didn't feel right""",,"""I thought the system of encoding information was very rational.""",-3
C-2022-1_U87,"""An information source outputs symbols at regular time intervals. What is important when encoding when sending information is to be able to return it uniquely, to be able to return it quickly, and to express it as short as possible. There are conditions.
""","""I had misunderstood that the information source was just the output destination of the information on its own, but I'm glad I cleared up that misunderstanding.""","""When encoding, for example, on page 24 of the textbook used in this lecture, sunny days are ○ and cloudy days are ○ ●. ● I thought it would be fine, but is it possible to realize this kind of thing?

""",,"""I didn't really understand the meaning of the optimization calculations at the end of today's lecture, so I'd like to focus on that and go to the next class.""",-3
C-2022-1_U87,"""An information source outputs symbols at regular time intervals. What is important when encoding when sending information is to be able to return it uniquely, to be able to return it quickly, and to express it as short as possible. There are conditions.
""","""I had misunderstood that the information source was just the output destination of the information on its own, but I'm glad I cleared up that misunderstanding.""","""When encoding, for example, on page 24 of the textbook used in this lecture, sunny days are ○ and cloudy days are ○ ●. ● I thought it would be fine, but is it possible to realize this kind of thing?

""",,"""I didn't really understand the meaning of the optimization calculations at the end of today's lecture, so I'd like to focus on that and go to the next class.""",-3
C-2022-1_U87,"""An information source outputs symbols at regular time intervals. What is important when encoding when sending information is to be able to return it uniquely, to be able to return it quickly, and to express it as short as possible. There are conditions.
""","""I had misunderstood that the information source was just the output destination of the information on its own, but I'm glad I cleared up that misunderstanding.""","""When encoding, for example, on page 24 of the textbook used in this lecture, sunny days are ○ and cloudy days are ○ ●. ● I thought it would be fine, but is it possible to realize this kind of thing?

""",,"""I didn't really understand the meaning of the optimization calculations at the end of today's lecture, so I'd like to focus on that and go to the next class.""",-3
C-2022-1_U87,"""An information source outputs symbols at regular time intervals. What is important when encoding when sending information is to be able to return it uniquely, to be able to return it quickly, and to express it as short as possible. There are conditions.
""","""I had misunderstood that the information source was just the output destination of the information on its own, but I'm glad I cleared up that misunderstanding.""","""When encoding, for example, on page 24 of the textbook used in this lecture, sunny days are ○ and cloudy days are ○ ●. ● I thought it would be fine, but is it possible to realize this kind of thing?

""",,"""I didn't really understand the meaning of the optimization calculations at the end of today's lecture, so I'd like to focus on that and go to the next class.""",-3
C-2022-1_U88,,"""I was able to understand source coding, average codeword length, unique decodability, fixed-length code, instantaneous decodability, prefix code, and code tree. I also learned how to reduce the amount of data.""","""Not so far.""",,"""I learned for the first time that the capacitance can be changed simply by changing the arrangement of the signals. I was able to enjoy the lessons because they used many familiar examples and illustrations. I think it's difficult, but it was easy to understand.""",-3
C-2022-1_U88,,"""I was able to understand source coding, average codeword length, unique decodability, fixed-length code, instantaneous decodability, prefix code, and code tree. I also learned how to reduce the amount of data.""","""Not so far.""",,"""I learned for the first time that the capacitance can be changed simply by changing the arrangement of the signals. I was able to enjoy the lessons because they used many familiar examples and illustrations. I think it's difficult, but it was easy to understand.""",-3
C-2022-1_U88,,"""I was able to understand source coding, average codeword length, unique decodability, fixed-length code, instantaneous decodability, prefix code, and code tree. I also learned how to reduce the amount of data.""","""Not so far.""",,"""I learned for the first time that the capacitance can be changed simply by changing the arrangement of the signals. I was able to enjoy the lessons because they used many familiar examples and illustrations. I think it's difficult, but it was easy to understand.""",-3
C-2022-1_U89,,,"""I was keenly aware that entropy calculations are logarithmic calculations, and that mathematics skills are essential for information science. I couldn't solve them at the same speed as when I was in high school, so I thoroughly reviewed high school mathematics. Also, I've had trouble understanding some of the prefixes, so I'll try to do my homework and review without fail.""",,"""First of all, I misunderstood the meaning of some words, so I thought that I had to have a minimum knowledge of the terminology of information science. I was able to know the original meaning of the information source, which was a benefit. However, In order to deepen my understanding of the content of the class, I was keenly aware that it was essential to thoroughly prepare for and review the class. I felt that the basis of the process of information transmission was consistent, and when I thought that the content of how to shorten the information code and transmit it was used in modern technology, I felt a kind of excitement. I think I felt something. After all, knowledge of mathematics is important for learning information science, so I decided to study mathematics as well.""",-3
C-2022-1_U89,,,"""I was keenly aware that entropy calculations are logarithmic calculations, and that mathematics skills are essential for information science. I couldn't solve them at the same speed as when I was in high school, so I thoroughly reviewed high school mathematics. Also, I've had trouble understanding some of the prefixes, so I'll try to do my homework and review without fail.""",,"""First of all, I misunderstood the meaning of some words, so I thought that I had to have a minimum knowledge of the terminology of information science. I was able to know the original meaning of the information source, which was a benefit. However, In order to deepen my understanding of the content of the class, I was keenly aware that it was essential to thoroughly prepare for and review the class. I felt that the basis of the process of information transmission was consistent, and when I thought that the content of how to shorten the information code and transmit it was used in modern technology, I felt a kind of excitement. I think I felt something. After all, knowledge of mathematics is important for learning information science, so I decided to study mathematics as well.""",-3
C-2022-1_U9,"""The number of codes can be reduced by the probability of occurrence.
If it's a word prefix, it doesn't take extra effort, but if it's not, there's a different pattern and it's difficult. ""","""The amount of information was more complex than I ever thought""",,,"""I want to properly remember complicated things such as calculation methods""",-3
C-2022-1_U9,"""The number of codes can be reduced by the probability of occurrence.
If it's a word prefix, it doesn't take extra effort, but if it's not, there's a different pattern and it's difficult. ""","""The amount of information was more complex than I ever thought""",,,"""I want to properly remember complicated things such as calculation methods""",-3
C-2022-1_U9,"""The number of codes can be reduced by the probability of occurrence.
If it's a word prefix, it doesn't take extra effort, but if it's not, there's a different pattern and it's difficult. ""","""The amount of information was more complex than I ever thought""",,,"""I want to properly remember complicated things such as calculation methods""",-3
C-2022-1_U90,,"""I understood code trees very well.""",,,,-3
C-2022-1_U91,"""Method of transmitting information without mistakes using only black and white balls""","""Even if the arrangement of black and white balls is the same, the way it is perceived changes depending on how it is divided, and the computer cannot distinguish between them, causing an error.
""","""Late understanding of prefixes, etc.""","""I want to learn more about prefix ranges again""","""Uniqueness of information is important for accurate transmission of information.
""",-3
C-2022-1_U91,"""Method of transmitting information without mistakes using only black and white balls""","""Even if the arrangement of black and white balls is the same, the way it is perceived changes depending on how it is divided, and the computer cannot distinguish between them, causing an error.
""","""Late understanding of prefixes, etc.""","""I want to learn more about prefix ranges again""","""Uniqueness of information is important for accurate transmission of information.
""",-3
C-2022-1_U91,"""Method of transmitting information without mistakes using only black and white balls""","""Even if the arrangement of black and white balls is the same, the way it is perceived changes depending on how it is divided, and the computer cannot distinguish between them, causing an error.
""","""Late understanding of prefixes, etc.""","""I want to learn more about prefix ranges again""","""Uniqueness of information is important for accurate transmission of information.
""",-3
C-2022-1_U91,"""Method of transmitting information without mistakes using only black and white balls""","""Even if the arrangement of black and white balls is the same, the way it is perceived changes depending on how it is divided, and the computer cannot distinguish between them, causing an error.
""","""Late understanding of prefixes, etc.""","""I want to learn more about prefix ranges again""","""Uniqueness of information is important for accurate transmission of information.
""",-3
C-2022-1_U91,"""Method of transmitting information without mistakes using only black and white balls""","""Even if the arrangement of black and white balls is the same, the way it is perceived changes depending on how it is divided, and the computer cannot distinguish between them, causing an error.
""","""Late understanding of prefixes, etc.""","""I want to learn more about prefix ranges again""","""Uniqueness of information is important for accurate transmission of information.
""",-3
C-2022-1_U92,"""Information is expressed in a simplified way using some symbols""","""Information is conveyed in an easy-to-understand manner""",,,"""I forgot to write a diary, so I forgot some of the content of the lecture, so I couldn't write a diary accurately.""",-3
C-2022-1_U92,"""Information is expressed in a simplified way using some symbols""","""Information is conveyed in an easy-to-understand manner""",,,"""I forgot to write a diary, so I forgot some of the content of the lecture, so I couldn't write a diary accurately.""",-3
C-2022-1_U92,"""Information is expressed in a simplified way using some symbols""","""Information is conveyed in an easy-to-understand manner""",,,"""I forgot to write a diary, so I forgot some of the content of the lecture, so I couldn't write a diary accurately.""",-3
C-2022-1_U93,"""When source encoding, we aim to be quick with a single interpretation. That's why we use prefixes.""","""The average codeword length and entropy have been calculated.""","""I didn't know what entropy was in the first place.""",,"""Sorry, I forgot to use the marker.""",-3
C-2022-1_U93,"""When source encoding, we aim to be quick with a single interpretation. That's why we use prefixes.""","""The average codeword length and entropy have been calculated.""","""I didn't know what entropy was in the first place.""",,"""Sorry, I forgot to use the marker.""",-3
C-2022-1_U93,"""When source encoding, we aim to be quick with a single interpretation. That's why we use prefixes.""","""The average codeword length and entropy have been calculated.""","""I didn't know what entropy was in the first place.""",,"""Sorry, I forgot to use the marker.""",-3
C-2022-1_U93,"""When source encoding, we aim to be quick with a single interpretation. That's why we use prefixes.""","""The average codeword length and entropy have been calculated.""","""I didn't know what entropy was in the first place.""",,"""Sorry, I forgot to use the marker.""",-3
C-2022-1_U94,"""Source encoding should be as short as possible, provided that it is uniquely reversible and quickly reversible. Initial codes are called instantaneously combinable codes.""","""You can find the desired codeword tone by finding the entropy
""",,,"""Suddenly it got difficult.""",-3
C-2022-1_U94,"""Source encoding should be as short as possible, provided that it is uniquely reversible and quickly reversible. Initial codes are called instantaneously combinable codes.""","""You can find the desired codeword tone by finding the entropy
""",,,"""Suddenly it got difficult.""",-3
C-2022-1_U94,"""Source encoding should be as short as possible, provided that it is uniquely reversible and quickly reversible. Initial codes are called instantaneously combinable codes.""","""You can find the desired codeword tone by finding the entropy
""",,,"""Suddenly it got difficult.""",-3
C-2022-1_U95,,"""I found that mathematics is very useful for information, such as entropy.""","""It was difficult to distinguish between the properties of prefixes and non-initials""",,"""It was interesting that the minimum value can be expressed in terms of entropy""",-3
C-2022-1_U95,,"""I found that mathematics is very useful for information, such as entropy.""","""It was difficult to distinguish between the properties of prefixes and non-initials""",,"""It was interesting that the minimum value can be expressed in terms of entropy""",-3
C-2022-1_U95,,"""I found that mathematics is very useful for information, such as entropy.""","""It was difficult to distinguish between the properties of prefixes and non-initials""",,"""It was interesting that the minimum value can be expressed in terms of entropy""",-3
C-2022-1_U96,"""Regarding the stationary memorylessness of the information source, there is no relationship between the probability of the occurrence and the relationship between the sequential occurrences. The information source encoder or vice versa is called the information source coder, which encodes the sequence from the information source. The encoding length is expressed in bits.The shorter this length, the shorter the time required for data transfer, etc. The average codeword length is obtained by multiplying the codeword length of one symbol by the emission probability of the information source.Points is to assign short word lengths to symbols that are likely to appear.The condition for assigning codes is to be unique and quickly reversible.Word lengths that are the same word or separated by a single character are unique. Entropy is the lower limit of the average codeword length, and the upper limit is obtained by adding 1 to that value.""","""Exercises 1 C1, 2.0 C2, 3.1 C3, 2.7
Exercise 2 ○/●● or ○●/●, ○●/●○ or ○/●●/○
Exercise 3 2.2465""","""Proof of how to calculate entropy, proof of why entropy plus 1 gives upper bound,""","""Is it possible to determine the average compound word length by the same value as the entropy value?""","""It was very interesting to be asked for numerical values.""",-3
C-2022-1_U96,"""Regarding the stationary memorylessness of the information source, there is no relationship between the probability of the occurrence and the relationship between the sequential occurrences. The information source encoder or vice versa is called the information source coder, which encodes the sequence from the information source. The encoding length is expressed in bits.The shorter this length, the shorter the time required for data transfer, etc. The average codeword length is obtained by multiplying the codeword length of one symbol by the emission probability of the information source.Points is to assign short word lengths to symbols that are likely to appear.The condition for assigning codes is to be unique and quickly reversible.Word lengths that are the same word or separated by a single character are unique. Entropy is the lower limit of the average codeword length, and the upper limit is obtained by adding 1 to that value.""","""Exercises 1 C1, 2.0 C2, 3.1 C3, 2.7
Exercise 2 ○/●● or ○●/●, ○●/●○ or ○/●●/○
Exercise 3 2.2465""","""Proof of how to calculate entropy, proof of why entropy plus 1 gives upper bound,""","""Is it possible to determine the average compound word length by the same value as the entropy value?""","""It was very interesting to be asked for numerical values.""",-3
C-2022-1_U96,"""Regarding the stationary memorylessness of the information source, there is no relationship between the probability of the occurrence and the relationship between the sequential occurrences. The information source encoder or vice versa is called the information source coder, which encodes the sequence from the information source. The encoding length is expressed in bits.The shorter this length, the shorter the time required for data transfer, etc. The average codeword length is obtained by multiplying the codeword length of one symbol by the emission probability of the information source.Points is to assign short word lengths to symbols that are likely to appear.The condition for assigning codes is to be unique and quickly reversible.Word lengths that are the same word or separated by a single character are unique. Entropy is the lower limit of the average codeword length, and the upper limit is obtained by adding 1 to that value.""","""Exercises 1 C1, 2.0 C2, 3.1 C3, 2.7
Exercise 2 ○/●● or ○●/●, ○●/●○ or ○/●●/○
Exercise 3 2.2465""","""Proof of how to calculate entropy, proof of why entropy plus 1 gives upper bound,""","""Is it possible to determine the average compound word length by the same value as the entropy value?""","""It was very interesting to be asked for numerical values.""",-3
C-2022-1_U96,"""Regarding the stationary memorylessness of the information source, there is no relationship between the probability of the occurrence and the relationship between the sequential occurrences. The information source encoder or vice versa is called the information source coder, which encodes the sequence from the information source. The encoding length is expressed in bits.The shorter this length, the shorter the time required for data transfer, etc. The average codeword length is obtained by multiplying the codeword length of one symbol by the emission probability of the information source.Points is to assign short word lengths to symbols that are likely to appear.The condition for assigning codes is to be unique and quickly reversible.Word lengths that are the same word or separated by a single character are unique. Entropy is the lower limit of the average codeword length, and the upper limit is obtained by adding 1 to that value.""","""Exercises 1 C1, 2.0 C2, 3.1 C3, 2.7
Exercise 2 ○/●● or ○●/●, ○●/●○ or ○/●●/○
Exercise 3 2.2465""","""Proof of how to calculate entropy, proof of why entropy plus 1 gives upper bound,""","""Is it possible to determine the average compound word length by the same value as the entropy value?""","""It was very interesting to be asked for numerical values.""",-3
C-2022-1_U96,"""Regarding the stationary memorylessness of the information source, there is no relationship between the probability of the occurrence and the relationship between the sequential occurrences. The information source encoder or vice versa is called the information source coder, which encodes the sequence from the information source. The encoding length is expressed in bits.The shorter this length, the shorter the time required for data transfer, etc. The average codeword length is obtained by multiplying the codeword length of one symbol by the emission probability of the information source.Points is to assign short word lengths to symbols that are likely to appear.The condition for assigning codes is to be unique and quickly reversible.Word lengths that are the same word or separated by a single character are unique. Entropy is the lower limit of the average codeword length, and the upper limit is obtained by adding 1 to that value.""","""Exercises 1 C1, 2.0 C2, 3.1 C3, 2.7
Exercise 2 ○/●● or ○●/●, ○●/●○ or ○/●●/○
Exercise 3 2.2465""","""Proof of how to calculate entropy, proof of why entropy plus 1 gives upper bound,""","""Is it possible to determine the average compound word length by the same value as the entropy value?""","""It was very interesting to be asked for numerical values.""",-3
D-2020_U1,,,"""I want to learn more about the sampling theorem later.""",,,0
D-2020_U10,,"""I learned about quantization and encoding of sampled signals.""",,,,0
D-2020_U11,,"""What exactly are the four signal types? Sampling.""",,,,-3
D-2020_U12,"""Signals are classified into four categories depending on whether their time and amplitude are continuous or discrete.
Converting an analog signal into a digital signal has advantages such as ease of processing and ease of storage and copying. """,,,,,-3
D-2020_U13,"""I learned about the types of signals and the benefits of digitization""",,,,,1
D-2020_U14,,"""I was able to understand the process of converting analog signals to digital signals (sampling and quantization)""",,,"""It was easy to understand with lots of examples""",0
D-2020_U14,,"""I was able to understand the process of converting analog signals to digital signals (sampling and quantization)""",,,"""It was easy to understand with lots of examples""",0
D-2020_U15,,"""Sampling, Quantization and Encoding Concepts""",,,,1
D-2020_U16,,,,,"""I want to finish my submission early""",-2
D-2020_U18,,"""I was able to gain a detailed understanding of the mechanisms and principles involved in converting analog signals into digital signals.
I was able to understand why digital signal processing is performed by knowing the merits. ""","""Nothing in particular.""",,"""Digital"" and ""analog"" are words that we often hear on a daily basis,
I never thought too much about the meaning.
However, in today's lecture, we will mainly focus on signals and know the difference between analog and digital.
I found it very useful because I was able to know the strengths and weaknesses of each. """,1
D-2020_U18,,"""I was able to gain a detailed understanding of the mechanisms and principles involved in converting analog signals into digital signals.
I was able to understand why digital signal processing is performed by knowing the merits. ""","""Nothing in particular.""",,"""Digital"" and ""analog"" are words that we often hear on a daily basis,
I never thought too much about the meaning.
However, in today's lecture, we will mainly focus on signals and know the difference between analog and digital.
I found it very useful because I was able to know the strengths and weaknesses of each. """,1
D-2020_U18,,"""I was able to gain a detailed understanding of the mechanisms and principles involved in converting analog signals into digital signals.
I was able to understand why digital signal processing is performed by knowing the merits. ""","""Nothing in particular.""",,"""Digital"" and ""analog"" are words that we often hear on a daily basis,
I never thought too much about the meaning.
However, in today's lecture, we will mainly focus on signals and know the difference between analog and digital.
I found it very useful because I was able to know the strengths and weaknesses of each. """,1
D-2020_U2,"""Signals can be classified into four types depending on whether the time and amplitude values ​​are continuous or discrete.
When A/D converts to a digital signal, (1) sampling, (2) quantization, and (3) encoding are performed. The advantage of digital signals is that they do not deteriorate and can be processed accurately. ""","""Three important points (sampling, quantization, encoding) of the principle of A/D converter were well understood.""","""Nothing in particular.""","""Nothing in particular.""",,1
D-2020_U2,"""Signals can be classified into four types depending on whether the time and amplitude values ​​are continuous or discrete.
When A/D converts to a digital signal, (1) sampling, (2) quantization, and (3) encoding are performed. The advantage of digital signals is that they do not deteriorate and can be processed accurately. ""","""Three important points (sampling, quantization, encoding) of the principle of A/D converter were well understood.""","""Nothing in particular.""","""Nothing in particular.""",,1
D-2020_U2,"""Signals can be classified into four types depending on whether the time and amplitude values ​​are continuous or discrete.
When A/D converts to a digital signal, (1) sampling, (2) quantization, and (3) encoding are performed. The advantage of digital signals is that they do not deteriorate and can be processed accurately. ""","""Three important points (sampling, quantization, encoding) of the principle of A/D converter were well understood.""","""Nothing in particular.""","""Nothing in particular.""",,1
D-2020_U2,"""Signals can be classified into four types depending on whether the time and amplitude values ​​are continuous or discrete.
When A/D converts to a digital signal, (1) sampling, (2) quantization, and (3) encoding are performed. The advantage of digital signals is that they do not deteriorate and can be processed accurately. ""","""Three important points (sampling, quantization, encoding) of the principle of A/D converter were well understood.""","""Nothing in particular.""","""Nothing in particular.""",,1
D-2020_U21,"""Digitalization has advantages and disadvantages
Digitization also makes it easier to process images. ""","""I found that if the D/A conversion was left as it was, problems would occur.""",,,,1
D-2020_U21,"""Digitalization has advantages and disadvantages
Digitization also makes it easier to process images. ""","""I found that if the D/A conversion was left as it was, problems would occur.""",,,,1
D-2020_U22,"""Processes and Characteristics of Digital Signal Processing""",,,,,1
D-2020_U23,,"""Characteristics of digital signals and an overview of digital signal processing.""",,,,-2
D-2020_U24,"""Today we learned about Fourier series.""",,,,,1
D-2020_U25,,"""Signals can be classified into four types by amplitude or time""",,,,1
D-2020_U26,"""Discrete Time in Digital Signals: Sampling
-> Make this amplitude a discrete value: quantization
-> Convert this to binary: Encoding""",,,,,1
D-2020_U27,"""Description of Fourier Series Expansion""","""Understood the meaning and usage of Fourier series expansion and complex Fourier series expansion""",,,,-1
D-2020_U27,"""Description of Fourier Series Expansion""","""Understood the meaning and usage of Fourier series expansion and complex Fourier series expansion""",,,,-1
D-2020_U28,,,"""None.""","""Nothing in particular.""",,0
D-2020_U28,,,"""None.""","""Nothing in particular.""",,0
D-2020_U29,"""Overview of digital signal processing. Learned about signal types, A/D conversion (sampling, quantization, coding), D/A conversion (sampling theorem), etc.""",,,"""I fully understand the merits of digital, but on the contrary, I wonder if there are any advantages of analog signals that are not treated as digital signals.""","""While listening to the lecture, I summarized the main points in a notebook. I thought it was easy to read.""",1
D-2020_U29,"""Overview of digital signal processing. Learned about signal types, A/D conversion (sampling, quantization, coding), D/A conversion (sampling theorem), etc.""",,,"""I fully understand the merits of digital, but on the contrary, I wonder if there are any advantages of analog signals that are not treated as digital signals.""","""While listening to the lecture, I summarized the main points in a notebook. I thought it was easy to read.""",1
D-2020_U29,"""Overview of digital signal processing. Learned about signal types, A/D conversion (sampling, quantization, coding), D/A conversion (sampling theorem), etc.""",,,"""I fully understand the merits of digital, but on the contrary, I wonder if there are any advantages of analog signals that are not treated as digital signals.""","""While listening to the lecture, I summarized the main points in a notebook. I thought it was easy to read.""",1
D-2020_U3,"""Types of signal processing and their overview (especially about digital signal processing)""",,,,,1
D-2020_U30,"""Overview of Fourier Series, Complex Fourier Series, and Spectra""",,,,,1
D-2020_U31,"""Signals are classified into four types according to whether they are continuous or discrete in time and amplitude.
An A/D converter is used to convert analog to digital. It is converted to digital through steps of sampling, quantization and encoding. ""","""Sampling, quantization, and encoding have been mentioned before, and I didn't understand them very well, but this time I was able to understand them.""",,,"""I thought I was a little short on notes.""",1
D-2020_U31,"""Signals are classified into four types according to whether they are continuous or discrete in time and amplitude.
An A/D converter is used to convert analog to digital. It is converted to digital through steps of sampling, quantization and encoding. ""","""Sampling, quantization, and encoding have been mentioned before, and I didn't understand them very well, but this time I was able to understand them.""",,,"""I thought I was a little short on notes.""",1
D-2020_U31,"""Signals are classified into four types according to whether they are continuous or discrete in time and amplitude.
An A/D converter is used to convert analog to digital. It is converted to digital through steps of sampling, quantization and encoding. ""","""Sampling, quantization, and encoding have been mentioned before, and I didn't understand them very well, but this time I was able to understand them.""",,,"""I thought I was a little short on notes.""",1
D-2020_U32,"""Converting an analog signal to a digital signal has many advantages.
Analog signals can be converted to digital signals by sampling, quantizing, and encoding. """,,,,,1
D-2020_U33,"""Applications of familiar signal processing""",,,,,0
D-2020_U35,"""How to Convert Analog Signals to Digital Signals and Advantages of Digital Signals""","""Digital signals have many advantages not only for personal computers but also for humans""",,,,-1
D-2020_U35,"""How to Convert Analog Signals to Digital Signals and Advantages of Digital Signals""","""Digital signals have many advantages not only for personal computers but also for humans""",,,,-1
D-2020_U36,,,,,"""Thanks to the appropriate use of diagrams and images in the teaching materials, I was able to gain a better understanding. Especially digital image processing was explained very carefully.""",1
D-2020_U37,"""What is Digital Signal Processing?""",,,,,1
D-2020_U39,"""Fundamentals of analog-to-digital conversion""",,,,"""It was easy to understand some of the content I had heard before.""",1
D-2020_U39,"""Fundamentals of analog-to-digital conversion""",,,,"""It was easy to understand some of the content I had heard before.""",1
D-2020_U4,,"""rough content""",,,,1
D-2020_U40,"""Overview of digital signal processing and introduction to its applications""","""I was able to fully understand how the sampling, quantization, and encoding processes of the A/D converter are performed.""",,,,1
D-2020_U40,"""Overview of digital signal processing and introduction to its applications""","""I was able to fully understand how the sampling, quantization, and encoding processes of the A/D converter are performed.""",,,,1
D-2020_U41,"""Overview of Digital Signal Processing
Sampling and quantization, encoding
Sampling theorem (amount of data required for reconstruction)""",,,,,0
D-2020_U42,"""Since this was the first session, we talked about basic knowledge such as what digital signal processing is and what its advantages are.""",,,,"""This class was clear and easy to understand.""",-1
D-2020_U42,"""Since this was the first session, we talked about basic knowledge such as what digital signal processing is and what its advantages are.""",,,,"""This class was clear and easy to understand.""",-1
D-2020_U43,,"""Types of signals and their characteristics (graph)
Methods for converting analog signals to digital signals (especially in image processing)""",,,,1
D-2020_U44,,,,,"""It was easy to understand because I haven't come up with formulas yet.""",1
D-2020_U45,"""In the signal framework, digital signals are viewed as signals with discrete amplitudes at discrete times.
If analog signals are converted to digital signals, they can be processed on a PC.
Digital signals have become indispensable in a wide range of fields because they can be processed by a PC.""","""I understand the principle of A/D conversion.""","""I don't know why the sampling theorem holds
What kind of noise is generated? """,,"""I'm glad it went so quickly""",0
D-2020_U45,"""In the signal framework, digital signals are viewed as signals with discrete amplitudes at discrete times.
If analog signals are converted to digital signals, they can be processed on a PC.
Digital signals have become indispensable in a wide range of fields because they can be processed by a PC.""","""I understand the principle of A/D conversion.""","""I don't know why the sampling theorem holds
What kind of noise is generated? """,,"""I'm glad it went so quickly""",0
D-2020_U45,"""In the signal framework, digital signals are viewed as signals with discrete amplitudes at discrete times.
If analog signals are converted to digital signals, they can be processed on a PC.
Digital signals have become indispensable in a wide range of fields because they can be processed by a PC.""","""I understand the principle of A/D conversion.""","""I don't know why the sampling theorem holds
What kind of noise is generated? """,,"""I'm glad it went so quickly""",0
D-2020_U45,"""In the signal framework, digital signals are viewed as signals with discrete amplitudes at discrete times.
If analog signals are converted to digital signals, they can be processed on a PC.
Digital signals have become indispensable in a wide range of fields because they can be processed by a PC.""","""I understand the principle of A/D conversion.""","""I don't know why the sampling theorem holds
What kind of noise is generated? """,,"""I'm glad it went so quickly""",0
D-2020_U47,"""Relationship and conversion between analog and digital signals such as sampling and quantization""","""I didn't have a good grasp of the image of sampling and quantization, but I was able to get a concrete image by looking at the graph transformation diagram.""","""Find the time to find out more about the benefits of digital signals""",,"""The digital signal of an image was mentioned as a familiar example, which increased my motivation for this subject.""",0
D-2020_U47,"""Relationship and conversion between analog and digital signals such as sampling and quantization""","""I didn't have a good grasp of the image of sampling and quantization, but I was able to get a concrete image by looking at the graph transformation diagram.""","""Find the time to find out more about the benefits of digital signals""",,"""The digital signal of an image was mentioned as a familiar example, which increased my motivation for this subject.""",0
D-2020_U47,"""Relationship and conversion between analog and digital signals such as sampling and quantization""","""I didn't have a good grasp of the image of sampling and quantization, but I was able to get a concrete image by looking at the graph transformation diagram.""","""Find the time to find out more about the benefits of digital signals""",,"""The digital signal of an image was mentioned as a familiar example, which increased my motivation for this subject.""",0
D-2020_U47,"""Relationship and conversion between analog and digital signals such as sampling and quantization""","""I didn't have a good grasp of the image of sampling and quantization, but I was able to get a concrete image by looking at the graph transformation diagram.""","""Find the time to find out more about the benefits of digital signals""",,"""The digital signal of an image was mentioned as a familiar example, which increased my motivation for this subject.""",0
D-2020_U48,,"""I was able to understand that signals can be classified into four types according to whether their time and amplitude are continuous or discrete, respectively, and the operations (sampling, quantization, encoding) that convert analog signals to digital signals.""","""I didn't know much about D/A conversion (especially the sampling theorem)""",,"""When I learned that digital signal processing is used in various fields, my interest grew.""",1
D-2020_U48,,"""I was able to understand that signals can be classified into four types according to whether their time and amplitude are continuous or discrete, respectively, and the operations (sampling, quantization, encoding) that convert analog signals to digital signals.""","""I didn't know much about D/A conversion (especially the sampling theorem)""",,"""When I learned that digital signal processing is used in various fields, my interest grew.""",1
D-2020_U48,,"""I was able to understand that signals can be classified into four types according to whether their time and amplitude are continuous or discrete, respectively, and the operations (sampling, quantization, encoding) that convert analog signals to digital signals.""","""I didn't know much about D/A conversion (especially the sampling theorem)""",,"""When I learned that digital signal processing is used in various fields, my interest grew.""",1
D-2020_U49,,"""It was mostly a review of what I had learned in technical college, but I was able to understand it again.""",,,,1
D-2020_U50,"""Signals are classified into four types: analog signals, multi-level signals, sampled signals, and digital signals, and the characteristics of each are checked in graphs.
A/D conversion involves the operations of sampling, quantization, and encoding.
In D/A conversion, whether or not the analog signal can be restored depends on whether or not the analog signal contains only frequency components below 1/2 of the sampling frequency.
Check the flow of digitization using an image as an example.
Sampling determines the number of pixels, and quantization converts the light intensity of each pixel into a numerical value. ""","""What kind of graph will the four types of signal forms look like?
How the sampling, quantization, and encoding operations are performed.
What number of bits is used to represent each pixel of an image? """,,,,0
D-2020_U50,"""Signals are classified into four types: analog signals, multi-level signals, sampled signals, and digital signals, and the characteristics of each are checked in graphs.
A/D conversion involves the operations of sampling, quantization, and encoding.
In D/A conversion, whether or not the analog signal can be restored depends on whether or not the analog signal contains only frequency components below 1/2 of the sampling frequency.
Check the flow of digitization using an image as an example.
Sampling determines the number of pixels, and quantization converts the light intensity of each pixel into a numerical value. ""","""What kind of graph will the four types of signal forms look like?
How the sampling, quantization, and encoding operations are performed.
What number of bits is used to represent each pixel of an image? """,,,,0
D-2020_U52,"""Signal classification and morphology,
conversion of analog and digital signals,
I learned about the application examples of digital signal processing. """,,,,"""When I looked around me, I realized that digital signal processing technology is used in unexpectedly familiar places, and I thought it would be interesting to learn about it from the basics.""",1
D-2020_U52,"""Signal classification and morphology,
conversion of analog and digital signals,
I learned about the application examples of digital signal processing. """,,,,"""When I looked around me, I realized that digital signal processing technology is used in unexpectedly familiar places, and I thought it would be interesting to learn about it from the basics.""",1
D-2020_U53,,"""It gave me a good understanding of how the conversion from analog to digital is done.""",,,"""I didn't prepare for class, so I'll do my best next time.""",-3
D-2020_U53,,"""It gave me a good understanding of how the conversion from analog to digital is done.""",,,"""I didn't prepare for class, so I'll do my best next time.""",-3
D-2020_U57,"""There are two main types of signals: continuous-time signals and discrete-time signals.
Sampling, quantization, and coding are performed in the A/D converter of the digital signal processing system, and the digitization of images was taken as an example to understand. ""","""I grasped the outline of the digital signal processing system.""",,,"""I forgot to press the button here and there.""",-1
D-2020_U57,"""There are two main types of signals: continuous-time signals and discrete-time signals.
Sampling, quantization, and coding are performed in the A/D converter of the digital signal processing system, and the digitization of images was taken as an example to understand. ""","""I grasped the outline of the digital signal processing system.""",,,"""I forgot to press the button here and there.""",-1
D-2020_U57,"""There are two main types of signals: continuous-time signals and discrete-time signals.
Sampling, quantization, and coding are performed in the A/D converter of the digital signal processing system, and the digitization of images was taken as an example to understand. ""","""I grasped the outline of the digital signal processing system.""",,,"""I forgot to press the button here and there.""",-1
D-2020_U59,"""Analog-to-digital conversion technology is used to express human senses in machines.""",,,,,-2
D-2020_U6,,"""Advantages of Digital Signals, Compatibility""","""Advantages of analog signals (other than being accurate information)""",,,1
D-2020_U6,,"""Advantages of Digital Signals, Compatibility""","""Advantages of analog signals (other than being accurate information)""",,,1
D-2020_U61,,"""Sampling, Quantization and Encoding, Methods of Converting Analog Information to Digital Information""",,,,-3
D-2020_U62,"""What is digital signal processing? I learned the classification, forms, characteristics, and advantages of signals. I also learned about various techniques using digital signal processing.""","""What is digital signal processing in general? Terms related to digital signal processing. Forms of signals. Characteristics and advantages of digital signal processing. Procedures for image processing, etc.""",,,"""I learned a little about image processing, which I am interested in. I learned that image processing can be done using digital signal processing. Images are expressed through procedures such as sampling, quantization, and encoding. understood.""",0
D-2020_U62,"""What is digital signal processing? I learned the classification, forms, characteristics, and advantages of signals. I also learned about various techniques using digital signal processing.""","""What is digital signal processing in general? Terms related to digital signal processing. Forms of signals. Characteristics and advantages of digital signal processing. Procedures for image processing, etc.""",,,"""I learned a little about image processing, which I am interested in. I learned that image processing can be done using digital signal processing. Images are expressed through procedures such as sampling, quantization, and encoding. understood.""",0
D-2020_U62,"""What is digital signal processing? I learned the classification, forms, characteristics, and advantages of signals. I also learned about various techniques using digital signal processing.""","""What is digital signal processing in general? Terms related to digital signal processing. Forms of signals. Characteristics and advantages of digital signal processing. Procedures for image processing, etc.""",,,"""I learned a little about image processing, which I am interested in. I learned that image processing can be done using digital signal processing. Images are expressed through procedures such as sampling, quantization, and encoding. understood.""",0
D-2020_U63,"""I deepened my understanding of what it means to classify signals and quantize and sample them based on examples of audio processing and image processing.""",,,,,0
D-2020_U64,"""Machines receive information from signals, and there are four types of signals depending on whether the time and amplitude are continuous or discrete. Digital signal processing is the process of converting analog signals into digital signals and then converting them back into analog signals. be.""","""We found that digital signals have various advantages, and that analog signals are converted to digital signals in many situations.""",,,,0
D-2020_U64,"""Machines receive information from signals, and there are four types of signals depending on whether the time and amplitude are continuous or discrete. Digital signal processing is the process of converting analog signals into digital signals and then converting them back into analog signals. be.""","""We found that digital signals have various advantages, and that analog signals are converted to digital signals in many situations.""",,,,0
D-2020_U66,,"""There is a basic theorem in digital signals called the sampling theorem, which is applied in various situations such as audio.""",,,,1
D-2020_U67,"""Description of digital information, about the connection between discrete and continuous information.""",,,,"""Digital signal processing seems to be the basis of various systems, so I thought I would learn it well.""",-2
D-2020_U67,"""Description of digital information, about the connection between discrete and continuous information.""",,,,"""Digital signal processing seems to be the basis of various systems, so I thought I would learn it well.""",-2
D-2020_U68,,"""I was able to systematically understand where the theorems related to signals that I learned in my second year were specifically used in signal processing.""",,,,-1
D-2020_U69,,,,,"""Since I play games a lot, it was good that the meaning of anti-aliasing was easy to understand.""",-2
D-2020_U7,"""Overview of Digital Signal Processing
(1) Signal classification
(2) Types of signal processing
(3) About A/D conversion
Learned with specific examples. ""","""Understood sampling, quantization, and coding in A/D conversion.""",,,,1
D-2020_U7,"""Overview of Digital Signal Processing
(1) Signal classification
(2) Types of signal processing
(3) About A/D conversion
Learned with specific examples. ""","""Understood sampling, quantization, and coding in A/D conversion.""",,,,1
D-2020_U8,,,"""I didn't know what kind of features and uses there are for multilevel signals and sampled signals, so I'd like to find out.""",,,-1
D-2021_U1,"""The general flow of converting information, which is a continuous analog signal, into a digital signal suitable for processing.
Classification of signals, verbal understanding of A/D conversion, characteristics of digital signal processing""","""A verbal understanding of the basic high-level flow of digital signal processing.""",,,"""I remembered a class that used MATLAB.
""",-1
D-2021_U1,"""The general flow of converting information, which is a continuous analog signal, into a digital signal suitable for processing.
Classification of signals, verbal understanding of A/D conversion, characteristics of digital signal processing""","""A verbal understanding of the basic high-level flow of digital signal processing.""",,,"""I remembered a class that used MATLAB.
""",-1
D-2021_U1,"""The general flow of converting information, which is a continuous analog signal, into a digital signal suitable for processing.
Classification of signals, verbal understanding of A/D conversion, characteristics of digital signal processing""","""A verbal understanding of the basic high-level flow of digital signal processing.""",,,"""I remembered a class that used MATLAB.
""",-1
D-2021_U100,"""Signals are divided into continuous-time signals and discrete-time signals that show continuous changes. Continuous-time signals are further classified into analog signals with continuous amplitude and multi-level signals with discrete amplitude. Discrete-time signals are also classified in the same way. These signals are classified into sampled signals and digital signals.The process of processing these signals to extract the desired characteristics and information is called signal processing.Among these, analog signals are converted into binary digital signals. The conversion system is called a digital signal processing system.The operations performed in the digital signal processing system include A/D conversion and D/A conversion.Sampling, quantization, and coding are among the A/D conversions. is performed and the analog signal is converted to a digital signal.In addition, the digital signal is restored to an analog signal in the D/A conversion. If not, the original signal can be completely reconstructed from the sample values.""
The digital signal processing of this kind of flow is characterized by excellent stability and flexibility of processing content, and the ability to perform more complicated processing. """,,,,"""It was good because I was able to take classes while using the Marker and BookLoll functions.
I think I was able to understand most of the content of the class. """,1
D-2021_U100,"""Signals are divided into continuous-time signals and discrete-time signals that show continuous changes. Continuous-time signals are further classified into analog signals with continuous amplitude and multi-level signals with discrete amplitude. Discrete-time signals are also classified in the same way. These signals are classified into sampled signals and digital signals.The process of processing these signals to extract the desired characteristics and information is called signal processing.Among these, analog signals are converted into binary digital signals. The conversion system is called a digital signal processing system.The operations performed in the digital signal processing system include A/D conversion and D/A conversion.Sampling, quantization, and coding are among the A/D conversions. is performed and the analog signal is converted to a digital signal.In addition, the digital signal is restored to an analog signal in the D/A conversion. If not, the original signal can be completely reconstructed from the sample values.""
The digital signal processing of this kind of flow is characterized by excellent stability and flexibility of processing content, and the ability to perform more complicated processing. """,,,,"""It was good because I was able to take classes while using the Marker and BookLoll functions.
I think I was able to understand most of the content of the class. """,1
D-2021_U101,,,,,"""I learned that it's good to take notes during class.""",1
D-2021_U102,"""I learned about signal classification, A/D conversion, which is the basis of digital signal processing, and the advantages of D/A conversion and digitization.""","""Sampling, quantization, and coding during A/D conversion I understood the sampling theorem during D/A conversion""",,,"""I'm not used to using BookRoll yet, so I want to get used to it as soon as possible.""",1
D-2021_U102,"""I learned about signal classification, A/D conversion, which is the basis of digital signal processing, and the advantages of D/A conversion and digitization.""","""Sampling, quantization, and coding during A/D conversion I understood the sampling theorem during D/A conversion""",,,"""I'm not used to using BookRoll yet, so I want to get used to it as soon as possible.""",1
D-2021_U102,"""I learned about signal classification, A/D conversion, which is the basis of digital signal processing, and the advantages of D/A conversion and digitization.""","""Sampling, quantization, and coding during A/D conversion I understood the sampling theorem during D/A conversion""",,,"""I'm not used to using BookRoll yet, so I want to get used to it as soon as possible.""",1
D-2021_U103,"""I learned the general contents such as the classification of signals, the flow of signal processing in analog and digital equipment, and the characteristics of digitization.""","""I only vaguely understood terms such as sampling, but knowing the classification of signals made my understanding deeper.""",,,"""I used the terms analog signal and digital signal as a matter of course, but it was good to know that there is a clear standard for classification.""",1
D-2021_U103,"""I learned the general contents such as the classification of signals, the flow of signal processing in analog and digital equipment, and the characteristics of digitization.""","""I only vaguely understood terms such as sampling, but knowing the classification of signals made my understanding deeper.""",,,"""I used the terms analog signal and digital signal as a matter of course, but it was good to know that there is a clear standard for classification.""",1
D-2021_U103,"""I learned the general contents such as the classification of signals, the flow of signal processing in analog and digital equipment, and the characteristics of digitization.""","""I only vaguely understood terms such as sampling, but knowing the classification of signals made my understanding deeper.""",,,"""I used the terms analog signal and digital signal as a matter of course, but it was good to know that there is a clear standard for classification.""",1
D-2021_U104,,"""How D/A and A/D converters work, and the theorems that explain them.""",,,,1
D-2021_U13,,,,,"""By converting it to a digital signal, it became possible to process it easily, so I wanted to know more about conversion standards for A/D converters and D/A converters.""",1
D-2021_U14,"""Signal classification, sampling, quantization, encoding, sampling theorem were the key words.
Remember that there are many types of signals in the classification of signals. The sampling theorem is an important topic that will come up in the future. ""","""Understood signal classification, A/D converters, and D/A converters.""","""Nothing in particular.""",,"""I'm worried about the future because there are a lot of things that seem to require a lot of calculations.""",1
D-2021_U14,"""Signal classification, sampling, quantization, encoding, sampling theorem were the key words.
Remember that there are many types of signals in the classification of signals. The sampling theorem is an important topic that will come up in the future. ""","""Understood signal classification, A/D converters, and D/A converters.""","""Nothing in particular.""",,"""I'm worried about the future because there are a lot of things that seem to require a lot of calculations.""",1
D-2021_U14,"""Signal classification, sampling, quantization, encoding, sampling theorem were the key words.
Remember that there are many types of signals in the classification of signals. The sampling theorem is an important topic that will come up in the future. ""","""Understood signal classification, A/D converters, and D/A converters.""","""Nothing in particular.""",,"""I'm worried about the future because there are a lot of things that seem to require a lot of calculations.""",1
D-2021_U14,"""Signal classification, sampling, quantization, encoding, sampling theorem were the key words.
Remember that there are many types of signals in the classification of signals. The sampling theorem is an important topic that will come up in the future. ""","""Understood signal classification, A/D converters, and D/A converters.""","""Nothing in particular.""",,"""I'm worried about the future because there are a lot of things that seem to require a lot of calculations.""",1
D-2021_U15,"""The difference between continuous and discrete signals, an overview of what digital signal processing does""","""There are two aspects of time and amplitude for both continuous and discrete signals.""",,,"""I realized again that digital signal processing plays a very important role today.""",1
D-2021_U15,"""The difference between continuous and discrete signals, an overview of what digital signal processing does""","""There are two aspects of time and amplitude for both continuous and discrete signals.""",,,"""I realized again that digital signal processing plays a very important role today.""",1
D-2021_U15,"""The difference between continuous and discrete signals, an overview of what digital signal processing does""","""There are two aspects of time and amplitude for both continuous and discrete signals.""",,,"""I realized again that digital signal processing plays a very important role today.""",1
D-2021_U16,"""Types of Signals, Converting Analog Signals to Digital Signals""","""A signal can be divided into four types, continuous or discrete, in terms of time and amplitude.""",,,,1
D-2021_U16,"""Types of Signals, Converting Analog Signals to Digital Signals""","""A signal can be divided into four types, continuous or discrete, in terms of time and amplitude.""",,,,1
D-2021_U17,"""Introduction to Digital Signal Processing""","""I now know how to refer to signals as continuous or discrete in time and amplitude, and what some basic terms mean.""",,,"""The class was often cut off in the middle, so I didn't understand what he was explaining during that time. (My friend had the same symptoms, so it seems to be a Teams problem.)
I was stressed because I had to wait for the operation to return to the library LGC because it was being read. """,1
D-2021_U17,"""Introduction to Digital Signal Processing""","""I now know how to refer to signals as continuous or discrete in time and amplitude, and what some basic terms mean.""",,,"""The class was often cut off in the middle, so I didn't understand what he was explaining during that time. (My friend had the same symptoms, so it seems to be a Teams problem.)
I was stressed because I had to wait for the operation to return to the library LGC because it was being read. """,1
D-2021_U17,"""Introduction to Digital Signal Processing""","""I now know how to refer to signals as continuous or discrete in time and amplitude, and what some basic terms mean.""",,,"""The class was often cut off in the middle, so I didn't understand what he was explaining during that time. (My friend had the same symptoms, so it seems to be a Teams problem.)
I was stressed because I had to wait for the operation to return to the library LGC because it was being read. """,1
D-2021_U18,"""Digital signal processing based on five senses
""",,,,,1
D-2021_U19,,"""Understood the types of signals""",,,"""I understand it at this stage. I will do my best to keep up.""",1
D-2021_U19,,"""Understood the types of signals""",,,"""I understand it at this stage. I will do my best to keep up.""",1
D-2021_U20,,"""Information must be input to machines as signals, and signals can be divided into four types depending on whether the time and amplitude are continuous or discrete.
In the A/D conversion process, there are processes such as sampling, quantization, and encoding.""",,,,1
D-2021_U21,"""What is Digital Signal Processing?""","""Digital signal processing is converting analog signals into digital signals""",,,,1
D-2021_U21,"""What is Digital Signal Processing?""","""Digital signal processing is converting analog signals into digital signals""",,,,1
D-2021_U22,,"""Signals are categorized into four types according to time, amplitude continuity, and discontinuity.
""",,,"""I was able to acquire basic knowledge about signal processing. From now on, I would like to deepen my understanding of each keyword in class.""",1
D-2021_U22,,"""Signals are categorized into four types according to time, amplitude continuity, and discontinuity.
""",,,"""I was able to acquire basic knowledge about signal processing. From now on, I would like to deepen my understanding of each keyword in class.""",1
D-2021_U23,,"""Signal processing extracts target information by processing the original information.
Sampling frequency (1/2 or less of the sampling frequency) determines whether or not it can be completely restored. """,,,,1
D-2021_U24,"""I learned the basic flow of digital signal processing.
I learned the names of signal types and processing methods. """,,,,"""It was easy to understand because the graphs were shown for each type of signal.
I mistakenly clicked the post button on the retrospective journal and the button to return to the previous page because they were too close to each other. """,-3
D-2021_U24,"""I learned the basic flow of digital signal processing.
I learned the names of signal types and processing methods. """,,,,"""It was easy to understand because the graphs were shown for each type of signal.
I mistakenly clicked the post button on the retrospective journal and the button to return to the previous page because they were too close to each other. """,-3
D-2021_U27,"""Understanding the procedure of digital signal processing. Signals are divided into four types based on continuous discrete time and amplitude. Examples of processing various analog signals into digital signals""","""Sampling an analog signal and converting it to a discrete sampled signal. Then quantizing it to make the signal correspond to a determined level. Then encoding it and converting the quantized signal to a binary digital code.""",,,,1
D-2021_U27,"""Understanding the procedure of digital signal processing. Signals are divided into four types based on continuous discrete time and amplitude. Examples of processing various analog signals into digital signals""","""Sampling an analog signal and converting it to a discrete sampled signal. Then quantizing it to make the signal correspond to a determined level. Then encoding it and converting the quantized signal to a binary digital code.""",,,,1
D-2021_U28,,,,,"""I was able to acquire basic knowledge of digital signal processing.""",1
D-2021_U29,,,"""I wondered if there was a difference between continuous and discrete amplitude graphs of discrete-time signals.""",,,1
D-2021_U31,,,"""I couldn't remember all the meanings of the vocabulary""",,,1
D-2021_U41,,"""Difference between Digital and Analog""","""A/D Converter Sampling Formula""",,"""I couldn't get an image of the formula x(n)=x(nT) for sampling.""",1
D-2021_U41,,"""Difference between Digital and Analog""","""A/D Converter Sampling Formula""",,"""I couldn't get an image of the formula x(n)=x(nT) for sampling.""",1
D-2021_U41,,"""Difference between Digital and Analog""","""A/D Converter Sampling Formula""",,"""I couldn't get an image of the formula x(n)=x(nT) for sampling.""",1
D-2021_U43,,"""Sampling, Encoding, Quantizing""",,,,1
D-2021_U45,"""Explanation of Words, Benefits of Digitization""","""Difference between Analog Signal Processing and Digital Signal Processing""",,,,-3
D-2021_U45,"""Explanation of Words, Benefits of Digitization""","""Difference between Analog Signal Processing and Digital Signal Processing""",,,,-3
D-2021_U46,"""If you want to reproduce the five human senses with a machine, you have to convert them into signals.""","""There are many types of signals that can be converted into signals, and they can be roughly divided into continuous-time signals and discrete-time signals.""",,,,1
D-2021_U46,"""If you want to reproduce the five human senses with a machine, you have to convert them into signals.""","""There are many types of signals that can be converted into signals, and they can be roughly divided into continuous-time signals and discrete-time signals.""",,,,1
D-2021_U49,"""In the field of signals, about the signals around us
Overview of Digital Signal Shari
""",,,,,1
D-2021_U54,,,,,"""I wanted to deepen my understanding of this lecture.""",0
D-2021_U56,,,,,"""I found it useful to be able to organize important parts in my own way with markers.""",1
D-2021_U57,"""Explanation of Basic Words in Signal Processing""","""sampling""",,,,0
D-2021_U57,"""Explanation of Basic Words in Signal Processing""","""sampling""",,,,0
D-2021_U61,"""On the basics of signals. They are classified according to whether or not they are continuous, and how they can take on values. Digital signal processing requires more steps than analog signal processing, but there are There are many advantages, such as flexibility.""",,,,"""I'm glad that I was able to understand what kind of digital signals there are. I'd like to take notes and deepen my understanding.""",1
D-2021_U61,"""On the basics of signals. They are classified according to whether or not they are continuous, and how they can take on values. Digital signal processing requires more steps than analog signal processing, but there are There are many advantages, such as flexibility.""",,,,"""I'm glad that I was able to understand what kind of digital signals there are. I'd like to take notes and deepen my understanding.""",1
D-2021_U62,"""Signals are divided into four types: continuous time, discrete time and continuous amplitude, and discrete amplitude. Digital signal processing requires various types of processing. The advantage of digital signal processing is that it is resistant to noise and does not deteriorate. There are various advantages such as sampling and quantization in signal processing.""","""The difference between continuous amplitude and discrete amplitude is that in continuous amplitude x(T) takes any value, but x(nT) takes only values ​​on a fixed scale. The sampling theorem states that an analog signal is 1 at sampling frequency T. If it contains only frequency components of /2 or less, it can be perfectly reproduced.If it contains more than 1/2, alias noise will occur.""",,,,1
D-2021_U62,"""Signals are divided into four types: continuous time, discrete time and continuous amplitude, and discrete amplitude. Digital signal processing requires various types of processing. The advantage of digital signal processing is that it is resistant to noise and does not deteriorate. There are various advantages such as sampling and quantization in signal processing.""","""The difference between continuous amplitude and discrete amplitude is that in continuous amplitude x(T) takes any value, but x(nT) takes only values ​​on a fixed scale. The sampling theorem states that an analog signal is 1 at sampling frequency T. If it contains only frequency components of /2 or less, it can be perfectly reproduced.If it contains more than 1/2, alias noise will occur.""",,,,1
D-2021_U63,"""The overview of digital signal processing was explained.""","""There are analog signals and digital signals in signals, and it was found that there is a sampling theorem that the original signal can be restored from the sample value depending on the frequency component of the analog signal.""",,,,1
D-2021_U63,"""The overview of digital signal processing was explained.""","""There are analog signals and digital signals in signals, and it was found that there is a sampling theorem that the original signal can be restored from the sample value depending on the frequency component of the analog signal.""",,,,1
D-2021_U64,"""Fourier series for analog and digital signals""","""On the general characteristics of digital signals""",,,"""It's helpful to know which page the student is looking at and where the marker is.""",1
D-2021_U64,"""Fourier series for analog and digital signals""","""On the general characteristics of digital signals""",,,"""It's helpful to know which page the student is looking at and where the marker is.""",1
D-2021_U64,"""Fourier series for analog and digital signals""","""On the general characteristics of digital signals""",,,"""It's helpful to know which page the student is looking at and where the marker is.""",1
D-2021_U67,,,,,"""I was able to get a rough overview of digital signal processing. There were some words I had heard before.""",1
D-2021_U69,,,,"""How fast is digital signal processing compared to analog signal processing?""","""I'm glad I was able to organize my own notes and mark important words on BookRoll. Especially since it was my first time using BookRoll so much, it was very fulfilling. I want to continue to do my best in this flow. """,1
D-2021_U69,,,,"""How fast is digital signal processing compared to analog signal processing?""","""I'm glad I was able to organize my own notes and mark important words on BookRoll. Especially since it was my first time using BookRoll so much, it was very fulfilling. I want to continue to do my best in this flow. """,1
D-2021_U70,,"""I understood roughly what the four types of signals were, and understood the general flow of the A/D converter and D/A converter.""","""Details of A/D and D/A converters.""",,,1
D-2021_U70,,"""I understood roughly what the four types of signals were, and understood the general flow of the A/D converter and D/A converter.""","""Details of A/D and D/A converters.""",,,1
D-2021_U71,"""Digital signal processing allows us to process signals precisely in a form that can be used by computers.""","""I learned about the benefits of signal types and digital signal processing.""",,,"""I understand a little bit about what digital signal processing is.""",0
D-2021_U71,"""Digital signal processing allows us to process signals precisely in a form that can be used by computers.""","""I learned about the benefits of signal types and digital signal processing.""",,,"""I understand a little bit about what digital signal processing is.""",0
D-2021_U71,"""Digital signal processing allows us to process signals precisely in a form that can be used by computers.""","""I learned about the benefits of signal types and digital signal processing.""",,,"""I understand a little bit about what digital signal processing is.""",0
D-2021_U72,"""I learned analog to digital conversion""",,"""I could only vaguely understand the whole thing.""",,,1
D-2021_U72,"""I learned analog to digital conversion""",,"""I could only vaguely understand the whole thing.""",,,1
D-2021_U73,"""Overview of Digital Signal Processing
Basic Knowledge of Signals""","""I was able to understand what kind of operations digital signal processing involves.
I was able to understand 4 signals for signal classification""","""I was writing on the blackboard and using markers, and I was worried whether I could vote for understanding on all the slides.""",,,1
D-2021_U73,"""Overview of Digital Signal Processing
Basic Knowledge of Signals""","""I was able to understand what kind of operations digital signal processing involves.
I was able to understand 4 signals for signal classification""","""I was writing on the blackboard and using markers, and I was worried whether I could vote for understanding on all the slides.""",,,1
D-2021_U73,"""Overview of Digital Signal Processing
Basic Knowledge of Signals""","""I was able to understand what kind of operations digital signal processing involves.
I was able to understand 4 signals for signal classification""","""I was writing on the blackboard and using markers, and I was worried whether I could vote for understanding on all the slides.""",,,1
D-2021_U74,,,,,"""I was able to learn about fields where knowledge of digital signal processing is useful, and my motivation to learn increased. From next time, I would like to proceed with handwritten notes in parallel with class.""",1
D-2021_U75,,,"""I would like to study and understand what I didn't understand much about the contents when I am compiling my notes.""",,"""It was interesting to have different learning tools.""",1
D-2021_U75,,,"""I would like to study and understand what I didn't understand much about the contents when I am compiling my notes.""",,"""It was interesting to have different learning tools.""",1
D-2021_U77,,,,,"""I thought that the content of the lessons from now on would be important content that is often used in modern society.""",1
D-2021_U79,,"""An analog signal was a signal consisting of continuous time and continuous amplitude, but in order to convert it to a digital signal, it is necessary to discretize it in the time direction by sampling and discretize it in the amplitude direction by quantization. That means.""",,,"""I was able to understand well how to convert to a digital signal and how to distinguish between time and amplitude.""",1
D-2021_U79,,"""An analog signal was a signal consisting of continuous time and continuous amplitude, but in order to convert it to a digital signal, it is necessary to discretize it in the time direction by sampling and discretize it in the amplitude direction by quantization. That means.""",,,"""I was able to understand well how to convert to a digital signal and how to distinguish between time and amplitude.""",1
D-2021_U81,,"""Signals can be classified into four types.
Converting an analog signal to a digital signal has various advantages. ""","""How to distinguish between sampled and digital signals.""","""How to distinguish between the two signals in (3).""",,1
D-2021_U81,,"""Signals can be classified into four types.
Converting an analog signal to a digital signal has various advantages. ""","""How to distinguish between sampled and digital signals.""","""How to distinguish between the two signals in (3).""",,1
D-2021_U81,,"""Signals can be classified into four types.
Converting an analog signal to a digital signal has various advantages. ""","""How to distinguish between sampled and digital signals.""","""How to distinguish between the two signals in (3).""",,1
D-2021_U82,"""Signal Classification/Digital Signal Processing""","""Difference between analog signal processing and digital signal processing""",,,"""So far I understand.""",1
D-2021_U82,"""Signal Classification/Digital Signal Processing""","""Difference between analog signal processing and digital signal processing""",,,"""So far I understand.""",1
D-2021_U82,"""Signal Classification/Digital Signal Processing""","""Difference between analog signal processing and digital signal processing""",,,"""So far I understand.""",1
D-2021_U83,,"""Signal types and representative examples""",,,,1
D-2021_U84,"""I learned the basics of digital signal processing.
I learned about the meaning of important words such as sampling and quantization. """,,,,"""It was easy to understand because I had prepared.""",1
D-2021_U84,"""I learned the basics of digital signal processing.
I learned about the meaning of important words such as sampling and quantization. """,,,,"""It was easy to understand because I had prepared.""",1
D-2021_U85,,"""I understood the process of converting analog signals into digital signals. I understood how convenient digital signals are.""","""In the sampling theorem, I didn't understand why the frequency component can't be restored unless it is less than 1/2.""",,,1
D-2021_U85,,"""I understood the process of converting analog signals into digital signals. I understood how convenient digital signals are.""","""In the sampling theorem, I didn't understand why the frequency component can't be restored unless it is less than 1/2.""",,,1
D-2021_U86,"""Types and Principles of Signal Processing""",,,,"""It was easy to understand""",1
D-2021_U86,"""Types and Principles of Signal Processing""",,,,"""It was easy to understand""",1
D-2021_U87,,,,,"""My preparation was a little lax, so from next time onwards, I'll prepare properly before attending.""",1
D-2021_U88,,,"""Frequency components less than half the sampling frequency of the sampling theorem is a mystery""",,,1
D-2021_U89,,"""Difference between digital signal and analog signal, mechanism of conversion""",,,,1
D-2021_U90,"""A detailed summary of the features of digital signal processing.""",,,,"""There's a lot to write, and I can't make it in time for class.""",1
D-2021_U90,"""A detailed summary of the features of digital signal processing.""",,,,"""There's a lot to write, and I can't make it in time for class.""",1
D-2021_U91,,,,,"""I was intrigued by the specific examples.""",1
D-2021_U93,"""Digital signal processing is also widely used in medical engineering and economics.
In addition, there are two types of signals, continuous and discontinuous, in terms of time and amplitude, respectively.
Making them continuous -> discontinuous is called sampling (time) and quantization (amplitude). ""","""I understand the definitions of words that appear in signal processing (sampling, quantum, or discretization).""",,,"""I was able to concentrate and listen to the story from beginning to end.
It was easy to understand because it was explained in an easy-to-understand manner with images. """,1
D-2021_U93,"""Digital signal processing is also widely used in medical engineering and economics.
In addition, there are two types of signals, continuous and discontinuous, in terms of time and amplitude, respectively.
Making them continuous -> discontinuous is called sampling (time) and quantization (amplitude). ""","""I understand the definitions of words that appear in signal processing (sampling, quantum, or discretization).""",,,"""I was able to concentrate and listen to the story from beginning to end.
It was easy to understand because it was explained in an easy-to-understand manner with images. """,1
D-2021_U93,"""Digital signal processing is also widely used in medical engineering and economics.
In addition, there are two types of signals, continuous and discontinuous, in terms of time and amplitude, respectively.
Making them continuous -> discontinuous is called sampling (time) and quantization (amplitude). ""","""I understand the definitions of words that appear in signal processing (sampling, quantum, or discretization).""",,,"""I was able to concentrate and listen to the story from beginning to end.
It was easy to understand because it was explained in an easy-to-understand manner with images. """,1
D-2021_U94,"""I learned the basics of digital signal processing, such as types of signals and sampling for signal processing.""","""Signals have both continuous and discrete amplitudes and recording times, and I was able to understand the procedure for signal processing that converts them.""","""I still didn't know much about the sampling theorem.""",,,1
D-2021_U94,"""I learned the basics of digital signal processing, such as types of signals and sampling for signal processing.""","""Signals have both continuous and discrete amplitudes and recording times, and I was able to understand the procedure for signal processing that converts them.""","""I still didn't know much about the sampling theorem.""",,,1
D-2021_U94,"""I learned the basics of digital signal processing, such as types of signals and sampling for signal processing.""","""Signals have both continuous and discrete amplitudes and recording times, and I was able to understand the procedure for signal processing that converts them.""","""I still didn't know much about the sampling theorem.""",,,1
D-2021_U96,,,,"""In what situations do multilevel signals appear?""","""It was easy to understand because there were many words I had heard before.
I learned about digital signal processing, which is used in everyday life, and my interest in the content of the course increased. """,1
D-2021_U96,,,,"""In what situations do multilevel signals appear?""","""It was easy to understand because there were many words I had heard before.
I learned about digital signal processing, which is used in everyday life, and my interest in the content of the course increased. """,1
D-2021_U97,,"""Basic terms and concepts of signals and signal processing.
Sampling converts an analog signal into a sampled signal by discretizing it in the time direction.
Quantization converts a sampled signal into a digital signal by discretizing it in the amplitude direction. """,,,,1
D-2021_U98,"""Formula Explanation of Fourier Series""",,,,,-1
D-2021_U99,,"""We learned that unless the sampling frequency is more than twice the maximum frequency of analog values, noise that did not exist originally will occur.
Digital signal processing has been found to be applied in various fields. """,,,"""The explanation was very detailed and easy to understand!!""",1
D-2021_U99,,"""We learned that unless the sampling frequency is more than twice the maximum frequency of analog values, noise that did not exist originally will occur.
Digital signal processing has been found to be applied in various fields. """,,,"""The explanation was very detailed and easy to understand!!""",1
D-2022_U1,,"""Digital signal processing may require mathematical knowledge""",,,,0
D-2022_U13,"""Signals have continuous and discrete amplitudes as well as time.
Digital signal processing includes processes such as sampling, quantization, and encoding.
Digital Shigaraki processing has various advantages. """,,,,,-1
D-2022_U14,,,"""Regarding the sampling theorem, I didn't have a mathematical formula for the frequency component below 1/2 of the sampling frequency, so I had a hard time imagining it.""",,,1
D-2022_U21,"""I learned how to convert an analog signal to a digital signal and examples of how the technology is used.""","""I learned how digital signals such as images and sounds are processed (sampling → quantization → encoding, etc.)""",,,"""I'm curious as to what kind of calculations are being done.""",1
D-2022_U21,"""I learned how to convert an analog signal to a digital signal and examples of how the technology is used.""","""I learned how digital signals such as images and sounds are processed (sampling → quantization → encoding, etc.)""",,,"""I'm curious as to what kind of calculations are being done.""",1
D-2022_U21,"""I learned how to convert an analog signal to a digital signal and examples of how the technology is used.""","""I learned how digital signals such as images and sounds are processed (sampling → quantization → encoding, etc.)""",,,"""I'm curious as to what kind of calculations are being done.""",1
D-2022_U24,,,,,"""I felt a sense of familiarity with the fact that signal processing is familiar and used in various ways.""",1
D-2022_U25,"""All kinds of information are input as signals, and the signals are roughly classified into four types. Signal processing systems are classified according to the continuity of time components, linearity, time invariance, causality, etc. Perform a certain transformation. A system is said to be linear if two conditions are met. Digitization has all the advantages.""","""Signals are classified into four types depending on whether the time and amplitude value are continuous or discontinuous.""","""I could not quite understand the meaning of the graph of the amplitude value of the signal over time in the form of the signal.""",,"""I've spent a lot of time trying to understand the lectures, so I would like to make sure that I can fully understand the lectures as they are in a field that may be of personal interest to me.""",1
D-2022_U25,"""All kinds of information are input as signals, and the signals are roughly classified into four types. Signal processing systems are classified according to the continuity of time components, linearity, time invariance, causality, etc. Perform a certain transformation. A system is said to be linear if two conditions are met. Digitization has all the advantages.""","""Signals are classified into four types depending on whether the time and amplitude value are continuous or discontinuous.""","""I could not quite understand the meaning of the graph of the amplitude value of the signal over time in the form of the signal.""",,"""I've spent a lot of time trying to understand the lectures, so I would like to make sure that I can fully understand the lectures as they are in a field that may be of personal interest to me.""",1
D-2022_U25,"""All kinds of information are input as signals, and the signals are roughly classified into four types. Signal processing systems are classified according to the continuity of time components, linearity, time invariance, causality, etc. Perform a certain transformation. A system is said to be linear if two conditions are met. Digitization has all the advantages.""","""Signals are classified into four types depending on whether the time and amplitude value are continuous or discontinuous.""","""I could not quite understand the meaning of the graph of the amplitude value of the signal over time in the form of the signal.""",,"""I've spent a lot of time trying to understand the lectures, so I would like to make sure that I can fully understand the lectures as they are in a field that may be of personal interest to me.""",1
D-2022_U25,"""All kinds of information are input as signals, and the signals are roughly classified into four types. Signal processing systems are classified according to the continuity of time components, linearity, time invariance, causality, etc. Perform a certain transformation. A system is said to be linear if two conditions are met. Digitization has all the advantages.""","""Signals are classified into four types depending on whether the time and amplitude value are continuous or discontinuous.""","""I could not quite understand the meaning of the graph of the amplitude value of the signal over time in the form of the signal.""",,"""I've spent a lot of time trying to understand the lectures, so I would like to make sure that I can fully understand the lectures as they are in a field that may be of personal interest to me.""",1
D-2022_U26,,"""I understand the benefits of digital signals and what they do with digital signal processing.""",,,,1
D-2022_U28,"""An explanation of what digital signal processing is and where it is used.""",,,,,1
D-2022_U29,"""I learned the basic definitions (?) of analog and digital signals, and the basics of A/D conversion such as sampling, quantization, and coding shallowly and broadly.""","""Mechanism of signal processing""",,,,1
D-2022_U29,"""I learned the basic definitions (?) of analog and digital signals, and the basics of A/D conversion such as sampling, quantization, and coding shallowly and broadly.""","""Mechanism of signal processing""",,,,1
D-2022_U31,,"""Today I finally understood that the sampling theorem, which I learned in the signal and system class, is important in digital->analog conversion. Sampled signals and digital signals are """,,,,0
D-2022_U32,"""Explains the differences between digital and analog signals and their respective advantages and disadvantages.""","""Analog signals are continuous signals that are difficult to remove noise and tend to deteriorate, and cannot be processed by computers. Digital signals, on the other hand, are discrete signals that are resistant to noise and can be expected to be transmitted with high precision. can be processed with """,,,"""There were times when I missed the lectures because the speed of drawing the markers was slow, so I want to get used to the lectures and speed up my movements.""",1
D-2022_U32,"""Explains the differences between digital and analog signals and their respective advantages and disadvantages.""","""Analog signals are continuous signals that are difficult to remove noise and tend to deteriorate, and cannot be processed by computers. Digital signals, on the other hand, are discrete signals that are resistant to noise and can be expected to be transmitted with high precision. can be processed with """,,,"""There were times when I missed the lectures because the speed of drawing the markers was slow, so I want to get used to the lectures and speed up my movements.""",1
D-2022_U32,"""Explains the differences between digital and analog signals and their respective advantages and disadvantages.""","""Analog signals are continuous signals that are difficult to remove noise and tend to deteriorate, and cannot be processed by computers. Digital signals, on the other hand, are discrete signals that are resistant to noise and can be expected to be transmitted with high precision. can be processed with """,,,"""There were times when I missed the lectures because the speed of drawing the markers was slow, so I want to get used to the lectures and speed up my movements.""",1
D-2022_U33,"""I learned about the types of signals and an overview of signal processing systems.""",,,,"""I learned about signals in the signal and system course that I took in my second year, but I think I was able to review the overview because there was a lot of knowledge that was missing.""",0
D-2022_U33,"""I learned about the types of signals and an overview of signal processing systems.""",,,,"""I learned about signals in the signal and system course that I took in my second year, but I think I was able to review the overview because there was a lot of knowledge that was missing.""",0
D-2022_U34,,,,,"""It was good that the explanation was clear and easy to understand.""",1
D-2022_U35,,,"""There was nothing in particular that I didn't understand.""",,"""I was able to listen to the lecture while using BookRoll's marker and memo functions, which was very useful when I took notes later.""",1
D-2022_U35,,,"""There was nothing in particular that I didn't understand.""",,"""I was able to listen to the lecture while using BookRoll's marker and memo functions, which was very useful when I took notes later.""",1
D-2022_U36,,"""Flow of A/D conversion.""","""Benefits of converting to digital signals. D/A conversion (particularly the restoration of the sampling theorem and so on).""",,"""Recently I've heard a lot about organic EL and 4K.",1
D-2022_U36,,"""Flow of A/D conversion.""","""Benefits of converting to digital signals. D/A conversion (particularly the restoration of the sampling theorem and so on).""",,"""Recently I've heard a lot about organic EL and 4K.",1
D-2022_U36,,"""Flow of A/D conversion.""","""Benefits of converting to digital signals. D/A conversion (particularly the restoration of the sampling theorem and so on).""",,"""Recently I've heard a lot about organic EL and 4K.",1
D-2022_U37,"""What is a signal, what is signal processing, what is digital signal processing, and specific examples of how signal processing is used were explained.""",,,"""In what areas does analog signal processing greatly outperform digital signal processing?""","""Looking back, it seems that most of the signal processing in the world is not analog signal processing but digital signal processing. I was also interested in sensors that recognize signals. It was refreshing to have quantization with levels other than 01. In addition, since I had only analog and digital signals in mind, I was able to create sampled signals and multi-valued signals that were continuous only on one side of time and amplitude. looked fresh.""",-1
D-2022_U37,"""What is a signal, what is signal processing, what is digital signal processing, and specific examples of how signal processing is used were explained.""",,,"""In what areas does analog signal processing greatly outperform digital signal processing?""","""Looking back, it seems that most of the signal processing in the world is not analog signal processing but digital signal processing. I was also interested in sensors that recognize signals. It was refreshing to have quantization with levels other than 01. In addition, since I had only analog and digital signals in mind, I was able to create sampled signals and multi-valued signals that were continuous only on one side of time and amplitude. looked fresh.""",-1
D-2022_U37,"""What is a signal, what is signal processing, what is digital signal processing, and specific examples of how signal processing is used were explained.""",,,"""In what areas does analog signal processing greatly outperform digital signal processing?""","""Looking back, it seems that most of the signal processing in the world is not analog signal processing but digital signal processing. I was also interested in sensors that recognize signals. It was refreshing to have quantization with levels other than 01. In addition, since I had only analog and digital signals in mind, I was able to create sampled signals and multi-valued signals that were continuous only on one side of time and amplitude. looked fresh.""",-1
D-2022_U39,"""When a signal is periodic, it can be represented by the Fourier series of trigonometric functions.
Fourier series can be converted to complex Fourier series
""","""Derivation from Fourier series to complex Fourier series
Derivation of Fourier Coefficients""",,,,1
D-2022_U39,"""When a signal is periodic, it can be represented by the Fourier series of trigonometric functions.
Fourier series can be converted to complex Fourier series
""","""Derivation from Fourier series to complex Fourier series
Derivation of Fourier Coefficients""",,,,1
D-2022_U40,,"""Due to the sampling period when digitizing, it is not possible to return to an analog signal perfectly""",,,,1
D-2022_U41,,"""The Difference Between Sampling, Quantizing, and Encoding
""","""Sampled and Digital Signals""",,"""I became interested in signal processing after learning about AD conversion in general.""",0
D-2022_U41,,"""The Difference Between Sampling, Quantizing, and Encoding
""","""Sampled and Digital Signals""",,"""I became interested in signal processing after learning about AD conversion in general.""",0
D-2022_U41,,"""The Difference Between Sampling, Quantizing, and Encoding
""","""Sampled and Digital Signals""",,"""I became interested in signal processing after learning about AD conversion in general.""",0
D-2022_U42,"""I learned about the outline and characteristics of digital signal processing.""",,,,"""Also, it was interesting to see that digital signal processing can be used for taste sensors and visual angle information processing. It was easier to understand because there were reference images for sampling.""",1
D-2022_U42,"""I learned about the outline and characteristics of digital signal processing.""",,,,"""Also, it was interesting to see that digital signal processing can be used for taste sensors and visual angle information processing. It was easier to understand because there were reference images for sampling.""",1
D-2022_U43,,"""Using the sampling theorem, I found that digital can be converted and restored to analog.""","""I didn't understand the analog low-pass filter very well.""",,,1
D-2022_U43,,"""Using the sampling theorem, I found that digital can be converted and restored to analog.""","""I didn't understand the analog low-pass filter very well.""",,,1
D-2022_U45,"""Introduction to some terminology of digital signal processing
about signals and signal processing""",,,,"""It was easy to understand
A very rewarding class.""",1
D-2022_U45,"""Introduction to some terminology of digital signal processing
about signals and signal processing""",,,,"""It was easy to understand
A very rewarding class.""",1
D-2022_U47,,,,,"""I haven't gotten used to it yet, and it took me some time""",1
D-2022_U5,"""There are various forms such as continuous-time signals and discrete-time signals. There are several procedures for converting digital signals, such as filters that cut unnecessary harmonic components during A/D conversion and D/A conversion. Is necessary.""","""I was able to understand a little about the outline of the digital conversion process.""",,,,-2
D-2022_U5,"""There are various forms such as continuous-time signals and discrete-time signals. There are several procedures for converting digital signals, such as filters that cut unnecessary harmonic components during A/D conversion and D/A conversion. Is necessary.""","""I was able to understand a little about the outline of the digital conversion process.""",,,,-2
D-2022_U51,,,"""I didn't know how to specifically express the conditions for noise generation with a formula.""",,,1
D-2022_U52,"""Sampling (Discretize waves by sampling frequency) → Quantization (Determine division scale) → Encoding (Convert quantized value to 2bit)""","""Quantization has also appeared in information theory, so knowledge is connected.""",,,,1
D-2022_U52,"""Sampling (Discretize waves by sampling frequency) → Quantization (Determine division scale) → Encoding (Convert quantized value to 2bit)""","""Quantization has also appeared in information theory, so knowledge is connected.""",,,,1
D-2022_U53,"""We classify signals according to whether they are taken discretely or continuously in the time and amplitude directions. The sampling theorem states that if an analog signal contains only half the frequency components of the sampling frequency, Restorable.""","""Lesson format, how to proceed.""","""I didn't quite understand the sampling theorem.""",,,-2
D-2022_U53,"""We classify signals according to whether they are taken discretely or continuously in the time and amplitude directions. The sampling theorem states that if an analog signal contains only half the frequency components of the sampling frequency, Restorable.""","""Lesson format, how to proceed.""","""I didn't quite understand the sampling theorem.""",,,-2
D-2022_U53,"""We classify signals according to whether they are taken discretely or continuously in the time and amplitude directions. The sampling theorem states that if an analog signal contains only half the frequency components of the sampling frequency, Restorable.""","""Lesson format, how to proceed.""","""I didn't quite understand the sampling theorem.""",,,-2
D-2022_U54,,,,,"""I want to prepare well for the next Fourier series.""",1
D-2022_U55,"""Types of signals and mechanisms of digital signal processing systems for signal processing""","""Signals include analog signals, multilevel signals, sampled signals, and digital signals.
A/D converters in digital signal processing systems are sampling, quantizing, and encoding
Reconstruction of analog signals with frequencies less than half the sampling frequency produces no noise, while analog signals with frequencies above half the sampling frequency produce noise.
""","""Submission to Library LGC""",,,1
D-2022_U55,"""Types of signals and mechanisms of digital signal processing systems for signal processing""","""Signals include analog signals, multilevel signals, sampled signals, and digital signals.
A/D converters in digital signal processing systems are sampling, quantizing, and encoding
Reconstruction of analog signals with frequencies less than half the sampling frequency produces no noise, while analog signals with frequencies above half the sampling frequency produce noise.
""","""Submission to Library LGC""",,,1
D-2022_U55,"""Types of signals and mechanisms of digital signal processing systems for signal processing""","""Signals include analog signals, multilevel signals, sampled signals, and digital signals.
A/D converters in digital signal processing systems are sampling, quantizing, and encoding
Reconstruction of analog signals with frequencies less than half the sampling frequency produces no noise, while analog signals with frequencies above half the sampling frequency produce noise.
""","""Submission to Library LGC""",,,1
D-2022_U56,"""I learned an overview of digital signal processing. I learned about important words.""",,,,"""I was able to understand the words that I didn't really understand in the second semester class.""",1
D-2022_U56,"""I learned an overview of digital signal processing. I learned about important words.""",,,,"""I was able to understand the words that I didn't really understand in the second semester class.""",1
D-2022_U57,"""Types and forms of signals, system overview and advantages of digital signal processing.""","""I understood the outline of the signal processing system and understood that sampling, quantization, and encoding are performed in the A/D converter.""","""Nothing in particular.""",,,1
D-2022_U57,"""Types and forms of signals, system overview and advantages of digital signal processing.""","""I understood the outline of the signal processing system and understood that sampling, quantization, and encoding are performed in the A/D converter.""","""Nothing in particular.""",,,1
D-2022_U57,"""Types and forms of signals, system overview and advantages of digital signal processing.""","""I understood the outline of the signal processing system and understood that sampling, quantization, and encoding are performed in the A/D converter.""","""Nothing in particular.""",,,1
D-2022_U58,"""I learned about the basics of digital signal processing. I learned signal classification, signal processing system classification, and application of signal processing.""","""I was able to understand the classification of signals and the properties of signal processing systems. I was also able to learn practical examples of signal processing.""",,,"""I think it was good to know what kind of technology signal processing is applied to.""",1
D-2022_U58,"""I learned about the basics of digital signal processing. I learned signal classification, signal processing system classification, and application of signal processing.""","""I was able to understand the classification of signals and the properties of signal processing systems. I was also able to learn practical examples of signal processing.""",,,"""I think it was good to know what kind of technology signal processing is applied to.""",1
D-2022_U58,"""I learned about the basics of digital signal processing. I learned signal classification, signal processing system classification, and application of signal processing.""","""I was able to understand the classification of signals and the properties of signal processing systems. I was also able to learn practical examples of signal processing.""",,,"""I think it was good to know what kind of technology signal processing is applied to.""",1
D-2022_U59,,,"""How the spectrum relates to the properties of the signal""",,,1
D-2022_U60,"""I learned a lot of keywords for digital signal processing.""","""I was able to understand the whole picture of digital signal processing somehow.""","""Sampling theorem and more.""",,,1
D-2022_U60,"""I learned a lot of keywords for digital signal processing.""","""I was able to understand the whole picture of digital signal processing somehow.""","""Sampling theorem and more.""",,,1
D-2022_U60,"""I learned a lot of keywords for digital signal processing.""","""I was able to understand the whole picture of digital signal processing somehow.""","""Sampling theorem and more.""",,,1
D-2022_U61,"""I gave a rough overview of the whole digital signal.""",,,,,1
D-2022_U62,,"""There are four classifications of signals according to time and amplitude, the process of conversion (sampling, quantization, encoding) from an analog signal that is continuous in both to a digital signal that is discrete in both (sampling, quantization, encoding), and the nature of the signal. and the characteristics of digital signal processing.""","""About the concrete formula of the sampling theorem.""","""None.""",,1
D-2022_U62,,"""There are four classifications of signals according to time and amplitude, the process of conversion (sampling, quantization, encoding) from an analog signal that is continuous in both to a digital signal that is discrete in both (sampling, quantization, encoding), and the nature of the signal. and the characteristics of digital signal processing.""","""About the concrete formula of the sampling theorem.""","""None.""",,1
D-2022_U62,,"""There are four classifications of signals according to time and amplitude, the process of conversion (sampling, quantization, encoding) from an analog signal that is continuous in both to a digital signal that is discrete in both (sampling, quantization, encoding), and the nature of the signal. and the characteristics of digital signal processing.""","""About the concrete formula of the sampling theorem.""","""None.""",,1
D-2022_U65,"""Overview of Digital Signal Processing""",,,,"""This lesson will be the basis for future classes, so I will review it thoroughly.""",0
D-2022_U65,"""Overview of Digital Signal Processing""",,,,"""This lesson will be the basis for future classes, so I will review it thoroughly.""",0
D-2022_U66,,"""I learned the basics of digital signal processing
""",,,,-1
D-2022_U69,,"""It turns out that there are four types of signals.""","""I wondered if there would be anything to learn about multilevel signals in the future.""","""I wondered if there would be anything to learn about multilevel signals in the future.""",,1
D-2022_U69,,"""It turns out that there are four types of signals.""","""I wondered if there would be anything to learn about multilevel signals in the future.""","""I wondered if there would be anything to learn about multilevel signals in the future.""",,1
D-2022_U69,,"""It turns out that there are four types of signals.""","""I wondered if there would be anything to learn about multilevel signals in the future.""","""I wondered if there would be anything to learn about multilevel signals in the future.""",,1
D-2022_U7,"""Overview of Digital Signal Processing""","""I understood the general flow of the digital signal processing system.""","""I only vaguely understood the quantization and encoding of sampled signals.""",,"""It was good because I could roughly understand what digital signal processing is. Because it was online, I forgot about the class and missed it. It took me a long time to understand the material by myself. I'm sorry, so I'll try to remember to attend first.""",1
D-2022_U7,"""Overview of Digital Signal Processing""","""I understood the general flow of the digital signal processing system.""","""I only vaguely understood the quantization and encoding of sampled signals.""",,"""It was good because I could roughly understand what digital signal processing is. Because it was online, I forgot about the class and missed it. It took me a long time to understand the material by myself. I'm sorry, so I'll try to remember to attend first.""",1
D-2022_U7,"""Overview of Digital Signal Processing""","""I understood the general flow of the digital signal processing system.""","""I only vaguely understood the quantization and encoding of sampled signals.""",,"""It was good because I could roughly understand what digital signal processing is. Because it was online, I forgot about the class and missed it. It took me a long time to understand the material by myself. I'm sorry, so I'll try to remember to attend first.""",1
D-2022_U7,"""Overview of Digital Signal Processing""","""I understood the general flow of the digital signal processing system.""","""I only vaguely understood the quantization and encoding of sampled signals.""",,"""It was good because I could roughly understand what digital signal processing is. Because it was online, I forgot about the class and missed it. It took me a long time to understand the material by myself. I'm sorry, so I'll try to remember to attend first.""",1
D-2022_U71,"""Machine cannot process in analog state.""",,,,,-3
D-2022_U72,"""Explanation of basic terms in digital signal processing and introduction of specific examples of signal processing""","""I was able to generally understand the meaning of terms I had never heard before, such as sampling, sampling theorem, quantization, and encoding.""","""I didn't quite understand how to distinguish between sampled signals and digital signals.""",,"""The text was concise and easy to understand.""",1
D-2022_U72,"""Explanation of basic terms in digital signal processing and introduction of specific examples of signal processing""","""I was able to generally understand the meaning of terms I had never heard before, such as sampling, sampling theorem, quantization, and encoding.""","""I didn't quite understand how to distinguish between sampled signals and digital signals.""",,"""The text was concise and easy to understand.""",1
D-2022_U72,"""Explanation of basic terms in digital signal processing and introduction of specific examples of signal processing""","""I was able to generally understand the meaning of terms I had never heard before, such as sampling, sampling theorem, quantization, and encoding.""","""I didn't quite understand how to distinguish between sampled signals and digital signals.""",,"""The text was concise and easy to understand.""",1
D-2022_U72,"""Explanation of basic terms in digital signal processing and introduction of specific examples of signal processing""","""I was able to generally understand the meaning of terms I had never heard before, such as sampling, sampling theorem, quantization, and encoding.""","""I didn't quite understand how to distinguish between sampled signals and digital signals.""",,"""The text was concise and easy to understand.""",1
D-2022_U73,"""Types and forms of signals
About the properties, benefits and types of signal processing""","""About the difference between analog signals and digital signals, which has been ambiguous until now
About the characteristics of signal processing systems""",,,,-2
D-2022_U73,"""Types and forms of signals
About the properties, benefits and types of signal processing""","""About the difference between analog signals and digital signals, which has been ambiguous until now
About the characteristics of signal processing systems""",,,,-2
D-2022_U74,"""Signal Processing Overview""",,,,,1
D-2022_U75,,"""When is the sampling theorem used?
Why does noise occur when converting to analog signals?""",,,,-1
D-2022_U76,,,,"""None for now""","""In this class, I was able to learn the prerequisite knowledge about digital signal processing.""",1
D-2022_U76,,,,"""None for now""","""In this class, I was able to learn the prerequisite knowledge about digital signal processing.""",1
D-2022_U77,,"""I was able to get a clearer picture of the application and properties of digital signal processing.""","""I didn't understand the reasoning behind the sampling theorem, which said that it should be less than 1/2 the frequency.""",,,1
D-2022_U77,,"""I was able to get a clearer picture of the application and properties of digital signal processing.""","""I didn't understand the reasoning behind the sampling theorem, which said that it should be less than 1/2 the frequency.""",,,1
D-2022_U8,"""On Causality, Time Invariance, and Linearity of Signal Processing Systems""","""On the merits and demerits of digital and analog""",,,,1
D-2022_U8,"""On Causality, Time Invariance, and Linearity of Signal Processing Systems""","""On the merits and demerits of digital and analog""",,,,1
D-2022_U83,"""What is digital signal processing and what is it for?""",,,,,1
D-2022_U84,"""An explanation of the meaning of words such as sampling.""",,,,"""This time there was no difficult mathematics, so I was able to understand it well.""",1
D-2022_U84,"""An explanation of the meaning of words such as sampling.""",,,,"""This time there was no difficult mathematics, so I was able to understand it well.""",1
D-2022_U85,,"""Understood terms like sampling, quantization, etc.""",,,"""It was good to learn the characteristics of different signals.""",1
D-2022_U85,,"""Understood terms like sampling, quantization, etc.""",,,"""It was good to learn the characteristics of different signals.""",1
D-2022_U87,"""I learned an overview of signal processing. I learned basic introductory knowledge.""","""I was able to understand that signals are classified by continuous/discrete with respect to the elements (variables) of time and amplitude.
I was able to understand the flow of the digital signal processing system. """,,,,1
D-2022_U87,"""I learned an overview of signal processing. I learned basic introductory knowledge.""","""I was able to understand that signals are classified by continuous/discrete with respect to the elements (variables) of time and amplitude.
I was able to understand the flow of the digital signal processing system. """,,,,1
D-2022_U89,,,"""In this class, I couldn't understand the difference between sampled signals and digital signals enough to explain to others.
I would like to check the documents again. """,,"""From the contents of this appendix, I learned that it is deeply related to medicine. I am interested in electroencephalograms and image analysis, so I would like to continue to concentrate on lectures.""",1
D-2022_U89,,,"""In this class, I couldn't understand the difference between sampled signals and digital signals enough to explain to others.
I would like to check the documents again. """,,"""From the contents of this appendix, I learned that it is deeply related to medicine. I am interested in electroencephalograms and image analysis, so I would like to continue to concentrate on lectures.""",1
D-2022_U9,,,"""I wanted to know a little more about discrete-time signals.""",,,1
D-2022_U90,"""Learn an overview of digital signal processing.""",,,,,1
D-2022_U91,"""I learned about systems and overviews such as A/D converters and DA converters for digital signal processing, advantages of digital signal processing, etc. I actually used markers, stamps, and library LGC.""",,,,"""I was able to learn a lot of important words about digital signal processing. I'm looking forward to learning more about these topics in the future. In this class, I actually learned how to use the various functions I learned in class 0."" I got used to using it.""",1
D-2022_U91,"""I learned about systems and overviews such as A/D converters and DA converters for digital signal processing, advantages of digital signal processing, etc. I actually used markers, stamps, and library LGC.""",,,,"""I was able to learn a lot of important words about digital signal processing. I'm looking forward to learning more about these topics in the future. In this class, I actually learned how to use the various functions I learned in class 0."" I got used to using it.""",1
D-2022_U92,"""Fundamentals in Digital Signal Processing
""","""Digital signal processing converts analog signals into digital signals by sampling and quantizing them. I learned that signal processing systems have rules such as linearity, time invariance, and causality. rice field.""","""Sometimes there are words I don't understand, so I want to review them.""","""Nothing in particular.""","""Classes started in earnest, and the contents were the same, but there were many class systems that I had to memorize, and it was difficult to keep up. .""",1
D-2022_U92,"""Fundamentals in Digital Signal Processing
""","""Digital signal processing converts analog signals into digital signals by sampling and quantizing them. I learned that signal processing systems have rules such as linearity, time invariance, and causality. rice field.""","""Sometimes there are words I don't understand, so I want to review them.""","""Nothing in particular.""","""Classes started in earnest, and the contents were the same, but there were many class systems that I had to memorize, and it was difficult to keep up. .""",1
D-2022_U92,"""Fundamentals in Digital Signal Processing
""","""Digital signal processing converts analog signals into digital signals by sampling and quantizing them. I learned that signal processing systems have rules such as linearity, time invariance, and causality. rice field.""","""Sometimes there are words I don't understand, so I want to review them.""","""Nothing in particular.""","""Classes started in earnest, and the contents were the same, but there were many class systems that I had to memorize, and it was difficult to keep up. .""",1
D-2022_U92,"""Fundamentals in Digital Signal Processing
""","""Digital signal processing converts analog signals into digital signals by sampling and quantizing them. I learned that signal processing systems have rules such as linearity, time invariance, and causality. rice field.""","""Sometimes there are words I don't understand, so I want to review them.""","""Nothing in particular.""","""Classes started in earnest, and the contents were the same, but there were many class systems that I had to memorize, and it was difficult to keep up. .""",1
D-2022_U92,"""Fundamentals in Digital Signal Processing
""","""Digital signal processing converts analog signals into digital signals by sampling and quantizing them. I learned that signal processing systems have rules such as linearity, time invariance, and causality. rice field.""","""Sometimes there are words I don't understand, so I want to review them.""","""Nothing in particular.""","""Classes started in earnest, and the contents were the same, but there were many class systems that I had to memorize, and it was difficult to keep up. .""",1
D-2022_U93,"""Signals are broadly classified into four categories. In this class, we will study digital signals. A/D converters and D/A converters are composed of multiple signal processing systems. They include causality and time invariance.
There are rules such as The purpose of this class is to understand how to use digitization because there are many advantages and characteristics of digitization, and there are advantages other than analog signals.
""",,,,,1
