{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"qVxUi7YlWDq6"},"source":["# README"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uwTVLCTXWGuR"},"source":["#Setup"]},{"cell_type":"code","execution_count":148,"metadata":{"id":"VgAHilC2WZ16"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math\n","import itertools\n","import random\n","import torch\n","import os\n","import gzip\n","import json\n","from tqdm import tqdm\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge, LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from transformers import AutoModelForMaskedLM, DataCollatorForWholeWordMask, DataCollatorForLanguageModeling, pipeline\n","from transformers import AdamW, get_linear_schedule_with_warmup, TrainerCallback\n","from sklearn.model_selection import StratifiedKFold\n","import shutil\n","from datasets import load_metric\n","import gc\n","gc.enable()\n","from sklearn.svm import SVR, LinearSVR\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.linear_model import Lasso, BayesianRidge, Perceptron, SGDRegressor"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YtQiZchuYObs"},"source":["# Constants"]},{"cell_type":"code","execution_count":149,"metadata":{"id":"MPuHJc1eYQJE"},"outputs":[],"source":["BASE_PATH = '/home/masa1357/Dockerdata/gitfile/kaggle_clrp_1st_place_solution'"]},{"cell_type":"code","execution_count":150,"metadata":{"id":"VIOcjB6-bHPj"},"outputs":[],"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","SEED = 28\n","seed_everything(seed=SEED)\n","MAX_LENGTH = 256"]},{"cell_type":"code","execution_count":151,"metadata":{"id":"EEj-F1o6xHZC"},"outputs":[],"source":["# fine-tuned model paths\n","# adjust path if you have saved the models in different directories\n","ALBERT_TRAINED_1 = os.path.join(BASE_PATH, 'models/albert-xxlarge-2-models')#OK\n","ALBERT_TRAINED_2 = os.path.join(BASE_PATH, 'models/albert-xxlarge-low-lr')#OK\n","ALBERT_TRAINED_3 = os.path.join(BASE_PATH, 'models/ALBERT_3/albert-xxlarge-all-data')#OK\n","DEBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/deberta-large')#OK\n","DEBERTA_TRAINED_2 = os.path.join(BASE_PATH, 'models/deberta-large-low-lr')#OK\n","DEBERTA_TRAINED_3 = os.path.join(BASE_PATH, 'models/deberta-augmented-continued')#OK\n","ROBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/roberta-large-two-models')#OK\n","ELECTRA_TRAINED_1 = os.path.join(BASE_PATH, 'models/electra-large')#OK"]},{"cell_type":"code","execution_count":152,"metadata":{"id":"eDuIc01S1kJC"},"outputs":[],"source":["# ensemble model paths\n","RIDGE_ENSEMBLE_1 = os.path.join(BASE_PATH, 'models/electra-larger-ensemble')\n","RIDGE_ENSEMBLE_2 = os.path.join(BASE_PATH, 'models/huge-ensemble')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xkLqmtm8Wsck"},"source":["# Functions"]},{"cell_type":"code","execution_count":153,"metadata":{"id":"J0DBzdmgYEMy"},"outputs":[],"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]"]},{"cell_type":"code","execution_count":154,"metadata":{"id":"EnFw0t5lXY03"},"outputs":[],"source":["def predict_fast(model_name=None, data=None, init_model=None, tokenizer=None, num_labels=1, is_multilabel=False, output_logits=False, use_softmax=False):\n","  device = \"cuda:0\"\n","  tokenizer = AutoTokenizer.from_pretrained(model_name) if model_name else tokenizer\n","  config = AutoConfig.from_pretrained(model_name, num_labels=num_labels) if model_name else None\n","  model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config) if model_name else init_model\n","  model.to(device)\n","  model.eval()\n","  y_pred = []\n","  batches = chunks(data, 32)\n","  for batch in tqdm(batches):\n","    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n","    input_ids = inputs['input_ids'].to(device)\n","    attention = inputs['attention_mask'].to(device)\n","    inputs = {\n","        'input_ids': input_ids,\n","        'attention_mask': attention\n","    }\n","    with torch.no_grad():        \n","          outputs = model(**inputs)\n","    if not use_softmax:\n","      logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n","    else:\n","      logits = nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy().squeeze().tolist()\n","    if is_multilabel and not output_logits:\n","      logits = np.argmax(logits, axis=-1)\n","    y_pred.extend(logits)\n","  del model\n","  gc.collect()\n","  return y_pred"]},{"cell_type":"code","execution_count":155,"metadata":{"id":"Y_GGOXV1bBJ1"},"outputs":[],"source":["def rms(y_actual, y_predicted):\n","  return mean_squared_error(y_actual, y_predicted, squared=False)"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[],"source":["from joblib import load"]},{"cell_type":"code","execution_count":157,"metadata":{"id":"K1MlM14B2pIw"},"outputs":[],"source":["def make_ensembler_predictions(fold_predictions, ensembler_dirs, return_mean=True):\n","  final_predictions = []\n","  for idx, predictions in enumerate(fold_predictions):\n","    #print(f\"Length of predictions for fold {idx}: {len(predictions)}\")  # Change this line\n","    clf = load(ensembler_dirs[idx])\n","    n_features = clf.coef_.shape[-1]  # The number of features used by the model\n","    #print(f\"The model was trained with {n_features} features.\")\n","    Y = np.column_stack(predictions)\n","    y_preds = clf.predict(Y)\n","    final_predictions.append(y_preds)\n","  \n","  if return_mean:\n","    preds = np.vstack(final_predictions)\n","    del final_predictions\n","    return np.mean(preds, axis=0)\n","  else:\n","    return final_predictions"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FjBEUthJYFYy"},"source":["# Load test data"]},{"cell_type":"code","execution_count":158,"metadata":{"id":"CoQs5JkaYII6"},"outputs":[],"source":["# You will need to place the test data in /data/test/test.csv\n","test_df = pd.read_csv(os.path.join(BASE_PATH, 'data/test/test.csv'))\n","test_tx = [str(t) for t in test_df.excerpt.values]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"q_1BmLqC3JTf"},"source":["# Prediction"]},{"cell_type":"code","execution_count":159,"metadata":{"id":"_jxQx9i8ZI7X"},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00,  1.33it/s]\n","1it [00:00,  7.14it/s]\n","1it [00:00,  1.39it/s]\n","1it [00:00,  7.07it/s]\n","1it [00:00,  9.83it/s]\n","1it [00:00, 10.13it/s]\n","1it [00:00,  1.39it/s]\n","1it [00:00,  7.14it/s]\n","1it [00:00,  1.39it/s]\n","1it [00:00,  7.08it/s]\n","1it [00:00, 10.05it/s]\n","1it [00:00,  9.74it/s]\n","1it [00:00,  1.39it/s]\n","1it [00:00,  7.03it/s]\n","1it [00:00,  1.37it/s]\n","1it [00:00,  7.10it/s]\n","1it [00:00, 10.03it/s]\n","1it [00:00, 10.05it/s]\n","1it [00:00,  1.38it/s]\n","1it [00:00,  7.06it/s]\n","1it [00:00,  1.39it/s]\n","1it [00:00,  7.06it/s]\n","1it [00:00,  9.73it/s]\n","1it [00:00, 10.01it/s]\n","1it [00:00,  1.38it/s]\n","1it [00:00,  7.11it/s]\n","1it [00:00,  1.38it/s]\n","1it [00:00,  7.07it/s]\n","1it [00:00, 10.06it/s]\n","1it [00:00,  9.72it/s]\n","1it [00:00,  1.37it/s]\n","1it [00:00,  7.06it/s]\n","1it [00:00,  1.39it/s]\n","1it [00:00,  7.05it/s]\n","1it [00:00,  9.92it/s]\n","1it [00:00, 10.02it/s]\n","1it [00:00,  1.38it/s]\n","1it [00:00,  7.01it/s]\n","1it [00:00,  7.07it/s]\n"]}],"source":["# Getting transformer predictions\n","\n","model_dirs = [\n","    ALBERT_TRAINED_1,\n","    DEBERTA_TRAINED_1,\n","    ALBERT_TRAINED_2,\n","    DEBERTA_TRAINED_2,\n","    ROBERTA_TRAINED_1,\n","    ELECTRA_TRAINED_1\n","]\n","\n","fold_predictions = {\n","    'fold_0': [],\n","    'fold_1': [],\n","    'fold_2': [],\n","    'fold_3': [],\n","    'fold_4': [],\n","    'fold_5': [],\n","}\n","\n","for i in range(6):\n","  for model in model_dirs:\n","    preds = predict_fast(model_name=os.path.join(model, 'model_fold_' + str(i) + '/best'), data=test_tx)\n","    fold_predictions['fold_' + str(i)].append(np.array(preds))\n","\n","# Getting predictions from special models\n","albert_single_preds = predict_fast(model_name=os.path.join(ALBERT_TRAINED_3), data=test_tx)\n","deberta_bs_0 = predict_fast(model_name=os.path.join(DEBERTA_TRAINED_3, 'model_fold_0/best'), data=test_tx)\n","deberta_bs_1 = predict_fast(model_name=os.path.join(DEBERTA_TRAINED_3, 'model_fold_1/best'), data=test_tx)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lqyyDlJ95gXp"},"source":["# Ensembling"]},{"cell_type":"code","execution_count":160,"metadata":{},"outputs":[],"source":["from joblib import load"]},{"cell_type":"code","execution_count":161,"metadata":{"id":"uIoSp7aLZR4-"},"outputs":[],"source":["ridge_dirs_1 = []\n","ridge_dirs_2 = []\n","\n","for i in [1,2,4,5]:\n","  ridge_dirs_1.append(os.path.join(RIDGE_ENSEMBLE_1, 'model_fold_' + str(i) + '/ridge_model.joblib'))\n","\n","ensemble_1_preds = make_ensembler_predictions(\n","    fold_predictions=[fold_predictions['fold_' + str(i)] for i in [1,2,4,5]],\n","    ensembler_dirs=ridge_dirs_1\n",")"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[],"source":["for i in range(6):\n","  ridge_dirs_2.append(os.path.join(RIDGE_ENSEMBLE_2, 'model_fold_' + str(i) + '/ridge_model.joblib'))\n","\n","#fold_predictions_modified = [fold[:-1] for fold in fold_predictions['fold_' + str(i)] for i in range(6)]\n","\n","ensemble_2_preds = make_ensembler_predictions(\n","    fold_predictions=[fold_predictions['fold_' + str(i)] for i in range(6)],\n","    ensembler_dirs=ridge_dirs_2\n",")"]},{"cell_type":"code","execution_count":163,"metadata":{"id":"JVmyeHfa7nVQ"},"outputs":[],"source":["bs_mean_preds = np.array(deberta_bs_0) * 0.5 + np.array(deberta_bs_1) * 0.5\n","bs_alb_mean_preds = np.array(albert_single_preds) * 0.65 + np.array(bs_mean_preds) * 0.35"]},{"cell_type":"code","execution_count":166,"metadata":{"id":"XeHbkl7P8IEn"},"outputs":[],"source":["final_predictions = np.array(ensemble_1_preds) * 3./8. + np.array(ensemble_2_preds) * 2./8. + np.array(bs_alb_mean_preds) * 3./8.\n","#final_predictions = np.array(ensemble_1_preds) * 0.5 + np.array(bs_alb_mean_preds) * 0.5"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[{"data":{"text/plain":["array([-0.42082693, -0.49184339, -0.52151403, -2.11151913, -1.97552823,\n","       -1.44326278,  0.38189215])"]},"execution_count":167,"metadata":{},"output_type":"execute_result"}],"source":["final_predictions"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8RzkUikD8gVD"},"source":["# Submission"]},{"cell_type":"code","execution_count":165,"metadata":{"id":"pZtBGVv48TSq"},"outputs":[],"source":["submission_df = pd.DataFrame({'id': test_df.id, 'target': final_predictions})\n","submission_df.to_csv(os.path.join(BASE_PATH, 'data/submission/submission.csv'))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMyauuEM+piup5zOPcCsiSU","name":"clrp_inference.ipynb","provenance":[{"file_id":"1DxfF_qp323oibSpevw94mIkv3woRrkVO","timestamp":1629148748856}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
