{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"clrp_inference.ipynb","provenance":[{"file_id":"1DxfF_qp323oibSpevw94mIkv3woRrkVO","timestamp":1629148748856}],"toc_visible":true,"authorship_tag":"ABX9TyMyauuEM+piup5zOPcCsiSU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qVxUi7YlWDq6"},"source":["# README"]},{"cell_type":"markdown","metadata":{"id":"uwTVLCTXWGuR"},"source":["#Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6JW9m3nWIf-","executionInfo":{"status":"ok","timestamp":1628353277352,"user_tz":-120,"elapsed":25550,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"eb86b4d8-36bf-491b-eb39-99374066f147"},"source":["!pip install torch\n","!pip install transformers\n","!pip install numpy\n","!pip install pandas\n","!pip install sklearn\n","!pip install datasets\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 12.9 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 49.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 53.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 63.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Collecting sentence-transformers\n","  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.9.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 26.8 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=5ee9e039a3dd976c9a1fde5fa89ca792d7fe48e07b4660dac4354258a5c2df38\n","  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n","Successfully built sentence-transformers\n","Installing collected packages: sentencepiece, sentence-transformers\n","Successfully installed sentence-transformers-2.0.0 sentencepiece-0.1.96\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n","Collecting datasets\n","  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 11.8 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Collecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 70.1 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 64.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting tqdm>=4.42\n","  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: tqdm, xxhash, fsspec, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed datasets-1.11.0 fsspec-2021.7.0 tqdm-4.62.0 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VgAHilC2WZ16"},"source":["import numpy as np\n","import pandas as pd\n","import math\n","import itertools\n","import random\n","import torch\n","import os\n","import gzip\n","import json\n","from tqdm import tqdm\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge, LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from transformers import AutoModelForMaskedLM, DataCollatorForWholeWordMask, DataCollatorForLanguageModeling, pipeline\n","from transformers import AdamW, get_linear_schedule_with_warmup, TrainerCallback\n","from sklearn.model_selection import StratifiedKFold\n","import shutil\n","from datasets import load_metric\n","import gc\n","gc.enable()\n","from sklearn.svm import SVR, LinearSVR\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.linear_model import Lasso, BayesianRidge, Perceptron, SGDRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FqQyqJrWYblS","executionInfo":{"status":"ok","timestamp":1628353306242,"user_tz":-120,"elapsed":23059,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"d05fade5-8ab3-4252-efde-b6c88d66e85d"},"source":["from google.colab import drive\n","drive.mount('gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YtQiZchuYObs"},"source":["# Constants"]},{"cell_type":"code","metadata":{"id":"MPuHJc1eYQJE"},"source":["BASE_PATH = 'gdrive/MyDrive/Lit/Lit_Submission'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIOcjB6-bHPj"},"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","SEED = 28\n","seed_everything(seed=SEED)\n","MAX_LENGTH = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEj-F1o6xHZC"},"source":["# fine-tuned model paths\n","# adjust path if you have saved the models in different directories\n","ALBERT_TRAINED_1 = os.path.join(BASE_PATH, 'models/albert-xxlarge-no-cv-continued')\n","ALBERT_TRAINED_2 = os.path.join(BASE_PATH, 'models/albert-xxlarge-no-cv-continued-low-lr')\n","ALBERT_TRAINED_3 = os.path.join(BASE_PATH, 'models/albert-xxlarge-all-data')\n","DEBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/deberta-large-augmented-continued')\n","DEBERTA_TRAINED_2 = os.path.join(BASE_PATH, 'models/deberta-large-augmented-continued-low-lr')\n","DEBERTA_TRAINED_3 = os.path.join(BASE_PATH, 'models/deberta-augmented-continued')\n","ROBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/roberta-large-2-models')\n","ELECTRA_TRAINED_1 = os.path.join(BASE_PATH, 'models/electra-large-continued')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDuIc01S1kJC"},"source":["# ensemble model paths\n","RIDGE_ENSEMBLE_1 = os.path.join(BASE_PATH, 'models/electra-larger-ensemble')\n","RIDGE_ENSEMBLE_2 = os.path.join(BASE_PATH, 'models/huge-ensemble')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xkLqmtm8Wsck"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"EnFw0t5lXY03"},"source":["def predict_fast(model_name=None, data=None, init_model=None, tokenizer=None, num_labels=1, is_multilabel=False, output_logits=False, use_softmax=False):\n","  device = \"cuda:0\"\n","  tokenizer = AutoTokenizer.from_pretrained(model_name) if model_name else tokenizer\n","  config = AutoConfig.from_pretrained(model_name, num_labels=num_labels) if model_name else None\n","  model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config) if model_name else init_model\n","  model.to(device)\n","  model.eval()\n","  y_pred = []\n","  batches = chunks(data, 32)\n","  for batch in tqdm(batches):\n","    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n","    input_ids = inputs['input_ids'].to(device)\n","    attention = inputs['attention_mask'].to(device)\n","    inputs = {\n","        'input_ids': input_ids,\n","        'attention_mask': attention\n","    }\n","    with torch.no_grad():        \n","          outputs = model(**inputs)\n","    if not use_softmax:\n","      logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n","    else:\n","      logits = nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy().squeeze().tolist()\n","    if is_multilabel and not output_logits:\n","      logits = np.argmax(logits, axis=-1)\n","    y_pred.extend(logits)\n","  del model\n","  gc.collect()\n","  return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0DBzdmgYEMy"},"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_GGOXV1bBJ1"},"source":["def rms(y_actual, y_predicted):\n","  return mean_squared_error(y_actual, y_predicted, squared=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1MlM14B2pIw"},"source":["def make_ensembler_predictions(fold_predictions, ensembler_dirs, return_mean=True):\n","  final_predictions = []\n","  for idx, predictions in enumerate(fold_predictions):\n","    clf = load(ensembler_dirs[idx])\n","    Y = np.column_stack(predictions)\n","    y_preds = clf.predict(Y)\n","    final_predictions.append(y_preds)\n","  \n","  if return_mean:\n","    preds = np.vstack(final_predictions)\n","    del final_predictions\n","    return np.mean(preds, axis=0)\n","  else:\n","    return final_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FjBEUthJYFYy"},"source":["# Load test data"]},{"cell_type":"code","metadata":{"id":"CoQs5JkaYII6"},"source":["# You will need to place the test data in /data/test/test.csv\n","test_df = pd.read_csv(os.path.join(BASE_PATH, 'data/test/test.csv'))\n","test_tx = [str(t) for t in test_df.excerpt.values]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q_1BmLqC3JTf"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"id":"_jxQx9i8ZI7X"},"source":["# Getting transformer predictions\n","\n","model_dirs = [\n","    ALBERT_TRAINED_1,\n","    DEBERTA_TRAINED_1,\n","    ALBERT_TRAINED_2,\n","    DEBERTA_TRAINED_2,\n","    ROBERTA_TRAINED_1,\n","    ELECTRA_TRAINED_1\n","]\n","\n","fold_predictions = {\n","    'fold_0': [],\n","    'fold_1': [],\n","    'fold_2': [],\n","    'fold_3': [],\n","    'fold_4': [],\n","    'fold_5': [],\n","}\n","\n","for i in range(6):\n","  for model in model_dirs:\n","    preds = predict_fast(model_name=os.path.join(model, 'model_fold_' + str(i) + '/best'), data=test_tx)\n","    fold_predictions['fold_' + str(i)].append(np.array(preds))\n","\n","# Getting predictions from special models\n","albert_single_preds = predict_fast(model_name=os.path.join(ALBERT_TRAINED_3, 'best'), data=test_tx)\n","deberta_bs_0 = predict_fast(model_name=os.path.joun(DEBERTA_TRAINED_3, 'model_fold_0/best'), data=test_tx)\n","deberta_bs_1 = predict_fast(model_name=os.path.joun(DEBERTA_TRAINED_3, 'model_fold_1/best'), data=test_tx)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lqyyDlJ95gXp"},"source":["# Ensembling"]},{"cell_type":"code","metadata":{"id":"uIoSp7aLZR4-"},"source":["ridge_dirs_1 = []\n","ridge_dirs_2 = []\n","\n","for i in [1,2,4,5]:\n","  ridge_dirs_1.append(os.path.join(RIDGE_ENSEMBLE_1, 'model_fold_' + str(i) + 'ridge_model.joblib'))\n","\n","for i in range(6):\n","  ridge_dirs_2.append(os.path.join(RIDGE_ENSEMBLE_2, 'model_fold_' + str(i) + 'ridge_model.joblib'))\n","\n","\n","ensemble_1_preds = make_ensembler_predictions(\n","    fold_predictions=[fold_predictions['fold_' + str(i)] for i in [1,2,4,5]],\n","    ensembler_dirs=ridge_dirs_1\n",")\n","\n","ensemble_2_preds = make_ensembler_predictions(\n","    fold_predictions=[fold_predictions['fold_' + str(i)] for i in range(6)],\n","    ensembler_dirs=ridge_dirs_2\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVmyeHfa7nVQ"},"source":["bs_mean_preds = np.array(deberta_bs_0) * 0.5 + np.array(deberta_bs_1) * 0.5\n","bs_alb_mean_preds = np.array(albert_single_preds) * 0.65 + np.array(bs_mean_preds) * 0.35"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeHbkl7P8IEn"},"source":["final_predictions = np.array(ensemble_1_preds) * 3./8. + np.array(ensemble_2_preds) * 2./8. + np.array(bs_alb_mean_preds) * 3./8."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8RzkUikD8gVD"},"source":["# Submission"]},{"cell_type":"code","metadata":{"id":"pZtBGVv48TSq"},"source":["submission_df = pd.DataFrame({'id': test_df.id, 'target': final_predictions})\n","submission_df.to_csv(os.path.join(BASE_PATH, 'data/submission/submission.csv'))"],"execution_count":null,"outputs":[]}]}