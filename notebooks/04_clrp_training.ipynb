{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"qVxUi7YlWDq6"},"source":["# README"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uwTVLCTXWGuR"},"source":["#Setup"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"VgAHilC2WZ16"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math\n","import itertools\n","import random\n","import torch\n","import os\n","import gzip\n","import json\n","from tqdm import tqdm\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge, LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sentence_transformers import SentenceTransformer, util, losses, models\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from transformers import AutoModelForMaskedLM, DataCollatorForWholeWordMask, DataCollatorForLanguageModeling, pipeline\n","from transformers import AdamW, get_linear_schedule_with_warmup, TrainerCallback\n","from sklearn.model_selection import StratifiedKFold\n","import shutil\n","from datasets import load_metric\n","import gc\n","gc.enable()\n","from sklearn.svm import SVR, LinearSVR\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.linear_model import Lasso, BayesianRidge, Perceptron, SGDRegressor"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YtQiZchuYObs"},"source":["# Constants"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MPuHJc1eYQJE"},"outputs":[],"source":["BASE_PATH = '/home/masa1357/Dockerdata/gitfile/kaggle_clrp_1st_place_solution/'"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu_num\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# print(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VIOcjB6-bHPj"},"outputs":[],"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","SEED = 28\n","seed_everything(seed=SEED)\n","MAX_LENGTH = 256"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EEj-F1o6xHZC"},"outputs":[],"source":["# fine-tuned model paths\n","# adjust path if you have saved the models in different directories\n","ALBERT_TRAINED_1 = os.path.join(BASE_PATH, 'models/albert-xxlarge-2-models')#OK\n","ALBERT_TRAINED_2 = os.path.join(BASE_PATH, 'models/albert-xxlarge-low-lr')#OK\n","ALBERT_TRAINED_3 = os.path.join(BASE_PATH, 'models/ALBERT_3/albert-xxlarge-all-data')#OK\n","DEBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/deberta-large')#OK\n","DEBERTA_TRAINED_2 = os.path.join(BASE_PATH, 'models/deberta-large-low-lr')#OK\n","DEBERTA_TRAINED_3 = os.path.join(BASE_PATH, 'models/deberta-augmented-continued')#OK\n","ROBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/roberta-large-two-models')#OK\n","ELECTRA_TRAINED_1 = os.path.join(BASE_PATH, 'models/electra-large')#OK"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xkLqmtm8Wsck"},"source":["# Functions"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"I3o18TZGWtqM"},"outputs":[],"source":["def train_model(\n","    model_dir,\n","    out_dir,\n","    data,\n","    data_labels,\n","    test_data=None,\n","    test_labels=None,\n","    do_eval=False,\n","    do_epoch_eval=False,\n","    do_save_best=False,\n","    hyperparams={'bs': 16, 'lr': 1e-4, 'ep': 5, 'bias': False, 'init': None},\n","    cfg={'num_labels': 1, 'logging_steps': 500, 'is_multilabel': False, 'keep_layers': None}\n","    ):\n","  tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","  \n","  train_encodings = tokenizer(data, truncation=True, padding=True, max_length=MAX_LENGTH)\n","  if test_data:\n","    test_encodings = tokenizer(test_data, truncation=True, padding=True, max_length=MAX_LENGTH)\n","  \n","\n","  class LitDataset(torch.utils.data.Dataset):\n","      def __init__(self, encodings, labels):\n","          self.encodings = encodings\n","          self.labels = labels\n","\n","      def __getitem__(self, idx):\n","          item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","          item['labels'] = torch.tensor(self.labels[idx])\n","          return item\n","\n","      def __len__(self):\n","          return len(self.labels)\n","\n","  train_dataset = LitDataset(train_encodings, data_labels)\n","  if test_data:\n","    test_dataset = LitDataset(test_encodings, test_labels)\n","  \n","  train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=hyperparams['bs'])\n","  training_steps = len(train_dataloader) * hyperparams['ep'] \n","  warmup_steps = math.ceil(training_steps  * 0.06)\n","\n","  training_args = TrainingArguments(\n","      output_dir=out_dir,          # output directory\n","      num_train_epochs=hyperparams['ep'],              # total number of training epochs\n","      per_device_train_batch_size=hyperparams['bs'],  # batch size per device during training\n","      per_device_eval_batch_size=1,   # batch size for evaluationing rate scheduler\n","      logging_dir='/tmp/logs',            # directory for storing logs\n","      logging_steps=cfg['logging_steps'],\n","      seed=SEED,\n","      weight_decay=hyperparams['weight_decay'],\n","      learning_rate=hyperparams['lr'],\n","      save_strategy='no'\n","  )\n","  config = AutoConfig.from_pretrained(\n","      model_dir,\n","      num_labels=cfg['num_labels'],\n","      hidden_dropout_prob=hyperparams['hidden_dropout'],\n","      attention_probs_dropout_prob=hyperparams['attention_probs_dropout'])\n","  model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=cfg['num_labels'])\n","  if hyperparams['init']:\n","    model = reinitialize_layers(model, hyperparams['init'])\n","  model.config = AutoConfig.from_pretrained(model_dir, num_labels=cfg['num_labels'])\n","  model.num_labels = cfg['num_labels']\n","  if cfg['keep_layers']:\n","    new_layers = torch.nn.ModuleList([layer_module for i, layer_module in enumerate(model.base_model.encoder.layer) if i in cfg['keep_layers']])\n","    model.base_model.encoder.layer = new_layers\n","    model.config.num_hidden_layers = len(cfg['keep_layers'])\n","\n","  optimizer = AdamW(model.parameters(), correct_bias=hyperparams['bias'], lr=hyperparams['lr'])\n","  scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_training_steps=training_steps, num_warmup_steps=warmup_steps)\n","  device = \"cuda:0\"\n","  \n","  scores = []\n","  best_score = 1.0\n","  metric = load_metric(\"accuracy\")\n","\n","  class EvalCallback(TrainerCallback):\n","    def on_log(self, args, state, control, **kwargs):\n","      if do_save_best:\n","        model = kwargs['model']\n","        y_pred = predict_fast(init_model=model, tokenizer=tokenizer, data=test_data, num_labels=cfg['num_labels'], is_multilabel=cfg['is_multilabel'])\n","        model.train()\n","        curr_score = rms(test_labels, y_pred) if not cfg['is_multilabel'] else metric.compute(predictions=y_pred, references=test_labels)['accuracy']\n","        print('Score: ', curr_score)\n","\n","        if len(scores) == 0 or min(scores) > curr_score:\n","          print(f'is min {curr_score} is smaller than {scores}')\n","          best_score = curr_score\n","          save_dir = os.path.join(out_dir, 'best')\n","          model.save_pretrained(save_dir)\n","          tokenizer.save_pretrained(save_dir)\n","          with open(os.path.join(save_dir, 'hyperparams.txt'), 'w') as f:\n","            hyperparams['score'] = curr_score\n","            hyperparams['step'] = state.global_step\n","            hyperparams['trainset_size'] = len(data_labels)\n","            f.write(json.dumps(hyperparams))\n","        scores.append(curr_score)\n","\n","  trainer = Trainer(\n","      model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset=train_dataset,         # training dataset\n","      optimizers=(optimizer, scheduler),\n","      callbacks=[EvalCallback]             # evaluation dataset\n","  )\n","\n","  trainer.train()\n","\n","  if not do_save_best:\n","    model.save_pretrained(out_dir)\n","    tokenizer.save_pretrained(out_dir)\n","  print('Training done')\n","\n","  if do_save_best:\n","    del model\n","    gc.collect()\n","    return min(scores)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"flUcyrIbW7mE"},"outputs":[],"source":["def train_cv_v2(model_dir, out_dir, fold_dir, hyperparams, cfg, kfolds=[0, 1, 2, 3, 4, 5], continue_training=False, deduplicate=False, soft_label_model=None):\n","  scores = []\n","  for fold in kfolds:\n","    train_df = pd.read_csv(fold_dir + '/train_fold_' + str(fold) + '.csv')\n","    val_df = pd.read_csv(fold_dir + '/val_fold_' + str(fold) + '.csv')\n","    if deduplicate:\n","      train_df = train_df.drop_duplicates(subset=['excerpt'])\n","    train_tx = [str(t) for t in train_df.excerpt.values]\n","    train_sc = [float(t) for t in train_df.target.values]\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(t) for t in val_df.target.values]\n","\n","    model_out_dir = out_dir + '/model_fold_' + str(fold)\n","    if continue_training:\n","      final_model_dir = model_dir + '/model_fold_' + str(fold) + '/best'\n","    else:\n","      final_model_dir = model_dir\n","    \n","    if cfg['soft_labels'] == 'add':\n","      preds = predict_fast(final_model_dir, train_tx)\n","      train_tx = train_tx + train_tx\n","      train_sc = train_sc + preds\n","    if cfg['soft_labels'] == 'only':\n","      preds = predict_fast(final_model_dir, train_tx)\n","      train_tx = train_tx\n","      train_sc = preds\n","    if soft_label_model and cfg['soft_labels'] == 'add':\n","      preds = predict_fast(soft_label_model + '/model_fold_' + str(fold) + '/best', train_tx)\n","      train_sc = train_sc + preds\n","      train_tx = train_tx + train_tx\n","    if soft_label_model and cfg['soft_labels'] == 'only':\n","      preds = predict_fast(soft_label_model + '/model_fold_' + str(fold) + '/best', train_tx)\n","      train_sc = preds\n","      train_tx = train_tx\n","      \n","    best_score = train_model(\n","        model_dir=final_model_dir,\n","        out_dir=model_out_dir,\n","        data=train_tx,\n","        data_labels=train_sc,\n","        test_data=val_tx,\n","        test_labels=val_sc,\n","        do_save_best=True,\n","        hyperparams=hyperparams,\n","        cfg=cfg\n","      )\n","    scores.append(best_score)\n","  cv_score = np.mean(scores)\n","  with open(out_dir + '/eval.txt', 'w') as f:\n","    f.write('CV score is ' + str(cv_score))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"EnFw0t5lXY03"},"outputs":[],"source":["def predict_fast(model_name=None, data=None, init_model=None, tokenizer=None, num_labels=1, is_multilabel=False, output_logits=False, use_softmax=False):\n","  device = \"cuda:0\"\n","  tokenizer = AutoTokenizer.from_pretrained(model_name) if model_name else tokenizer\n","  config = AutoConfig.from_pretrained(model_name, num_labels=num_labels) if model_name else None\n","  model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config) if model_name else init_model\n","  model.to(device)\n","  model.eval()\n","  y_pred = []\n","  batches = chunks(data, 32)\n","  for batch in tqdm(batches):\n","    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n","    input_ids = inputs['input_ids'].to(device)\n","    attention = inputs['attention_mask'].to(device)\n","    inputs = {\n","        'input_ids': input_ids,\n","        'attention_mask': attention\n","    }\n","    with torch.no_grad():        \n","          outputs = model(**inputs)\n","    if not use_softmax:\n","      logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n","    else:\n","      logits = nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy().squeeze().tolist()\n","    if is_multilabel and not output_logits:\n","      logits = np.argmax(logits, axis=-1)\n","    y_pred.extend(logits)\n","  del model\n","  gc.collect()\n","  return y_pred"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"V9nwoUWhXfgM"},"outputs":[],"source":["def get_oof_predictions(model_dirs, fold_dir, out_dir, kfolds=[0,1,2,3,4,5]):\n","  df = pd.DataFrame()\n","  \n","  for fold in kfolds:\n","    val_df = pd.read_csv(fold_dir + '/val_fold_' + str(fold) + '.csv')\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(t) for t in val_df.target.values]\n","    fold_df = pd.DataFrame()\n","    fold_df['fold'] = [fold for v in val_sc]\n","    fold_df['excerpt'] = val_tx\n","    fold_df['target'] = val_sc\n","    fold_df['id'] = val_df['id']\n","\n","    for model in model_dirs:\n","      final_model_dir = model + '/model_fold_' + str(fold) + '/best'\n","      model_name = model.split('/')[-1]\n","      preds = predict_fast(final_model_dir, val_tx)\n","      fold_df[model_name] = preds\n","    df = df.append(fold_df, ignore_index=True)\n","  \n","  df.to_csv(out_dir)  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_bin_stratified(df, n_bins=20, n_splits=5):\n","    df['bin'] = pd.cut(df.target, n_bins, labels=[i for i in range(n_bins)])\n","    \n","    df['fold'] = np.nan\n","\n","    skf = StratifiedKFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n","    gen_skf = skf.split(df.id, y=df.bin)\n","\n","    for fold, (idx_train, idx_val) in enumerate(gen_skf):\n","        df.loc[idx_val, 'fold'] = fold\n","    \n","    df['fold'] = df['fold'].astype('int8')"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Y_GGOXV1bBJ1"},"outputs":[],"source":["def rms(y_actual, y_predicted):\n","  return mean_squared_error(y_actual, y_predicted, squared=False)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# FIX errno\n","import errno\n","# FIX dump\n","from joblib import dump\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["def postprocess_predictions(predictions, bin_predictions, bin_averages, threshold=0.58):\n","  new_predictions = []\n","  for idx, p in enumerate(predictions):\n","    if abs(p - bin_averages[bin_predictions[idx][0]]) > 0.5 and np.argmax(bin_predictions[idx][1]) > threshold:\n","      new_predictions.append(np.mean([p, bin_averages[bin_predictions[idx][0]]]))\n","    else:\n","      new_predictions.append(p)\n","  return new_predictions"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["from itertools import combinations\n","from sklearn.metrics import mean_squared_error\n","\n","def find_best_stack(avg_df, ridge_names, drop_models=False):\n","    best_rmse = float('inf')\n","    best_combination = None\n","\n","    # Iterate over all possible combinations of models\n","    for r in range(1, len(ridge_names)+1):\n","        for subset in combinations(ridge_names, r):\n","            # Calculate the mean prediction\n","            mean_pred = avg_df[list(subset)].mean(axis=1)\n","            \n","            # Calculate the RMSE of the mean prediction\n","            rmse = mean_squared_error(avg_df['target'], mean_pred, squared=False)\n","            \n","            # If this RMSE is better than the current best, update the best RMSE and combination\n","            if rmse < best_rmse:\n","                best_rmse = rmse\n","                best_combination = subset\n","\n","    return best_combination\n"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"0sehwzzrXqio"},"outputs":[],"source":["# BUG don't defined\n","# - [x] 1.errno\n","# - [x] 2.dump\n","# - [x] 3.find_best_stack\n","# - [x] 4.postprocess_predictions\n","# - [x] 5.rms\n","def train_leaky_ensembler(oof_dir, model_names, out_dir, kfolds=[0,1,2,3,4,5], model_bins=[], clf='ridge', find_opt_avg=False, bin_avg_dir=None, use_postprocessing=False):\n","  df = pd.read_csv(oof_dir)\n","\n","  if find_opt_avg:\n","    msk = np.random.rand(len(df)) < 0.2\n","    df_test = df[msk].reset_index(drop=True)\n","    df = df[~msk].reset_index(drop=True)\n","    \n","  get_bin_stratified(df, n_splits=6)\n","\n","  results = []\n","  if find_opt_avg:\n","    avg_df = pd.DataFrame()\n","    avg_df['target'] = [float(f) for f in df_test['target']]\n","  for fold in kfolds:\n","    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n","    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n","    \n","    train_tx = [str(t) for t in train_df.excerpt.values]\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(f) for f in val_df.target.values]\n","    train_sc = [float(f) for f in train_df.target.values]\n","\n","    train_predictions = []\n","    val_predictions = []\n","    avg_predictions = []\n","\n","    if len(model_bins) > 0 and not use_postprocessing:\n","      for model_name in model_bins:\n","        preds = [json.loads(p) for p in train_df[model_name].values]\n","        preds_val = [json.loads(p) for p in val_df[model_name].values]\n","        if bin_avg_dir:\n","          with open(bin_avg_dir, 'r') as f:\n","            averages = json.loads(f.read())\n","          preds = [averages[np.argmax(p)] for p in preds]\n","          preds_val = [averages[np.argmax(p)] for p in preds_val]\n","\n","        train_predictions.append(preds)\n","        val_predictions.append(preds_val)\n","    \n","    for model_name in model_names:\n","      preds = [float(f) for f in train_df[model_name].values]\n","      train_predictions.append(np.array(preds))\n","      preds_val = [float(f) for f in val_df[model_name].values]\n","      val_predictions.append(np.array(preds_val))\n","      if find_opt_avg:\n","        preds_avg = [float(f) for f in df_test[model_name].values]\n","        avg_predictions.append(np.array(preds_avg))\n","    \n","    X = np.column_stack(train_predictions)\n","    \n","    if clf == 'ridge':\n","      clf = Ridge(alpha=1.0)\n","    elif clf == 'linearsvr':\n","      clf = LinearSVR(max_iter=1000000)\n","    elif clf == 'svr':\n","      clf = SVR()\n","    elif clf == 'kernel':\n","      clf = KernelRidge()\n","    elif clf == 'gbr':\n","      clf = GradientBoostingRegressor()\n","    elif clf == 'linear':\n","      clf = LinearRegression()\n","    elif clf == 'lasso':\n","      clf = Lasso()\n","    elif clf == 'bayes':\n","      clf = BayesianRidge()\n","    elif clf == 'perceptron':\n","      clf = SGDRegressor()\n","    \n","    clf.fit(X, train_sc)\n","\n","    final_out = out_dir + '/model_fold_' + str(fold) + '/'\n","    if not os.path.exists(os.path.dirname(final_out)):\n","      try:\n","          os.makedirs(os.path.dirname(final_out))\n","      except OSError as exc: # Guard against race condition\n","          if exc.errno != errno.EEXIST:\n","              raise\n","    dump(clf, final_out + 'ridge_model.joblib')\n","\n","    Y = np.column_stack(val_predictions)\n","\n","    y_preds = clf.predict(Y)\n","    if use_postprocessing:\n","      preds_val = [json.loads(p) for p in val_df[model_bins[0]].values]\n","      with open(bin_avg_dir, 'r') as f:\n","            averages = json.loads(f.read())\n","      preds_val_bins = [np.argmax(p) for p in preds_val]\n","      zipped = list(zip(preds_val_bins, preds_val))\n","      y_preds = postprocess_predictions(y_preds, zipped, averages)\n","\n","    score = rms(val_sc, y_preds)\n","    print('Score is: ', score)\n","    results.append(score)\n","\n","    if find_opt_avg:\n","      Y_test = np.column_stack(avg_predictions)\n","      y_preds_test = clf.predict(Y_test)\n","      avg_df['fold_' + str(fold)] = y_preds_test\n","  \n","  if find_opt_avg:\n","    ridge_names = ['fold_' + str(fold) for fold in range(kfolds)]\n","    print(find_best_stack(avg_df, ridge_names, drop_models=False))\n","\n","  with open(out_dir + '/eval.txt', 'w') as f:\n","    mean = np.mean(results)\n","    print('CV ist: ', mean)\n","    f.write('CV is: ' + str(mean))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"J0DBzdmgYEMy"},"outputs":[],"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FjBEUthJYFYy"},"source":["# Pretraining models"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"CoQs5JkaYII6"},"outputs":[],"source":["# Load the pseudo-labeled training data for pretraining models\n","train_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/predicted/predicted.csv'))\n","train_tx = [str(t) for t in train_df.excerpt.values]\n","train_sc = [float(t) for t in train_df.target.values]"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_jxQx9i8ZI7X"},"outputs":[],"source":["# Load the entire training set from the original competition for validation during pretraining\n","val_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/original/train.csv'))\n","val_tx = [str(t) for t in train_df.excerpt.values]\n","val_sc = [float(t) for t in train_df.target.values]"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"uIoSp7aLZR4-"},"outputs":[],"source":["# Train an ALBERT model\n","\n","model_name = 'albert-xxlarge-v2'\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.01,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.07,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 60,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ALBERT_PRETRAINED = os.path.join(BASE_PATH, 'models/albert-xxlarge-no-cv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751,"referenced_widgets":["6fe21e46a1b44bf8b5e43027e73376a7","12726890add04fe6aa64cec205e05f05","eebc87e23ac34b7d947d4a5bbb64f5ca","be782cc5c1c8488a8c97131739437e05","c3ddab55f4d744b1912d884122978df4","f4dfe24236874484ad73205f2612257d","1d41db217eec4602bf7f9838f5d769bd","4afd4111264f4a0fa9579d1b301b4601","5db45fe62cf54877bdd1bbd8cc98da28","6a38f1a6e951441a9defc9398c540098","551e0e9d097347aabc0c6bebd01d2082","5388dbecd0fb49c88abf02733747e01b","d56efd20fa814a9b957a7dc49056032d","db12d6399bc941f59c6ae60d2beb11f2","db59f537fd6049fe901d042905823c30","072298bfd93644968c71b5fa7b84a952","b97a3a30bdfd4612b09b2d5e0447d381","244ecc5b53a444d9b06b8981b85c970f","9f23ccc019dc4046a6cb4347a397ad79","916ed8c81bf64a8984fc1e40cefdaa00","5e13ecccb3774e1d8d66394f80788eb5","f317ba33d8df46bc811d8f21f45868e0"]},"executionInfo":{"elapsed":41725,"status":"ok","timestamp":1628353410510,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"trfdyCkAaEgS","outputId":"fc68485e-37c3-48ae-b167-6545dc0e4d78"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.bias']\n","- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/tmp/ipykernel_975427/3347279979.py:74: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3815' max='3815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3815/3815 11:36:41, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>60</td>\n","      <td>8.637400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>3.487500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.895200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.094500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.712400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.465100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.373500</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.322300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.274300</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.296700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.163100</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.168300</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.196700</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.130300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.112300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.085200</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.073200</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.074700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.078600</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.077100</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.082800</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.058200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.050900</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.050300</td>\n","    </tr>\n","    <tr>\n","      <td>1980</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>2040</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>2160</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>2220</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>2280</td>\n","      <td>0.038800</td>\n","    </tr>\n","    <tr>\n","      <td>2340</td>\n","      <td>0.042900</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.026300</td>\n","    </tr>\n","    <tr>\n","      <td>2460</td>\n","      <td>0.029800</td>\n","    </tr>\n","    <tr>\n","      <td>2520</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>2580</td>\n","      <td>0.037700</td>\n","    </tr>\n","    <tr>\n","      <td>2640</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.032200</td>\n","    </tr>\n","    <tr>\n","      <td>2760</td>\n","      <td>0.028300</td>\n","    </tr>\n","    <tr>\n","      <td>2820</td>\n","      <td>0.029800</td>\n","    </tr>\n","    <tr>\n","      <td>2880</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>2940</td>\n","      <td>0.021500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.026600</td>\n","    </tr>\n","    <tr>\n","      <td>3060</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>3120</td>\n","      <td>0.017400</td>\n","    </tr>\n","    <tr>\n","      <td>3180</td>\n","      <td>0.022600</td>\n","    </tr>\n","    <tr>\n","      <td>3240</td>\n","      <td>0.021500</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.020300</td>\n","    </tr>\n","    <tr>\n","      <td>3360</td>\n","      <td>0.018500</td>\n","    </tr>\n","    <tr>\n","      <td>3420</td>\n","      <td>0.019900</td>\n","    </tr>\n","    <tr>\n","      <td>3480</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>3540</td>\n","      <td>0.023700</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.021300</td>\n","    </tr>\n","    <tr>\n","      <td>3660</td>\n","      <td>0.021100</td>\n","    </tr>\n","    <tr>\n","      <td>3720</td>\n","      <td>0.018400</td>\n","    </tr>\n","    <tr>\n","      <td>3780</td>\n","      <td>0.018700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["143it [09:34,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  2.4724326828566308\n","is min 2.4724326828566308 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.6261113322019147\n","is min 1.6261113322019147 is smaller than [2.4724326828566308]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:34,  4.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.2382114282735124\n","is min 1.2382114282735124 is smaller than [2.4724326828566308, 1.6261113322019147]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:34,  4.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8307748337080949\n","is min 0.8307748337080949 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:35,  4.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6699659748066764\n","is min 0.6699659748066764 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:35,  4.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6095859441192493\n","is min 0.6095859441192493 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:35,  4.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49570119262401324\n","is min 0.49570119262401324 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:34,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5951307450469295\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.38556877974187387\n","is min 0.38556877974187387 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:34,  4.02s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46415313261570956\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.30167225140091514\n","is min 0.30167225140091514 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:34,  4.02s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8091544663570209\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:34,  4.02s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35171971905965443\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:34,  4.02s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34414852981525146\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:34,  4.02s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37126143932883837\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:34,  4.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2598407135895769\n","is min 0.2598407135895769 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:34,  4.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2228464173286103\n","is min 0.2228464173286103 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:34,  4.02s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2510136222937503\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24481901878477488\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23501769343129786\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2084207408779208\n","is min 0.2084207408779208 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27096740083214366\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:32,  4.00s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22529955129597068\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2030326020444604\n","is min 0.2030326020444604 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1855980143156472\n","is min 0.1855980143156472 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2191443796511697\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16730965007322166\n","is min 0.16730965007322166 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18291989960003677\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2019890943621976\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:34,  4.02s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17601716703277046\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1709428050130544\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16370083961862703\n","is min 0.16370083961862703 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:33,  4.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14341060540823583\n","is min 0.14341060540823583 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20681427353621434\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:33,  4.01s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19878128240589682\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:32,  4.00s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13941787429397656\n","is min 0.13941787429397656 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:32,  4.00s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24509122909784195\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:31,  4.00s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14509823556475573\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14945943201785525\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1490927537202429\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:29,  3.98s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13095789812624467\n","is min 0.13095789812624467 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13947510328993964\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:29,  3.98s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17832777033590355\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:28,  3.98s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1339956069155411\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:29,  3.98s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18521502810153598\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:29,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13475580832801193\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:29,  3.99s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.12986235804920723\n","is min 0.12986235804920723 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1973788032505254\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:30,  3.99s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.12107435002396282\n","is min 0.12107435002396282 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:29,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14704125229584641\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:29,  3.98s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1165606752010814\n","is min 0.1165606752010814 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254, 0.12107435002396282, 0.14704125229584641]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:29,  3.98s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.12375583977398368\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:30,  3.99s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.11652796069277027\n","is min 0.11652796069277027 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254, 0.12107435002396282, 0.14704125229584641, 0.1165606752010814, 0.12375583977398368]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:31,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1257456917417422\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1305454390011354\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:31,  3.99s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.11070383722061311\n","is min 0.11070383722061311 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254, 0.12107435002396282, 0.14704125229584641, 0.1165606752010814, 0.12375583977398368, 0.11652796069277027, 0.1257456917417422, 0.1305454390011354]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:31,  4.00s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.11051214402022252\n","is min 0.11051214402022252 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254, 0.12107435002396282, 0.14704125229584641, 0.1165606752010814, 0.12375583977398368, 0.11652796069277027, 0.1257456917417422, 0.1305454390011354, 0.11070383722061311]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13067900855607087\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13801090469833469\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:30,  3.99s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.11695873168019079\n"]},{"name":"stderr","output_type":"stream","text":["143it [09:29,  3.98s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.10970693269836586\n","is min 0.10970693269836586 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254, 0.12107435002396282, 0.14704125229584641, 0.1165606752010814, 0.12375583977398368, 0.11652796069277027, 0.1257456917417422, 0.1305454390011354, 0.11070383722061311, 0.11051214402022252, 0.13067900855607087, 0.13801090469833469, 0.11695873168019079]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:30,  3.99s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.10183029722293394\n","is min 0.10183029722293394 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254, 0.12107435002396282, 0.14704125229584641, 0.1165606752010814, 0.12375583977398368, 0.11652796069277027, 0.1257456917417422, 0.1305454390011354, 0.11070383722061311, 0.11051214402022252, 0.13067900855607087, 0.13801090469833469, 0.11695873168019079, 0.10970693269836586]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:30,  3.99s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.0994916672241441\n","is min 0.0994916672241441 is smaller than [2.4724326828566308, 1.6261113322019147, 1.2382114282735124, 0.8307748337080949, 0.6699659748066764, 0.6095859441192493, 0.49570119262401324, 0.5951307450469295, 0.38556877974187387, 0.46415313261570956, 0.30167225140091514, 0.8091544663570209, 0.35171971905965443, 0.34414852981525146, 0.37126143932883837, 0.2598407135895769, 0.2228464173286103, 0.2510136222937503, 0.24481901878477488, 0.23501769343129786, 0.2084207408779208, 0.27096740083214366, 0.22529955129597068, 0.2030326020444604, 0.1855980143156472, 0.2191443796511697, 0.16730965007322166, 0.18291989960003677, 0.2019890943621976, 0.17601716703277046, 0.1709428050130544, 0.16370083961862703, 0.14341060540823583, 0.20681427353621434, 0.19878128240589682, 0.13941787429397656, 0.24509122909784195, 0.14509823556475573, 0.14945943201785525, 0.1490927537202429, 0.13095789812624467, 0.13947510328993964, 0.17832777033590355, 0.1339956069155411, 0.18521502810153598, 0.13475580832801193, 0.12986235804920723, 0.1973788032505254, 0.12107435002396282, 0.14704125229584641, 0.1165606752010814, 0.12375583977398368, 0.11652796069277027, 0.1257456917417422, 0.1305454390011354, 0.11070383722061311, 0.11051214402022252, 0.13067900855607087, 0.13801090469833469, 0.11695873168019079, 0.10970693269836586, 0.10183029722293394]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [09:29,  3.98s/it]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.10300967809098473\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"data":{"text/plain":["0.0994916672241441"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_model(\n","    model_dir=model_name,\n","    out_dir=ALBERT_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d7a3a38272ff48ba8125b50be1b157d4","bff952736ffd4b50ae75acb020fd481b","6b7bf1bf7414490dbfad3d33f9a44ab3","5b14760830124e63b302f63944690cea","dbb3d4a578cd4564a53414ceef71da2b","2e6b0ee16bbb480ca3dd6f81d080dca1","60548b7369d54fc09a1ecd823daa418a","e6831b4a9736483aa3aefc9bb2318a2a","b6b87bbdbf354587b1330eff467f6174","462f1ab065bd4a68b44f3e5f82f6d6c8","1fbc5226341945e6b64a2ac45af52004","91f8052331ba482e8380aaf7e83fc1db","845c5936fd96438b87a1cce2974d78e5","7415cf21ec1f4148b19b1409784429d3","d78f3bc7a3e24eab92569fdaf83f7ba4","48f85b79c58d4cd59eca639d19bd1f90","ac2bd1da3ced4f3b91b484bd745e86da","cc421dd21cf44c97a5a2feda0a02e72b","e108e22beefe4dbfa21f01a189070bb0","e0baea8e01ce4a3cab96f14b4b9944e6","04d257aaf71e41f8b93223540f12e546","9f8b910cb89742648ffc9df643d8cca3","41780e8505b04e1aa48fca3005dfcf3e","0f8896d36a3e4c718ca5eb7d2a4db036","ed4cc8276fd947ee95e9e420cceaab0f","4cf4929d93724b88be6d1d428bdfaa97","902edc73112946b88d55afe299ff680a","6495b6f0569240ca9af463481aec94da","704350d386904fdba4b2782392f4c0bc","75fab396ec05456093e052d7b5dfb596","2b304b633c654429ba05a1f48447ddb4","aa8cf38b1fc54d47a2adc5c0a58ac504","ba20d6ba371f4f96b3d379713ed39642","33f156b8e7874b87a9f61d1a065c4c96","1f290f5083de46cc8370d3949c8e36b6","0c05fa677771495296077d2cf6360cfe","613d68d5434a47c89ef55f0cd1436977","e3b3b1add5944372a3349cee1957f85c","019d1122d3544181b5af8fcb0bf7ca0d","6890671c6b1043b38ffc66c85e2449c4","7070960c8eac4935902546d358b07231","eac90ccd9584470cb7adfbc9c7e2679c","a659a7f4171640ffa54d69ed7a7f1be2","ba0e39c775894ab897462870c7beadc5","1c2543a0ab094134a25f6603ab1fd6d9","e8a73c92d4d646949922cd665cbda390","b04c05d8dc8b4b71bbc8c4bce8b3d2b3","beee0635e9634f0e9bdb43bf4036e422","eb2d90da017b40618608151bafd7bcd1","fcb6c02ee7df43edaac1e1a2ade1f1a6","33641ab74dad49f3a86d0d8fa46b7a1e","2ecbc2a60c2c43dc94a81fda94a8c65f","886de66ecec3421886e3f50e479a6ff0","55fbffecf6d047b28a0ed099ccb3c394","5a21c7fa7b0b4ac18487f03367a85246"]},"executionInfo":{"elapsed":99248,"status":"ok","timestamp":1628353662900,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"LfjD9r7TayIc","outputId":"b3c4b548-a0cc-44d0-84b9-1dd5a61323ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52.0/52.0 [00:00<00:00, 191kB/s]\n","Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 475/475 [00:00<00:00, 1.07MB/s]\n","Downloading (â€¦)olve/main/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 1.26MB/s]\n","Downloading (â€¦)olve/main/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 498kB/s]\n","Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.63G/1.63G [04:55<00:00, 5.51MB/s]\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-large and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/tmp/ipykernel_107131/202785219.py:75: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n","Downloading builder script: 4.21kB [00:00, 4.94MB/s]                                                                                                                   \n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3052' max='3052' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3052/3052 5:02:18, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>20</td>\n","      <td>1.760600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.736800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.241500</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.623100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.517300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.449100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.382400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.399000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.337800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.278900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.244600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.219400</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.117400</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.140100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.128000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.156200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.164100</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.090700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.086000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.225700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.124300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.103800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.078300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.131000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.085100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.069300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.063900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.083500</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.116100</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.075400</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.087000</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.052700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.044500</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.075000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.048600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.057000</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.045300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.100800</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.075700</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.032000</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.042400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.051400</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.052600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.034400</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.033500</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.059300</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.039300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.072600</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.071900</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.035900</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.037300</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.039800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.046200</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.023300</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.029500</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.035300</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.028000</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.031900</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.032600</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.031400</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.037500</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.025700</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.022800</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.018300</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.022300</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.025000</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.021600</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.022000</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.022500</td>\n","    </tr>\n","    <tr>\n","      <td>1980</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.034800</td>\n","    </tr>\n","    <tr>\n","      <td>2020</td>\n","      <td>0.029900</td>\n","    </tr>\n","    <tr>\n","      <td>2040</td>\n","      <td>0.020400</td>\n","    </tr>\n","    <tr>\n","      <td>2060</td>\n","      <td>0.028500</td>\n","    </tr>\n","    <tr>\n","      <td>2080</td>\n","      <td>0.046500</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>2120</td>\n","      <td>0.029400</td>\n","    </tr>\n","    <tr>\n","      <td>2140</td>\n","      <td>0.025500</td>\n","    </tr>\n","    <tr>\n","      <td>2160</td>\n","      <td>0.026000</td>\n","    </tr>\n","    <tr>\n","      <td>2180</td>\n","      <td>0.017000</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.024000</td>\n","    </tr>\n","    <tr>\n","      <td>2220</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>2240</td>\n","      <td>0.018300</td>\n","    </tr>\n","    <tr>\n","      <td>2260</td>\n","      <td>0.019600</td>\n","    </tr>\n","    <tr>\n","      <td>2280</td>\n","      <td>0.015800</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>2320</td>\n","      <td>0.030200</td>\n","    </tr>\n","    <tr>\n","      <td>2340</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>2360</td>\n","      <td>0.019000</td>\n","    </tr>\n","    <tr>\n","      <td>2380</td>\n","      <td>0.014700</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.018300</td>\n","    </tr>\n","    <tr>\n","      <td>2420</td>\n","      <td>0.029200</td>\n","    </tr>\n","    <tr>\n","      <td>2440</td>\n","      <td>0.017900</td>\n","    </tr>\n","    <tr>\n","      <td>2460</td>\n","      <td>0.016500</td>\n","    </tr>\n","    <tr>\n","      <td>2480</td>\n","      <td>0.020000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.015800</td>\n","    </tr>\n","    <tr>\n","      <td>2520</td>\n","      <td>0.016600</td>\n","    </tr>\n","    <tr>\n","      <td>2540</td>\n","      <td>0.013400</td>\n","    </tr>\n","    <tr>\n","      <td>2560</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>2580</td>\n","      <td>0.020200</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.014200</td>\n","    </tr>\n","    <tr>\n","      <td>2620</td>\n","      <td>0.014700</td>\n","    </tr>\n","    <tr>\n","      <td>2640</td>\n","      <td>0.021200</td>\n","    </tr>\n","    <tr>\n","      <td>2660</td>\n","      <td>0.019800</td>\n","    </tr>\n","    <tr>\n","      <td>2680</td>\n","      <td>0.016800</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>2720</td>\n","      <td>0.018300</td>\n","    </tr>\n","    <tr>\n","      <td>2740</td>\n","      <td>0.018300</td>\n","    </tr>\n","    <tr>\n","      <td>2760</td>\n","      <td>0.015200</td>\n","    </tr>\n","    <tr>\n","      <td>2780</td>\n","      <td>0.013300</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>2820</td>\n","      <td>0.013500</td>\n","    </tr>\n","    <tr>\n","      <td>2840</td>\n","      <td>0.017100</td>\n","    </tr>\n","    <tr>\n","      <td>2860</td>\n","      <td>0.016200</td>\n","    </tr>\n","    <tr>\n","      <td>2880</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.023400</td>\n","    </tr>\n","    <tr>\n","      <td>2920</td>\n","      <td>0.021800</td>\n","    </tr>\n","    <tr>\n","      <td>2940</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>2960</td>\n","      <td>0.014600</td>\n","    </tr>\n","    <tr>\n","      <td>2980</td>\n","      <td>0.015100</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.017400</td>\n","    </tr>\n","    <tr>\n","      <td>3020</td>\n","      <td>0.017100</td>\n","    </tr>\n","    <tr>\n","      <td>3040</td>\n","      <td>0.015900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["143it [01:33,  1.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.3350963896607595\n","is min 1.3350963896607595 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:35,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.2834833490791542\n","is min 1.2834833490791542 is smaller than [1.3350963896607595]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:38,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.9552349926731662\n","is min 0.9552349926731662 is smaller than [1.3350963896607595, 1.2834833490791542]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7702634223235508\n","is min 0.7702634223235508 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7196539422237326\n","is min 0.7196539422237326 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6655039906832414\n","is min 0.6655039906832414 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6166063019356198\n","is min 0.6166063019356198 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5649435818362472\n","is min 0.5649435818362472 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.519535704908144\n","is min 0.519535704908144 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5246172820094712\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3940467151365691\n","is min 0.3940467151365691 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34838946392346026\n","is min 0.34838946392346026 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3404752253298752\n","is min 0.3404752253298752 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.33477695130387014\n","is min 0.33477695130387014 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3393148429027819\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3119921422983576\n","is min 0.3119921422983576 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3289565399999835\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28375767423265735\n","is min 0.28375767423265735 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.505988889623087\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44050686884921103\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2341779910645545\n","is min 0.2341779910645545 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23138606783110877\n","is min 0.23138606783110877 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26311406475069266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4815354470201004\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25034916335597196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25745963726026877\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2515357997169274\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2228087933685203\n","is min 0.2228087933685203 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2550394196065679\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.38074066260025036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49046816745174926\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19534854659053966\n","is min 0.19534854659053966 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.32798125569141057\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3479522577043194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18375730757441885\n","is min 0.18375730757441885 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.286017823795592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4258992434428349\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23866979817870745\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18897802248249937\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19439670663858513\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20077797848026782\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.39057702629673796\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17856276154417353\n","is min 0.17856276154417353 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194, 0.18375730757441885, 0.286017823795592, 0.4258992434428349, 0.23866979817870745, 0.18897802248249937, 0.19439670663858513, 0.20077797848026782, 0.39057702629673796]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2737218673372419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24248368209161433\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2771677484574719\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.210978613041161\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3024562228521363\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18797168839803188\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.39718614826605486\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17150852032392963\n","is min 0.17150852032392963 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194, 0.18375730757441885, 0.286017823795592, 0.4258992434428349, 0.23866979817870745, 0.18897802248249937, 0.19439670663858513, 0.20077797848026782, 0.39057702629673796, 0.17856276154417353, 0.2737218673372419, 0.24248368209161433, 0.2771677484574719, 0.210978613041161, 0.3024562228521363, 0.18797168839803188, 0.39718614826605486]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2444053347920921\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3279699836108626\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2854091755447002\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23507729301564625\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23041351236152824\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17002615660668302\n","is min 0.17002615660668302 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194, 0.18375730757441885, 0.286017823795592, 0.4258992434428349, 0.23866979817870745, 0.18897802248249937, 0.19439670663858513, 0.20077797848026782, 0.39057702629673796, 0.17856276154417353, 0.2737218673372419, 0.24248368209161433, 0.2771677484574719, 0.210978613041161, 0.3024562228521363, 0.18797168839803188, 0.39718614826605486, 0.17150852032392963, 0.2444053347920921, 0.3279699836108626, 0.2854091755447002, 0.23507729301564625, 0.23041351236152824]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22342689952112696\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.32509878368641215\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16007610621135315\n","is min 0.16007610621135315 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194, 0.18375730757441885, 0.286017823795592, 0.4258992434428349, 0.23866979817870745, 0.18897802248249937, 0.19439670663858513, 0.20077797848026782, 0.39057702629673796, 0.17856276154417353, 0.2737218673372419, 0.24248368209161433, 0.2771677484574719, 0.210978613041161, 0.3024562228521363, 0.18797168839803188, 0.39718614826605486, 0.17150852032392963, 0.2444053347920921, 0.3279699836108626, 0.2854091755447002, 0.23507729301564625, 0.23041351236152824, 0.17002615660668302, 0.22342689952112696, 0.32509878368641215]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28856749377096974\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22950920674018027\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3503630018166107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2851134934196054\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20870027892791834\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.33592026632030053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.29354178139676373\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.177371279785555\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1692328935575017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22012798651288415\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.33355515879797615\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25304363787618167\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21955468102692455\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:40,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2284475654711921\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23804976358504212\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.15085128236590048\n","is min 0.15085128236590048 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194, 0.18375730757441885, 0.286017823795592, 0.4258992434428349, 0.23866979817870745, 0.18897802248249937, 0.19439670663858513, 0.20077797848026782, 0.39057702629673796, 0.17856276154417353, 0.2737218673372419, 0.24248368209161433, 0.2771677484574719, 0.210978613041161, 0.3024562228521363, 0.18797168839803188, 0.39718614826605486, 0.17150852032392963, 0.2444053347920921, 0.3279699836108626, 0.2854091755447002, 0.23507729301564625, 0.23041351236152824, 0.17002615660668302, 0.22342689952112696, 0.32509878368641215, 0.16007610621135315, 0.28856749377096974, 0.22950920674018027, 0.3503630018166107, 0.2851134934196054, 0.20870027892791834, 0.33592026632030053, 0.29354178139676373, 0.177371279785555, 0.1692328935575017, 0.22012798651288415, 0.33355515879797615, 0.25304363787618167, 0.21955468102692455, 0.2284475654711921, 0.23804976358504212]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23288840722693124\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2358828944280986\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16148376058331942\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22204157575996056\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2764739170352061\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20457610972173432\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.29521923964238583\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16546069098834504\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35877819142321504\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16985647303569423\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18091116593426265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2333184618827277\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22239746157801124\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3307640882238239\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18276005274766186\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25768285970303145\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2308266857990206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2060426429002137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22752138433967722\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22997609872179234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2620896294409803\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2620683255754921\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1310326962976596\n","is min 0.1310326962976596 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194, 0.18375730757441885, 0.286017823795592, 0.4258992434428349, 0.23866979817870745, 0.18897802248249937, 0.19439670663858513, 0.20077797848026782, 0.39057702629673796, 0.17856276154417353, 0.2737218673372419, 0.24248368209161433, 0.2771677484574719, 0.210978613041161, 0.3024562228521363, 0.18797168839803188, 0.39718614826605486, 0.17150852032392963, 0.2444053347920921, 0.3279699836108626, 0.2854091755447002, 0.23507729301564625, 0.23041351236152824, 0.17002615660668302, 0.22342689952112696, 0.32509878368641215, 0.16007610621135315, 0.28856749377096974, 0.22950920674018027, 0.3503630018166107, 0.2851134934196054, 0.20870027892791834, 0.33592026632030053, 0.29354178139676373, 0.177371279785555, 0.1692328935575017, 0.22012798651288415, 0.33355515879797615, 0.25304363787618167, 0.21955468102692455, 0.2284475654711921, 0.23804976358504212, 0.15085128236590048, 0.23288840722693124, 0.2358828944280986, 0.16148376058331942, 0.22204157575996056, 0.2764739170352061, 0.20457610972173432, 0.29521923964238583, 0.16546069098834504, 0.35877819142321504, 0.16985647303569423, 0.18091116593426265, 0.2333184618827277, 0.22239746157801124, 0.3307640882238239, 0.18276005274766186, 0.25768285970303145, 0.2308266857990206, 0.2060426429002137, 0.22752138433967722, 0.22997609872179234, 0.2620896294409803, 0.2620683255754921]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.33482711976312257\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24428284135394202\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2145444756148174\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.146144403991559\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2179980496993261\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3230077343612502\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21218443292105493\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23867131759741375\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25484658542089833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19899504773540286\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16992250309993928\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2535595734960861\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22586693329938193\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2280845480209275\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17019379634956383\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3447796890803394\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1939837610487386\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14556069423071089\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24273352207436327\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.182386688002014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.12351018220386077\n","is min 0.12351018220386077 is smaller than [1.3350963896607595, 1.2834833490791542, 0.9552349926731662, 0.7702634223235508, 0.7196539422237326, 0.6655039906832414, 0.6166063019356198, 0.5649435818362472, 0.519535704908144, 0.5246172820094712, 0.3940467151365691, 0.34838946392346026, 0.3404752253298752, 0.33477695130387014, 0.3393148429027819, 0.3119921422983576, 0.3289565399999835, 0.28375767423265735, 0.505988889623087, 0.44050686884921103, 0.2341779910645545, 0.23138606783110877, 0.26311406475069266, 0.4815354470201004, 0.25034916335597196, 0.25745963726026877, 0.2515357997169274, 0.2228087933685203, 0.2550394196065679, 0.38074066260025036, 0.49046816745174926, 0.19534854659053966, 0.32798125569141057, 0.3479522577043194, 0.18375730757441885, 0.286017823795592, 0.4258992434428349, 0.23866979817870745, 0.18897802248249937, 0.19439670663858513, 0.20077797848026782, 0.39057702629673796, 0.17856276154417353, 0.2737218673372419, 0.24248368209161433, 0.2771677484574719, 0.210978613041161, 0.3024562228521363, 0.18797168839803188, 0.39718614826605486, 0.17150852032392963, 0.2444053347920921, 0.3279699836108626, 0.2854091755447002, 0.23507729301564625, 0.23041351236152824, 0.17002615660668302, 0.22342689952112696, 0.32509878368641215, 0.16007610621135315, 0.28856749377096974, 0.22950920674018027, 0.3503630018166107, 0.2851134934196054, 0.20870027892791834, 0.33592026632030053, 0.29354178139676373, 0.177371279785555, 0.1692328935575017, 0.22012798651288415, 0.33355515879797615, 0.25304363787618167, 0.21955468102692455, 0.2284475654711921, 0.23804976358504212, 0.15085128236590048, 0.23288840722693124, 0.2358828944280986, 0.16148376058331942, 0.22204157575996056, 0.2764739170352061, 0.20457610972173432, 0.29521923964238583, 0.16546069098834504, 0.35877819142321504, 0.16985647303569423, 0.18091116593426265, 0.2333184618827277, 0.22239746157801124, 0.3307640882238239, 0.18276005274766186, 0.25768285970303145, 0.2308266857990206, 0.2060426429002137, 0.22752138433967722, 0.22997609872179234, 0.2620896294409803, 0.2620683255754921, 0.1310326962976596, 0.33482711976312257, 0.24428284135394202, 0.2145444756148174, 0.146144403991559, 0.2179980496993261, 0.3230077343612502, 0.21218443292105493, 0.23867131759741375, 0.25484658542089833, 0.19899504773540286, 0.16992250309993928, 0.2535595734960861, 0.22586693329938193, 0.2280845480209275, 0.17019379634956383, 0.3447796890803394, 0.1939837610487386, 0.14556069423071089, 0.24273352207436327, 0.182386688002014]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21785716555441978\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16484350635596007\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13923806458124952\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22873379587533793\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1828825387558029\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18785627986112813\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3470906484795278\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16032041962323137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2260831589589845\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23869076737963532\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17193340428813422\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16311608284383902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.13630990119469258\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24691482089835057\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20552815347459635\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27593921460280924\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21198392095509108\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23735113717427053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2002308018672074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22313853402351874\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23001374964061563\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:42,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17541348067544552\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:42,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16193884772886308\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:42,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14233095004705412\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2227260316049847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17901698990384143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16486031741684076\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23996518931812444\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20539554650421873\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19658889649571668\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17398922045743545\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23005158225276462\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:41,  1.40it/s]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22368336831050722\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"data":{"text/plain":["0.12351018220386077"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Train a DEBERTA model\n","model_name = 'microsoft/deberta-large'\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 20,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","DEBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/deberta-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=DEBERTA_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["62932fc171e54ad8a6e83d43bbecef28","7e266f1c703b43e2a1380fce6f749f4c","994983c7661840cda6a0d12d874605a5","6a89755c37e849359f19ea453f7a64e1","a3baefe68a214cc6a3f4616719547fed","694cac06d91d4ef99bf0e817d8ed9b15","9fa94d851b284aa0b6d8d8590f7a8d7f","2019d8e148a24245a802ad90d28f781c","fc943877ab974e009c3f603a77005346","e5c78f7c515a497a9c7a05f1a2661c3a","9792332c910147b6bf64cd330164c98d","bcc8278f44c34ec88a10a739a0cbeffc","2a6557ecc21e4838a06786b3947a073d","5cbcca203a664f5fa706408b54c9efda","82c212bad67f4d948af30a2c77794710","33976aa53a1641d486f194e3c19e5f03","5e750ab91db34b89a69ef11fe667069c","cce9baee6c7e402199003c1fb98bd206","429edfad527e4e8caa4627e6f2f83bc0","cfede7c27a8c4499925944119f1a6be5","cb6a512b72904f8f83f01ceacb5bd2ae","637523262dfc46d69847ca26bd009307","eb1139ebfb2a49249a58cda90cbc7ff8","1b7307fbab5f4d71a75d3e7de2fefdf9","02cf7113a3bd4029bee877c203b87de1","03dffc22176e4f86b5013ec5701961ba","f780e03a76924012a269932fe736d0ac","869a6a5af3e24c15a5f85fecb2450c22","1fc7897f470f4bbc86092083c0759e6a","cb6710f03f194276b008a53b5e120570","457294515e36418ca6ba7b7c9fcb899d","56267050b1354f1eb6ec79b758c5b31a","4a2d57e7f35d428393d374b5d9cc2f49","a8efe07af555436c803faeba3a090544","8df646e9927442ebbc00dcb84935a0cd","78d31076d57e40b2aec4106cc72d5331","71b5c02f4d0e4ec8a4c0aedea3866491","1fb2bbb9c3bc46e48ca6a93277c00b32","e2a41718e2684ff58ae266178918aaed","b746096d32c84fd8b1661033502a7e34","7ee23fd9355f4202b42c77215a50bcc9","751b8d67044b4e129014a26dcf0b442b","af2396e096a8459884990c8a9d63f9c9","fef0b635e92b4452a1e7d98fc9a303ac","a773068bd347414bb829a6e2e7c5e975","eb79e9523fe44d2ebc4b7c2baf578b2d","cbf7c6179c8940b999fb4980e1cd1ada","cf79d819e9aa453d9779b735e3ed1be2","d2c7ecc96bcf402582adaa75cfdc9ef8","a664243ec98b488f8479aefe34cef74e","2ebe8afbd64e4fe69559ff40eee28408","c1e3e9263f584157beaa54ce480c74f2","80f2a430804c4705bb60ee001c6ad758","a83dbb4207c647f59b814762bdb7c865","82b99e1a4caa4eb1ac8b0c99f71f88c9"]},"executionInfo":{"elapsed":49162,"status":"ok","timestamp":1628353769881,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"_WSipbOPb2LW","outputId":"c3f0984e-40ce-45b9-d243-862531f18c30"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading model.safetensors:   1%|â–‹                                                                                             | 10.5M/1.42G [00:03<07:56, 2.96MB/s]"]},{"name":"stderr","output_type":"stream","text":["Downloading model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42G/1.42G [01:12<00:00, 19.7MB/s]\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1144' max='1144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1144/1144 2:42:32, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.187000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.137200</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.932700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.808300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.688600</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.671500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.471300</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.447200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.411200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.366700</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.294800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.212100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.253100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.266400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.265500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.179700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.249000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.176900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.118800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.169900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.143500</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.193500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.165900</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.180400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.192400</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.170500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.099800</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.117600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.098600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.183800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.111500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.089700</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.096000</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.100200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.085000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.110600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.064000</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.078900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.070300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.112300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.101500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.064700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.072000</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.061500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.061300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.106700</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.069700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.071700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.079100</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.058200</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.069000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.069600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.036000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.074600</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.066900</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.083200</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.047400</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.052100</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.066600</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.055700</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.067600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.088700</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.063800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.074900</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.070500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.096400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.052200</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.051400</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.044900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.044300</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.058600</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.054400</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.037600</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.037800</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.055400</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.048200</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.057200</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.043200</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.044800</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.051600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.048400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["143it [01:10,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.0748452290566466\n","is min 1.0748452290566466 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:17,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.9719815687387546\n","is min 0.9719815687387546 is smaller than [1.0748452290566466]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:16,  1.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.9295639407064261\n","is min 0.9295639407064261 is smaller than [1.0748452290566466, 0.9719815687387546]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.9386372547880644\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8296605233050006\n","is min 0.8296605233050006 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.759551756085591\n","is min 0.759551756085591 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7088845800903404\n","is min 0.7088845800903404 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5704354662706834\n","is min 0.5704354662706834 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5862104225030701\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46661738202121766\n","is min 0.46661738202121766 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46812520951584147\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.39695065542214475\n","is min 0.39695065542214475 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.41140156581108317\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.392636989970454\n","is min 0.392636989970454 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3938082813271066\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6626677934876202\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6063483157165472\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4358067038550266\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5112413305612635\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43570601588393554\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3147673924387432\n","is min 0.3147673924387432 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317, 0.392636989970454, 0.3938082813271066, 0.6626677934876202, 0.6063483157165472, 0.4358067038550266, 0.5112413305612635, 0.43570601588393554]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5207103721246712\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3982608756850303\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5432209375725633\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5126143874247171\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5121238234248457\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5796645797345221\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.510056298714172\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4407941519740365\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24583774346685952\n","is min 0.24583774346685952 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317, 0.392636989970454, 0.3938082813271066, 0.6626677934876202, 0.6063483157165472, 0.4358067038550266, 0.5112413305612635, 0.43570601588393554, 0.3147673924387432, 0.5207103721246712, 0.3982608756850303, 0.5432209375725633, 0.5126143874247171, 0.5121238234248457, 0.5796645797345221, 0.510056298714172, 0.4407941519740365]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25047913702335317\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35833385073249197\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23384395690904758\n","is min 0.23384395690904758 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317, 0.392636989970454, 0.3938082813271066, 0.6626677934876202, 0.6063483157165472, 0.4358067038550266, 0.5112413305612635, 0.43570601588393554, 0.3147673924387432, 0.5207103721246712, 0.3982608756850303, 0.5432209375725633, 0.5126143874247171, 0.5121238234248457, 0.5796645797345221, 0.510056298714172, 0.4407941519740365, 0.24583774346685952, 0.25047913702335317, 0.35833385073249197]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2580767895951416\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5336277818806725\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4552096771617586\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.39797152056676927\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3317255877567981\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31013241907173655\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21783134356600833\n","is min 0.21783134356600833 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317, 0.392636989970454, 0.3938082813271066, 0.6626677934876202, 0.6063483157165472, 0.4358067038550266, 0.5112413305612635, 0.43570601588393554, 0.3147673924387432, 0.5207103721246712, 0.3982608756850303, 0.5432209375725633, 0.5126143874247171, 0.5121238234248457, 0.5796645797345221, 0.510056298714172, 0.4407941519740365, 0.24583774346685952, 0.25047913702335317, 0.35833385073249197, 0.23384395690904758, 0.2580767895951416, 0.5336277818806725, 0.4552096771617586, 0.39797152056676927, 0.3317255877567981, 0.31013241907173655]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26929455714353606\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2655857431436869\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5202666537860338\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5024695495923122\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20148863856113208\n","is min 0.20148863856113208 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317, 0.392636989970454, 0.3938082813271066, 0.6626677934876202, 0.6063483157165472, 0.4358067038550266, 0.5112413305612635, 0.43570601588393554, 0.3147673924387432, 0.5207103721246712, 0.3982608756850303, 0.5432209375725633, 0.5126143874247171, 0.5121238234248457, 0.5796645797345221, 0.510056298714172, 0.4407941519740365, 0.24583774346685952, 0.25047913702335317, 0.35833385073249197, 0.23384395690904758, 0.2580767895951416, 0.5336277818806725, 0.4552096771617586, 0.39797152056676927, 0.3317255877567981, 0.31013241907173655, 0.21783134356600833, 0.26929455714353606, 0.2655857431436869, 0.5202666537860338, 0.5024695495923122]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3596721548638806\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35107208568616555\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24524097446618373\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19708098839992175\n","is min 0.19708098839992175 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317, 0.392636989970454, 0.3938082813271066, 0.6626677934876202, 0.6063483157165472, 0.4358067038550266, 0.5112413305612635, 0.43570601588393554, 0.3147673924387432, 0.5207103721246712, 0.3982608756850303, 0.5432209375725633, 0.5126143874247171, 0.5121238234248457, 0.5796645797345221, 0.510056298714172, 0.4407941519740365, 0.24583774346685952, 0.25047913702335317, 0.35833385073249197, 0.23384395690904758, 0.2580767895951416, 0.5336277818806725, 0.4552096771617586, 0.39797152056676927, 0.3317255877567981, 0.31013241907173655, 0.21783134356600833, 0.26929455714353606, 0.2655857431436869, 0.5202666537860338, 0.5024695495923122, 0.20148863856113208, 0.3596721548638806, 0.35107208568616555, 0.24524097446618373]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2998476317153758\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2951653426479236\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26586566176443205\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.29209146712541584\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4346212346622212\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4274995518461691\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4316061245997022\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2426857114860269\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4972761531094909\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45354992745945677\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5290432495581427\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4768058936434846\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.30395341004921644\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3661232727831192\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5267661766686561\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6357179958605994\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47829524340616975\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5354234620964603\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44996942182517763\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.488475758381751\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3973256609157333\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.39447616989883605\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43122043227935664\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.39012684118679025\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6743048344745672\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24767170804707198\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22637317457897355\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28262583128567215\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44607107313836813\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3679689322285594\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31922157252947464\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25366654779848546\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3825295552677042\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4881359063166726\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44367478899239327\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44456105147107317\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3445810061941529\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2863396553130593\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2700672846098712\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23401485008437817\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37692742578452226\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37829047897227386\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4002740038272884\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35256238670449824\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.38192129672292385\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2820761204026791\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34878750715459206\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37917272964125937\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3088898704833531\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2639336656866404\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.12704855938069418\n","is min 0.12704855938069418 is smaller than [1.0748452290566466, 0.9719815687387546, 0.9295639407064261, 0.9386372547880644, 0.8296605233050006, 0.759551756085591, 0.7088845800903404, 0.5704354662706834, 0.5862104225030701, 0.46661738202121766, 0.46812520951584147, 0.39695065542214475, 0.41140156581108317, 0.392636989970454, 0.3938082813271066, 0.6626677934876202, 0.6063483157165472, 0.4358067038550266, 0.5112413305612635, 0.43570601588393554, 0.3147673924387432, 0.5207103721246712, 0.3982608756850303, 0.5432209375725633, 0.5126143874247171, 0.5121238234248457, 0.5796645797345221, 0.510056298714172, 0.4407941519740365, 0.24583774346685952, 0.25047913702335317, 0.35833385073249197, 0.23384395690904758, 0.2580767895951416, 0.5336277818806725, 0.4552096771617586, 0.39797152056676927, 0.3317255877567981, 0.31013241907173655, 0.21783134356600833, 0.26929455714353606, 0.2655857431436869, 0.5202666537860338, 0.5024695495923122, 0.20148863856113208, 0.3596721548638806, 0.35107208568616555, 0.24524097446618373, 0.19708098839992175, 0.2998476317153758, 0.2951653426479236, 0.26586566176443205, 0.29209146712541584, 0.4346212346622212, 0.4274995518461691, 0.4316061245997022, 0.2426857114860269, 0.4972761531094909, 0.45354992745945677, 0.5290432495581427, 0.4768058936434846, 0.30395341004921644, 0.3661232727831192, 0.5267661766686561, 0.6357179958605994, 0.47829524340616975, 0.5354234620964603, 0.44996942182517763, 0.488475758381751, 0.3973256609157333, 0.39447616989883605, 0.43122043227935664, 0.39012684118679025, 0.6743048344745672, 0.24767170804707198, 0.22637317457897355, 0.28262583128567215, 0.44607107313836813, 0.3679689322285594, 0.31922157252947464, 0.25366654779848546, 0.3825295552677042, 0.4881359063166726, 0.44367478899239327, 0.44456105147107317, 0.3445810061941529, 0.2863396553130593, 0.2700672846098712, 0.23401485008437817, 0.37692742578452226, 0.37829047897227386, 0.4002740038272884, 0.35256238670449824, 0.38192129672292385, 0.2820761204026791, 0.34878750715459206, 0.37917272964125937, 0.3088898704833531, 0.2639336656866404]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34549235115115107\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23654754106721515\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37184361058146786\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34439744321341803\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37894158524622334\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.36854469658517996\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43258740058278444\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2565943312742089\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2575669796690203\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3297397617965743\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.29159224378642684\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31266081549182284\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24009023288014505\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:14,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20921944937230724\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3673777991611483\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"data":{"text/plain":["0.12704855938069418"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Train a RoBERTa model\n","model_name = 'roberta-large'\n","hyperparams = {\n","  'bs': 8,\n","  'lr': 1e-5,\n","  'weight_decay': 0.01,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ROBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/roberta-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=ROBERTA_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bd242afef0ab4c3cb6b9f87717cdd344","1292580a726d491eaf064c9030ff1a35","c29f290b45d8475380626a8cad70c10f","71cb361ae38f4d8b95201eb7e3458965","bd8cf24968f24864a8e4f2c406426ac5","e8461044e198445884fcdbbac79a937c","6278a802693a48f089d2fb0d5c159cc9","c3efb3aa702041de99815ae25b9ed9b3","c914f3f58ca3436a80c4f1a48bac0872","c9d9fa1294954d3ebfc519a8aa155b2b","0453164bfded49c8bb0b7826e9190f15","b02adf7749384b84a9928b183565ffe6","c8cf91d3257e40c6addbdab6e43c39fd","0c5ca114ea1f469da95325d91f38d79e","f9fefdf355374256942ab6a0717ea8cc","53a20cba91cb4d498efefa81f96292b6","30194a43b72445389edeb445e7d71b9d","0ddafe40e1774eb8a65e891e9c4d8005","a91b8640c5b5445494dee1952a9508fd","246c3ab4a27e42b5bb00d25177c30065","f1db107c5f084fd384df120d75eac853","1062acd5853a4ab492415657e5b1639d","75f19f654a4d4d26bb431102cdaf6ad6","0ff0ac223dca4b2dbf0377c763eabdf9","9b512229653d427985f4bf9cc4bcad3e","3b6ff42c143741f8ac1ef39ee7f4f5fe","340ae92dba31406382b56af69026d5b9","a06b96a650894594bd3e10c43b4e58f6","ad8d432775134c2187fe3f53821049d7","b3cb7aa5e15d4f62996e6b473ce6bcef","ae4befe894374ea4ba4639e7238b0001","7f44c0772f544c6191df123810f7ede8","6dd8f7a12ffe412182a4ccc5266dd050","27fc9f209c424da2b4d3036de96badc1","571ae312ec664826807dca5ccffb390b","4ff5753d701940c0afdbc331012634e9","3c9d5461f6414ef0a033c6a098419ae9","4d7b09f0f3dd4299a7ce1d586fe15c08","2ef75b93f0cd4dc3ae0b74a21a967af8","ec386d7b500b440684b1050842a69ad4","2cd178aa7c4f4ad8b8f07d72750a824a","8829de1e90e04481a5ce6668558c22f8","f3b7b30ad39d4bfd8fe8aeb462f9e091","85f3e8aaf83748e899449c567244664e","6a656abe51244c5eaa8091bcc626c2d2","a7ad68d3c6fc4eeeb8f47df6a893510b","9823b8716027416bb07fd2aa35fdae8d","e4b9b2ea64e649918de011a1f1bfeac6","87d2b417d2e547b48ef1deb064d07cdd","986d22e0c67c4318aea89f64a3e1a7bc","308d554f512e47c0bec0eaea069ffa31","d1b7209908a64f4db31686c5d25f2fbf","5757c3974b7b435e8ceb531a897f58ed","7e13bdfc94c94de0abb94f660435a750","b7e6cf2574994104a3e89c652ff0db22"]},"executionInfo":{"elapsed":68800,"status":"ok","timestamp":1628353943089,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"TKTR9SyZcasB","outputId":"db4e1ba6-ebf4-44fd-a2ff-232c66a0cd1f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27.0/27.0 [00:00<00:00, 84.8kB/s]\n","Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 668/668 [00:00<00:00, 1.43MB/s]\n","Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 704kB/s]\n","Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 494kB/s]\n","Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [58:30<00:00, 383kB/s]\n","Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4004' max='4004' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4004/4004 9:16:29, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.987400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.363900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.017500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.608900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.570000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.271300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.195500</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.213800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.811700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.916400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.702900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.761800</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.701400</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.686800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.693500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.567200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.667900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.766000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.586100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.683500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.533600</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.440300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.242100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.362000</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.319500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.212700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.240400</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.287200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.194400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.187700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.166400</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.195100</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.168000</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.128900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.144300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.099000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.133900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.105900</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.123600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.122300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.197600</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.171300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.123600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.156600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.107500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.107100</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.108700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.086400</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.054400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.086200</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.085900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.085500</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.061800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.102900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.137000</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.090000</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.089800</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.074300</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.085600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.080400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.073100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.109000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.057200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.066100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.052600</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.061600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.078200</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.071400</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.125200</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.100100</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.060200</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.055200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.050000</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.044900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.084500</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.068900</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.055000</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.041600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.057400</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.060100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.055100</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.076100</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.072900</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.080900</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.069600</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.062900</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.059900</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.048700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.074900</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.061800</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.051200</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.063200</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.055600</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.029700</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.055400</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.050700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.053200</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.034400</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.054800</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.041700</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.034600</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.034400</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.063000</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.079900</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.070900</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.031100</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.044200</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.026400</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.023000</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.025200</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.033700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.026000</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.024800</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.027800</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.023000</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.027600</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.030400</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.041900</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.041700</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.025700</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.024800</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.029200</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.027000</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.026200</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.022200</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.019100</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.023000</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.026600</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.022400</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.039700</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.017400</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.019300</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.023600</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.026900</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.025300</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.027700</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.017300</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.027600</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.017500</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.021300</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.020100</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.023000</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>1980</td>\n","      <td>0.028800</td>\n","    </tr>\n","    <tr>\n","      <td>1990</td>\n","      <td>0.030700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.018800</td>\n","    </tr>\n","    <tr>\n","      <td>2010</td>\n","      <td>0.022000</td>\n","    </tr>\n","    <tr>\n","      <td>2020</td>\n","      <td>0.022300</td>\n","    </tr>\n","    <tr>\n","      <td>2030</td>\n","      <td>0.019200</td>\n","    </tr>\n","    <tr>\n","      <td>2040</td>\n","      <td>0.018800</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.036000</td>\n","    </tr>\n","    <tr>\n","      <td>2060</td>\n","      <td>0.022300</td>\n","    </tr>\n","    <tr>\n","      <td>2070</td>\n","      <td>0.019000</td>\n","    </tr>\n","    <tr>\n","      <td>2080</td>\n","      <td>0.021700</td>\n","    </tr>\n","    <tr>\n","      <td>2090</td>\n","      <td>0.017200</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.022800</td>\n","    </tr>\n","    <tr>\n","      <td>2110</td>\n","      <td>0.016000</td>\n","    </tr>\n","    <tr>\n","      <td>2120</td>\n","      <td>0.029900</td>\n","    </tr>\n","    <tr>\n","      <td>2130</td>\n","      <td>0.024500</td>\n","    </tr>\n","    <tr>\n","      <td>2140</td>\n","      <td>0.025300</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.023000</td>\n","    </tr>\n","    <tr>\n","      <td>2160</td>\n","      <td>0.022400</td>\n","    </tr>\n","    <tr>\n","      <td>2170</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>2180</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>2190</td>\n","      <td>0.017900</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.029400</td>\n","    </tr>\n","    <tr>\n","      <td>2210</td>\n","      <td>0.022000</td>\n","    </tr>\n","    <tr>\n","      <td>2220</td>\n","      <td>0.023900</td>\n","    </tr>\n","    <tr>\n","      <td>2230</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>2240</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>2260</td>\n","      <td>0.026400</td>\n","    </tr>\n","    <tr>\n","      <td>2270</td>\n","      <td>0.017200</td>\n","    </tr>\n","    <tr>\n","      <td>2280</td>\n","      <td>0.020100</td>\n","    </tr>\n","    <tr>\n","      <td>2290</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.013000</td>\n","    </tr>\n","    <tr>\n","      <td>2310</td>\n","      <td>0.017300</td>\n","    </tr>\n","    <tr>\n","      <td>2320</td>\n","      <td>0.016400</td>\n","    </tr>\n","    <tr>\n","      <td>2330</td>\n","      <td>0.017000</td>\n","    </tr>\n","    <tr>\n","      <td>2340</td>\n","      <td>0.015400</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.020800</td>\n","    </tr>\n","    <tr>\n","      <td>2360</td>\n","      <td>0.012800</td>\n","    </tr>\n","    <tr>\n","      <td>2370</td>\n","      <td>0.016400</td>\n","    </tr>\n","    <tr>\n","      <td>2380</td>\n","      <td>0.016400</td>\n","    </tr>\n","    <tr>\n","      <td>2390</td>\n","      <td>0.024500</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.012700</td>\n","    </tr>\n","    <tr>\n","      <td>2410</td>\n","      <td>0.021300</td>\n","    </tr>\n","    <tr>\n","      <td>2420</td>\n","      <td>0.044200</td>\n","    </tr>\n","    <tr>\n","      <td>2430</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <td>2440</td>\n","      <td>0.017500</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.013900</td>\n","    </tr>\n","    <tr>\n","      <td>2460</td>\n","      <td>0.019600</td>\n","    </tr>\n","    <tr>\n","      <td>2470</td>\n","      <td>0.016100</td>\n","    </tr>\n","    <tr>\n","      <td>2480</td>\n","      <td>0.014100</td>\n","    </tr>\n","    <tr>\n","      <td>2490</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.015600</td>\n","    </tr>\n","    <tr>\n","      <td>2510</td>\n","      <td>0.015300</td>\n","    </tr>\n","    <tr>\n","      <td>2520</td>\n","      <td>0.017000</td>\n","    </tr>\n","    <tr>\n","      <td>2530</td>\n","      <td>0.013000</td>\n","    </tr>\n","    <tr>\n","      <td>2540</td>\n","      <td>0.016000</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.023300</td>\n","    </tr>\n","    <tr>\n","      <td>2560</td>\n","      <td>0.020800</td>\n","    </tr>\n","    <tr>\n","      <td>2570</td>\n","      <td>0.029300</td>\n","    </tr>\n","    <tr>\n","      <td>2580</td>\n","      <td>0.021100</td>\n","    </tr>\n","    <tr>\n","      <td>2590</td>\n","      <td>0.025000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.011800</td>\n","    </tr>\n","    <tr>\n","      <td>2610</td>\n","      <td>0.018100</td>\n","    </tr>\n","    <tr>\n","      <td>2620</td>\n","      <td>0.020500</td>\n","    </tr>\n","    <tr>\n","      <td>2630</td>\n","      <td>0.017500</td>\n","    </tr>\n","    <tr>\n","      <td>2640</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.011000</td>\n","    </tr>\n","    <tr>\n","      <td>2660</td>\n","      <td>0.017400</td>\n","    </tr>\n","    <tr>\n","      <td>2670</td>\n","      <td>0.012400</td>\n","    </tr>\n","    <tr>\n","      <td>2680</td>\n","      <td>0.026900</td>\n","    </tr>\n","    <tr>\n","      <td>2690</td>\n","      <td>0.030600</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.016200</td>\n","    </tr>\n","    <tr>\n","      <td>2710</td>\n","      <td>0.024900</td>\n","    </tr>\n","    <tr>\n","      <td>2720</td>\n","      <td>0.011400</td>\n","    </tr>\n","    <tr>\n","      <td>2730</td>\n","      <td>0.023600</td>\n","    </tr>\n","    <tr>\n","      <td>2740</td>\n","      <td>0.024100</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>2760</td>\n","      <td>0.023800</td>\n","    </tr>\n","    <tr>\n","      <td>2770</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>2780</td>\n","      <td>0.021000</td>\n","    </tr>\n","    <tr>\n","      <td>2790</td>\n","      <td>0.017900</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>2810</td>\n","      <td>0.019100</td>\n","    </tr>\n","    <tr>\n","      <td>2820</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>2830</td>\n","      <td>0.050800</td>\n","    </tr>\n","    <tr>\n","      <td>2840</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.017900</td>\n","    </tr>\n","    <tr>\n","      <td>2860</td>\n","      <td>0.016900</td>\n","    </tr>\n","    <tr>\n","      <td>2870</td>\n","      <td>0.022800</td>\n","    </tr>\n","    <tr>\n","      <td>2880</td>\n","      <td>0.058000</td>\n","    </tr>\n","    <tr>\n","      <td>2890</td>\n","      <td>0.027400</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.012500</td>\n","    </tr>\n","    <tr>\n","      <td>2910</td>\n","      <td>0.020700</td>\n","    </tr>\n","    <tr>\n","      <td>2920</td>\n","      <td>0.015900</td>\n","    </tr>\n","    <tr>\n","      <td>2930</td>\n","      <td>0.014800</td>\n","    </tr>\n","    <tr>\n","      <td>2940</td>\n","      <td>0.018200</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>2960</td>\n","      <td>0.014700</td>\n","    </tr>\n","    <tr>\n","      <td>2970</td>\n","      <td>0.016700</td>\n","    </tr>\n","    <tr>\n","      <td>2980</td>\n","      <td>0.010400</td>\n","    </tr>\n","    <tr>\n","      <td>2990</td>\n","      <td>0.026200</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.012300</td>\n","    </tr>\n","    <tr>\n","      <td>3010</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>3020</td>\n","      <td>0.016600</td>\n","    </tr>\n","    <tr>\n","      <td>3030</td>\n","      <td>0.016500</td>\n","    </tr>\n","    <tr>\n","      <td>3040</td>\n","      <td>0.018100</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.017800</td>\n","    </tr>\n","    <tr>\n","      <td>3060</td>\n","      <td>0.017700</td>\n","    </tr>\n","    <tr>\n","      <td>3070</td>\n","      <td>0.016000</td>\n","    </tr>\n","    <tr>\n","      <td>3080</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>3090</td>\n","      <td>0.019500</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.015200</td>\n","    </tr>\n","    <tr>\n","      <td>3110</td>\n","      <td>0.011900</td>\n","    </tr>\n","    <tr>\n","      <td>3120</td>\n","      <td>0.011600</td>\n","    </tr>\n","    <tr>\n","      <td>3130</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>3140</td>\n","      <td>0.070700</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.013300</td>\n","    </tr>\n","    <tr>\n","      <td>3160</td>\n","      <td>0.014900</td>\n","    </tr>\n","    <tr>\n","      <td>3170</td>\n","      <td>0.012900</td>\n","    </tr>\n","    <tr>\n","      <td>3180</td>\n","      <td>0.015600</td>\n","    </tr>\n","    <tr>\n","      <td>3190</td>\n","      <td>0.010200</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.013600</td>\n","    </tr>\n","    <tr>\n","      <td>3210</td>\n","      <td>0.010100</td>\n","    </tr>\n","    <tr>\n","      <td>3220</td>\n","      <td>0.013900</td>\n","    </tr>\n","    <tr>\n","      <td>3230</td>\n","      <td>0.012500</td>\n","    </tr>\n","    <tr>\n","      <td>3240</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.009400</td>\n","    </tr>\n","    <tr>\n","      <td>3260</td>\n","      <td>0.012600</td>\n","    </tr>\n","    <tr>\n","      <td>3270</td>\n","      <td>0.014700</td>\n","    </tr>\n","    <tr>\n","      <td>3280</td>\n","      <td>0.025500</td>\n","    </tr>\n","    <tr>\n","      <td>3290</td>\n","      <td>0.015300</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>3310</td>\n","      <td>0.015300</td>\n","    </tr>\n","    <tr>\n","      <td>3320</td>\n","      <td>0.015300</td>\n","    </tr>\n","    <tr>\n","      <td>3330</td>\n","      <td>0.010600</td>\n","    </tr>\n","    <tr>\n","      <td>3340</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>3350</td>\n","      <td>0.025000</td>\n","    </tr>\n","    <tr>\n","      <td>3360</td>\n","      <td>0.016800</td>\n","    </tr>\n","    <tr>\n","      <td>3370</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>3380</td>\n","      <td>0.018500</td>\n","    </tr>\n","    <tr>\n","      <td>3390</td>\n","      <td>0.016000</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.014100</td>\n","    </tr>\n","    <tr>\n","      <td>3410</td>\n","      <td>0.012900</td>\n","    </tr>\n","    <tr>\n","      <td>3420</td>\n","      <td>0.011000</td>\n","    </tr>\n","    <tr>\n","      <td>3430</td>\n","      <td>0.011100</td>\n","    </tr>\n","    <tr>\n","      <td>3440</td>\n","      <td>0.041200</td>\n","    </tr>\n","    <tr>\n","      <td>3450</td>\n","      <td>0.021200</td>\n","    </tr>\n","    <tr>\n","      <td>3460</td>\n","      <td>0.010600</td>\n","    </tr>\n","    <tr>\n","      <td>3470</td>\n","      <td>0.014100</td>\n","    </tr>\n","    <tr>\n","      <td>3480</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>3490</td>\n","      <td>0.009600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.011600</td>\n","    </tr>\n","    <tr>\n","      <td>3510</td>\n","      <td>0.008800</td>\n","    </tr>\n","    <tr>\n","      <td>3520</td>\n","      <td>0.012400</td>\n","    </tr>\n","    <tr>\n","      <td>3530</td>\n","      <td>0.011200</td>\n","    </tr>\n","    <tr>\n","      <td>3540</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>3550</td>\n","      <td>0.014300</td>\n","    </tr>\n","    <tr>\n","      <td>3560</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>3570</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>3580</td>\n","      <td>0.012800</td>\n","    </tr>\n","    <tr>\n","      <td>3590</td>\n","      <td>0.014200</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.026700</td>\n","    </tr>\n","    <tr>\n","      <td>3610</td>\n","      <td>0.019900</td>\n","    </tr>\n","    <tr>\n","      <td>3620</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>3630</td>\n","      <td>0.017700</td>\n","    </tr>\n","    <tr>\n","      <td>3640</td>\n","      <td>0.025300</td>\n","    </tr>\n","    <tr>\n","      <td>3650</td>\n","      <td>0.011200</td>\n","    </tr>\n","    <tr>\n","      <td>3660</td>\n","      <td>0.011900</td>\n","    </tr>\n","    <tr>\n","      <td>3670</td>\n","      <td>0.023400</td>\n","    </tr>\n","    <tr>\n","      <td>3680</td>\n","      <td>0.009300</td>\n","    </tr>\n","    <tr>\n","      <td>3690</td>\n","      <td>0.010300</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.009800</td>\n","    </tr>\n","    <tr>\n","      <td>3710</td>\n","      <td>0.012500</td>\n","    </tr>\n","    <tr>\n","      <td>3720</td>\n","      <td>0.010800</td>\n","    </tr>\n","    <tr>\n","      <td>3730</td>\n","      <td>0.010800</td>\n","    </tr>\n","    <tr>\n","      <td>3740</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>3760</td>\n","      <td>0.014900</td>\n","    </tr>\n","    <tr>\n","      <td>3770</td>\n","      <td>0.014500</td>\n","    </tr>\n","    <tr>\n","      <td>3780</td>\n","      <td>0.014300</td>\n","    </tr>\n","    <tr>\n","      <td>3790</td>\n","      <td>0.011500</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.010300</td>\n","    </tr>\n","    <tr>\n","      <td>3810</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>3820</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>3830</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>3840</td>\n","      <td>0.010600</td>\n","    </tr>\n","    <tr>\n","      <td>3850</td>\n","      <td>0.012500</td>\n","    </tr>\n","    <tr>\n","      <td>3860</td>\n","      <td>0.011400</td>\n","    </tr>\n","    <tr>\n","      <td>3870</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>3880</td>\n","      <td>0.010800</td>\n","    </tr>\n","    <tr>\n","      <td>3890</td>\n","      <td>0.012400</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.012300</td>\n","    </tr>\n","    <tr>\n","      <td>3910</td>\n","      <td>0.012600</td>\n","    </tr>\n","    <tr>\n","      <td>3920</td>\n","      <td>0.010200</td>\n","    </tr>\n","    <tr>\n","      <td>3930</td>\n","      <td>0.017700</td>\n","    </tr>\n","    <tr>\n","      <td>3940</td>\n","      <td>0.006800</td>\n","    </tr>\n","    <tr>\n","      <td>3950</td>\n","      <td>0.010500</td>\n","    </tr>\n","    <tr>\n","      <td>3960</td>\n","      <td>0.009200</td>\n","    </tr>\n","    <tr>\n","      <td>3970</td>\n","      <td>0.008400</td>\n","    </tr>\n","    <tr>\n","      <td>3980</td>\n","      <td>0.022800</td>\n","    </tr>\n","    <tr>\n","      <td>3990</td>\n","      <td>0.010500</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.023800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["143it [01:08,  2.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.3423287768124137\n","is min 1.3423287768124137 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:10,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.3289993063477046\n","is min 1.3289993063477046 is smaller than [1.3423287768124137]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:12,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.306494250903362\n","is min 1.306494250903362 is smaller than [1.3423287768124137, 1.3289993063477046]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.2753183582292598\n","is min 1.2753183582292598 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.2344306939466483\n","is min 1.2344306939466483 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.1856926551284714\n","is min 1.1856926551284714 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.128982858252043\n","is min 1.128982858252043 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:14,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.06721921498586\n","is min 1.06721921498586 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  1.005559735441436\n","is min 1.005559735441436 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.9447179321629441\n","is min 0.9447179321629441 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.892569115648123\n","is min 0.892569115648123 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8479875678445656\n","is min 0.8479875678445656 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8225722190452144\n","is min 0.8225722190452144 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8121944070284546\n","is min 0.8121944070284546 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.805838736270369\n","is min 0.805838736270369 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7955991509717045\n","is min 0.7955991509717045 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7807320341793025\n","is min 0.7807320341793025 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7639015888182208\n","is min 0.7639015888182208 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7379538136666504\n","is min 0.7379538136666504 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7106790617618624\n","is min 0.7106790617618624 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6536137536787526\n","is min 0.6536137536787526 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5887495206480371\n","is min 0.5887495206480371 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5496526338395209\n","is min 0.5496526338395209 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48504344276356703\n","is min 0.48504344276356703 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5053092182450131\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47431929652185656\n","is min 0.47431929652185656 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4243175134789028\n","is min 0.4243175134789028 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4150356791558825\n","is min 0.4150356791558825 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47650403215420634\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4324994320527204\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.42780231752891135\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5421736182044966\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35365917572197675\n","is min 0.35365917572197675 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3661526414070712\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4468099417234399\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.36316652791446996\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34120245629795054\n","is min 0.34120245629795054 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34270436191345405\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3056130560023356\n","is min 0.3056130560023356 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4288769698003781\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5965121701665309\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3314402192147096\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2876235298567453\n","is min 0.2876235298567453 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5477186006576337\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37269908863356727\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31111980169138287\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.29808211170657506\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2594687887292747\n","is min 0.2594687887292747 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3404229627886628\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2875446634761205\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.29886524859345576\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.363915144588318\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3706618180365271\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.624522332198934\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2385657710510502\n","is min 0.2385657710510502 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24504653480631555\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.87it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2964289549859992\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3651224477116114\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.42838310472937174\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34820471112306123\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3577555491547527\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4553199085048824\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2128518844751608\n","is min 0.2128518844751608 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.39565042967190833\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.87it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27399489125720056\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.87it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28766439695934765\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.87it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23784381851716357\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.87it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4009189755527674\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47366076437353505\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2609295871578254\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.262831277653683\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5476643237770321\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2037797217501099\n","is min 0.2037797217501099 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27456210876225423\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.87it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3305618311814909\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2282395057501444\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24295736510739405\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2221643326087925\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.87it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3225410443066288\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3303053480832647\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37940890159404267\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3397090703113985\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2067055171855026\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23148146852480872\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20971641600873073\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3105797999324896\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3420017570790874\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.261313178507257\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.261715882385504\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.420331655197485\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2723803376313865\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23458294331625634\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.33290467601375884\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.42922784328471764\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2232510111114141\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19893303689362346\n","is min 0.19893303689362346 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.244502419609793\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3677945150296257\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31853612057000646\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22265463607501357\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.238341616619749\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2652969829390051\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3613382955384702\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25911839142067045\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17282123358451687\n","is min 0.17282123358451687 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141, 0.19893303689362346, 0.244502419609793, 0.3677945150296257, 0.31853612057000646, 0.22265463607501357, 0.238341616619749, 0.2652969829390051, 0.3613382955384702, 0.25911839142067045]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3968040374400449\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20296930914423938\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35352266826818474\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.32207801316932355\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.40331648076056176\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16290968756789984\n","is min 0.16290968756789984 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141, 0.19893303689362346, 0.244502419609793, 0.3677945150296257, 0.31853612057000646, 0.22265463607501357, 0.238341616619749, 0.2652969829390051, 0.3613382955384702, 0.25911839142067045, 0.17282123358451687, 0.3968040374400449, 0.20296930914423938, 0.35352266826818474, 0.32207801316932355, 0.40331648076056176]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3187263371008177\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22182963116667315\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2188188917942006\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4308338174538334\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17491610863327825\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19356000473182736\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1931170368431915\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2517373464337043\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3124864540477146\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.41024337250726917\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27732579242228095\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21306013896427417\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.285085475084633\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.37147788560445966\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2604353929817815\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.15185899403905592\n","is min 0.15185899403905592 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141, 0.19893303689362346, 0.244502419609793, 0.3677945150296257, 0.31853612057000646, 0.22265463607501357, 0.238341616619749, 0.2652969829390051, 0.3613382955384702, 0.25911839142067045, 0.17282123358451687, 0.3968040374400449, 0.20296930914423938, 0.35352266826818474, 0.32207801316932355, 0.40331648076056176, 0.16290968756789984, 0.3187263371008177, 0.22182963116667315, 0.2188188917942006, 0.4308338174538334, 0.17491610863327825, 0.19356000473182736, 0.1931170368431915, 0.2517373464337043, 0.3124864540477146, 0.41024337250726917, 0.27732579242228095, 0.21306013896427417, 0.285085475084633, 0.37147788560445966, 0.2604353929817815]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2340958471818421\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3518984741472351\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2164979899757701\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2778823627889841\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1467363466405698\n","is min 0.1467363466405698 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141, 0.19893303689362346, 0.244502419609793, 0.3677945150296257, 0.31853612057000646, 0.22265463607501357, 0.238341616619749, 0.2652969829390051, 0.3613382955384702, 0.25911839142067045, 0.17282123358451687, 0.3968040374400449, 0.20296930914423938, 0.35352266826818474, 0.32207801316932355, 0.40331648076056176, 0.16290968756789984, 0.3187263371008177, 0.22182963116667315, 0.2188188917942006, 0.4308338174538334, 0.17491610863327825, 0.19356000473182736, 0.1931170368431915, 0.2517373464337043, 0.3124864540477146, 0.41024337250726917, 0.27732579242228095, 0.21306013896427417, 0.285085475084633, 0.37147788560445966, 0.2604353929817815, 0.15185899403905592, 0.2340958471818421, 0.3518984741472351, 0.2164979899757701, 0.2778823627889841]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26012435270439904\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4030556874522458\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1920664844561215\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28297599964339387\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27299825114746357\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24020947893272526\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14244052672166435\n","is min 0.14244052672166435 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141, 0.19893303689362346, 0.244502419609793, 0.3677945150296257, 0.31853612057000646, 0.22265463607501357, 0.238341616619749, 0.2652969829390051, 0.3613382955384702, 0.25911839142067045, 0.17282123358451687, 0.3968040374400449, 0.20296930914423938, 0.35352266826818474, 0.32207801316932355, 0.40331648076056176, 0.16290968756789984, 0.3187263371008177, 0.22182963116667315, 0.2188188917942006, 0.4308338174538334, 0.17491610863327825, 0.19356000473182736, 0.1931170368431915, 0.2517373464337043, 0.3124864540477146, 0.41024337250726917, 0.27732579242228095, 0.21306013896427417, 0.285085475084633, 0.37147788560445966, 0.2604353929817815, 0.15185899403905592, 0.2340958471818421, 0.3518984741472351, 0.2164979899757701, 0.2778823627889841, 0.1467363466405698, 0.26012435270439904, 0.4030556874522458, 0.1920664844561215, 0.28297599964339387, 0.27299825114746357, 0.24020947893272526]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.355556409251322\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2161472568042991\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24859593914331238\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2539513799701304\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.34668515329573774\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2687992070707307\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.30360533976831217\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.29245879244177203\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2336097695949758\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28288865042880706\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2867425019435303\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22274442770585837\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21846252467583013\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2908325896425369\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1893374734911386\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2704077594132377\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27437215791888436\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20802532519246789\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1763867345557891\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.325432693122332\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3402033982054959\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20443921610083807\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18818476922717378\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2662134472044583\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.38059059979972654\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2623865846536543\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2399648833772993\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2855975641085403\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31644224869056903\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2442774648835001\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22524226105405018\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19441231220317975\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26315878425675215\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23126398417695904\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25530531302563675\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3094470708057221\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28171811961159293\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1505003472097368\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22157719958912814\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20647482573994586\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26689654318357064\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17398593583867664\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2975194544234098\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24510034073320502\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3414174560025974\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2884418885887006\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1894409341097721\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24612626567340484\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17462075987499828\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.206826791517804\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.30745293600120116\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2881368377885709\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2627786555229918\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1281626743910182\n","is min 0.1281626743910182 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141, 0.19893303689362346, 0.244502419609793, 0.3677945150296257, 0.31853612057000646, 0.22265463607501357, 0.238341616619749, 0.2652969829390051, 0.3613382955384702, 0.25911839142067045, 0.17282123358451687, 0.3968040374400449, 0.20296930914423938, 0.35352266826818474, 0.32207801316932355, 0.40331648076056176, 0.16290968756789984, 0.3187263371008177, 0.22182963116667315, 0.2188188917942006, 0.4308338174538334, 0.17491610863327825, 0.19356000473182736, 0.1931170368431915, 0.2517373464337043, 0.3124864540477146, 0.41024337250726917, 0.27732579242228095, 0.21306013896427417, 0.285085475084633, 0.37147788560445966, 0.2604353929817815, 0.15185899403905592, 0.2340958471818421, 0.3518984741472351, 0.2164979899757701, 0.2778823627889841, 0.1467363466405698, 0.26012435270439904, 0.4030556874522458, 0.1920664844561215, 0.28297599964339387, 0.27299825114746357, 0.24020947893272526, 0.14244052672166435, 0.355556409251322, 0.2161472568042991, 0.24859593914331238, 0.2539513799701304, 0.34668515329573774, 0.2687992070707307, 0.30360533976831217, 0.29245879244177203, 0.2336097695949758, 0.28288865042880706, 0.2867425019435303, 0.22274442770585837, 0.21846252467583013, 0.2908325896425369, 0.1893374734911386, 0.2704077594132377, 0.27437215791888436, 0.20802532519246789, 0.1763867345557891, 0.325432693122332, 0.3402033982054959, 0.20443921610083807, 0.18818476922717378, 0.2662134472044583, 0.38059059979972654, 0.2623865846536543, 0.2399648833772993, 0.2855975641085403, 0.31644224869056903, 0.2442774648835001, 0.22524226105405018, 0.19441231220317975, 0.26315878425675215, 0.23126398417695904, 0.25530531302563675, 0.3094470708057221, 0.28171811961159293, 0.1505003472097368, 0.22157719958912814, 0.20647482573994586, 0.26689654318357064, 0.17398593583867664, 0.2975194544234098, 0.24510034073320502, 0.3414174560025974, 0.2884418885887006, 0.1894409341097721, 0.24612626567340484, 0.17462075987499828, 0.206826791517804, 0.30745293600120116, 0.2881368377885709, 0.2627786555229918]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2642385750125696\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28725155845542777\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2593685480858057\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19931802898909176\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17317525663345576\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26680607750701796\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26149803369978747\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20742438739682334\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1921641547480561\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20486993527706399\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2679766929559969\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17964948698651334\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20714066694039127\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23205588690910137\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24732404534389454\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31689422680878115\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31354472133355715\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31018754659813624\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21463294391375148\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2743022177520566\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23990984020125478\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:16,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23370039984323315\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24974361989848873\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16661079771943485\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23824542477525365\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3466504355962707\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25243287422895294\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17499235046596878\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2557446551113816\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26335324034764224\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1578294708535751\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.30912830166546557\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3022045496272646\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20205262412042702\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2432894900139064\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24810101652404384\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19471872320347364\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2852862435876625\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2586790245879794\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20332070027383436\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25531389292162904\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2978578223471529\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2950596676401676\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1732195388513285\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20877663220403342\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26658416705133114\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25425861158376756\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3026800986427554\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19511685189664374\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.15971752773543943\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2331956684981573\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23551951047241163\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21755525389380412\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23837821819798244\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2471896222759209\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25465927836917457\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2710486702940298\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2285494734229825\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18715770858180616\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20711602013515235\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23013122127464078\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18265193149264997\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18604252279999872\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2793217014183409\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2929984731050376\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19607001403627344\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2763563099246464\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2501280950721747\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25090344209668636\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1918205883983579\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21736961597852547\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2317138264752448\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2221307692205781\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2522318462590564\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2331282958132083\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22438975630013985\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19823437552446418\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22626638302089697\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1555007513541123\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2566447916215294\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3142540230267175\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16397196421827687\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14587916834537562\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.35742251261927277\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28119087681114147\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22955011253333338\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2053893034620675\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2532129324980415\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22627372336186963\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2291731655947074\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25652090212892825\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1582309757661109\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19532014470237752\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2686386087772937\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2564835288466947\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19774590776050172\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24269027255331335\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27449541875576045\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25404635797285985\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.15281697859076113\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31122099463068975\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2212075398986415\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25398925577864995\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1914146982738523\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2019567746265957\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.17393671812672326\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18676696435777407\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27287390652650273\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2955453515484838\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2071683848512596\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20290753816175774\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1991675447668417\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23034948030709973\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22316288622153227\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19375484419291253\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22805657995559098\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.217451165659409\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2559922753266677\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23750177877268053\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1803169462340529\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22869863149590566\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2361263886453596\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23797785845799\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2433659049875135\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27114095594952864\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18413931742639028\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16378170617102142\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14942576256215878\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2639684848561976\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26699279269982856\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1655323042963255\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2475496994390625\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1887543810520827\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2398827199585824\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22924719626422482\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21428023664620077\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2543547779751987\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2472796693221517\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2037756571119883\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20083219966817026\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.31434487094817043\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21228886964737942\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22465371273464999\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25767524895833516\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1908089438887551\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20224825867031349\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16568766826857434\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23266421956018046\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18502731117243648\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18802805895706518\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.303775026357728\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1256021698283635\n","is min 0.1256021698283635 is smaller than [1.3423287768124137, 1.3289993063477046, 1.306494250903362, 1.2753183582292598, 1.2344306939466483, 1.1856926551284714, 1.128982858252043, 1.06721921498586, 1.005559735441436, 0.9447179321629441, 0.892569115648123, 0.8479875678445656, 0.8225722190452144, 0.8121944070284546, 0.805838736270369, 0.7955991509717045, 0.7807320341793025, 0.7639015888182208, 0.7379538136666504, 0.7106790617618624, 0.6536137536787526, 0.5887495206480371, 0.5496526338395209, 0.48504344276356703, 0.5053092182450131, 0.47431929652185656, 0.4243175134789028, 0.4150356791558825, 0.47650403215420634, 0.4324994320527204, 0.42780231752891135, 0.5421736182044966, 0.35365917572197675, 0.3661526414070712, 0.4468099417234399, 0.36316652791446996, 0.34120245629795054, 0.34270436191345405, 0.3056130560023356, 0.4288769698003781, 0.5965121701665309, 0.3314402192147096, 0.2876235298567453, 0.5477186006576337, 0.37269908863356727, 0.31111980169138287, 0.29808211170657506, 0.2594687887292747, 0.3404229627886628, 0.2875446634761205, 0.29886524859345576, 0.363915144588318, 0.3706618180365271, 0.624522332198934, 0.2385657710510502, 0.24504653480631555, 0.2964289549859992, 0.3651224477116114, 0.42838310472937174, 0.34820471112306123, 0.3577555491547527, 0.4553199085048824, 0.2128518844751608, 0.39565042967190833, 0.27399489125720056, 0.28766439695934765, 0.23784381851716357, 0.4009189755527674, 0.47366076437353505, 0.2609295871578254, 0.262831277653683, 0.5476643237770321, 0.2037797217501099, 0.27456210876225423, 0.3305618311814909, 0.2282395057501444, 0.24295736510739405, 0.2221643326087925, 0.3225410443066288, 0.3303053480832647, 0.37940890159404267, 0.3397090703113985, 0.2067055171855026, 0.23148146852480872, 0.20971641600873073, 0.3105797999324896, 0.3420017570790874, 0.261313178507257, 0.261715882385504, 0.420331655197485, 0.2723803376313865, 0.23458294331625634, 0.33290467601375884, 0.42922784328471764, 0.2232510111114141, 0.19893303689362346, 0.244502419609793, 0.3677945150296257, 0.31853612057000646, 0.22265463607501357, 0.238341616619749, 0.2652969829390051, 0.3613382955384702, 0.25911839142067045, 0.17282123358451687, 0.3968040374400449, 0.20296930914423938, 0.35352266826818474, 0.32207801316932355, 0.40331648076056176, 0.16290968756789984, 0.3187263371008177, 0.22182963116667315, 0.2188188917942006, 0.4308338174538334, 0.17491610863327825, 0.19356000473182736, 0.1931170368431915, 0.2517373464337043, 0.3124864540477146, 0.41024337250726917, 0.27732579242228095, 0.21306013896427417, 0.285085475084633, 0.37147788560445966, 0.2604353929817815, 0.15185899403905592, 0.2340958471818421, 0.3518984741472351, 0.2164979899757701, 0.2778823627889841, 0.1467363466405698, 0.26012435270439904, 0.4030556874522458, 0.1920664844561215, 0.28297599964339387, 0.27299825114746357, 0.24020947893272526, 0.14244052672166435, 0.355556409251322, 0.2161472568042991, 0.24859593914331238, 0.2539513799701304, 0.34668515329573774, 0.2687992070707307, 0.30360533976831217, 0.29245879244177203, 0.2336097695949758, 0.28288865042880706, 0.2867425019435303, 0.22274442770585837, 0.21846252467583013, 0.2908325896425369, 0.1893374734911386, 0.2704077594132377, 0.27437215791888436, 0.20802532519246789, 0.1763867345557891, 0.325432693122332, 0.3402033982054959, 0.20443921610083807, 0.18818476922717378, 0.2662134472044583, 0.38059059979972654, 0.2623865846536543, 0.2399648833772993, 0.2855975641085403, 0.31644224869056903, 0.2442774648835001, 0.22524226105405018, 0.19441231220317975, 0.26315878425675215, 0.23126398417695904, 0.25530531302563675, 0.3094470708057221, 0.28171811961159293, 0.1505003472097368, 0.22157719958912814, 0.20647482573994586, 0.26689654318357064, 0.17398593583867664, 0.2975194544234098, 0.24510034073320502, 0.3414174560025974, 0.2884418885887006, 0.1894409341097721, 0.24612626567340484, 0.17462075987499828, 0.206826791517804, 0.30745293600120116, 0.2881368377885709, 0.2627786555229918, 0.1281626743910182, 0.2642385750125696, 0.28725155845542777, 0.2593685480858057, 0.19931802898909176, 0.17317525663345576, 0.26680607750701796, 0.26149803369978747, 0.20742438739682334, 0.1921641547480561, 0.20486993527706399, 0.2679766929559969, 0.17964948698651334, 0.20714066694039127, 0.23205588690910137, 0.24732404534389454, 0.31689422680878115, 0.31354472133355715, 0.31018754659813624, 0.21463294391375148, 0.2743022177520566, 0.23990984020125478, 0.23370039984323315, 0.24974361989848873, 0.16661079771943485, 0.23824542477525365, 0.3466504355962707, 0.25243287422895294, 0.17499235046596878, 0.2557446551113816, 0.26335324034764224, 0.1578294708535751, 0.30912830166546557, 0.3022045496272646, 0.20205262412042702, 0.2432894900139064, 0.24810101652404384, 0.19471872320347364, 0.2852862435876625, 0.2586790245879794, 0.20332070027383436, 0.25531389292162904, 0.2978578223471529, 0.2950596676401676, 0.1732195388513285, 0.20877663220403342, 0.26658416705133114, 0.25425861158376756, 0.3026800986427554, 0.19511685189664374, 0.15971752773543943, 0.2331956684981573, 0.23551951047241163, 0.21755525389380412, 0.23837821819798244, 0.2471896222759209, 0.25465927836917457, 0.2710486702940298, 0.2285494734229825, 0.18715770858180616, 0.20711602013515235, 0.23013122127464078, 0.18265193149264997, 0.18604252279999872, 0.2793217014183409, 0.2929984731050376, 0.19607001403627344, 0.2763563099246464, 0.2501280950721747, 0.25090344209668636, 0.1918205883983579, 0.21736961597852547, 0.2317138264752448, 0.2221307692205781, 0.2522318462590564, 0.2331282958132083, 0.22438975630013985, 0.19823437552446418, 0.22626638302089697, 0.1555007513541123, 0.2566447916215294, 0.3142540230267175, 0.16397196421827687, 0.14587916834537562, 0.35742251261927277, 0.28119087681114147, 0.22955011253333338, 0.2053893034620675, 0.2532129324980415, 0.22627372336186963, 0.2291731655947074, 0.25652090212892825, 0.1582309757661109, 0.19532014470237752, 0.2686386087772937, 0.2564835288466947, 0.19774590776050172, 0.24269027255331335, 0.27449541875576045, 0.25404635797285985, 0.15281697859076113, 0.31122099463068975, 0.2212075398986415, 0.25398925577864995, 0.1914146982738523, 0.2019567746265957, 0.17393671812672326, 0.18676696435777407, 0.27287390652650273, 0.2955453515484838, 0.2071683848512596, 0.20290753816175774, 0.1991675447668417, 0.23034948030709973, 0.22316288622153227, 0.19375484419291253, 0.22805657995559098, 0.217451165659409, 0.2559922753266677, 0.23750177877268053, 0.1803169462340529, 0.22869863149590566, 0.2361263886453596, 0.23797785845799, 0.2433659049875135, 0.27114095594952864, 0.18413931742639028, 0.16378170617102142, 0.14942576256215878, 0.2639684848561976, 0.26699279269982856, 0.1655323042963255, 0.2475496994390625, 0.1887543810520827, 0.2398827199585824, 0.22924719626422482, 0.21428023664620077, 0.2543547779751987, 0.2472796693221517, 0.2037756571119883, 0.20083219966817026, 0.31434487094817043, 0.21228886964737942, 0.22465371273464999, 0.25767524895833516, 0.1908089438887551, 0.20224825867031349, 0.16568766826857434, 0.23266421956018046, 0.18502731117243648, 0.18802805895706518, 0.303775026357728]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21920359446117357\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.3403651724835902\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16402660762701357\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23952501168560958\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21011004064230676\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.27161387685101884\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22347393053489245\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1747852152902681\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20690935941718286\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22251158460983403\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28691314515587674\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22295143850034488\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.19624313488119888\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20599503053304208\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.30009681316577785\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18075999622910002\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14575428424714892\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24698912448924035\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24132401117454827\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24380031769553223\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18791132432167676\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2178628880638185\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20208954823391095\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.180210963337141\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.28082191210651947\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2588549621477355\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2192864036356789\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21361028026474657\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25117950352862595\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.26606143420035455\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16322233836613578\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.22558438948195744\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2013021466965314\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2382032182686502\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.25041516426593285\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.18183033534984305\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2549238652005651\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2625489722495959\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24014066582648075\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21921539228104073\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16593638152713217\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.222990765550518\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2894111591398426\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.14418567853580283\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23928619038477383\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20484280721630274\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2418833312313861\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.21821711064710472\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.2065505511989683\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1915641178508449\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23442746929991023\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.1893489719031905\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.23619015980110447\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.20992032631129254\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","143it [01:15,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.24099914287557161\n"]},{"name":"stderr","output_type":"stream","text":["143it [01:15,  1.89it/s]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.16334453935244994\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"data":{"text/plain":["0.1256021698283635"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Train an ELECTRA model\n","model_name = 'google/electra-large-discriminator'\n","hyperparams = {\n","  'bs': 4,\n","  'lr': 8e-6,\n","  'weight_decay': 0.1,\n","  'ep': 7,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ELECTRA_PRETRAINED = os.path.join(BASE_PATH, 'models/electra-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=ELECTRA_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LZp4MeZUdFsm"},"source":["# Training models"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"J3deWnW2dLTv"},"source":["In total, I trained 3 deberta-large, 1 roberta-large, 3 albert-xxlarge and 1 electra-large model for my winning submission.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ze54BKZdYvk"},"outputs":[],"source":["# Training the ALBERT models"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"bRuHZIARd-GJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/tmp/ipykernel_16155/202785219.py:75: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:57:14, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.271600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.262700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.200800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.241800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.304900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.312600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.207700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.223600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.185500</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.229600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.153900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.187700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.228500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.245900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.169100</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.302600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.178200</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.255000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.246300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.195900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.243800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.281700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.254200</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.238500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.374800</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.288300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.267600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.297200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.189700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.255700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.246300</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.182100</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.225100</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.343100</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.192000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.276800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.239300</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.309800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.310700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.196400</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.178600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.127400</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.099100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.107900</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.144300</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.215700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.136900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.206400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.170400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.125000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.165800</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.183000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.212700</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.170400</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.256800</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.169900</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.218400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.190000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.219000</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.192500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.194400</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.176500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.161500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.279200</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.084700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.190100</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.215500</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.193100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.218100</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.139400</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.138900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.162700</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.160600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.170800</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.169200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.233000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.181600</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.174200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.087900</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.108600</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.135900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.072800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.163300</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.125800</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.131000</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.075600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.121700</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.094900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.148700</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.119400</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.070400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.078800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.110300</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.112000</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.100500</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.081900</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.085400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.067600</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.081800</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.101400</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.100300</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.142600</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.136600</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.169000</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.094600</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.127100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.110700</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.120200</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.138400</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.083500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.104000</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.049700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.080600</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.089300</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.124100</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.058200</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.073300</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.063800</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.050100</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.063700</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.060200</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.095300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.068600</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.051100</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.075700</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.071100</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.119000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.060500</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.066400</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.048400</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.084900</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.060500</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.048900</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.048900</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.054400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.048700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.050900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.051200</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.046900</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.062200</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.054800</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.061400</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.057700</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.068400</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.064600</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.029800</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.043700</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.034400</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.027000</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.024900</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.032600</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.020100</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.036800</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.029700</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.029400</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.021300</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.023900</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.025300</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.028100</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.029900</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.018200</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.025900</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.033400</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.033700</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.028900</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.036200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:56,  3.79s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45585228717880494\n","is min 0.45585228717880494 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46551880724824846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46050671983651603\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47381531675317956\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4698086579189461\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4610061951431681\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46937222273133283\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4546948138439853\n","is min 0.4546948138439853 is smaller than [0.45585228717880494, 0.46551880724824846, 0.46050671983651603, 0.47381531675317956, 0.4698086579189461, 0.4610061951431681, 0.46937222273133283]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4604836881557128\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4771677681127614\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45565543775696304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47093264538457874\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46400934522510917\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47500687634017796\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49761329792460035\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46340662632931434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46951023018493954\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4570865833516615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4774871279900175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48226194586749055\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45137274992846066\n","is min 0.45137274992846066 is smaller than [0.45585228717880494, 0.46551880724824846, 0.46050671983651603, 0.47381531675317956, 0.4698086579189461, 0.4610061951431681, 0.46937222273133283, 0.4546948138439853, 0.4604836881557128, 0.4771677681127614, 0.45565543775696304, 0.47093264538457874, 0.46400934522510917, 0.47500687634017796, 0.49761329792460035, 0.46340662632931434, 0.46951023018493954, 0.4570865833516615, 0.4774871279900175, 0.48226194586749055]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.598838769958183\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49390813593943667\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46945514876899663\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5904139262757815\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5331305481476755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46403223371158697\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4627423749021582\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5073992011642063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5270879358182098\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4809209749286983\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45681399264594535\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5858312993498909\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4685074928470662\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.541612950278835\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4603809553952251\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4905933671639969\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46685845527397035\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4658880799995996\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4610371563829243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4846965089704985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4580529812995471\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46619545624787617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4698238657798803\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5595949227329028\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5185327551582092\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5443469073932713\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47369945848538014\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5378466266985632\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47639780444900975\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48310061599650594\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49681058610853535\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46801123354436097\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47201408550431667\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5385473779403688\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48432865687362814\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5167672204583551\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48626441036789597\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4952334246624483\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4990681253977106\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4687999309232077\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.510951074598667\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5206240213739481\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47204639660730713\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48371884942693233\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4701004694276261\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5295784491034591\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5137774422696418\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5186708942457827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48742980338467273\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5123902112510664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4944934214430465\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4797743795124176\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4919692577329276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.477799912657732\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5432101480137338\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4882110182286617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48370777577695373\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4833034085227538\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.463937238379426\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46948643706056165\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4655392777637771\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5414296264441498\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5281197366428431\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48698069892957235\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719532968209087\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4691515495257699\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4708407208288145\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4745119590356595\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5310654165156866\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.523523641767033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47467342739783436\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4907021493069266\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5274044732449132\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4781424514271903\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4979442874160811\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47785621039339227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48681216973012365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47681431408198005\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4665306469017585\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47003122088082727\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4781613193619846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5092729327356598\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5302787350265828\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47258217768937394\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4834252238534637\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5425392327561406\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48332779869254044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49152812717743716\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48258919401418604\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4921097333958926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.488522960126592\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48087543218366724\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47828711529106704\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5774899796591071\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49995480411255094\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5013997764849172\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719158617133569\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664985121290402\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4691760032983553\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4787229088321141\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48984865465110117\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4750447526170342\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4876778749385265\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48148881126177623\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47816661392239473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4906827279715717\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674562214897389\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4709970244200858\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48064743879889454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4696421067824147\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469079200326159\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5037627469791466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47762501315239353\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48554792911086775\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689505546880347\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49863103359959343\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48464094841617666\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718332358513225\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48198004693807023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5175000728990865\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4721796645160606\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4736215111376597\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48130551761054213\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48668826721161396\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4827364484971016\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4852769756493307\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48715176050410547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4896248187751244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4933226002672178\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4840683629647419\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48615247420798285\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4863543909259811\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5070917514693801\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.501108172680944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4820824751530924\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4801614410191462\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4780741111397198\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47550575621603347\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4864098117388261\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4945221659815314\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47374047636970346\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47001560601552467\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719208707750308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.467680936917228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46180205662812224\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4660539933156377\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4969971267647603\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46980537377011033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47036227802130653\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47230383277722415\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47813188409073243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47287088039731634\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4771348481387636\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47402272303105586\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.474150385531021\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47004066010343293\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4704092608739654\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47142378753439074\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47061159940455344\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4980505431469339\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48040182782767266\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48302165580906536\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4732047387450677\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4735004236007808\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4717064761235791\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.476172021436019\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4841908102257606\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4793525769310505\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47934734918845273\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47232023307563115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4783719953774646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4863461427122154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.488327494124898\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47934331643845574\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4876248632263762\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4859695072517895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4859695072517895\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:57:57, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.198100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.241100</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.147300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.219300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.244400</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.235800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.213600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.200600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.293600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.164900</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.215800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.286700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.296800</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.239800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.249800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.178700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.282700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.177200</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.267900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.239400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.190300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.240800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.242300</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.235300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.216200</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.225100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.265800</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.281300</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.223200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.276200</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.289500</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.358400</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.199900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.255600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.210800</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.159700</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.276700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.300200</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.251600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.193200</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.217000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.238300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.173200</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.173700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.176900</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.263700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.154000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.142000</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.151800</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.267200</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.222000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.143600</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.190200</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.176200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.136900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.132800</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.177000</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.181600</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.181400</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.282900</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.186600</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.182800</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.208000</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.153700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.143900</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.198200</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.190400</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.141900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.210300</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.215600</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.110700</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.160100</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.169800</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.112500</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.127300</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.232700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.151500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.144200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.093800</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.072700</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.092200</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.088000</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.107500</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.081200</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.057400</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.091400</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.121200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.065000</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.102600</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.129500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.107900</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.115800</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.111400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.084100</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.104400</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.084700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.095100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.077000</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.082500</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.092100</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.066600</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.108700</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.086800</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.123100</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.090600</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.096300</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.063900</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.087700</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.083500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.092100</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.101500</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.113000</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.113600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.085000</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.086200</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.075900</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.070200</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.043600</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.061800</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.058800</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.051600</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.060400</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.089000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.066700</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.052600</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.059900</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.044800</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.030200</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.055400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.055300</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.046100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.053200</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.069100</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.079200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.048200</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.046200</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.034800</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.064200</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.034000</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.033500</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.046200</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.030200</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.035500</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.057200</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.027600</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.041900</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.029700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.035500</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.032100</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.021200</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.031200</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.021400</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.024200</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.037300</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.032400</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.054500</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.040700</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.030400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47850136155610384\n","is min 0.47850136155610384 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4813104833349116\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4820690015168998\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4909732480632819\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4773330029275828\n","is min 0.4773330029275828 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4721910287984913\n","is min 0.4721910287984913 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819, 0.4773330029275828]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814703513474859\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46974922632126337\n","is min 0.46974922632126337 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819, 0.4773330029275828, 0.4721910287984913, 0.4814703513474859]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4724724366894973\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47606943475974844\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4795756923236251\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760936643460962\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4707654280158081\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5539633494508829\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5053258926137577\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.526905885259495\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4995644267104374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4806521987124486\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5364945621097577\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48494542098059207\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4915355848171307\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4903266097147437\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47113176149718883\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47669048734332553\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4908586735831904\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5003808706856228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4812598354771864\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4725608250460103\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49332957854760306\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5012715974315645\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4875160523876814\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4956957264314655\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719772463456105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47895665725988706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4734632201230026\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4706156035682735\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4775659461010958\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.478741841717249\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5030929709836861\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5204394051081073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.585537609880547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5676469450309638\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47856068898501664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5062765756854092\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47655187553938194\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4856508065061251\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4711006218128828\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47338730893750297\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4873722648400074\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47234362805318897\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48357134887268566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4874199503420268\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4771579132955185\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4996440591770958\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4731259407694554\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5156924916884452\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49566462216023677\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4960346211911908\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5418487148477967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4859349725395484\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4712254356494338\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4819522422063309\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.521418809011057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4775704707253234\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4816289586319359\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47146240650756593\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4740076237833444\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48201947070304857\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4778520197904119\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49293787365482095\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5103858246559657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5067417311098941\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48230420085923326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47695077817901976\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48612917355918484\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5444185622094145\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46876263670148144\n","is min 0.46876263670148144 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819, 0.4773330029275828, 0.4721910287984913, 0.4814703513474859, 0.46974922632126337, 0.4724724366894973, 0.47606943475974844, 0.4795756923236251, 0.4760936643460962, 0.4707654280158081, 0.5539633494508829, 0.5053258926137577, 0.526905885259495, 0.4995644267104374, 0.4806521987124486, 0.5364945621097577, 0.48494542098059207, 0.4915355848171307, 0.4903266097147437, 0.47113176149718883, 0.47669048734332553, 0.4908586735831904, 0.5003808706856228, 0.4812598354771864, 0.4725608250460103, 0.49332957854760306, 0.5012715974315645, 0.4875160523876814, 0.4956957264314655, 0.4719772463456105, 0.47895665725988706, 0.4734632201230026, 0.4706156035682735, 0.4775659461010958, 0.478741841717249, 0.5030929709836861, 0.5204394051081073, 0.585537609880547, 0.5676469450309638, 0.47856068898501664, 0.5062765756854092, 0.47655187553938194, 0.4856508065061251, 0.4711006218128828, 0.47338730893750297, 0.4873722648400074, 0.47234362805318897, 0.48357134887268566, 0.4874199503420268, 0.4771579132955185, 0.4996440591770958, 0.4731259407694554, 0.5156924916884452, 0.49566462216023677, 0.4960346211911908, 0.5418487148477967, 0.4859349725395484, 0.4712254356494338, 0.4819522422063309, 0.521418809011057, 0.4775704707253234, 0.4816289586319359, 0.47146240650756593, 0.4740076237833444, 0.48201947070304857, 0.4778520197904119, 0.49293787365482095, 0.5103858246559657, 0.5067417311098941, 0.48230420085923326, 0.47695077817901976, 0.48612917355918484, 0.5444185622094145]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47425693676440817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48847743523607334\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4922201591061919\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4735692366733326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4914488643427641\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47391800059172967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4735394470595749\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48355916015348605\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4818407091763724\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47673809308340326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.490691659232381\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47238365078180355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.477005593218956\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48490194180433727\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49217360133075927\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4790554072422205\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49284564500290634\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5416297870489496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.479818649515887\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49412111351008287\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4904660250756243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4859051905587185\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4912075398329773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4990207162548327\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4800705031070069\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4912506566532835\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49290819943392983\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.477302776263304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5178759074609699\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48430683743595626\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47438776814385575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4733036023541883\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4748674869041388\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47292960512269544\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5167346501305217\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5155950360356276\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.542510263399959\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4750180087866838\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47603330979425434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4676178229359408\n","is min 0.4676178229359408 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819, 0.4773330029275828, 0.4721910287984913, 0.4814703513474859, 0.46974922632126337, 0.4724724366894973, 0.47606943475974844, 0.4795756923236251, 0.4760936643460962, 0.4707654280158081, 0.5539633494508829, 0.5053258926137577, 0.526905885259495, 0.4995644267104374, 0.4806521987124486, 0.5364945621097577, 0.48494542098059207, 0.4915355848171307, 0.4903266097147437, 0.47113176149718883, 0.47669048734332553, 0.4908586735831904, 0.5003808706856228, 0.4812598354771864, 0.4725608250460103, 0.49332957854760306, 0.5012715974315645, 0.4875160523876814, 0.4956957264314655, 0.4719772463456105, 0.47895665725988706, 0.4734632201230026, 0.4706156035682735, 0.4775659461010958, 0.478741841717249, 0.5030929709836861, 0.5204394051081073, 0.585537609880547, 0.5676469450309638, 0.47856068898501664, 0.5062765756854092, 0.47655187553938194, 0.4856508065061251, 0.4711006218128828, 0.47338730893750297, 0.4873722648400074, 0.47234362805318897, 0.48357134887268566, 0.4874199503420268, 0.4771579132955185, 0.4996440591770958, 0.4731259407694554, 0.5156924916884452, 0.49566462216023677, 0.4960346211911908, 0.5418487148477967, 0.4859349725395484, 0.4712254356494338, 0.4819522422063309, 0.521418809011057, 0.4775704707253234, 0.4816289586319359, 0.47146240650756593, 0.4740076237833444, 0.48201947070304857, 0.4778520197904119, 0.49293787365482095, 0.5103858246559657, 0.5067417311098941, 0.48230420085923326, 0.47695077817901976, 0.48612917355918484, 0.5444185622094145, 0.46876263670148144, 0.47425693676440817, 0.48847743523607334, 0.4922201591061919, 0.4735692366733326, 0.4914488643427641, 0.47391800059172967, 0.4735394470595749, 0.48355916015348605, 0.4818407091763724, 0.47673809308340326, 0.490691659232381, 0.47238365078180355, 0.477005593218956, 0.48490194180433727, 0.49217360133075927, 0.4790554072422205, 0.49284564500290634, 0.5416297870489496, 0.479818649515887, 0.49412111351008287, 0.4904660250756243, 0.4859051905587185, 0.4912075398329773, 0.4990207162548327, 0.4800705031070069, 0.4912506566532835, 0.49290819943392983, 0.477302776263304, 0.5178759074609699, 0.48430683743595626, 0.47438776814385575, 0.4733036023541883, 0.4748674869041388, 0.47292960512269544, 0.5167346501305217, 0.5155950360356276, 0.542510263399959, 0.4750180087866838, 0.47603330979425434]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47222562609289875\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46769140426266725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469586772732979\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760897906700204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4688492913539145\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47692136921254685\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4687782714865707\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4908204117123952\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47403314703318067\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5151356910431679\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49891754764219665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48422422688061195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48475363541763195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46826296404112927\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47016527468517727\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4678096898278617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4684851837660845\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48542833011345676\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47061311420708635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4741189465405257\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4716083101279325\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47828344252357907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5075848173735586\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4858544655608979\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4733459049841135\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4771419788955542\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47262070837338094\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4734163762451472\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.498361167825789\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4713719201789982\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4781940995845233\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4682885987203926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4742741656108414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469158854620344\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4687616433071937\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686452001648412\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760775057420016\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46776484648808686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4661693762787122\n","is min 0.4661693762787122 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819, 0.4773330029275828, 0.4721910287984913, 0.4814703513474859, 0.46974922632126337, 0.4724724366894973, 0.47606943475974844, 0.4795756923236251, 0.4760936643460962, 0.4707654280158081, 0.5539633494508829, 0.5053258926137577, 0.526905885259495, 0.4995644267104374, 0.4806521987124486, 0.5364945621097577, 0.48494542098059207, 0.4915355848171307, 0.4903266097147437, 0.47113176149718883, 0.47669048734332553, 0.4908586735831904, 0.5003808706856228, 0.4812598354771864, 0.4725608250460103, 0.49332957854760306, 0.5012715974315645, 0.4875160523876814, 0.4956957264314655, 0.4719772463456105, 0.47895665725988706, 0.4734632201230026, 0.4706156035682735, 0.4775659461010958, 0.478741841717249, 0.5030929709836861, 0.5204394051081073, 0.585537609880547, 0.5676469450309638, 0.47856068898501664, 0.5062765756854092, 0.47655187553938194, 0.4856508065061251, 0.4711006218128828, 0.47338730893750297, 0.4873722648400074, 0.47234362805318897, 0.48357134887268566, 0.4874199503420268, 0.4771579132955185, 0.4996440591770958, 0.4731259407694554, 0.5156924916884452, 0.49566462216023677, 0.4960346211911908, 0.5418487148477967, 0.4859349725395484, 0.4712254356494338, 0.4819522422063309, 0.521418809011057, 0.4775704707253234, 0.4816289586319359, 0.47146240650756593, 0.4740076237833444, 0.48201947070304857, 0.4778520197904119, 0.49293787365482095, 0.5103858246559657, 0.5067417311098941, 0.48230420085923326, 0.47695077817901976, 0.48612917355918484, 0.5444185622094145, 0.46876263670148144, 0.47425693676440817, 0.48847743523607334, 0.4922201591061919, 0.4735692366733326, 0.4914488643427641, 0.47391800059172967, 0.4735394470595749, 0.48355916015348605, 0.4818407091763724, 0.47673809308340326, 0.490691659232381, 0.47238365078180355, 0.477005593218956, 0.48490194180433727, 0.49217360133075927, 0.4790554072422205, 0.49284564500290634, 0.5416297870489496, 0.479818649515887, 0.49412111351008287, 0.4904660250756243, 0.4859051905587185, 0.4912075398329773, 0.4990207162548327, 0.4800705031070069, 0.4912506566532835, 0.49290819943392983, 0.477302776263304, 0.5178759074609699, 0.48430683743595626, 0.47438776814385575, 0.4733036023541883, 0.4748674869041388, 0.47292960512269544, 0.5167346501305217, 0.5155950360356276, 0.542510263399959, 0.4750180087866838, 0.47603330979425434, 0.4676178229359408, 0.47222562609289875, 0.46769140426266725, 0.469586772732979, 0.4760897906700204, 0.4688492913539145, 0.47692136921254685, 0.4687782714865707, 0.4908204117123952, 0.47403314703318067, 0.5151356910431679, 0.49891754764219665, 0.48422422688061195, 0.48475363541763195, 0.46826296404112927, 0.47016527468517727, 0.4678096898278617, 0.4684851837660845, 0.48542833011345676, 0.47061311420708635, 0.4741189465405257, 0.4716083101279325, 0.47828344252357907, 0.5075848173735586, 0.4858544655608979, 0.4733459049841135, 0.4771419788955542, 0.47262070837338094, 0.4734163762451472, 0.498361167825789, 0.4713719201789982, 0.4781940995845233, 0.4682885987203926, 0.4742741656108414, 0.469158854620344, 0.4687616433071937, 0.4686452001648412, 0.4760775057420016, 0.46776484648808686]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686487386783246\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4672054694349438\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48120847174145065\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48421672526176845\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47350611011206134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4737238573345769\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4740486842374508\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4712275138844052\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46547681672366165\n","is min 0.46547681672366165 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819, 0.4773330029275828, 0.4721910287984913, 0.4814703513474859, 0.46974922632126337, 0.4724724366894973, 0.47606943475974844, 0.4795756923236251, 0.4760936643460962, 0.4707654280158081, 0.5539633494508829, 0.5053258926137577, 0.526905885259495, 0.4995644267104374, 0.4806521987124486, 0.5364945621097577, 0.48494542098059207, 0.4915355848171307, 0.4903266097147437, 0.47113176149718883, 0.47669048734332553, 0.4908586735831904, 0.5003808706856228, 0.4812598354771864, 0.4725608250460103, 0.49332957854760306, 0.5012715974315645, 0.4875160523876814, 0.4956957264314655, 0.4719772463456105, 0.47895665725988706, 0.4734632201230026, 0.4706156035682735, 0.4775659461010958, 0.478741841717249, 0.5030929709836861, 0.5204394051081073, 0.585537609880547, 0.5676469450309638, 0.47856068898501664, 0.5062765756854092, 0.47655187553938194, 0.4856508065061251, 0.4711006218128828, 0.47338730893750297, 0.4873722648400074, 0.47234362805318897, 0.48357134887268566, 0.4874199503420268, 0.4771579132955185, 0.4996440591770958, 0.4731259407694554, 0.5156924916884452, 0.49566462216023677, 0.4960346211911908, 0.5418487148477967, 0.4859349725395484, 0.4712254356494338, 0.4819522422063309, 0.521418809011057, 0.4775704707253234, 0.4816289586319359, 0.47146240650756593, 0.4740076237833444, 0.48201947070304857, 0.4778520197904119, 0.49293787365482095, 0.5103858246559657, 0.5067417311098941, 0.48230420085923326, 0.47695077817901976, 0.48612917355918484, 0.5444185622094145, 0.46876263670148144, 0.47425693676440817, 0.48847743523607334, 0.4922201591061919, 0.4735692366733326, 0.4914488643427641, 0.47391800059172967, 0.4735394470595749, 0.48355916015348605, 0.4818407091763724, 0.47673809308340326, 0.490691659232381, 0.47238365078180355, 0.477005593218956, 0.48490194180433727, 0.49217360133075927, 0.4790554072422205, 0.49284564500290634, 0.5416297870489496, 0.479818649515887, 0.49412111351008287, 0.4904660250756243, 0.4859051905587185, 0.4912075398329773, 0.4990207162548327, 0.4800705031070069, 0.4912506566532835, 0.49290819943392983, 0.477302776263304, 0.5178759074609699, 0.48430683743595626, 0.47438776814385575, 0.4733036023541883, 0.4748674869041388, 0.47292960512269544, 0.5167346501305217, 0.5155950360356276, 0.542510263399959, 0.4750180087866838, 0.47603330979425434, 0.4676178229359408, 0.47222562609289875, 0.46769140426266725, 0.469586772732979, 0.4760897906700204, 0.4688492913539145, 0.47692136921254685, 0.4687782714865707, 0.4908204117123952, 0.47403314703318067, 0.5151356910431679, 0.49891754764219665, 0.48422422688061195, 0.48475363541763195, 0.46826296404112927, 0.47016527468517727, 0.4678096898278617, 0.4684851837660845, 0.48542833011345676, 0.47061311420708635, 0.4741189465405257, 0.4716083101279325, 0.47828344252357907, 0.5075848173735586, 0.4858544655608979, 0.4733459049841135, 0.4771419788955542, 0.47262070837338094, 0.4734163762451472, 0.498361167825789, 0.4713719201789982, 0.4781940995845233, 0.4682885987203926, 0.4742741656108414, 0.469158854620344, 0.4687616433071937, 0.4686452001648412, 0.4760775057420016, 0.46776484648808686, 0.4661693762787122, 0.4686487386783246, 0.4672054694349438, 0.48120847174145065, 0.48421672526176845, 0.47350611011206134, 0.4737238573345769, 0.4740486842374508, 0.4712275138844052]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4897407284062172\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5175035690431574\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46584084218567773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4916437009024404\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4665720339198361\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46796957744119233\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4687012109638278\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4673748784455299\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4807073882687815\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47250612474796044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48979103466789364\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48316184424994757\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4671531621159238\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47705743070790874\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46882235293105895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689370707164997\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46843321764677076\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4648889860151928\n","is min 0.4648889860151928 is smaller than [0.47850136155610384, 0.4813104833349116, 0.4820690015168998, 0.4909732480632819, 0.4773330029275828, 0.4721910287984913, 0.4814703513474859, 0.46974922632126337, 0.4724724366894973, 0.47606943475974844, 0.4795756923236251, 0.4760936643460962, 0.4707654280158081, 0.5539633494508829, 0.5053258926137577, 0.526905885259495, 0.4995644267104374, 0.4806521987124486, 0.5364945621097577, 0.48494542098059207, 0.4915355848171307, 0.4903266097147437, 0.47113176149718883, 0.47669048734332553, 0.4908586735831904, 0.5003808706856228, 0.4812598354771864, 0.4725608250460103, 0.49332957854760306, 0.5012715974315645, 0.4875160523876814, 0.4956957264314655, 0.4719772463456105, 0.47895665725988706, 0.4734632201230026, 0.4706156035682735, 0.4775659461010958, 0.478741841717249, 0.5030929709836861, 0.5204394051081073, 0.585537609880547, 0.5676469450309638, 0.47856068898501664, 0.5062765756854092, 0.47655187553938194, 0.4856508065061251, 0.4711006218128828, 0.47338730893750297, 0.4873722648400074, 0.47234362805318897, 0.48357134887268566, 0.4874199503420268, 0.4771579132955185, 0.4996440591770958, 0.4731259407694554, 0.5156924916884452, 0.49566462216023677, 0.4960346211911908, 0.5418487148477967, 0.4859349725395484, 0.4712254356494338, 0.4819522422063309, 0.521418809011057, 0.4775704707253234, 0.4816289586319359, 0.47146240650756593, 0.4740076237833444, 0.48201947070304857, 0.4778520197904119, 0.49293787365482095, 0.5103858246559657, 0.5067417311098941, 0.48230420085923326, 0.47695077817901976, 0.48612917355918484, 0.5444185622094145, 0.46876263670148144, 0.47425693676440817, 0.48847743523607334, 0.4922201591061919, 0.4735692366733326, 0.4914488643427641, 0.47391800059172967, 0.4735394470595749, 0.48355916015348605, 0.4818407091763724, 0.47673809308340326, 0.490691659232381, 0.47238365078180355, 0.477005593218956, 0.48490194180433727, 0.49217360133075927, 0.4790554072422205, 0.49284564500290634, 0.5416297870489496, 0.479818649515887, 0.49412111351008287, 0.4904660250756243, 0.4859051905587185, 0.4912075398329773, 0.4990207162548327, 0.4800705031070069, 0.4912506566532835, 0.49290819943392983, 0.477302776263304, 0.5178759074609699, 0.48430683743595626, 0.47438776814385575, 0.4733036023541883, 0.4748674869041388, 0.47292960512269544, 0.5167346501305217, 0.5155950360356276, 0.542510263399959, 0.4750180087866838, 0.47603330979425434, 0.4676178229359408, 0.47222562609289875, 0.46769140426266725, 0.469586772732979, 0.4760897906700204, 0.4688492913539145, 0.47692136921254685, 0.4687782714865707, 0.4908204117123952, 0.47403314703318067, 0.5151356910431679, 0.49891754764219665, 0.48422422688061195, 0.48475363541763195, 0.46826296404112927, 0.47016527468517727, 0.4678096898278617, 0.4684851837660845, 0.48542833011345676, 0.47061311420708635, 0.4741189465405257, 0.4716083101279325, 0.47828344252357907, 0.5075848173735586, 0.4858544655608979, 0.4733459049841135, 0.4771419788955542, 0.47262070837338094, 0.4734163762451472, 0.498361167825789, 0.4713719201789982, 0.4781940995845233, 0.4682885987203926, 0.4742741656108414, 0.469158854620344, 0.4687616433071937, 0.4686452001648412, 0.4760775057420016, 0.46776484648808686, 0.4661693762787122, 0.4686487386783246, 0.4672054694349438, 0.48120847174145065, 0.48421672526176845, 0.47350611011206134, 0.4737238573345769, 0.4740486842374508, 0.4712275138844052, 0.46547681672366165, 0.4897407284062172, 0.5175035690431574, 0.46584084218567773, 0.4916437009024404, 0.4665720339198361, 0.46796957744119233, 0.4687012109638278, 0.4673748784455299, 0.4807073882687815, 0.47250612474796044, 0.48979103466789364, 0.48316184424994757, 0.4671531621159238, 0.47705743070790874, 0.46882235293105895, 0.4689370707164997, 0.46843321764677076]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47036862151580544\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4713868657149308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4676019230468\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46931655345480444\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4969560122152365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48303642963175497\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4653992849615615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47452913516951883\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47483652928643505\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5084702707162639\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48010877267134516\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.470419695196208\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4717421069314637\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47546874558185687\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47546874558185687\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:58:30, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.301700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.217000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.257200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.267700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.168000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.201900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.230900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.206300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.226400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.208100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.249500</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.244400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.227100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.191100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.266800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.174600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.276100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.313100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.290400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.389800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.306500</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.277300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.286100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.206100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.188500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.264800</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.254100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.250600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.198600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.212100</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.302200</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.227700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.343600</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.237800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.244600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.227400</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.328800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.199700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.238700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.159900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.112800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.227700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.172500</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.168100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.154000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.117100</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.169600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.156600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.189800</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.136700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.254900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.191700</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.196000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.236100</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.205100</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.158200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.185700</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.223100</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.154200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.238400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.096400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.209800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.159600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.165600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.171000</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.149500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.186300</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.239300</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.126200</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.209300</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.137200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.157400</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.187200</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.188500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.156100</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.148800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.208700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.141300</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.174600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.104500</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.061300</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.111500</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.101000</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.130200</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.099000</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.079400</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.078600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.085900</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.118000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.134300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.106600</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.111000</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.075600</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.076500</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.099700</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.100900</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.095400</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.118600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.094600</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.135000</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.093200</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.093400</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.139500</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.080800</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.093400</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.135900</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.087000</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.113200</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.100800</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.089300</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.103600</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.118000</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.110500</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.068300</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.079600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.079600</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.073100</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.058300</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.075200</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.071100</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.054400</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.069300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.048200</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.058800</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.059700</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.046000</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.060900</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.054100</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.066600</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.052000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.057000</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.057200</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.060200</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.076300</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.060900</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.046500</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.067500</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.055300</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.049400</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.088400</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.041600</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.051900</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.032400</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.036300</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.031000</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.038100</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.029300</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.027800</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.063400</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.029800</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.035800</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.032100</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.054000</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.035800</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.039800</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.028800</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.029700</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.037600</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.043400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4676054533423553\n","is min 0.4676054533423553 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4666921931666266\n","is min 0.4666921931666266 is smaller than [0.4676054533423553]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46696358443942243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47642292958551374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46588552006062534\n","is min 0.46588552006062534 is smaller than [0.4676054533423553, 0.4666921931666266, 0.46696358443942243, 0.47642292958551374]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46573618441718434\n","is min 0.46573618441718434 is smaller than [0.4676054533423553, 0.4666921931666266, 0.46696358443942243, 0.47642292958551374, 0.46588552006062534]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47887778122324115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4747028878843801\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664474038416896\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4819591734701737\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46844741194754136\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4678138674212857\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4693555673699648\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4913879092422518\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5073865853533631\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5117759353401676\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48156835232325945\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5775216453239294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6196263532309867\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6272679884092033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4865802739156908\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48215178239449985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46973965892572717\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5265120382813518\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5345426696395953\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6232071076538971\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46989524640842983\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47181630885241554\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4774406128469124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262839578747048\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5904686420981015\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6341643370000265\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5117505436060403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46716952525729577\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49291326144632536\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5417349531229789\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5073975262258539\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5042183816951944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4880718203509082\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48036352705249125\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689789213756688\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4900832483034083\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718094862618778\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4783816381167244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.514277279736018\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4996856197451961\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4866376634448431\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5277106824393868\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4947442653718349\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4726590582769699\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4751948062469843\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49590184623700245\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5105837499942307\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5785243132615228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4830333565078434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4980382469582391\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5029499715542376\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4780157244909575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.518049892875315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5106634073469519\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48476677656400385\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4676840313851191\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46834347488710004\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4731628777378578\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4661532966670794\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.495653282674531\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4660487279790453\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47208566383448236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5204341802602472\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4662157195901006\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4699628270540202\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47536107520265863\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4733719858649775\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46752621949536305\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4766259306349837\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674279713443563\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4692451888785351\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4668534971217338\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5138767315927003\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4663314332915662\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49631510112297833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47351178585575054\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4697944030076061\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46501667069371017\n","is min 0.46501667069371017 is smaller than [0.4676054533423553, 0.4666921931666266, 0.46696358443942243, 0.47642292958551374, 0.46588552006062534, 0.46573618441718434, 0.47887778122324115, 0.4747028878843801, 0.4664474038416896, 0.4819591734701737, 0.46844741194754136, 0.4678138674212857, 0.4693555673699648, 0.4913879092422518, 0.5073865853533631, 0.5117759353401676, 0.48156835232325945, 0.5775216453239294, 0.6196263532309867, 0.6272679884092033, 0.4865802739156908, 0.48215178239449985, 0.46973965892572717, 0.5265120382813518, 0.5345426696395953, 0.6232071076538971, 0.46989524640842983, 0.47181630885241554, 0.4774406128469124, 0.5262839578747048, 0.5904686420981015, 0.6341643370000265, 0.5117505436060403, 0.46716952525729577, 0.49291326144632536, 0.5417349531229789, 0.5073975262258539, 0.5042183816951944, 0.4880718203509082, 0.48036352705249125, 0.4689789213756688, 0.4900832483034083, 0.4718094862618778, 0.4783816381167244, 0.514277279736018, 0.4996856197451961, 0.4866376634448431, 0.5277106824393868, 0.4947442653718349, 0.4726590582769699, 0.4751948062469843, 0.49590184623700245, 0.5105837499942307, 0.5785243132615228, 0.4830333565078434, 0.4980382469582391, 0.5029499715542376, 0.4780157244909575, 0.518049892875315, 0.5106634073469519, 0.48476677656400385, 0.4676840313851191, 0.46834347488710004, 0.4731628777378578, 0.4661532966670794, 0.495653282674531, 0.4660487279790453, 0.47208566383448236, 0.5204341802602472, 0.4662157195901006, 0.4699628270540202, 0.47536107520265863, 0.4733719858649775, 0.46752621949536305, 0.4766259306349837, 0.4674279713443563, 0.4692451888785351, 0.4668534971217338, 0.5138767315927003, 0.4663314332915662, 0.49631510112297833, 0.47351178585575054, 0.4697944030076061]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4667918288944472\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.476801134526247\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49261811696244956\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5280262750385187\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48670243964441723\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5071301846400843\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5116409176483431\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5431131499115305\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.477714196983023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48939507558988105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4706585140642283\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4950522311547232\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5266456007981057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48777171912906797\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5550160680455436\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.569962716936951\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49431762904556087\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5030471049922605\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48522574613477737\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49004178603614756\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.478463257460745\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47043944850802083\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5051467853793062\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48404789952545013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4811604108480245\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47754401093155024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.492174276394048\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779459719115337\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47835198419705466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49237603718914175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4847545834104105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49588590180376346\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4735223123006655\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46848308376335573\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4884512611345559\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.495797464003694\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4916981824822223\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5126867700981544\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4915792119483609\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49325960139349373\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4844726718264333\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4801607088011436\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47995573177254036\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49122370152218675\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47915172888870844\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48337638798500376\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48367875557881146\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814718976808943\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4871002912077139\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4791846274369858\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47770737026816823\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48761979158942204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4769485795693175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48022865553478394\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48234544501577803\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4910684221993227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47711442705276125\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48992318563259596\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4898339258512545\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4940434613762161\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48220411808953767\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.499432505502721\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4912731706735714\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5211507460096994\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4791317087937\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48907746536414554\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49020988658600073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4703749927343798\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46847857748854155\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4989171246765741\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.476286814516861\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48345927660616533\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49357186389429514\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4751439441347308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49120194839729947\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760041849628328\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49229121014889016\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4785064036992009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4727715043510003\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47316226713025\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46599359071973895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4820349942064959\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4738760598833129\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689478433655468\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4735117733544669\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46483315627469096\n","is min 0.46483315627469096 is smaller than [0.4676054533423553, 0.4666921931666266, 0.46696358443942243, 0.47642292958551374, 0.46588552006062534, 0.46573618441718434, 0.47887778122324115, 0.4747028878843801, 0.4664474038416896, 0.4819591734701737, 0.46844741194754136, 0.4678138674212857, 0.4693555673699648, 0.4913879092422518, 0.5073865853533631, 0.5117759353401676, 0.48156835232325945, 0.5775216453239294, 0.6196263532309867, 0.6272679884092033, 0.4865802739156908, 0.48215178239449985, 0.46973965892572717, 0.5265120382813518, 0.5345426696395953, 0.6232071076538971, 0.46989524640842983, 0.47181630885241554, 0.4774406128469124, 0.5262839578747048, 0.5904686420981015, 0.6341643370000265, 0.5117505436060403, 0.46716952525729577, 0.49291326144632536, 0.5417349531229789, 0.5073975262258539, 0.5042183816951944, 0.4880718203509082, 0.48036352705249125, 0.4689789213756688, 0.4900832483034083, 0.4718094862618778, 0.4783816381167244, 0.514277279736018, 0.4996856197451961, 0.4866376634448431, 0.5277106824393868, 0.4947442653718349, 0.4726590582769699, 0.4751948062469843, 0.49590184623700245, 0.5105837499942307, 0.5785243132615228, 0.4830333565078434, 0.4980382469582391, 0.5029499715542376, 0.4780157244909575, 0.518049892875315, 0.5106634073469519, 0.48476677656400385, 0.4676840313851191, 0.46834347488710004, 0.4731628777378578, 0.4661532966670794, 0.495653282674531, 0.4660487279790453, 0.47208566383448236, 0.5204341802602472, 0.4662157195901006, 0.4699628270540202, 0.47536107520265863, 0.4733719858649775, 0.46752621949536305, 0.4766259306349837, 0.4674279713443563, 0.4692451888785351, 0.4668534971217338, 0.5138767315927003, 0.4663314332915662, 0.49631510112297833, 0.47351178585575054, 0.4697944030076061, 0.46501667069371017, 0.4667918288944472, 0.476801134526247, 0.49261811696244956, 0.5280262750385187, 0.48670243964441723, 0.5071301846400843, 0.5116409176483431, 0.5431131499115305, 0.477714196983023, 0.48939507558988105, 0.4706585140642283, 0.4950522311547232, 0.5266456007981057, 0.48777171912906797, 0.5550160680455436, 0.569962716936951, 0.49431762904556087, 0.5030471049922605, 0.48522574613477737, 0.49004178603614756, 0.478463257460745, 0.47043944850802083, 0.5051467853793062, 0.48404789952545013, 0.4811604108480245, 0.47754401093155024, 0.492174276394048, 0.4779459719115337, 0.47835198419705466, 0.49237603718914175, 0.4847545834104105, 0.49588590180376346, 0.4735223123006655, 0.46848308376335573, 0.4884512611345559, 0.495797464003694, 0.4916981824822223, 0.5126867700981544, 0.4915792119483609, 0.49325960139349373, 0.4844726718264333, 0.4801607088011436, 0.47995573177254036, 0.49122370152218675, 0.47915172888870844, 0.48337638798500376, 0.48367875557881146, 0.4814718976808943, 0.4871002912077139, 0.4791846274369858, 0.47770737026816823, 0.48761979158942204, 0.4769485795693175, 0.48022865553478394, 0.48234544501577803, 0.4910684221993227, 0.47711442705276125, 0.48992318563259596, 0.4898339258512545, 0.4940434613762161, 0.48220411808953767, 0.499432505502721, 0.4912731706735714, 0.5211507460096994, 0.4791317087937, 0.48907746536414554, 0.49020988658600073, 0.4703749927343798, 0.46847857748854155, 0.4989171246765741, 0.476286814516861, 0.48345927660616533, 0.49357186389429514, 0.4751439441347308, 0.49120194839729947, 0.4760041849628328, 0.49229121014889016, 0.4785064036992009, 0.4727715043510003, 0.47316226713025, 0.46599359071973895, 0.4820349942064959, 0.4738760598833129, 0.4689478433655468, 0.4735117733544669]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46249560374361626\n","is min 0.46249560374361626 is smaller than [0.4676054533423553, 0.4666921931666266, 0.46696358443942243, 0.47642292958551374, 0.46588552006062534, 0.46573618441718434, 0.47887778122324115, 0.4747028878843801, 0.4664474038416896, 0.4819591734701737, 0.46844741194754136, 0.4678138674212857, 0.4693555673699648, 0.4913879092422518, 0.5073865853533631, 0.5117759353401676, 0.48156835232325945, 0.5775216453239294, 0.6196263532309867, 0.6272679884092033, 0.4865802739156908, 0.48215178239449985, 0.46973965892572717, 0.5265120382813518, 0.5345426696395953, 0.6232071076538971, 0.46989524640842983, 0.47181630885241554, 0.4774406128469124, 0.5262839578747048, 0.5904686420981015, 0.6341643370000265, 0.5117505436060403, 0.46716952525729577, 0.49291326144632536, 0.5417349531229789, 0.5073975262258539, 0.5042183816951944, 0.4880718203509082, 0.48036352705249125, 0.4689789213756688, 0.4900832483034083, 0.4718094862618778, 0.4783816381167244, 0.514277279736018, 0.4996856197451961, 0.4866376634448431, 0.5277106824393868, 0.4947442653718349, 0.4726590582769699, 0.4751948062469843, 0.49590184623700245, 0.5105837499942307, 0.5785243132615228, 0.4830333565078434, 0.4980382469582391, 0.5029499715542376, 0.4780157244909575, 0.518049892875315, 0.5106634073469519, 0.48476677656400385, 0.4676840313851191, 0.46834347488710004, 0.4731628777378578, 0.4661532966670794, 0.495653282674531, 0.4660487279790453, 0.47208566383448236, 0.5204341802602472, 0.4662157195901006, 0.4699628270540202, 0.47536107520265863, 0.4733719858649775, 0.46752621949536305, 0.4766259306349837, 0.4674279713443563, 0.4692451888785351, 0.4668534971217338, 0.5138767315927003, 0.4663314332915662, 0.49631510112297833, 0.47351178585575054, 0.4697944030076061, 0.46501667069371017, 0.4667918288944472, 0.476801134526247, 0.49261811696244956, 0.5280262750385187, 0.48670243964441723, 0.5071301846400843, 0.5116409176483431, 0.5431131499115305, 0.477714196983023, 0.48939507558988105, 0.4706585140642283, 0.4950522311547232, 0.5266456007981057, 0.48777171912906797, 0.5550160680455436, 0.569962716936951, 0.49431762904556087, 0.5030471049922605, 0.48522574613477737, 0.49004178603614756, 0.478463257460745, 0.47043944850802083, 0.5051467853793062, 0.48404789952545013, 0.4811604108480245, 0.47754401093155024, 0.492174276394048, 0.4779459719115337, 0.47835198419705466, 0.49237603718914175, 0.4847545834104105, 0.49588590180376346, 0.4735223123006655, 0.46848308376335573, 0.4884512611345559, 0.495797464003694, 0.4916981824822223, 0.5126867700981544, 0.4915792119483609, 0.49325960139349373, 0.4844726718264333, 0.4801607088011436, 0.47995573177254036, 0.49122370152218675, 0.47915172888870844, 0.48337638798500376, 0.48367875557881146, 0.4814718976808943, 0.4871002912077139, 0.4791846274369858, 0.47770737026816823, 0.48761979158942204, 0.4769485795693175, 0.48022865553478394, 0.48234544501577803, 0.4910684221993227, 0.47711442705276125, 0.48992318563259596, 0.4898339258512545, 0.4940434613762161, 0.48220411808953767, 0.499432505502721, 0.4912731706735714, 0.5211507460096994, 0.4791317087937, 0.48907746536414554, 0.49020988658600073, 0.4703749927343798, 0.46847857748854155, 0.4989171246765741, 0.476286814516861, 0.48345927660616533, 0.49357186389429514, 0.4751439441347308, 0.49120194839729947, 0.4760041849628328, 0.49229121014889016, 0.4785064036992009, 0.4727715043510003, 0.47316226713025, 0.46599359071973895, 0.4820349942064959, 0.4738760598833129, 0.4689478433655468, 0.4735117733544669, 0.46483315627469096]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4648646574051822\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46570751909427316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4666120534128933\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48596614195294124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4883220557008733\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4704202350549013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48527569912524077\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46956967624049817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4789390652106504\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5027995151762122\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4783831446563791\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47548735994970776\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4681107180200729\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4646829020902718\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46765503252543916\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47156011415306925\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4665133551249051\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47207160273413834\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719777033793057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5057122293837959\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47209122631116496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49123690239518086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47041689985924784\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47360171313243743\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49320079371577114\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4728585367824542\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4728585367824542\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:58:05, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.194600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.163800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.292600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.262400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.143900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.207700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.227400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.200300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.250400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.189100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.202600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.281700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.222000</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.259100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.243200</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.196600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.239300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.232200</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.345800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.274000</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.408900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.275100</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.324900</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.179900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.255700</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.246600</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.234000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.201800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.206400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.212400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.252500</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.258600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.309900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.224900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.234400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.318000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.287900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.290400</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.191000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.230000</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.138700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.149500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.149500</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.244500</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.166500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.188200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.146600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.174900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.228000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.181200</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.126400</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.127100</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.185900</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.172600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.171100</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.170900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.205300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.201500</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.125800</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.213100</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.135400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.198500</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.185000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.153700</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.127700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.105700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.166500</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.235900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.167500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.168500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.184200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.201300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.132600</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.170900</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.201400</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.202200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.209900</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.181200</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.105600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.074400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.097700</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.086300</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.057300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.095500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.078800</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.087700</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.096500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.135600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.145900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.095500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.114300</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.078000</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.069400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.105400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.117200</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.101400</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.157900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.117000</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.103700</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.093200</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.124400</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.119700</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.107800</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.087000</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.083900</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.119700</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.092300</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.079900</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.098400</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.085900</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.085000</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.086900</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.094300</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.119000</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.094400</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.064600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.056300</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.075200</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.115900</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.071000</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.060700</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.066200</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.074500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.029500</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.070900</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.075200</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.097300</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.067500</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.071300</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.068200</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.056000</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.035700</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.051600</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.055200</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.051200</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.090300</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.066400</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.067100</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.054000</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.108100</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.067000</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.035900</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.038800</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.037300</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.052500</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.054700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.050200</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.044800</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.025600</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.036000</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.046000</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.035800</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.036600</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.029600</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.037800</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.036000</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.026200</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.031500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47380864426094094\n","is min 0.47380864426094094 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4774923900145043\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47295364318870803\n","is min 0.47295364318870803 is smaller than [0.47380864426094094, 0.4774923900145043]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4728098259642077\n","is min 0.4728098259642077 is smaller than [0.47380864426094094, 0.4774923900145043, 0.47295364318870803]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47354771716573024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46890028731442923\n","is min 0.46890028731442923 is smaller than [0.47380864426094094, 0.4774923900145043, 0.47295364318870803, 0.4728098259642077, 0.47354771716573024]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4644053481881035\n","is min 0.4644053481881035 is smaller than [0.47380864426094094, 0.4774923900145043, 0.47295364318870803, 0.4728098259642077, 0.47354771716573024, 0.46890028731442923]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46707564979194743\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4620875761500658\n","is min 0.4620875761500658 is smaller than [0.47380864426094094, 0.4774923900145043, 0.47295364318870803, 0.4728098259642077, 0.47354771716573024, 0.46890028731442923, 0.4644053481881035, 0.46707564979194743]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4670739107244561\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45786835167571627\n","is min 0.45786835167571627 is smaller than [0.47380864426094094, 0.4774923900145043, 0.47295364318870803, 0.4728098259642077, 0.47354771716573024, 0.46890028731442923, 0.4644053481881035, 0.46707564979194743, 0.4620875761500658, 0.4670739107244561]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45795333418037576\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4744743691718644\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46352089926429985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4658394175900773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4625506869968545\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5258367504178518\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47479604099075085\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46671640596728214\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5561468968863187\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5664894056705412\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6581051094761394\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48132321382476967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48772785994802637\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4781872814666155\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49020749776588485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5033215976453718\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5044954440033474\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5382613311351371\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48538426059990697\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.507009877258652\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5260529405377596\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48052725454646755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48224439241673767\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5670085998053644\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4835095244858987\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5124120042305123\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4873179984359655\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4803895893929125\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48865244762933524\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48903520291078706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46385282606983713\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47954237901257685\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49340771389152793\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4807967884862512\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47871281979239044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4786989636507085\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5138125184920977\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46522172681120205\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5374186309387408\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49756460921724094\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48335148332871175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5035777209634212\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5306485052624496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46789373694556785\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4720457386142767\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49803222562358807\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4771949167135657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4722051156725278\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48829653765130504\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.509759607678698\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49744366037855664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4849415690563798\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48835281656576185\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4904796560901508\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4532757202734248\n","is min 0.4532757202734248 is smaller than [0.47380864426094094, 0.4774923900145043, 0.47295364318870803, 0.4728098259642077, 0.47354771716573024, 0.46890028731442923, 0.4644053481881035, 0.46707564979194743, 0.4620875761500658, 0.4670739107244561, 0.45786835167571627, 0.45795333418037576, 0.4744743691718644, 0.46352089926429985, 0.4658394175900773, 0.4625506869968545, 0.5258367504178518, 0.47479604099075085, 0.46671640596728214, 0.5561468968863187, 0.5664894056705412, 0.6581051094761394, 0.48132321382476967, 0.48772785994802637, 0.4781872814666155, 0.49020749776588485, 0.5033215976453718, 0.5044954440033474, 0.5382613311351371, 0.48538426059990697, 0.507009877258652, 0.5260529405377596, 0.48052725454646755, 0.48224439241673767, 0.5670085998053644, 0.4835095244858987, 0.5124120042305123, 0.4873179984359655, 0.4803895893929125, 0.48865244762933524, 0.48903520291078706, 0.46385282606983713, 0.47954237901257685, 0.49340771389152793, 0.4807967884862512, 0.47871281979239044, 0.4786989636507085, 0.5138125184920977, 0.46522172681120205, 0.5374186309387408, 0.49756460921724094, 0.48335148332871175, 0.5035777209634212, 0.5306485052624496, 0.46789373694556785, 0.4720457386142767, 0.49803222562358807, 0.4771949167135657, 0.4722051156725278, 0.48829653765130504, 0.509759607678698, 0.49744366037855664, 0.4849415690563798, 0.48835281656576185, 0.4904796560901508]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4506264181519584\n","is min 0.4506264181519584 is smaller than [0.47380864426094094, 0.4774923900145043, 0.47295364318870803, 0.4728098259642077, 0.47354771716573024, 0.46890028731442923, 0.4644053481881035, 0.46707564979194743, 0.4620875761500658, 0.4670739107244561, 0.45786835167571627, 0.45795333418037576, 0.4744743691718644, 0.46352089926429985, 0.4658394175900773, 0.4625506869968545, 0.5258367504178518, 0.47479604099075085, 0.46671640596728214, 0.5561468968863187, 0.5664894056705412, 0.6581051094761394, 0.48132321382476967, 0.48772785994802637, 0.4781872814666155, 0.49020749776588485, 0.5033215976453718, 0.5044954440033474, 0.5382613311351371, 0.48538426059990697, 0.507009877258652, 0.5260529405377596, 0.48052725454646755, 0.48224439241673767, 0.5670085998053644, 0.4835095244858987, 0.5124120042305123, 0.4873179984359655, 0.4803895893929125, 0.48865244762933524, 0.48903520291078706, 0.46385282606983713, 0.47954237901257685, 0.49340771389152793, 0.4807967884862512, 0.47871281979239044, 0.4786989636507085, 0.5138125184920977, 0.46522172681120205, 0.5374186309387408, 0.49756460921724094, 0.48335148332871175, 0.5035777209634212, 0.5306485052624496, 0.46789373694556785, 0.4720457386142767, 0.49803222562358807, 0.4771949167135657, 0.4722051156725278, 0.48829653765130504, 0.509759607678698, 0.49744366037855664, 0.4849415690563798, 0.48835281656576185, 0.4904796560901508, 0.4532757202734248]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49577257098926963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45252764651833616\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5114601464217375\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5144952379654024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46123072113103447\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5043718024663897\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49692185379722453\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4582804525393755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45783032295836895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.520814562842598\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.466177721559072\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46625190423574575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4658637922424128\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4629412173529396\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4820126530136203\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4723444030812678\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4646391749952063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46756646039102406\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48162946747575036\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4914025219830364\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5459399968865343\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5834823405879502\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49116275873293086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4741798221756598\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4699370841074553\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4834791525893379\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4639728594763589\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4588045911374662\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47712680472427127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5041649001850244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5279877643478944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5546337775579544\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4595117871534367\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4684911631539009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47790863648042897\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4934984957939807\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48528016337165714\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47525252381525573\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47004178403958174\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48746497566228547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5072873149815827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48010409227015227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4895271765859243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4691276895584063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5257591970830595\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4679246524301376\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47913830550008374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4617411331447988\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46226841679451763\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4649476979345558\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48216596156574737\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5018968446718363\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46409959582743127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49309168456268965\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4846721592666689\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5070966261263107\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45992560494889073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4601851152937499\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4727476701781322\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48521669126040073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4622551371039525\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664467387386929\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4942283221079618\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48965681743856543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4938466447639221\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47411025097159715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4790329143202065\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48496721780819646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664449182328417\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4720319632772115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4809686140543483\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4672669905931875\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4915736254320445\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4643260889717972\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4645683468315086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4685095231975985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46388360325558425\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680443100992808\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49635716725056706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5246010738700831\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4654795744626172\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.491747144408352\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4745416561446084\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4739988664130236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46479737566514134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4715959294226359\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4671657100086774\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46920726644660776\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4645730844816096\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5019857467990896\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5352405575691679\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5342446311413862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4990817216749562\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4736819667925884\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46536094043950244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46533515883347937\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46542092959555154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48700102069356044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4647527523580414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4758149192482959\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4837994641056591\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674726281571724\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46352768573573194\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4669600433998167\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45954832552945446\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.472827806459915\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47105556867895326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47485538507894864\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47188963142026746\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4754249794647763\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46816152310945236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4761771494668209\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46815265881752216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47582356517399227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4679373575823346\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4721934602900355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4658234922843099\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4627608100792814\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46451877216445875\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46743308825558816\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46676568064742696\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4808839925873687\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49300287605901294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49331033819561826\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4854555221138574\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46170833055433946\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4682926208268829\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4625783618738664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46653349762498586\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47274576718760825\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47274576718760825\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:59:28, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.161600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.205900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.249200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.281700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.173700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.212000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.288400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.233100</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.233700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.216000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.211600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.263400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.187700</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.212300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.181500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.203000</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.180800</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.221900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.231500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.257600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.179400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.292300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.275400</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.235400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.222400</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.334500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.233000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.363400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.254700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.254600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.309500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.262900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.263900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.384300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.311500</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.250700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.186500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.288600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.235300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.121000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.134300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.185300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.129600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.128300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.229300</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.196000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.139400</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.173000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.238100</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.175700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.130400</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.188300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.222800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.198900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.235400</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.195100</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.166300</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.168100</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.174500</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.161300</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.157600</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.144500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.161200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.204400</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.128600</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.215000</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.108600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.174900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.129400</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.309800</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.176500</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.245400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.216300</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.172700</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.184100</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.165700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.131300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.096900</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.070900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.068600</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.104700</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.091000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.106100</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.105300</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.129500</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.077000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.075400</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.106800</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.087300</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.067000</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.079000</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.140800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.105800</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.108500</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.164900</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.153600</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.108600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.089100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.058000</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.075600</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.075100</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.077100</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.090300</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.081100</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.093900</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.125500</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.119600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.130000</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.173300</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.085800</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.086700</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.097900</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.131700</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.088900</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.080900</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.063300</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.064500</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.047700</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.070300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.050100</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.055700</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.053400</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.059800</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.081400</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.046900</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.055000</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.045100</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.069600</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.063800</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.039300</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.093200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.058300</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.070400</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.070500</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.051100</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.035900</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.054900</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.046000</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.032800</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.027500</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.037500</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.024000</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.050800</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.056700</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.032800</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.041600</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.053400</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.053400</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.028300</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.046500</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.049400</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.027200</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.049800</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.027500</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.032100</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.033400</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.025900</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.042900</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.026300</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.029800</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.030300</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.036600</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.033000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47967071598536015\n","is min 0.47967071598536015 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4781401435304487\n","is min 0.4781401435304487 is smaller than [0.47967071598536015]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48507091759007065\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48770536206994536\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47644147508694157\n","is min 0.47644147508694157 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4737880010329622\n","is min 0.4737880010329622 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536, 0.47644147508694157]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4988781606627038\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.473113140725372\n","is min 0.473113140725372 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536, 0.47644147508694157, 0.4737880010329622, 0.4988781606627038]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47547558111486093\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47287417544508886\n","is min 0.47287417544508886 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536, 0.47644147508694157, 0.4737880010329622, 0.4988781606627038, 0.473113140725372, 0.47547558111486093]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4894685996376904\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4817170727838897\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4990950932797944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4964359485738574\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5184244315398391\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49672489034079753\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48010667877188057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47964169301022574\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.498554773440204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.572923408600788\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5289621775882316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.537475752613097\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4970007411187174\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4801355713511162\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5344711697122074\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5154375375453473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5212871337916233\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5271127811397247\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5196840211905566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47500921810209684\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5216049753928605\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.499183977735709\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.599794702127831\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5078537645112985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5540656730845579\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5307227460620021\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4776605807051231\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4799781444971566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5107637827224237\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5001178368845438\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4979977699001744\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5687820681692566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5132961503701042\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48238116432800243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5919241550609721\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4704958923644493\n","is min 0.4704958923644493 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536, 0.47644147508694157, 0.4737880010329622, 0.4988781606627038, 0.473113140725372, 0.47547558111486093, 0.47287417544508886, 0.4894685996376904, 0.4817170727838897, 0.4990950932797944, 0.4964359485738574, 0.5184244315398391, 0.49672489034079753, 0.48010667877188057, 0.47964169301022574, 0.498554773440204, 0.572923408600788, 0.5289621775882316, 0.537475752613097, 0.4970007411187174, 0.4801355713511162, 0.5344711697122074, 0.5154375375453473, 0.5212871337916233, 0.5271127811397247, 0.5196840211905566, 0.47500921810209684, 0.5216049753928605, 0.499183977735709, 0.599794702127831, 0.5078537645112985, 0.5540656730845579, 0.5307227460620021, 0.4776605807051231, 0.4799781444971566, 0.5107637827224237, 0.5001178368845438, 0.4979977699001744, 0.5687820681692566, 0.5132961503701042, 0.48238116432800243, 0.5919241550609721]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47626559219509407\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4684162066117837\n","is min 0.4684162066117837 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536, 0.47644147508694157, 0.4737880010329622, 0.4988781606627038, 0.473113140725372, 0.47547558111486093, 0.47287417544508886, 0.4894685996376904, 0.4817170727838897, 0.4990950932797944, 0.4964359485738574, 0.5184244315398391, 0.49672489034079753, 0.48010667877188057, 0.47964169301022574, 0.498554773440204, 0.572923408600788, 0.5289621775882316, 0.537475752613097, 0.4970007411187174, 0.4801355713511162, 0.5344711697122074, 0.5154375375453473, 0.5212871337916233, 0.5271127811397247, 0.5196840211905566, 0.47500921810209684, 0.5216049753928605, 0.499183977735709, 0.599794702127831, 0.5078537645112985, 0.5540656730845579, 0.5307227460620021, 0.4776605807051231, 0.4799781444971566, 0.5107637827224237, 0.5001178368845438, 0.4979977699001744, 0.5687820681692566, 0.5132961503701042, 0.48238116432800243, 0.5919241550609721, 0.4704958923644493, 0.47626559219509407]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47065997289730277\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4865563212261253\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46969968764035686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4785054273146649\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5728506031252523\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5020700326768569\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4877016452102545\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5303531717597803\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.500802371637577\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4909648482493798\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4923125135615041\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48181284261875773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5209349872722989\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.461840742933937\n","is min 0.461840742933937 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536, 0.47644147508694157, 0.4737880010329622, 0.4988781606627038, 0.473113140725372, 0.47547558111486093, 0.47287417544508886, 0.4894685996376904, 0.4817170727838897, 0.4990950932797944, 0.4964359485738574, 0.5184244315398391, 0.49672489034079753, 0.48010667877188057, 0.47964169301022574, 0.498554773440204, 0.572923408600788, 0.5289621775882316, 0.537475752613097, 0.4970007411187174, 0.4801355713511162, 0.5344711697122074, 0.5154375375453473, 0.5212871337916233, 0.5271127811397247, 0.5196840211905566, 0.47500921810209684, 0.5216049753928605, 0.499183977735709, 0.599794702127831, 0.5078537645112985, 0.5540656730845579, 0.5307227460620021, 0.4776605807051231, 0.4799781444971566, 0.5107637827224237, 0.5001178368845438, 0.4979977699001744, 0.5687820681692566, 0.5132961503701042, 0.48238116432800243, 0.5919241550609721, 0.4704958923644493, 0.47626559219509407, 0.4684162066117837, 0.47065997289730277, 0.4865563212261253, 0.46969968764035686, 0.4785054273146649, 0.5728506031252523, 0.5020700326768569, 0.4877016452102545, 0.5303531717597803, 0.500802371637577, 0.4909648482493798, 0.4923125135615041, 0.48181284261875773, 0.5209349872722989]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46997529466477195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5020576495602052\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5500157901816175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5069042051853577\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4858987675989818\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4785502403720757\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4870699457907741\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47637151870939914\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5060425560202368\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48600831540918643\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4710553602487156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4894874754015936\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47572060714324943\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47063928620010304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4922103715274832\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4661911989705537\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4668694550303521\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4741420751677638\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4798341306051063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5091778326096175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4755142203033572\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4898947297310985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4912917922823316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4902507551050621\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47485543767755356\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4702848750093224\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5147494595982559\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45903922352723653\n","is min 0.45903922352723653 is smaller than [0.47967071598536015, 0.4781401435304487, 0.48507091759007065, 0.48770536206994536, 0.47644147508694157, 0.4737880010329622, 0.4988781606627038, 0.473113140725372, 0.47547558111486093, 0.47287417544508886, 0.4894685996376904, 0.4817170727838897, 0.4990950932797944, 0.4964359485738574, 0.5184244315398391, 0.49672489034079753, 0.48010667877188057, 0.47964169301022574, 0.498554773440204, 0.572923408600788, 0.5289621775882316, 0.537475752613097, 0.4970007411187174, 0.4801355713511162, 0.5344711697122074, 0.5154375375453473, 0.5212871337916233, 0.5271127811397247, 0.5196840211905566, 0.47500921810209684, 0.5216049753928605, 0.499183977735709, 0.599794702127831, 0.5078537645112985, 0.5540656730845579, 0.5307227460620021, 0.4776605807051231, 0.4799781444971566, 0.5107637827224237, 0.5001178368845438, 0.4979977699001744, 0.5687820681692566, 0.5132961503701042, 0.48238116432800243, 0.5919241550609721, 0.4704958923644493, 0.47626559219509407, 0.4684162066117837, 0.47065997289730277, 0.4865563212261253, 0.46969968764035686, 0.4785054273146649, 0.5728506031252523, 0.5020700326768569, 0.4877016452102545, 0.5303531717597803, 0.500802371637577, 0.4909648482493798, 0.4923125135615041, 0.48181284261875773, 0.5209349872722989, 0.461840742933937, 0.46997529466477195, 0.5020576495602052, 0.5500157901816175, 0.5069042051853577, 0.4858987675989818, 0.4785502403720757, 0.4870699457907741, 0.47637151870939914, 0.5060425560202368, 0.48600831540918643, 0.4710553602487156, 0.4894874754015936, 0.47572060714324943, 0.47063928620010304, 0.4922103715274832, 0.4661911989705537, 0.4668694550303521, 0.4741420751677638, 0.4798341306051063, 0.5091778326096175, 0.4755142203033572, 0.4898947297310985, 0.4912917922823316, 0.4902507551050621, 0.47485543767755356, 0.4702848750093224, 0.5147494595982559]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47925846536546807\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46451894417101874\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47264476546474304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4930152264152216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4920095107709325\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47264481398526365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5091595652863493\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4886766935496967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47225453634519154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718243766795272\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49390838758179134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49697971374168326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4773852090424086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4756257086524839\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47281121969732076\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4791478156513662\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4994788088263625\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4808146574798735\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5530945058886766\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6079923952996414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5119344512470474\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46634012169842554\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46832199821363013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4666115356729223\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5294941332110925\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46898061252893414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4670759295061304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47679969466994654\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49391044080329216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47578150119454055\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4875872989036181\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47405322498697605\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4740594988226591\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5053658562088129\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47024027638318305\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4708790656506301\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689889124340265\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46442536636316517\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4693122042320566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4961507889008442\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4791086084314415\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5183055577116809\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47643369036531097\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5024518416946613\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4908812420985226\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4705519256360735\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46493187610990294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48939552716022855\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4690529855059707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4780967838417649\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4730766997790998\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49153912036099967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46996608532330536\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47569306976738523\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4751456426227481\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4731347937839514\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4906849617293107\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4962336335329753\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4754498998718517\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4964127734796572\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49946093493838767\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4932962468225099\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47937773475453044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48710616399133116\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4788395941232778\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47827051236552215\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4776075066222668\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4782976042438756\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5010164469843086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4682164654118024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47299501312680325\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4766813459906388\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4739379235408125\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686581588796175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48909704807242627\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49527359394269416\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4790102268660355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4714572913975023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47369639173445627\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47356174278696256\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5104489017874146\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5165924889879142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5021800270510816\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4810126735780877\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49230666489190195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4809374573893415\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48298367514266916\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48331867516097343\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49761240085874636\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.477561825130922\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47389233727226526\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.475153011954061\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47755820006295635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47815541157482927\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4978577225380645\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.482942629377096\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.491477169424244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4808512923149925\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48493787513343156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4784489645940353\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47517842595469956\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719466626936145\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4800825008207748\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4737460077007953\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4782893877341872\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4827373551294615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4795203398393588\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4795203398393588\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:59:14, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.225100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.169900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.183800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.173400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.240900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.194800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.194300</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.270900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.253200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.226400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.264800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.290200</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.198300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.260600</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.208800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.258900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.281500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.258600</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.219100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.222400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.235500</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.298400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.198600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.255500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.289100</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.236500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.309700</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.255100</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.349400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.203100</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.373100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.285500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.224600</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.301900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.212300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.301800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.301000</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.296400</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.205700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.263800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.200100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.161500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.126100</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.177100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.225600</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.107400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.110800</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.133900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.189000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.219900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.135100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.207700</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.267800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.219700</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.162500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.181500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.129300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.312100</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.192200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.126500</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.206000</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.129500</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.192000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.151800</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.173300</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.216700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.156500</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.240200</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.189900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.138000</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.153000</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.134600</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.244800</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.171300</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.154200</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.222100</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.168100</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.175000</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.279600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.096300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.098900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.112700</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.136900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.089700</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.081500</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.066800</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.095600</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.089200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.146300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.070000</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.079400</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.068600</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.073300</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.088100</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.082500</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.093400</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.103000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.092400</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.112300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.109000</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.136900</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.131300</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.077900</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.110900</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.063900</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.058000</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.070300</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.099800</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.095600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.075900</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.087800</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.108600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.111800</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.077500</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.061300</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.055600</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.073900</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.056400</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.058800</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.063300</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.065500</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.070300</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.044500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.057100</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.050300</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.052800</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.036400</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.044000</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.073200</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.067500</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.057200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.050800</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.031900</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.041900</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.055200</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.029800</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.041600</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.049700</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.037900</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.029400</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.033500</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.064200</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.033400</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.026000</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.031100</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.028500</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.029300</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.020800</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.029400</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.026600</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.025500</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.017400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44452250761106965\n","is min 0.44452250761106965 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44417572282010165\n","is min 0.44417572282010165 is smaller than [0.44452250761106965]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4451550969465949\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44536286336137004\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44300237120627967\n","is min 0.44300237120627967 is smaller than [0.44452250761106965, 0.44417572282010165, 0.4451550969465949, 0.44536286336137004]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4479093161870963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4434111809397606\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5040220734697785\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44688369493177327\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43919585257060684\n","is min 0.43919585257060684 is smaller than [0.44452250761106965, 0.44417572282010165, 0.4451550969465949, 0.44536286336137004, 0.44300237120627967, 0.4479093161870963, 0.4434111809397606, 0.5040220734697785, 0.44688369493177327]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44072611548593427\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4930789986218635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4467965654876192\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4565625898236911\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4846450795634306\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4554477936371151\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49643834036134354\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4392023708185089\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4354717698374679\n","is min 0.4354717698374679 is smaller than [0.44452250761106965, 0.44417572282010165, 0.4451550969465949, 0.44536286336137004, 0.44300237120627967, 0.4479093161870963, 0.4434111809397606, 0.5040220734697785, 0.44688369493177327, 0.43919585257060684, 0.44072611548593427, 0.4930789986218635, 0.4467965654876192, 0.4565625898236911, 0.4846450795634306, 0.4554477936371151, 0.49643834036134354, 0.4392023708185089]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44564204977369326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4573570376772185\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44842723027212894\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48858659932367615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5360378476977508\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4418510488012262\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4659637223160823\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.448709499387649\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5162638237671919\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47281296071290213\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47430453649490173\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5483828495781085\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5244092461728742\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5501939772183498\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43923042086053926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44373812465765455\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44803066658492774\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46366874014041987\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4519545732230797\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5717754715652685\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49849367274720224\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5014246844900788\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4478540414499229\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4676131397021287\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46234779162851597\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4598812638996315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4460669470259334\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46148386824509585\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44701907228941556\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.440369800118296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44623541241393483\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45944679700493385\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4500787379340605\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46915912501986523\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4586017182895336\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4606191769939345\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4493346789381528\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5244683032823495\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948664200514808\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4524604401875344\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4484156611183171\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43936312681448175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4488267505846176\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49230805460945776\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4666349502847817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4699133730322524\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4949770251316717\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5081204967961391\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5443260957271567\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49985382776962706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4442411485925622\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45317739100683163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46582753763895457\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45540414083065156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.452087111997543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45947018787916405\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45777831131139846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47267790627374157\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46708155591775996\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.496244319653861\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47012407659719796\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.454268282536355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45034887658134515\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45282226241125706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5137744060374864\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4568136463632673\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4463547202945076\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4600701442092061\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4938698615170122\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5064277996085371\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4657631831385425\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45888710629583773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4483047307264639\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4669140392160315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4490956546838072\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.451034091663971\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4550420604269764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45865205718705304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4616040973789542\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4575844943583084\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5010335370788475\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5710895012698025\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4842888140113129\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4684502712580744\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46008312785636996\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45796234263696767\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47135948153569657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46502139301385725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4472533468114172\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4465347961167624\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44647724203198014\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4615927016898854\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4543476772028635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46806001904083905\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4995429778006957\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5011747416731844\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4810433864050447\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4748902588584617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4553899416844549\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4543072192763064\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664433722090273\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4497534506861358\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4716471236039851\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46820316117926125\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45509787346950425\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4496759981718992\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4527610613835875\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4750893027187362\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46943631704641225\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47561898701253824\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4766819637190837\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4832805963767532\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674272360250399\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45571368610502505\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45034016674977484\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45667406578653846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45243414435256046\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4564476622560065\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45469625518954676\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4514017206626388\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46245602971257704\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4543143962360257\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4602714018112292\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47008562012360494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.449005196536501\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4622737638407064\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4581153796735275\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45503938552623274\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46548440155766935\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5009380572146158\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45728942691468527\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45995572551118713\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45402809728325005\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45057635617556563\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45799824618463686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4944146375947157\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4728824533594141\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4493750021129176\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4685882891797558\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45657341583678307\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44928032485551805\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4459855217010967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45361284964007764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4833649957691172\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45060500086451644\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45806845504438853\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45719069379238075\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46533253203656555\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4580654803555114\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4479357910371403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4658719758562885\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45010748936382305\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46572948409619314\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44672575008168497\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4553921601650163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4479845777171764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4524615990085332\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47383090118499244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4475155955326077\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45560159033082376\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4526008669636741\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.452067838290247\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4585204059173177\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46672127717355805\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45216165923112284\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45540663831283607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4543801496157192\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4591531094570434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45242195927524637\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45064182202943703\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46121798809023373\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4587212775872407\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44867273580918676\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4558006492991046\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4862680621799253\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4483966483454829\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4501226816267056\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45470366972907184\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45470366972907184\n","Training done\n"]}],"source":["# albert 1\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.01,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.07,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ALBERT_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"v0YuArTWeglx"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 4:00:12, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.271500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.264000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.197000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.243000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.304600</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.315500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.208100</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.224900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.186900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.226100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.149200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.185800</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.227900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.236200</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.183300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.294700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.168700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.261300</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.223200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.231800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.186300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.237300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.240300</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.260400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.260300</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.305400</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.240900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.224300</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.267100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.189500</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.269000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.242400</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.189100</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.237700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.325900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.178700</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.259200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.218800</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.270100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.276300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.212100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.192500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.139900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.104600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.106300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.165400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.253600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.167500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.238300</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.215800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.146600</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.178000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.189200</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.200600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.159800</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.152300</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.184400</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.244000</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.210500</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.230400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.206800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.190200</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.172900</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.153500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.296100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.103500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.189800</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.181600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.227700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.170000</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.127700</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.138300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.147400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.178000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.187100</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.157200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.195500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.173700</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.168300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.115300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.120800</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.112100</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.063400</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.102800</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.102800</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.108100</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.079600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.070500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.098800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.067300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.140100</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.125900</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.084300</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.063700</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.122000</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.132600</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.083000</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.076200</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.081000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.083200</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.098900</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.098200</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.105300</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.108800</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.152900</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.102400</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.115800</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.107400</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.112400</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.119500</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.091200</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.120200</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.059300</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.075400</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.096300</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.125400</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.066300</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.076200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.062300</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.087200</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.044800</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.061800</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.056900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.070100</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.058000</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.066400</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.037500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.056300</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.049000</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.048900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.042400</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.049700</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.048600</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.037000</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.068200</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.043900</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.048100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.069300</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.049400</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.036300</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.066800</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.071600</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.041200</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.062300</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.025500</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.024300</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.029400</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.032800</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.032600</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.022500</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.034800</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.058400</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.028500</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.018300</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.036300</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.035900</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.030300</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.038400</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.027000</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.026700</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.024500</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.023000</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.034800</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.044200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4557647680114362\n","is min 0.4557647680114362 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:59,  3.96s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46215025510866514\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.96s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46036646540287907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.95s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4731932970363317\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47269870146169657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.467402426456958\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47132661185233127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45400166283087307\n","is min 0.45400166283087307 is smaller than [0.4557647680114362, 0.46215025510866514, 0.46036646540287907, 0.4731932970363317, 0.47269870146169657, 0.467402426456958, 0.47132661185233127]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45682853678110197\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4655855221132313\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45535644684313575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48496325867325196\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46107449877524503\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46191626165938937\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46788448267743354\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47204021882503233\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5006738208923616\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4553575690471403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46506489704757825\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4573263020097341\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4515052794976247\n","is min 0.4515052794976247 is smaller than [0.4557647680114362, 0.46215025510866514, 0.46036646540287907, 0.4731932970363317, 0.47269870146169657, 0.467402426456958, 0.47132661185233127, 0.45400166283087307, 0.45682853678110197, 0.4655855221132313, 0.45535644684313575, 0.48496325867325196, 0.46107449877524503, 0.46191626165938937, 0.46788448267743354, 0.47204021882503233, 0.5006738208923616, 0.4553575690471403, 0.46506489704757825, 0.4573263020097341]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5300806661765184\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5077996650957397\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4626434057432268\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4924332938182045\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46316320097372143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4698960455283344\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45908027123824713\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.493898243867605\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4987351990256147\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4894672902886781\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46330912019856685\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5854980798591205\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4592553187970993\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4961579061078315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4501725997663205\n","is min 0.4501725997663205 is smaller than [0.4557647680114362, 0.46215025510866514, 0.46036646540287907, 0.4731932970363317, 0.47269870146169657, 0.467402426456958, 0.47132661185233127, 0.45400166283087307, 0.45682853678110197, 0.4655855221132313, 0.45535644684313575, 0.48496325867325196, 0.46107449877524503, 0.46191626165938937, 0.46788448267743354, 0.47204021882503233, 0.5006738208923616, 0.4553575690471403, 0.46506489704757825, 0.4573263020097341, 0.4515052794976247, 0.5300806661765184, 0.5077996650957397, 0.4626434057432268, 0.4924332938182045, 0.46316320097372143, 0.4698960455283344, 0.45908027123824713, 0.493898243867605, 0.4987351990256147, 0.4894672902886781, 0.46330912019856685, 0.5854980798591205, 0.4592553187970993, 0.4961579061078315]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4967450121829402\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46088770077425023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47031354837042827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4550481951353859\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4566644850606614\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45372265409622353\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47065229223507665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46412992379872786\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5384536674555882\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4697006912416869\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5164704329819084\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48480875745578056\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5164902295683222\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4714095100075352\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5649647181227642\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680605343227871\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46051000400869024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4564367652059563\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4782974075870494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46462223317178386\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4672634272857973\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4621943875667926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4950509678217793\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5068538891873684\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4663694607169384\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4729224604520058\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49333377987103033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469905829503362\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48628507537144827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5082113426735042\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4663446011844147\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4619598017505073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4665080536456754\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4698232718488507\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48217861377618715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680562366677041\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47315381642163457\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4766478813948135\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4934360534093977\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4700897120808501\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.95s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4986601865420907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4783825785470989\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47284825894696725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49464339175244193\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.463277119726062\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4717037193479768\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4599125496560945\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4655517394665721\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686412393831886\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4737346694622202\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48169257998367276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4815091814623715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46798516618859154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5044087404742646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49407495189361456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47439343588049654\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4792410359217102\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48935398479058617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49378931538021303\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4742283561239326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719733307328081\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46330965411724073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.95s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46357980370520463\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.465988813305216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4688998977942089\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.95s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.478450928886038\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47862958801871813\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4941038483490338\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47796722989701823\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47293389897922733\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5222004812304083\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4736853912138014\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4765755198972889\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48481741824814073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48267679965790405\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48732022320463436\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4809729068963622\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47715182516176957\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5475120769134674\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49297727682456144\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5154391647727922\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4994818693347941\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48106654155389783\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48142474216929304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47937560519392886\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4846191434899548\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48677867382150347\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4862701110292163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48028036802434365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4822478092363455\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686130517652281\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48959520798781303\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.95s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4762476319101602\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4840548356554436\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4954697813474456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47593970694294463\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4812253316253722\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4756242011040417\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47575827555360994\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760915627522086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47581950904463116\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47242931181857706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46907883864923033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46960125301461825\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4765473892118947\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4768180404341804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4704151138214096\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4751845837335372\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4741298658027754\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4844663530001133\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4804215467059607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47317448333374507\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4839250311336811\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4890100804821015\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4774196126636545\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47985451663137674\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4771507726447029\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4880275131873762\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4835078255268488\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47396910614197363\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4778647394562676\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47850938359722467\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49571653210205674\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4739859001770245\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4774961720328356\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48725656664136374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680220755060384\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.466819303745392\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48243245144161645\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46470994663795073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47013994707286566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48254942589952543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47481705415409603\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47385915188502786\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4961484146990893\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47016629197282594\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4685545262290551\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4728839188134243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47125565122294955\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46576651875529845\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4688547956465243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46612979619576905\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46185817689258624\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46558294428796565\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4869730978656797\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46932636952350687\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814768509121592\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4663756016138525\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47084124281205547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4645539497327407\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47650564063486295\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46626559673483764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4702000981050757\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47060842960882915\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4675496383074824\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.473275350841404\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46896842233623737\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46450696500894956\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47002577261806355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4758233757116771\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674906384784291\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674906384784291\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:59:39, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.198200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.241800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.146800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.218100</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.242700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.237400</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.213200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.201200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.166200</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.209300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.277100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.288900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.244500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.203300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.169900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.283000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.177400</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.282800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.228500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.195800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.254000</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.227000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.219700</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.227200</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.246700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.258600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.258800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.207800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.266400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.283000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.335400</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.181500</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.232800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.198400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.151800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.289100</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.323800</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.339100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.305400</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.365600</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.128800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.175100</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.185400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.167700</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.223400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.146200</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.144000</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.133600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.275700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.217700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.128800</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.192800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.181400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.144500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.131100</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.199400</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.198900</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.178700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.271700</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.175700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.145400</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.171300</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.216200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.160400</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.143300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.204000</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.176800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.136800</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.183100</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.220000</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.129500</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.180400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.187300</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.120200</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.120400</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.199500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.145000</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.150700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.075700</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.090700</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.122900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.090300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.103200</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.126400</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.074600</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.055400</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.100700</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.126200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.083800</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.118700</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.111200</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.102500</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.113000</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.096000</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.094400</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.115200</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.088200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.103500</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.075000</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.090600</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.091900</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.075800</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.110800</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.088900</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.098000</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.088400</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.075500</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.076400</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.098400</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.114500</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.101800</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.081900</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.094900</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.066200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.057900</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.093300</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.066600</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.042100</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.071600</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.057500</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.031400</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.078000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.047900</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.060300</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.041000</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.054600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.054000</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.045100</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.044200</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.038100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.029200</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.068400</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.064800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.072900</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.033700</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.035500</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.024200</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.026000</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.018400</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.026200</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.034500</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.032600</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.024300</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.023900</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.028900</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.038100</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.024700</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.032800</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.155500</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.024700</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.021500</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.028900</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.020700</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.026900</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.024400</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.033400</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.023900</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.027200</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.026200</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.032800</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.032500</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.026500</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.031900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47842298675050443\n","is min 0.47842298675050443 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:59,  3.97s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4801493054168234\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.96s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48152072875737206\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48978877755102634\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47675650086012017\n","is min 0.47675650086012017 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4715687314741763\n","is min 0.4715687314741763 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4846920791817457\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680493263980728\n","is min 0.4680493263980728 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017, 0.4715687314741763, 0.4846920791817457]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4801508806662185\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47388299057572864\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4823298206942087\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47508962733115756\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4732022562154581\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4973834831145869\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4756185684272432\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5151951045583245\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48681200938678787\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948485245043643\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5349560498245105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4829504689795815\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5074984318692559\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814495824587557\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4700274003129929\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47814210496196113\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4657032352375685\n","is min 0.4657032352375685 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017, 0.4715687314741763, 0.4846920791817457, 0.4680493263980728, 0.4801508806662185, 0.47388299057572864, 0.4823298206942087, 0.47508962733115756, 0.4732022562154581, 0.4973834831145869, 0.4756185684272432, 0.5151951045583245, 0.48681200938678787, 0.4948485245043643, 0.5349560498245105, 0.4829504689795815, 0.5074984318692559, 0.4814495824587557, 0.4700274003129929, 0.47814210496196113]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46893649648714963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47623693287774116\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4672133899085612\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4727480523387633\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4980130022571762\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4918134492210952\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4768040919691912\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4684540234538484\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4769045289384331\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4667909556716578\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48924873818784453\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5099379951923387\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6571321454143961\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6807135463588159\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6686992774238318\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4775055138203465\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4688803139301011\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4638245408850571\n","is min 0.4638245408850571 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017, 0.4715687314741763, 0.4846920791817457, 0.4680493263980728, 0.4801508806662185, 0.47388299057572864, 0.4823298206942087, 0.47508962733115756, 0.4732022562154581, 0.4973834831145869, 0.4756185684272432, 0.5151951045583245, 0.48681200938678787, 0.4948485245043643, 0.5349560498245105, 0.4829504689795815, 0.5074984318692559, 0.4814495824587557, 0.4700274003129929, 0.47814210496196113, 0.4657032352375685, 0.46893649648714963, 0.47623693287774116, 0.4672133899085612, 0.4727480523387633, 0.4980130022571762, 0.4918134492210952, 0.4768040919691912, 0.4684540234538484, 0.4769045289384331, 0.4667909556716578, 0.48924873818784453, 0.5099379951923387, 0.6571321454143961, 0.6807135463588159, 0.6686992774238318, 0.4775055138203465, 0.4688803139301011]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48561510993930446\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47761207970675096\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:59,  3.94s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4721302666443853\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47253486688233726\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.474078572222072\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47715596621455814\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469005032450752\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48957519543682065\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5147560146289997\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47438630680296234\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48506616315313156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948370799883454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5283507520226374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5102074259334954\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4767855251388166\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.540244476602435\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47647121652292596\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46668288991998713\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46678247994618277\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5285038740181691\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4775061190336824\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46259943857840463\n","is min 0.46259943857840463 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017, 0.4715687314741763, 0.4846920791817457, 0.4680493263980728, 0.4801508806662185, 0.47388299057572864, 0.4823298206942087, 0.47508962733115756, 0.4732022562154581, 0.4973834831145869, 0.4756185684272432, 0.5151951045583245, 0.48681200938678787, 0.4948485245043643, 0.5349560498245105, 0.4829504689795815, 0.5074984318692559, 0.4814495824587557, 0.4700274003129929, 0.47814210496196113, 0.4657032352375685, 0.46893649648714963, 0.47623693287774116, 0.4672133899085612, 0.4727480523387633, 0.4980130022571762, 0.4918134492210952, 0.4768040919691912, 0.4684540234538484, 0.4769045289384331, 0.4667909556716578, 0.48924873818784453, 0.5099379951923387, 0.6571321454143961, 0.6807135463588159, 0.6686992774238318, 0.4775055138203465, 0.4688803139301011, 0.4638245408850571, 0.48561510993930446, 0.47761207970675096, 0.4721302666443853, 0.47253486688233726, 0.474078572222072, 0.47715596621455814, 0.469005032450752, 0.48957519543682065, 0.5147560146289997, 0.47438630680296234, 0.48506616315313156, 0.4948370799883454, 0.5283507520226374, 0.5102074259334954, 0.4767855251388166, 0.540244476602435, 0.47647121652292596, 0.46668288991998713, 0.46678247994618277, 0.5285038740181691, 0.4775061190336824]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.468289692164452\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48906628047257017\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46336096086741313\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47163956152368236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48763643039129045\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47104845745306423\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5361315386646783\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.473842775870068\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4715895890333239\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4673788478459004\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4832479567754574\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45978674135429887\n","is min 0.45978674135429887 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017, 0.4715687314741763, 0.4846920791817457, 0.4680493263980728, 0.4801508806662185, 0.47388299057572864, 0.4823298206942087, 0.47508962733115756, 0.4732022562154581, 0.4973834831145869, 0.4756185684272432, 0.5151951045583245, 0.48681200938678787, 0.4948485245043643, 0.5349560498245105, 0.4829504689795815, 0.5074984318692559, 0.4814495824587557, 0.4700274003129929, 0.47814210496196113, 0.4657032352375685, 0.46893649648714963, 0.47623693287774116, 0.4672133899085612, 0.4727480523387633, 0.4980130022571762, 0.4918134492210952, 0.4768040919691912, 0.4684540234538484, 0.4769045289384331, 0.4667909556716578, 0.48924873818784453, 0.5099379951923387, 0.6571321454143961, 0.6807135463588159, 0.6686992774238318, 0.4775055138203465, 0.4688803139301011, 0.4638245408850571, 0.48561510993930446, 0.47761207970675096, 0.4721302666443853, 0.47253486688233726, 0.474078572222072, 0.47715596621455814, 0.469005032450752, 0.48957519543682065, 0.5147560146289997, 0.47438630680296234, 0.48506616315313156, 0.4948370799883454, 0.5283507520226374, 0.5102074259334954, 0.4767855251388166, 0.540244476602435, 0.47647121652292596, 0.46668288991998713, 0.46678247994618277, 0.5285038740181691, 0.4775061190336824, 0.46259943857840463, 0.468289692164452, 0.48906628047257017, 0.46336096086741313, 0.47163956152368236, 0.48763643039129045, 0.47104845745306423, 0.5361315386646783, 0.473842775870068, 0.4715895890333239, 0.4673788478459004, 0.4832479567754574]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469599815702954\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4961940967420258\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46343607317926466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4796616569240629\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4758408474284229\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719910925976779\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4720754805773608\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.466393899658811\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4695776240103081\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4711646639418904\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47263495665047817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4770033632530239\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4684488440547068\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4732856821375819\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4918545972484616\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47542450371866607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48043404552849345\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4851962346030264\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4726109172973581\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48356541893872323\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48077408852862535\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47618621609053524\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46614295086790764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49819402529173445\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4861449696540055\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4867086010705798\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4954715713522365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4701713121487539\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4895844784468294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4633318248646296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4681175366480783\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4970691246496447\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4642363035626784\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4697946710987337\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.514649448550737\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5202298415384188\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5120516436633813\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5099342879140707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4606469402846899\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4751493522996694\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4604284113202704\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46781197639779787\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46736708771724245\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45785340781064904\n","is min 0.45785340781064904 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017, 0.4715687314741763, 0.4846920791817457, 0.4680493263980728, 0.4801508806662185, 0.47388299057572864, 0.4823298206942087, 0.47508962733115756, 0.4732022562154581, 0.4973834831145869, 0.4756185684272432, 0.5151951045583245, 0.48681200938678787, 0.4948485245043643, 0.5349560498245105, 0.4829504689795815, 0.5074984318692559, 0.4814495824587557, 0.4700274003129929, 0.47814210496196113, 0.4657032352375685, 0.46893649648714963, 0.47623693287774116, 0.4672133899085612, 0.4727480523387633, 0.4980130022571762, 0.4918134492210952, 0.4768040919691912, 0.4684540234538484, 0.4769045289384331, 0.4667909556716578, 0.48924873818784453, 0.5099379951923387, 0.6571321454143961, 0.6807135463588159, 0.6686992774238318, 0.4775055138203465, 0.4688803139301011, 0.4638245408850571, 0.48561510993930446, 0.47761207970675096, 0.4721302666443853, 0.47253486688233726, 0.474078572222072, 0.47715596621455814, 0.469005032450752, 0.48957519543682065, 0.5147560146289997, 0.47438630680296234, 0.48506616315313156, 0.4948370799883454, 0.5283507520226374, 0.5102074259334954, 0.4767855251388166, 0.540244476602435, 0.47647121652292596, 0.46668288991998713, 0.46678247994618277, 0.5285038740181691, 0.4775061190336824, 0.46259943857840463, 0.468289692164452, 0.48906628047257017, 0.46336096086741313, 0.47163956152368236, 0.48763643039129045, 0.47104845745306423, 0.5361315386646783, 0.473842775870068, 0.4715895890333239, 0.4673788478459004, 0.4832479567754574, 0.45978674135429887, 0.469599815702954, 0.4961940967420258, 0.46343607317926466, 0.4796616569240629, 0.4758408474284229, 0.4719910925976779, 0.4720754805773608, 0.466393899658811, 0.4695776240103081, 0.4711646639418904, 0.47263495665047817, 0.4770033632530239, 0.4684488440547068, 0.4732856821375819, 0.4918545972484616, 0.47542450371866607, 0.48043404552849345, 0.4851962346030264, 0.4726109172973581, 0.48356541893872323, 0.48077408852862535, 0.47618621609053524, 0.46614295086790764, 0.49819402529173445, 0.4861449696540055, 0.4867086010705798, 0.4954715713522365, 0.4701713121487539, 0.4895844784468294, 0.4633318248646296, 0.4681175366480783, 0.4970691246496447, 0.4642363035626784, 0.4697946710987337, 0.514649448550737, 0.5202298415384188, 0.5120516436633813, 0.5099342879140707, 0.4606469402846899, 0.4751493522996694, 0.4604284113202704, 0.46781197639779787, 0.46736708771724245]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4772399099266072\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.93s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.458218385753239\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47803607053875086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4604931421414936\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4679926201536161\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4653691978186139\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46798183427753\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4723266463649092\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47596198643515725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680996908480988\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46567122774436304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46175884692992014\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46680788787903865\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46378241656271124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4630354365228135\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47763529782176417\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4768161312273447\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46143292484012494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46322748701873473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47410602590927425\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46391699217012394\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47900399653812953\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4899967844202377\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814521011613888\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46577718550809305\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4658929968080709\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4649159541283597\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4709497241903064\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4692409675359348\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47648069470318366\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4662153002723791\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46626095958060343\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47626295018310844\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47254148696110443\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4743964598168154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4782190933201258\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48061623198294706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4826371510262328\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46329326880205757\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4739145669416478\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47487577076471693\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4711692596158143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4723114870599111\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47027763259489386\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46790966215483387\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46847093774844156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46776633064745626\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4753791178283148\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4693079751705127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47201069906606025\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4620614928775991\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674929422598747\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4672230107162355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4639080583966549\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4619453386590458\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4905616809993635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4656269207854076\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4802844749700686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47330730960749035\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4590675290374388\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46188589619963794\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4710224063410858\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46268103195014004\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47517742675762037\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48652211240164434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46405671540408905\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4734292363405304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4872773101205325\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46302984729212543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46063205561778864\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.462290143325929\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47549772514446753\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4599814006808419\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4697273874133004\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45892414036373147\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4571549815778663\n","is min 0.4571549815778663 is smaller than [0.47842298675050443, 0.4801493054168234, 0.48152072875737206, 0.48978877755102634, 0.47675650086012017, 0.4715687314741763, 0.4846920791817457, 0.4680493263980728, 0.4801508806662185, 0.47388299057572864, 0.4823298206942087, 0.47508962733115756, 0.4732022562154581, 0.4973834831145869, 0.4756185684272432, 0.5151951045583245, 0.48681200938678787, 0.4948485245043643, 0.5349560498245105, 0.4829504689795815, 0.5074984318692559, 0.4814495824587557, 0.4700274003129929, 0.47814210496196113, 0.4657032352375685, 0.46893649648714963, 0.47623693287774116, 0.4672133899085612, 0.4727480523387633, 0.4980130022571762, 0.4918134492210952, 0.4768040919691912, 0.4684540234538484, 0.4769045289384331, 0.4667909556716578, 0.48924873818784453, 0.5099379951923387, 0.6571321454143961, 0.6807135463588159, 0.6686992774238318, 0.4775055138203465, 0.4688803139301011, 0.4638245408850571, 0.48561510993930446, 0.47761207970675096, 0.4721302666443853, 0.47253486688233726, 0.474078572222072, 0.47715596621455814, 0.469005032450752, 0.48957519543682065, 0.5147560146289997, 0.47438630680296234, 0.48506616315313156, 0.4948370799883454, 0.5283507520226374, 0.5102074259334954, 0.4767855251388166, 0.540244476602435, 0.47647121652292596, 0.46668288991998713, 0.46678247994618277, 0.5285038740181691, 0.4775061190336824, 0.46259943857840463, 0.468289692164452, 0.48906628047257017, 0.46336096086741313, 0.47163956152368236, 0.48763643039129045, 0.47104845745306423, 0.5361315386646783, 0.473842775870068, 0.4715895890333239, 0.4673788478459004, 0.4832479567754574, 0.45978674135429887, 0.469599815702954, 0.4961940967420258, 0.46343607317926466, 0.4796616569240629, 0.4758408474284229, 0.4719910925976779, 0.4720754805773608, 0.466393899658811, 0.4695776240103081, 0.4711646639418904, 0.47263495665047817, 0.4770033632530239, 0.4684488440547068, 0.4732856821375819, 0.4918545972484616, 0.47542450371866607, 0.48043404552849345, 0.4851962346030264, 0.4726109172973581, 0.48356541893872323, 0.48077408852862535, 0.47618621609053524, 0.46614295086790764, 0.49819402529173445, 0.4861449696540055, 0.4867086010705798, 0.4954715713522365, 0.4701713121487539, 0.4895844784468294, 0.4633318248646296, 0.4681175366480783, 0.4970691246496447, 0.4642363035626784, 0.4697946710987337, 0.514649448550737, 0.5202298415384188, 0.5120516436633813, 0.5099342879140707, 0.4606469402846899, 0.4751493522996694, 0.4604284113202704, 0.46781197639779787, 0.46736708771724245, 0.45785340781064904, 0.4772399099266072, 0.458218385753239, 0.47803607053875086, 0.4604931421414936, 0.4679926201536161, 0.4653691978186139, 0.46798183427753, 0.4723266463649092, 0.47596198643515725, 0.4680996908480988, 0.46567122774436304, 0.46175884692992014, 0.46680788787903865, 0.46378241656271124, 0.4630354365228135, 0.47763529782176417, 0.4768161312273447, 0.46143292484012494, 0.46322748701873473, 0.47410602590927425, 0.46391699217012394, 0.47900399653812953, 0.4899967844202377, 0.4814521011613888, 0.46577718550809305, 0.4658929968080709, 0.4649159541283597, 0.4709497241903064, 0.4692409675359348, 0.47648069470318366, 0.4662153002723791, 0.46626095958060343, 0.47626295018310844, 0.47254148696110443, 0.4743964598168154, 0.4782190933201258, 0.48061623198294706, 0.4826371510262328, 0.46329326880205757, 0.4739145669416478, 0.47487577076471693, 0.4711692596158143, 0.4723114870599111, 0.47027763259489386, 0.46790966215483387, 0.46847093774844156, 0.46776633064745626, 0.4753791178283148, 0.4693079751705127, 0.47201069906606025, 0.4620614928775991, 0.4674929422598747, 0.4672230107162355, 0.4639080583966549, 0.4619453386590458, 0.4905616809993635, 0.4656269207854076, 0.4802844749700686, 0.47330730960749035, 0.4590675290374388, 0.46188589619963794, 0.4710224063410858, 0.46268103195014004, 0.47517742675762037, 0.48652211240164434, 0.46405671540408905, 0.4734292363405304, 0.4872773101205325, 0.46302984729212543, 0.46063205561778864, 0.462290143325929, 0.47549772514446753, 0.4599814006808419, 0.4697273874133004, 0.45892414036373147]\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4571549815778663\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:57:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.301600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.216700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.256700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.266800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.162900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.200400</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.223700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.199300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.223900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.200800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.233200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.242300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.224900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.190700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.257700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.168700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.260300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.311300</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.274900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.377400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.308600</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.305600</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.271200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.202600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.172400</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.208300</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.236100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.260700</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.188900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.222500</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.270100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.218600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.332400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.226800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.253500</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.224000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.303600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.182800</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.239100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.174500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.109400</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.207500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.162400</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.180600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.153600</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.128800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.177600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.176000</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.163600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.151900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.215600</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.157100</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.207400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.223100</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.221200</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.159100</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.176100</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.204300</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.154800</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.148400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.102000</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.209100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.156000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.170300</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.168600</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.135000</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.168300</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.232100</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.141700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.221000</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.122900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.163100</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.207100</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.209000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.155400</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.146800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.190400</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.143900</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.177300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.084900</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.099000</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.107700</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.108000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.095400</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.096200</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.083600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.086300</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.097800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.134900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.109200</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.109300</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.080700</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.094500</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.089800</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.112500</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.103400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.094900</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.119200</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.114800</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.138300</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.119500</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.088100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.093500</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.076100</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.116100</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.110100</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.124200</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.080700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.084500</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.095900</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.071200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.062900</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.058500</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.069800</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.047300</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.054200</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.034000</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.044000</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.078700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.069700</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.051200</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.052200</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.049800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.045100</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.046500</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.045300</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.092900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.057700</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.056200</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.047000</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.038100</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.057900</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.081700</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.046000</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.031100</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.037000</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.023700</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.041700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.028500</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.028000</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.020900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.026500</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.032000</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.029400</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.032000</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.026500</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.024500</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.029900</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.031400</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.041700</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.033000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46772557132338555\n","is min 0.46772557132338555 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4669624931944266\n","is min 0.4669624931944266 is smaller than [0.46772557132338555]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46699462075118003\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.92s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4726539741088957\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46547563477632975\n","is min 0.46547563477632975 is smaller than [0.46772557132338555, 0.4669624931944266, 0.46699462075118003, 0.4726539741088957]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46513662121585064\n","is min 0.46513662121585064 is smaller than [0.46772557132338555, 0.4669624931944266, 0.46699462075118003, 0.4726539741088957, 0.46547563477632975]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46840952769801414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4676862147383106\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4616589941425215\n","is min 0.4616589941425215 is smaller than [0.46772557132338555, 0.4669624931944266, 0.46699462075118003, 0.4726539741088957, 0.46547563477632975, 0.46513662121585064, 0.46840952769801414, 0.4676862147383106]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47028118752978104\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4647254150478402\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4741014749053451\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4720323123878044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47954694802959563\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.501158011366455\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4898665691672117\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47535622458910964\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5404335088517755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5710604367233983\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.590392467908541\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4639469362209928\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4838026571250158\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48577538265249537\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48994546402213085\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4876424598105341\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.531055685985943\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47331824393274335\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4658554053362297\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4714822489465321\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5172131401904029\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5716703008154564\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.630734603772546\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4736961519149057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4716553761455347\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4776313613074686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5135221545652218\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48167486038353136\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4875967155866302\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4870143811474466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46603900970175705\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46481147094287206\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4781719874745822\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47733423756887383\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47042486594464666\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5061452489521839\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48689339961884487\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5109949781033907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5015542100819649\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4723586173806982\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5069150052700496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5126718953113304\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5158548177955657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.488992287867636\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5911346012566948\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48001306559822\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4744041514248117\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.480023780269976\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4963171304774374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46667556622346895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4951615460337274\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47327065712880023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46329725730782956\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48029354710796374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4832925829209635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45963627246280303\n","is min 0.45963627246280303 is smaller than [0.46772557132338555, 0.4669624931944266, 0.46699462075118003, 0.4726539741088957, 0.46547563477632975, 0.46513662121585064, 0.46840952769801414, 0.4676862147383106, 0.4616589941425215, 0.47028118752978104, 0.4647254150478402, 0.4741014749053451, 0.4720323123878044, 0.47954694802959563, 0.501158011366455, 0.4898665691672117, 0.47535622458910964, 0.5404335088517755, 0.5710604367233983, 0.590392467908541, 0.4639469362209928, 0.4838026571250158, 0.48577538265249537, 0.48994546402213085, 0.4876424598105341, 0.531055685985943, 0.47331824393274335, 0.4658554053362297, 0.4714822489465321, 0.5172131401904029, 0.5716703008154564, 0.630734603772546, 0.4736961519149057, 0.4716553761455347, 0.4776313613074686, 0.5135221545652218, 0.48167486038353136, 0.4875967155866302, 0.4870143811474466, 0.46603900970175705, 0.46481147094287206, 0.4781719874745822, 0.47733423756887383, 0.47042486594464666, 0.5061452489521839, 0.48689339961884487, 0.5109949781033907, 0.5015542100819649, 0.4723586173806982, 0.5069150052700496, 0.5126718953113304, 0.5158548177955657, 0.488992287867636, 0.5911346012566948, 0.48001306559822, 0.4744041514248117, 0.480023780269976, 0.4963171304774374, 0.46667556622346895, 0.4951615460337274, 0.47327065712880023, 0.46329725730782956, 0.48029354710796374, 0.4832925829209635]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4742625241935811\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4720597396580993\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5000291287152328\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5058645723546448\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4655956529313828\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46360835818891183\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.471583470232227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5140392621792517\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4916925899924964\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46698027092000294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4724239554204779\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47468791318655257\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47218082419491036\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4778992082874413\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4698319015493203\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4911910737923565\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5107215155465392\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47566332828358154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4767121715160563\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47387925502729544\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46735710370593364\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5032699672664932\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48854059829279944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718605620429947\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4741856976584013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5149666711146373\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5117440525845577\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.471413167598282\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4712610334413884\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4687895240536748\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49705946399372564\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5346302192503914\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760622570939771\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5522610999842351\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5549031525168185\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49191339195183403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4874209344064217\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4880615169961142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4834835702696262\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4775923638804413\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.476292859166184\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5060269071491351\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4773990881170316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47589405444446153\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.488974482986057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4822445544662468\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4797887850751466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4805092036523615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4887356390156665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4870174241769286\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48172478577084\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47214522782149665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4733991037555355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4845957740755215\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47896470941488195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49568064108928045\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4829107427172082\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47955881142969087\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4725242609675216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4726023411610465\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47260611186843\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4752941640296675\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718588949772703\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48704231702635575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48473226449687296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47807794326353403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48454969850911794\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.526324870454723\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5354566171251615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4762297211929498\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4857103481907095\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4940567483960845\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4883571074978572\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4755896426956534\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48044730461332397\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4824797045085975\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4688625759349088\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4646519935308315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4749450717030991\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47152962718958485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4740397598801561\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4825200957532734\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5393790010445693\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5176043990463365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48517660619015557\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4768831639363372\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48729725940505153\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47205378965919\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47512445041689544\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47801574931085283\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48952923949312327\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48520064939868923\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48659747145476734\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47715161750151164\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4778224954934437\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47390618664533274\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4841637694779968\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4739594744224891\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5002025314243363\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4781641114192711\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47581554832766154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4732611365050174\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47860788072982424\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47873098146147963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469582174141141\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4722832600254532\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4693807445925944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47059205044255115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4786134666194615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5187337715515459\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48204881440686836\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47224835529803816\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47958655700313874\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48113113027714505\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4759353548406979\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46872722094798663\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47423076521816543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46361496279462805\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4766327514349993\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46301623871177805\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47106643478238414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4816569418795622\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4677668994162649\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4722608917834077\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4757567586755967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4660352522415626\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46644313962755607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4780805060281547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.470922701693442\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4795446143652315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48583198225439045\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47510816650569715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47510816650569715\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:56:59, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.194600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.164000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.291500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.264000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.142200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.205700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.226600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.198800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.258400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.198300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.205200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.279900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.221300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.252900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.232000</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.185900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.233300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.210100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.343400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.248900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.394800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.265500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.294500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.175900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.238900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.239800</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.232300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.188200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.205400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.212300</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.234700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.251700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.306800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.221500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.239600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.283900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.251500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.268600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.193100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.214000</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.157100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.166200</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.138300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.194400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.159700</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.184400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.160200</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.148600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.204500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.190900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.121000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.137600</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.181200</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.161500</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.169500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.185200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.189800</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.187400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.129700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.194200</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.151300</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.187900</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.204000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.199600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.150100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.127900</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.182400</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.228800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.193200</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.172500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.145600</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.163200</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.129300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.166300</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.203600</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.209600</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.184300</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.170600</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.102000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.082400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.127200</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.085700</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.070500</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.094100</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.082800</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.093100</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.099200</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.102800</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.121700</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.120600</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.112200</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.125300</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.090000</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.073000</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.072700</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.105100</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.098800</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.089200</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.099100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.105500</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.113000</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.100800</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.132300</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.120600</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.104900</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.113100</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.097300</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.098100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.152600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.067700</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.078900</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.095200</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.071700</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.079700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.087200</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.112700</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.130100</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.091000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.050000</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.054800</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.067500</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.056400</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.061400</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.041800</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.057500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.062000</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.080800</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.055000</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.055400</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.041200</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.058600</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.066600</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.049500</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.037300</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.043600</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.054500</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.028200</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.035800</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.026400</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.028900</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.036100</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.036900</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.023900</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.026200</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.033600</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.026400</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.037700</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.028300</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.030600</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.024500</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.028100</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.025700</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.031900</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.031000</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.035300</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.022000</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.024300</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.026000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47394701731484556\n","is min 0.47394701731484556 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47663739630729013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.473567375946616\n","is min 0.473567375946616 is smaller than [0.47394701731484556, 0.47663739630729013]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4742708828272259\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4731631515453141\n","is min 0.4731631515453141 is smaller than [0.47394701731484556, 0.47663739630729013, 0.473567375946616, 0.4742708828272259]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4682100723462658\n","is min 0.4682100723462658 is smaller than [0.47394701731484556, 0.47663739630729013, 0.473567375946616, 0.4742708828272259, 0.4731631515453141]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4648488782707591\n","is min 0.4648488782707591 is smaller than [0.47394701731484556, 0.47663739630729013, 0.473567375946616, 0.4742708828272259, 0.4731631515453141, 0.4682100723462658]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4748242970528586\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46365264196826206\n","is min 0.46365264196826206 is smaller than [0.47394701731484556, 0.47663739630729013, 0.473567375946616, 0.4742708828272259, 0.4731631515453141, 0.4682100723462658, 0.4648488782707591, 0.4748242970528586]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4875540228486686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.468222433997854\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4645818875140509\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4849870057860555\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4605526931675932\n","is min 0.4605526931675932 is smaller than [0.47394701731484556, 0.47663739630729013, 0.473567375946616, 0.4742708828272259, 0.4731631515453141, 0.4682100723462658, 0.4648488782707591, 0.4748242970528586, 0.46365264196826206, 0.4875540228486686, 0.468222433997854, 0.4645818875140509, 0.4849870057860555]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4605583687708687\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4763886978887055\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719773894053616\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4925484534793865\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.461006004876818\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5106584656446616\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.534559969875709\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5998553351536616\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4674399697766764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46710548803768487\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46881394840828833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48426924852360187\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5021740223235609\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47969688115507136\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5140473738965099\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5027255879363707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5071320295943572\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5111688821093615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46860491779316144\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49898171867686103\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5434966987337355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5011769197154305\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49835913496121104\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47220271016654763\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4701201384389645\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5049845731146981\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49109378560865136\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4961991765869481\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45834308123809653\n","is min 0.45834308123809653 is smaller than [0.47394701731484556, 0.47663739630729013, 0.473567375946616, 0.4742708828272259, 0.4731631515453141, 0.4682100723462658, 0.4648488782707591, 0.4748242970528586, 0.46365264196826206, 0.4875540228486686, 0.468222433997854, 0.4645818875140509, 0.4849870057860555, 0.4605526931675932, 0.4605583687708687, 0.4763886978887055, 0.4719773894053616, 0.4925484534793865, 0.461006004876818, 0.5106584656446616, 0.534559969875709, 0.5998553351536616, 0.4674399697766764, 0.46710548803768487, 0.46881394840828833, 0.48426924852360187, 0.5021740223235609, 0.47969688115507136, 0.5140473738965099, 0.5027255879363707, 0.5071320295943572, 0.5111688821093615, 0.46860491779316144, 0.49898171867686103, 0.5434966987337355, 0.5011769197154305, 0.49835913496121104, 0.47220271016654763, 0.4701201384389645, 0.5049845731146981, 0.49109378560865136, 0.4961991765869481]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46464974359805433\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4598176548654285\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45786724022370284\n","is min 0.45786724022370284 is smaller than [0.47394701731484556, 0.47663739630729013, 0.473567375946616, 0.4742708828272259, 0.4731631515453141, 0.4682100723462658, 0.4648488782707591, 0.4748242970528586, 0.46365264196826206, 0.4875540228486686, 0.468222433997854, 0.4645818875140509, 0.4849870057860555, 0.4605526931675932, 0.4605583687708687, 0.4763886978887055, 0.4719773894053616, 0.4925484534793865, 0.461006004876818, 0.5106584656446616, 0.534559969875709, 0.5998553351536616, 0.4674399697766764, 0.46710548803768487, 0.46881394840828833, 0.48426924852360187, 0.5021740223235609, 0.47969688115507136, 0.5140473738965099, 0.5027255879363707, 0.5071320295943572, 0.5111688821093615, 0.46860491779316144, 0.49898171867686103, 0.5434966987337355, 0.5011769197154305, 0.49835913496121104, 0.47220271016654763, 0.4701201384389645, 0.5049845731146981, 0.49109378560865136, 0.4961991765869481, 0.45834308123809653, 0.46464974359805433, 0.4598176548654285]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4683532183918728\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47314840284423715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47977340218555453\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5070041154441228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.515499318011553\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48545726084161595\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5495400529361738\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5214433888680373\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49473217304093087\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47582058309314945\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45875646096267436\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46845143302270453\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48715473999911857\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4647499016381496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46376891172263673\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46252570007700666\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49296781128700057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5336596016827425\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5450836845690088\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46727747188640273\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4581129148117783\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5184202228896049\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46817074433850836\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4841880636844105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4732952659740536\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4811707198762578\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5085669874279679\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5407961968702026\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47581753782822717\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47639775011058755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47800692665842986\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4648675191097453\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4878518592841345\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4747944669158882\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4649492336984091\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5106698252304358\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47149754205915007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48569053816373514\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46264217170152006\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4830770264067292\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46376797339269527\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5409967491661143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5258546000490785\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49179650407971615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5084392962025912\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4920414456903682\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4906394977049492\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46445232940113057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4587382519980571\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47490319502524175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47847308630785174\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4850074828395262\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4866379163307201\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45814410330579164\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5075496427343082\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49425331425229246\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4754171736943975\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48565920690927405\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47497927286886354\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5016065238693583\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46042216879810655\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49614123607890487\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46345078575082344\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46599784316402115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4619424121985212\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47901216810340547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4673663003559452\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48183392068235426\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4644854235601618\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.463646762478771\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48030547778216054\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48404145983499297\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4603386690688816\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4631574136386842\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46095418778120695\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46616782756634284\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46120394095649075\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46318815672129876\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46444342993964866\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4836722689143939\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46543191590441874\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48576041326503755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4665282611334919\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4845491740762212\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48838997070466916\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.486665259736041\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4683196771400803\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.467885282766843\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46544588616446114\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46697724747982167\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4848532562822778\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4807829957114003\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4697873728568774\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4727995099311963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4796551122849561\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760956841911876\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.475540134876556\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4848880257056374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47810323155109036\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46897271993490997\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4757205201854058\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47429795294879357\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4826435722820783\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48595710855564195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718440793593968\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4751832381778446\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48891344240554535\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47786873553232406\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4773401147624725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4742007517586069\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4950180584634778\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5063228683878802\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47440167414191925\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47302732270222686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47505557700472895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4709535238266651\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4894570592335267\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48268131329412023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4743474961145559\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4694915037328038\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48176081276241833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4776091979699689\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47617899563089044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4656529762060286\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46713485871985966\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4719150378899294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4670856687578114\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46757577026890024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4770724681656074\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689374943126306\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680564029908419\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46652353844775507\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4642293080199968\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4666108349864586\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46639280053991455\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4654495450272718\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.465747406958512\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4725746960362502\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4651166580068693\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47239388389296383\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47923993108113966\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4697207635397752\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4668770414040069\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4651858278906275\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47872907355648475\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4666622033740316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4638235047618977\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5103981584936974\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4773282492104533\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46874788500728776\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.467652426770882\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.467652426770882\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:57:57, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.161700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.205100</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.250200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.275400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.173900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.212700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.287700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.221400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.235900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.210800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.209300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.216600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.168500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.209700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.186400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.191300</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.180500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.227100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.237500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.248100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.169600</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.256100</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.238500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.222000</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.206500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.337400</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.221800</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.408700</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.242100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.268600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.176000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.325400</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.208800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.206300</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.360800</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.308700</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.246600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.179100</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.278300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.215900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.138800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.137400</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.163000</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.131200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.110200</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.217900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.172500</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.145700</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.166900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.225800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.193500</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.103700</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.161400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.249900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.238700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.256700</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.211600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.208000</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.154500</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.199300</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.147500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.131800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.151600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.137600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.209400</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.180200</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.204300</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.122800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.135700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.128100</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.276400</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.174900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.227500</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.199600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.160200</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.172200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.174200</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.162900</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.131400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.096300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.079200</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.087500</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.124000</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.112000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.162000</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.142200</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.156500</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.088300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.106300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.098000</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.065900</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.073200</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.120300</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.112900</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.149400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.198700</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.099000</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.133200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.091400</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.069100</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.090100</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.086700</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.090000</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.082900</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.094000</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.132100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.126600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.133900</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.170700</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.132600</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.139600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.125400</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.141500</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.123300</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.083800</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.076500</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.052700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.047400</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.087300</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.048700</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.064600</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.050600</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.069800</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.050600</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.066200</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.053100</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.069600</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.055600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.063000</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.053200</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.078400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.066500</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.062000</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.064200</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.063000</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.053200</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.039800</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.032400</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.057200</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.036600</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.023900</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.026300</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.046200</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.068700</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.030500</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.045500</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.025300</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.028200</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.045100</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.033500</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.044200</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.025700</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.034400</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.021300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4793946242127885\n","is min 0.4793946242127885 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4784799755081964\n","is min 0.4784799755081964 is smaller than [0.4793946242127885]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4813752453510355\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.91s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48591346331856033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4776562647685764\n","is min 0.4776562647685764 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47397494532200557\n","is min 0.47397494532200557 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4857200040431473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4752144488820081\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4730964863586089\n","is min 0.4730964863586089 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764, 0.47397494532200557, 0.4857200040431473, 0.4752144488820081]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47170900955269424\n","is min 0.47170900955269424 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764, 0.47397494532200557, 0.4857200040431473, 0.4752144488820081, 0.4730964863586089]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47297401667097244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47474755006602454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5156274669583365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4951894783011273\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48568442850342985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4953251640574451\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48425156884450077\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5014966425877673\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5127780123766422\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.533379982732982\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.490661578966823\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5073084131498325\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47808685313935906\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4790614999845661\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5303941312354904\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5061331305678736\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.565625729076615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5428017029618059\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5221295216628015\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5028894810633139\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46902149631807105\n","is min 0.46902149631807105 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764, 0.47397494532200557, 0.4857200040431473, 0.4752144488820081, 0.4730964863586089, 0.47170900955269424, 0.47297401667097244, 0.47474755006602454, 0.5156274669583365, 0.4951894783011273, 0.48568442850342985, 0.4953251640574451, 0.48425156884450077, 0.5014966425877673, 0.5127780123766422, 0.533379982732982, 0.490661578966823, 0.5073084131498325, 0.47808685313935906, 0.4790614999845661, 0.5303941312354904, 0.5061331305678736, 0.565625729076615, 0.5428017029618059, 0.5221295216628015, 0.5028894810633139]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4677628440828746\n","is min 0.4677628440828746 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764, 0.47397494532200557, 0.4857200040431473, 0.4752144488820081, 0.4730964863586089, 0.47170900955269424, 0.47297401667097244, 0.47474755006602454, 0.5156274669583365, 0.4951894783011273, 0.48568442850342985, 0.4953251640574451, 0.48425156884450077, 0.5014966425877673, 0.5127780123766422, 0.533379982732982, 0.490661578966823, 0.5073084131498325, 0.47808685313935906, 0.4790614999845661, 0.5303941312354904, 0.5061331305678736, 0.565625729076615, 0.5428017029618059, 0.5221295216628015, 0.5028894810633139, 0.46902149631807105]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49138701338986385\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48283420760046075\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5076554951025992\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5783315013724634\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4778319333810485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4640200940565012\n","is min 0.4640200940565012 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764, 0.47397494532200557, 0.4857200040431473, 0.4752144488820081, 0.4730964863586089, 0.47170900955269424, 0.47297401667097244, 0.47474755006602454, 0.5156274669583365, 0.4951894783011273, 0.48568442850342985, 0.4953251640574451, 0.48425156884450077, 0.5014966425877673, 0.5127780123766422, 0.533379982732982, 0.490661578966823, 0.5073084131498325, 0.47808685313935906, 0.4790614999845661, 0.5303941312354904, 0.5061331305678736, 0.565625729076615, 0.5428017029618059, 0.5221295216628015, 0.5028894810633139, 0.46902149631807105, 0.4677628440828746, 0.49138701338986385, 0.48283420760046075, 0.5076554951025992, 0.5783315013724634, 0.4778319333810485]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4743831250998948\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4968794047045959\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5062700199467421\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.505703591308366\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5062098533015653\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46702204130768327\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5164177127814831\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4641594995535471\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47332893411995824\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48033397812344314\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4707300167919899\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4647964699620647\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4660275678478602\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45774991474471977\n","is min 0.45774991474471977 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764, 0.47397494532200557, 0.4857200040431473, 0.4752144488820081, 0.4730964863586089, 0.47170900955269424, 0.47297401667097244, 0.47474755006602454, 0.5156274669583365, 0.4951894783011273, 0.48568442850342985, 0.4953251640574451, 0.48425156884450077, 0.5014966425877673, 0.5127780123766422, 0.533379982732982, 0.490661578966823, 0.5073084131498325, 0.47808685313935906, 0.4790614999845661, 0.5303941312354904, 0.5061331305678736, 0.565625729076615, 0.5428017029618059, 0.5221295216628015, 0.5028894810633139, 0.46902149631807105, 0.4677628440828746, 0.49138701338986385, 0.48283420760046075, 0.5076554951025992, 0.5783315013724634, 0.4778319333810485, 0.4640200940565012, 0.4743831250998948, 0.4968794047045959, 0.5062700199467421, 0.505703591308366, 0.5062098533015653, 0.46702204130768327, 0.5164177127814831, 0.4641594995535471, 0.47332893411995824, 0.48033397812344314, 0.4707300167919899, 0.4647964699620647, 0.4660275678478602]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.517585530255299\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4695390779560754\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4587228403088881\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4593512108598729\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4676686097708323\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46708786601510377\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4703971841349829\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46685447704591676\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4668781171471214\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45631278493294386\n","is min 0.45631278493294386 is smaller than [0.4793946242127885, 0.4784799755081964, 0.4813752453510355, 0.48591346331856033, 0.4776562647685764, 0.47397494532200557, 0.4857200040431473, 0.4752144488820081, 0.4730964863586089, 0.47170900955269424, 0.47297401667097244, 0.47474755006602454, 0.5156274669583365, 0.4951894783011273, 0.48568442850342985, 0.4953251640574451, 0.48425156884450077, 0.5014966425877673, 0.5127780123766422, 0.533379982732982, 0.490661578966823, 0.5073084131498325, 0.47808685313935906, 0.4790614999845661, 0.5303941312354904, 0.5061331305678736, 0.565625729076615, 0.5428017029618059, 0.5221295216628015, 0.5028894810633139, 0.46902149631807105, 0.4677628440828746, 0.49138701338986385, 0.48283420760046075, 0.5076554951025992, 0.5783315013724634, 0.4778319333810485, 0.4640200940565012, 0.4743831250998948, 0.4968794047045959, 0.5062700199467421, 0.505703591308366, 0.5062098533015653, 0.46702204130768327, 0.5164177127814831, 0.4641594995535471, 0.47332893411995824, 0.48033397812344314, 0.4707300167919899, 0.4647964699620647, 0.4660275678478602, 0.45774991474471977, 0.517585530255299, 0.4695390779560754, 0.4587228403088881, 0.4593512108598729, 0.4676686097708323, 0.46708786601510377, 0.4703971841349829, 0.46685447704591676, 0.4668781171471214]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4577746577839123\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48626040172720186\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5726938756570525\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262347510379529\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48630160650019205\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47344366900581886\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4750629373049224\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4709188301960966\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.495871104385241\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48674391856398846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46921431869327906\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48856609202593754\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47851461389807926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45716087063877786\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46528376347384426\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46447678371320766\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4584639234569276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4625781691490168\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4827293780155186\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4897552226973585\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4906941388159218\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5460945920263808\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5063025754480135\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4956472444702477\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686105062607853\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4970428051872686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5106117662923725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46589277314880206\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47575716664155\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46423706664477016\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46490297594350216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48538074328665254\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47977273714069896\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4669540747923139\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.474365557953351\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48686901680807726\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46561083754521265\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.467544894777893\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.470925095875494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4871112329242348\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4842748498346942\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48617964078482695\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47175584070655413\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4773025380543973\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48312673432645764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4669407836468938\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5357269701551985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5668473175376754\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49998871988576193\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5114243122398203\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49093835619652537\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4757890052314427\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5714631019437337\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47372360188950385\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46797245513073643\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4971202296837316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4695394245533145\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48196517633317554\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47395887487898086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.485766917424067\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4659824821157736\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4717998562350764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4607053066325933\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718759732147203\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46228252323155344\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46182751535530064\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.465629288859689\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49946684775067524\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.464884563628712\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47464566089181526\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48317189513274394\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4816360734274773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779124511612543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4800797494612611\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49037697324296275\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4730788640359154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4804429617791638\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4761845297152967\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49214198936433456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4702978671249498\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4783135037464778\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48598936780683055\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47452472899274306\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47067439139007083\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47979155017943875\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4742405658442862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4714723560786987\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48856172157793115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49070665406826536\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47772370208072007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47175900388133946\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4752415460275538\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4881237969646958\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4788875444366322\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4734916547533902\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4745280124183402\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48530824121065225\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4620383944567393\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4591941890347906\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4767864460874633\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46116611600148566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4606680674786961\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46623600424785\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48016013236290983\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5061985889489602\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4620217312067996\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.460883906535296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4657113481968593\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4631733041746272\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4770629506562866\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4989619316430057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47095940108013773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4870551010752449\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4864413933539604\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46958425187507963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4698220661374251\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46874267679421844\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4736941241153804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4713513768204467\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4765310624938787\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47919355885163495\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46871002163139164\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47481087199451383\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4703154028045161\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4742042448679164\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4774328539568602\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.476033784885893\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48206190941474186\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47118500090394827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4796118565077247\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48091824126492516\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4720607128419204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48002229211329145\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47355271701849916\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4694083402554294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4694083402554294\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 3:57:08, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.225000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.169800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.183300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.173900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.238300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.193800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.193100</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.276800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.235000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.215400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.260500</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.289400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.193300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.249400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.209500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.266600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.300100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.281100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.233400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.213700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.227300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.286400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.200100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.210300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.246700</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.222300</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.290900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.225500</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.324700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.175300</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.309500</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.250900</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.205900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.283200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.208900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.313200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.271800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.214500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.177600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.220200</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.205100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.183700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.142300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.181500</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.237000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.135700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.124900</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.128900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.216100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.252700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.142100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.208800</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.172000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.196800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.172100</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.187000</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.125300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.279400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.201200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.131100</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.211600</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.135800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.217400</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.156100</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.141100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.199000</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.157200</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.243600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.193700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.141100</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.183900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.128100</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.214400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.194900</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.159700</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.196500</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.178500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.171600</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.269400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.092900</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.098500</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.090500</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.122000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.079300</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.099900</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.073300</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.088500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.085300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.178300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.084400</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.096500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.130300</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.112200</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.096200</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.107600</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.086900</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.108800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.093300</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.118600</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.095100</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.075300</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.137200</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.060600</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.082200</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.118100</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.071600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.082800</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.099500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.101600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.103600</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.067700</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.123000</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.120200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.091500</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.054600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.061200</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.048400</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.065400</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.049700</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.060200</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.049000</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.041900</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.056200</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.046500</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.060100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.072300</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.040700</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.058600</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.043600</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.038400</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.031200</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.031400</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.036000</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.045300</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.061900</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.023300</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.017900</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.021000</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.028500</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.037300</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.022500</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.028100</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.027000</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.028200</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.035500</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.027500</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.032800</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.037800</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.025000</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.022700</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.020600</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.035000</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.026400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44470065970308037\n","is min 0.44470065970308037 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4443562877111386\n","is min 0.4443562877111386 is smaller than [0.44470065970308037]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4451523870206116\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44552451610906235\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4428221175916514\n","is min 0.4428221175916514 is smaller than [0.44470065970308037, 0.4443562877111386, 0.4451523870206116, 0.44552451610906235]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44736475580389706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4421244774713952\n","is min 0.4421244774713952 is smaller than [0.44470065970308037, 0.4443562877111386, 0.4451523870206116, 0.44552451610906235, 0.4428221175916514, 0.44736475580389706]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4759602729916607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.90s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4506762600016289\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4394043244403372\n","is min 0.4394043244403372 is smaller than [0.44470065970308037, 0.4443562877111386, 0.4451523870206116, 0.44552451610906235, 0.4428221175916514, 0.44736475580389706, 0.4421244774713952, 0.4759602729916607, 0.4506762600016289]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.440565541799472\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4677958951748102\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44200382818140715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4736164938272048\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4746752242018957\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47977038270589345\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5992473538359604\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5030509213803428\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5187846021031836\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44029158220252584\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44095511263588083\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4669923452426022\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4474207047531096\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4464297166685266\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44173999883043663\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4709141231138517\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45082385923323803\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49199741793701535\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4487246163484511\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45402534291458546\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.502952016657769\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5204729970477305\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5373112773486541\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44396812674732905\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46245385254868526\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4541191510263336\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44800791288647007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44701444201191315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.539302626339762\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4758592737096633\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5021250417540151\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45951401941939446\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46305934230520623\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47919236070054105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.489505715026947\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4642709379984974\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4751596545269229\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4851953695590142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44653967004663503\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4604415238058434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4485128874078194\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4413842586319322\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44567269367255236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4427504339809837\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4610700129306724\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45130535563156177\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4799517511230595\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45626878486901445\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4625820930086132\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4508231520215247\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45894981528135964\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4429220910685026\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4920453406701007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44766047072379744\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4461913181296784\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45397380535716736\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4887658573590922\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5150744411727143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.524122428861971\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4624903066099232\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44437309189609375\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44443033978614815\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.448449112874916\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44808156877465594\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44497119405298063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4586092478139462\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46806975632611\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.462618681478768\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47857862242503707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4753607690491789\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4419589876256378\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46834357300922724\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4701800094017531\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5138508412681475\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4578988563031594\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4524702829334752\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4575636321426861\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4905866610552869\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49084032416693485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47435441253867083\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4642439850143603\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4607127759302239\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48726308292113624\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5430874640666784\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689327041213356\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4491415481112096\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4645478829218827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4623238117969237\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49711969106781334\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4808056739311589\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.89s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48563897563694336\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45902756161380265\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48908421180867734\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4724758252385773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45693998376220174\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.484019078025748\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46389210834070327\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4589780561634292\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4466401731361367\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44869172360748494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4550526129624779\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4522716112007061\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45804761031028174\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4684206699779453\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5096314666646965\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779220202539377\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4746903680188521\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46499426702969515\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4557477973657959\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4578850595045426\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45578559489006193\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.448378976857265\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49442807502585456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46473885010899657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4443254258211852\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4584826831916981\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4567096079689747\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44920011051885705\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4490138387115692\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45968468141040547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44767427716743685\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45063490727731204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4494695580727132\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4488697535947364\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44939903403376186\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.448423539312434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45903904361036596\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45238368289730013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4516648705086561\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.457162140990014\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46934025312676986\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46800303595753395\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4642991799158844\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4620693939923052\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4593270320031395\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46030973019541804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4528525202319089\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46061623302783256\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47362419553781215\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46429616089463993\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4649315706342259\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45991398654279186\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4608201995673143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4573069549950381\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760761556449294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49120797740917593\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4728955742913127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45364558751304007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46604491166669176\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45555304101347033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44832181763304646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45519722859668926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4670999789008692\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4873263603591691\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48069716654019506\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4874323375800285\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779285496024655\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4584453219688684\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4600613736259702\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4639448867930121\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4669945298289953\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46608320868660846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4577240405162462\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4582823765927446\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45899760280259166\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45795331253198407\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4525012235310143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45263150062654706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46758200485148477\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4573068870175123\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4652372447715301\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47326023487182184\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46576302429387373\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4553093951479414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4604388513528695\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47020259666031056\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664877232018264\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4546984375823749\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4535068253249872\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45691736938491345\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4479795466765405\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.452601357265076\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4600254338864399\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46122847220786356\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.87s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4464091920235002\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46044736911062817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46339441532776\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:58,  3.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46339441532776\n","Training done\n"]}],"source":["# albert 2\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 7e-6,\n","  'weight_decay': 0.07,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ALBERT_TRAINED_2\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":21564,"status":"ok","timestamp":1628357046530,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"m2iQGSPFe7pW","outputId":"da793891-b87d-434b-a7ea-b1d188e38ef3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1892' max='1892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1892/1892 43:29, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>600</td>\n","      <td>0.230100</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.138200</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.070500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training done\n"]}],"source":["# albert 3\n","# albert 3 is special it is trained on all training data without evaluation.\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 600,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","train_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/original/train.csv'))\n","train_tx = [str(t) for t in train_df.excerpt.values]\n","train_sc = [float(t) for t in train_df.target.values]\n","\n","out_dir = ALBERT_TRAINED_3\n","\n","\n","train_model(\n","   model_dir=model_name,\n","   out_dir=out_dir,\n","   data=train_tx,\n","   data_labels=train_sc,\n","   hyperparams=hyperparams,\n","   cfg=cfg\n",")\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"QnKSaQWGpAUa"},"outputs":[],"source":["# Training the deberta models\n","DEBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/deberta-large-augmented')"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"HXYFgmVApREy"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:04, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.309600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.283600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.191800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.237300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.294900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.313900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.219700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.228100</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.190800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.232100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.198300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.166400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.256500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.253500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.179100</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.262600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.179400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.253000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.241600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.275300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.183500</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.248800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.257200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.235800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.206900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.305900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.252900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.251100</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.255900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.239800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.269800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.275900</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.236200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.206200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.379400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.214300</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.298400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.258300</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.222500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.170500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.228700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.212700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.170300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.088200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.101900</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.165900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.191100</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.126300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.209500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.224900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.165100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.164000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.145400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.183400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.143100</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.122600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.153600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.183200</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.174900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.194500</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.182600</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.181800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.159900</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.128400</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.188700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.104700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.175800</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.180800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.187900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.163800</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.143200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.119500</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.171500</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.175600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.098300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.159700</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.090100</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.132900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.112400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.069800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.096800</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.118000</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.093000</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.079300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.083300</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.132500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.072900</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.060300</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.086600</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.093400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.086700</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.086200</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.074800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.056600</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.062400</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.085300</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.100700</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.076500</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.096100</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.116500</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.077500</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.076000</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.078400</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.074000</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.085700</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.101600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.087200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.075100</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.060000</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.121500</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.063400</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.088600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.065400</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.050400</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.044500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.041700</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.059600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.053500</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.036400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.061400</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.060300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.043200</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.059700</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.034600</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.038200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:09,  1.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47703367801001606\n","is min 0.47703367801001606 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5221506696716361\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5718476142883364\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6419265441496605\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6166129692249498\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5326910989028727\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5430578059876134\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5656817409589315\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5150571290655229\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5815989660896447\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5347773067877941\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5012151673618328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6415596664212037\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4831880855762377\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.573754708561215\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5351158291701841\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47652441401928103\n","is min 0.47652441401928103 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5016489952758868\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49404834863176456\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6507922914811309\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5029510398662091\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4817692577987704\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5884172010959134\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5753264107003344\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4764310233551438\n","is min 0.4764310233551438 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6380925393345241\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5180056921910857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5040179088145673\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4717742390362436\n","is min 0.4717742390362436 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344, 0.4764310233551438, 0.6380925393345241, 0.5180056921910857, 0.5040179088145673]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5569355006687203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6593605611021843\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5045907251531082\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8236392277495207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779587009905688\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7353612737646396\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5148292314117991\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6648950589255433\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4725447033413721\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.557874436218457\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5061406819841241\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5951724728952308\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47155683071945526\n","is min 0.47155683071945526 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344, 0.4764310233551438, 0.6380925393345241, 0.5180056921910857, 0.5040179088145673, 0.4717742390362436, 0.5569355006687203, 0.6593605611021843, 0.5045907251531082, 0.8236392277495207, 0.4779587009905688, 0.7353612737646396, 0.5148292314117991, 0.6648950589255433, 0.4725447033413721, 0.557874436218457, 0.5061406819841241, 0.5951724728952308]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5930435525195703\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5089193600268562\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5761309321169713\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5224321631883367\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5968938119525932\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46804638704355506\n","is min 0.46804638704355506 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344, 0.4764310233551438, 0.6380925393345241, 0.5180056921910857, 0.5040179088145673, 0.4717742390362436, 0.5569355006687203, 0.6593605611021843, 0.5045907251531082, 0.8236392277495207, 0.4779587009905688, 0.7353612737646396, 0.5148292314117991, 0.6648950589255433, 0.4725447033413721, 0.557874436218457, 0.5061406819841241, 0.5951724728952308, 0.47155683071945526, 0.5930435525195703, 0.5089193600268562, 0.5761309321169713, 0.5224321631883367, 0.5968938119525932]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7453988639775931\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4691394899258918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.679801744591401\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362558713283687\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5802365520335829\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5020308579075499\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6426111365921265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5396927012792163\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5470416931213515\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579438258900236\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5709270101661293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49494011280418915\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5466867277518042\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5881087546007047\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5269512135225746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5581269148823998\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5414285669482821\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5372871319272573\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6862310661924542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5318939744851962\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5532583739722806\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5630463871826742\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6232809763095079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5375853819340598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.530565453813205\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6160095070240592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5394420816270895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5414822739609443\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5242688911163156\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5443419541127834\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6828392176860659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4998431459606332\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5338755611839251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6422497739343693\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5517647313748648\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689763768144568\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6281335404558498\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5737914733186674\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5603309941576761\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362848924513425\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5716035163198269\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6651077084340784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.512295815325008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5733000204549534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327602947170454\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5685657220221865\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6095086926111724\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6277854741114055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5129538929644024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5809242914577333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5431719701047886\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5535497247839285\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5339983184469523\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.65578572888162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5231561103463475\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5652360941663727\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5193087587764121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6328747119264554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5638012366085483\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5784397124890265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.593692753105692\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5671328932557911\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5056760727923532\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6177536623322608\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5170260800447141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5694686971380368\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5661820800798948\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5007135294316831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6646445884273944\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5150136278527121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5701978123166815\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6063318088527985\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5814675884562527\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5648089227144053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5643418048344861\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6064759777773288\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5618868075234085\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5476825586511775\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5808053690693121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5517903632678235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.523372609967995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5938355907827831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5616149231516502\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5368710559055542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6058465058960971\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5133460959453876\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5529807581981707\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5655897759716327\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5433915176709639\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5954302456998195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5368292198375011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5892022443867176\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5727246768464208\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5174877543336114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6068093620842527\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5578784558330329\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5665567139192612\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5615202144862046\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5621921783113997\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5271811834107533\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5430258322258779\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.553785552588941\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5365164411130097\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5585522756967048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5470285361838741\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5981448670435362\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5193757563451824\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5529271799133848\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6043110776578204\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5114352477510816\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:32, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.231200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.250500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.149600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.212300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.293000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.265700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.258000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.178700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.262100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.210100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.218200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.311000</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.307900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.248000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.282300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.251900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.180500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.218100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.209400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.268800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.260900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.272100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.227800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.235500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.288200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.212100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.251900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.231900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.340000</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.243800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.346500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.192200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.252700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.251300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.141200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.242600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.267900</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.285200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.216100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.230600</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.174500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.191700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.176200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.142800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.215500</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.112200</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.125600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.138400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.234600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.171200</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.102000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.200800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.172900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.133600</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.158500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.197200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.196700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.176700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.207200</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.208400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.139000</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.224500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.234900</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.191100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.168500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.229700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.162900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.111000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.200900</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.182200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.102900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.192800</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.167600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.111800</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.124800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.178300</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.108000</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.149400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.083400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.089700</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.094900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.099200</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.076700</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.058700</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.114900</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.081400</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.119400</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.112900</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.090500</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.087800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.098400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.076200</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.098800</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.096400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.092100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.074900</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.115600</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.113700</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.077200</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.059100</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.114700</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.096500</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.082500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.086000</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.107700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.124800</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.111100</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.087800</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.073000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.066000</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.060400</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.033000</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.047300</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.080400</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.032000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.074500</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.089100</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.077500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.055700</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.043000</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.043600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.052700</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.031200</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.039200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779189142115054\n","is min 0.4779189142115054 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5078425572813257\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.553386152041744\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5920353677214419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4916489285023035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.498862157755009\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5719067732936266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5257007517324956\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5577176616797201\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5322195297824196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49327249593616035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5241554717604623\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5379911169079183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6699807609393124\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4794605517040894\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6475966580053409\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5019959362300873\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4749109066539285\n","is min 0.4749109066539285 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5423986219532434\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.474580201839206\n","is min 0.474580201839206 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7255309027543988\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4685621200883598\n","is min 0.4685621200883598 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434, 0.474580201839206, 0.7255309027543988]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5455682361445073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5194289017321368\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5130006391669236\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5576259613702758\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5582287076055473\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47936017095351907\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6055120342138925\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5456576983087031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5169296879354051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4652793814580609\n","is min 0.4652793814580609 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434, 0.474580201839206, 0.7255309027543988, 0.4685621200883598, 0.5455682361445073, 0.5194289017321368, 0.5130006391669236, 0.5576259613702758, 0.5582287076055473, 0.47936017095351907, 0.6055120342138925, 0.5456576983087031, 0.5169296879354051]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5230697756565715\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5241675863013191\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5455541279795989\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5206055006999931\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5722734566130102\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5141795628488773\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6480964929333759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4830989709491082\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6059356434627031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49691584896230273\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5694222068215262\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5709800530925823\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362996050229508\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.520797450487917\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5128396427574151\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5365154943259912\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4959396493175762\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664682378251304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5757590803688307\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4826815658788871\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6212309540483844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4884502147966541\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6628725811145003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48754279072924783\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6579478220929482\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5058323258322253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6258678949783816\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5009611044888808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5468364597761148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6231195594746775\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.488930434304781\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5494189279174589\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5502206757522247\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6251688141646902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46621786305169244\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.630925279145884\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5227015576472264\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.640445023238784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4945754957917079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7414215115908128\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46968437233388305\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6071009918709347\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5178351629224457\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46410988326144326\n","is min 0.46410988326144326 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434, 0.474580201839206, 0.7255309027543988, 0.4685621200883598, 0.5455682361445073, 0.5194289017321368, 0.5130006391669236, 0.5576259613702758, 0.5582287076055473, 0.47936017095351907, 0.6055120342138925, 0.5456576983087031, 0.5169296879354051, 0.4652793814580609, 0.5230697756565715, 0.5241675863013191, 0.5455541279795989, 0.5206055006999931, 0.5722734566130102, 0.5141795628488773, 0.6480964929333759, 0.4830989709491082, 0.6059356434627031, 0.49691584896230273, 0.5694222068215262, 0.5709800530925823, 0.5362996050229508, 0.520797450487917, 0.5128396427574151, 0.5365154943259912, 0.4959396493175762, 0.4664682378251304, 0.5757590803688307, 0.4826815658788871, 0.6212309540483844, 0.4884502147966541, 0.6628725811145003, 0.48754279072924783, 0.6579478220929482, 0.5058323258322253, 0.6258678949783816, 0.5009611044888808, 0.5468364597761148, 0.6231195594746775, 0.488930434304781, 0.5494189279174589, 0.5502206757522247, 0.6251688141646902, 0.46621786305169244, 0.630925279145884, 0.5227015576472264, 0.640445023238784, 0.4945754957917079, 0.7414215115908128, 0.46968437233388305, 0.6071009918709347, 0.5178351629224457]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5546390562364023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5359136650283193\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5039022561355481\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.502077094170129\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5668251470232049\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5153162526925182\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49281436844705584\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5509129382526858\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5715530450142052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5802916313717328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5358364206865761\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6337576399139738\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5479519095490102\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5130221704591326\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6088081585847022\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5123259665071217\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5756517744598628\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5794441845043234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5337250804990521\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6053442664226699\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.496557686827873\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5868315659568863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5872344994094415\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4914313644625566\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6320631087662177\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5137643803706039\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6485577538581658\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4769672412156923\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5881123054927584\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6115116452545251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5406242082782831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5564179067405235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49849047591392814\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5421631710713625\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6159972568850012\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.496248564223014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6597055089234516\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4840178655735573\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6888549548969547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5123346161234134\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6121070372270002\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5356749817038148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5285640172445434\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5930204312398052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5447187642659863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.482252023758197\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5375252495672748\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.561744786244394\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5610433880650918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5192668668942432\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5522927492295379\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5740891867873107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5075299796480847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5147202168276245\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.601477794279395\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5510716238214055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49978456973784746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5631518868907385\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5145920357366808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5799510468518355\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5391334457591738\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5587705446330001\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5413187294871035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5073798122950983\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.59603486044167\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948355950579042\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48940474513911025\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6380535794183867\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.510408849528039\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.527301115868737\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5535149933184556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5212378309512435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5343256638691117\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5063830556814892\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5588043810322043\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5463276764368382\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5627971477345166\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.552914988358854\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5405408022405219\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462523296635715\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5076969836219132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5124533041809607\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 49:34, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.366000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.226500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.217600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.250700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.160700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.190800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.230200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.262900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.275300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.208500</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.266100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.246300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.288000</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.199100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.298800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.172100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.249500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.290500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.339400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.384200</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.309200</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.223200</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.333400</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.230600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.197500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.240000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.221600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.227400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.209100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.175300</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.253300</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.301600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.262800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.244900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.310400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.209800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.224500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.243900</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.192900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.180300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.106400</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.181300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.177400</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.144600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.146300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.163400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.114300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.131200</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.175400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.178400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.188200</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.136200</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.160300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.172400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.196500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.177200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.123700</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.195200</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.151100</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.159500</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.106700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.146100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.146300</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.137200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.185500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.152600</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.145700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.201800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.140400</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.186800</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.127100</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.137500</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.156000</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.195900</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.101300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.153000</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.202300</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.111500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.148200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.088100</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.072000</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.077700</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.102400</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.103600</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.069600</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.075600</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.108900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.054600</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.101100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.095300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.084500</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.084700</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.071400</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.097200</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.077900</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.079100</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.096100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.074400</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.105300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.062800</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.123500</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.090100</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.078200</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.076400</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.066700</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.079600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.065000</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.068700</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.077500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.114300</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.120200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.083700</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.102200</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.056700</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.068000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.060600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.081100</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.035700</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.033500</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.073100</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.036900</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.033600</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.043900</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.063900</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.046100</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.038400</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.037300</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.046200</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.038100</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.038400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.054200</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.048000</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.058800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.058300</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.050200</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.048700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4650006683971817\n","is min 0.4650006683971817 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49651300860663167\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5407970034269476\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4793737146096411\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5065065872997937\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5321520791485906\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.451150213009954\n","is min 0.451150213009954 is smaller than [0.4650006683971817, 0.49651300860663167, 0.5407970034269476, 0.4793737146096411, 0.5065065872997937, 0.5321520791485906]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6434646692140309\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48442639881435445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5861235670743571\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4945953747085839\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5398765290128986\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5485498461775293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5557489368604402\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5880422731150581\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5742388462849964\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5453868345580871\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48074546182006356\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.745473913253412\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5268233709128507\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.543348203697279\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5506134008870143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6130579734006555\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4704657277326491\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6458689246652712\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4768510341301204\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5077407186953385\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5761686650055771\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5740120955520963\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5185010002884783\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6683007563584203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5078875146908934\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4818437952013084\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6977586438844416\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5037706484424078\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4809009498461975\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5446747960242451\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.679882745535031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5001722232267624\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5734747908329548\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5285237401265803\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5177603874080564\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5497081989408745\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6609415622020235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46594504597410336\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5907818857309478\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49748165988237547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6887351174969892\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5314402107412968\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46993652177249473\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6947684655808237\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5005021903398726\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6089342425315426\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5289920646701343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4819464221498222\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.673253692788403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4624207854850339\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6175392809863293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4630147089589299\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6272131994553647\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5466462581400896\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5010065889726871\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49307049148802107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5053085251378607\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5249015121780986\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5880635652362342\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5036987540036537\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5577362402072225\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6379033283367226\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4783147680821158\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5914691780010617\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5404561410469162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.685679632118907\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.506454576685727\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5844050143565311\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5168892946016778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5616799495596514\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5103037521906675\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5168962642985848\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5332918982512902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5307855555339182\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6568632207700758\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5353419720837232\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5477612952968538\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.598117692376796\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4812595733422895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6118760299520879\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5301377802736154\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5781668270212553\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6357488434509181\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4841401345830624\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5166753646136392\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5985778444132629\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.549198849825067\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5089348129944903\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6274461280165288\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4652292549730833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5326497910934637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4845036059930727\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6677809608615745\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6008617437318484\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5045714207647569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5903994260673356\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.63297559569905\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4850882763400504\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6192943194274627\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5101939809704833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5317108696229487\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6512458599804328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5871908809621482\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5945549469926467\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6769387164169636\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5321188287318862\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6297826021146221\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.509474624932908\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5374884957519291\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5555074375830595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5601393615870662\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4816247594067262\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5864802013446858\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5028534823792803\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5181172575694196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5661664264843949\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5371069804177668\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5195235236382725\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5629295631466679\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4947743632108875\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6202854208436506\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5830313953792648\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48684005699039956\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5916963440015411\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5813026396381995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5184093482882066\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5992736576896424\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.511366813191643\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6169731200358927\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5731258125544739\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5974417860616048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5394037047643558\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5718092084395812\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5455094919262079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5196630331736912\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5638428945542504\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5650210675444797\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5782818698344943\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5526467987553217\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4909081269089915\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5512524189234651\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5223007490477496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6128220169982381\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5554653694416959\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5478851968154319\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5719844371598608\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.511601934638705\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5310103348149724\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5866677349962194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5347581027600584\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5806090354968114\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 49:45, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.232700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.131800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.277000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.262000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.159500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.232900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.173300</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.253600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.239000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.211400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.235700</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.291500</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.202200</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.231700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.160300</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.256100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.283900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.368800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.249700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.440400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.274000</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.324200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.220100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.246900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.217600</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.224800</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.202100</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.184600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.227900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.221700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.311400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.194100</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.279000</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.227300</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.336100</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.308600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.195900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.239500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.134800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.130800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.121900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.151800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.118700</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.183800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.156000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.157300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.203900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.161900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.135300</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.168500</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.142400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.143700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.137800</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.158100</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.230300</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.170700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.172200</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.193700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.148200</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.163800</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.138600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.129700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.104300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.179200</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.197700</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.139500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.121200</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.160600</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.130900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.099400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.204000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.191300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.205100</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.199700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.128700</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.116100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.094800</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.142600</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.088700</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.059900</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.080500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.066900</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.061300</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.087300</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.099000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.095200</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.108300</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.098900</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.078700</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.069800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.101000</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.114000</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.073100</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.097600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.086900</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.066300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.075500</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.096200</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.108200</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.093700</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.091600</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.094100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.083400</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.075500</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.072800</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.097800</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.088100</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.082100</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.113800</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.092500</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.058600</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.034000</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.046100</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.046100</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.046200</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.037800</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.067600</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.034800</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.051200</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.068500</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.039700</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.035000</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.043300</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.067500</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.043000</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.047900</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.052000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.052200</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.067900</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.032500</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.048900</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.039400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718647163905857\n","is min 0.4718647163905857 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814570939485718\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5141067593290214\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5112332348926591\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4857508137811437\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5111905902470965\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5155448052474135\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4854159040339859\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362944646410911\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49434147476659857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5529476800915253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4899394141796793\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5290228230260813\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4648130718316481\n","is min 0.4648130718316481 is smaller than [0.4718647163905857, 0.4814570939485718, 0.5141067593290214, 0.5112332348926591, 0.4857508137811437, 0.5111905902470965, 0.5155448052474135, 0.4854159040339859, 0.5362944646410911, 0.49434147476659857, 0.5529476800915253, 0.4899394141796793, 0.5290228230260813]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5125316182621136\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.466853401832799\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4806434904024772\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4744069950000827\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5725469729345906\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45061834852200333\n","is min 0.45061834852200333 is smaller than [0.4718647163905857, 0.4814570939485718, 0.5141067593290214, 0.5112332348926591, 0.4857508137811437, 0.5111905902470965, 0.5155448052474135, 0.4854159040339859, 0.5362944646410911, 0.49434147476659857, 0.5529476800915253, 0.4899394141796793, 0.5290228230260813, 0.4648130718316481, 0.5125316182621136, 0.466853401832799, 0.4806434904024772, 0.4744069950000827, 0.5725469729345906]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7065706922375368\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948910887928536\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5254272820524578\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5434007554414304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5185317544762277\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5486032758357996\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5225150924240731\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5424266457391813\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5622526377275081\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5318327800502073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5071867621982462\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4933823828196185\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5285015743379359\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.515529706528356\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5937731680071906\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4678632386335289\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6039736413939387\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814646025042345\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5351514715429959\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48238585047896726\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5167037471271336\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5240684730614512\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5232103668481393\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4903604172166523\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5430523444824769\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5212245388461753\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5218347218129991\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4862978156841008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.516877609700136\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5806621885671328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5195780237344019\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5094816544387749\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5790398129226717\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.497474802565163\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5511803489203655\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49058763917941994\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6208709226996436\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47447841376611016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5207826237652752\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327109464657231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5196828534123407\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4797947182251807\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48320768428223554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46776828249559044\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5789501499205174\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.515045178110902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5384516297621429\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.466337717849009\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5627844384003922\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48509053002746894\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5281131227454278\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5454458425624451\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6264944677697685\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45878054557317827\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6120196053027401\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4508077401313153\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5033767297489194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5423962910697816\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46512042604220294\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5419620423767647\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.550591815835427\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49812113616079146\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5055400739657923\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5041556517381959\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5441328705363965\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48193202517339734\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5079866220730662\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6284386430045182\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4579898739438861\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6255044295396893\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45565588525207656\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5526547228973807\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5176844542080371\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.521650994419212\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4794598259039148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5750365010094113\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5058635410180911\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.537303866791547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5214196924355393\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.484617712730345\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.481096398401489\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.531152016075542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5084635314193339\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4988444513112958\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5706336325788101\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45888120128491994\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5590460220158406\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6100686311068483\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.556526891219614\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6094127162201668\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.465898559935206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5099970313527111\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48926395966274966\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48061127426131406\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5605928788984661\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46395389334202203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5714606593719959\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4918511364632246\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4903541942989597\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5264800765904157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5597434083744572\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4573857762400916\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5769514618863583\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5109811214268157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4892543773735344\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5597283922213908\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5083630748102522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680260183875741\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4905644133506039\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5273063019909404\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49500357558113806\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4982628770151384\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5350924403508314\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5344443207868025\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4746764574944094\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49542183117216737\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5834281007282219\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4753867479106207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5324355618745739\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4765412697425975\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5058852011811242\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4930658993649898\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5591155812977637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5008185559490556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4756125032609388\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5105066793626382\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5562610693707912\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5248427951369388\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4691301078487023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5140765646071024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.533167034909507\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5192936702424061\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4902170982773449\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5149781286525064\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5333377715782036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.505991151579188\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5541396792623925\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5555786451581557\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:33, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.212600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.199000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.277500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.267000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.185200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.184100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.304200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.248000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.206200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.187200</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.168300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.213000</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.202500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.224800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.184300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.191500</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.206000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.232900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.250100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.255500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.208800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.257400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.250100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.196700</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.225800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.307800</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.325700</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.359000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.198400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.210600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.179500</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.253000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.312900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.249300</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.333500</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.286100</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.207800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.205400</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.287300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.223000</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.154900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.147100</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.131300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.147800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.094300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.170200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.128300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.116100</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.142900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.210600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.163200</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.155300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.186900</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.212600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.220000</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.234500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.199900</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.172400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.141300</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.194800</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.105900</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.147700</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.145100</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.120100</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.186800</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.134500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.166700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.125900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.123300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.116400</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.251100</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.158800</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.185400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.140200</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.159200</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.158800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.144300</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.135200</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.147900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.068900</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.079900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.062200</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.086300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.072500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.086600</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.116200</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.065600</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.078800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.080900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.075600</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.122100</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.067100</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.097600</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.074100</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.118100</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.117000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.090100</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.074800</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.064800</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.085900</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.074300</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.096300</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.104700</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.097700</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.115000</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.106000</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.063500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.074500</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.090000</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.100100</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.094300</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.066500</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.056600</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.044300</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.068700</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.063800</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.047900</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.049000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.049500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.058300</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.044900</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.028100</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.057000</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.055100</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.064300</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.066000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.055600</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.063900</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.071400</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.047400</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.041000</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.048900</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.041200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4953144397067215\n","is min 0.4953144397067215 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5144375268244277\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6004933009671859\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6050717361911311\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5360142065291152\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5323242494499048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.657989224928041\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5293429032516433\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5184082091317048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5997247981448144\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5646794220992095\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.539536551973102\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6231673476868723\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.502791612151777\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5679030346582625\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5810164889933674\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5210541161078143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5666968534953145\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.623745543989216\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4868965229635577\n","is min 0.4868965229635577 is smaller than [0.4953144397067215, 0.5144375268244277, 0.6004933009671859, 0.6050717361911311, 0.5360142065291152, 0.5323242494499048, 0.657989224928041, 0.5293429032516433, 0.5184082091317048, 0.5997247981448144, 0.5646794220992095, 0.539536551973102, 0.6231673476868723, 0.502791612151777, 0.5679030346582625, 0.5810164889933674, 0.5210541161078143, 0.5666968534953145, 0.623745543989216]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6282334375555272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49005954057882006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.584674792457818\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5438528339057062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5313259556400257\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5487445634687034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6158462993682833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6243724003469656\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5812288120951978\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5739974005481772\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5560614060157784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6745994105885321\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4901765893745292\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6139753569729534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48903876599940754\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6886799615464391\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49361832572505976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262842028284107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6143615702103992\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5838878874727972\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5218448686266691\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6336511551617052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5825773875919659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4868331732161712\n","is min 0.4868331732161712 is smaller than [0.4953144397067215, 0.5144375268244277, 0.6004933009671859, 0.6050717361911311, 0.5360142065291152, 0.5323242494499048, 0.657989224928041, 0.5293429032516433, 0.5184082091317048, 0.5997247981448144, 0.5646794220992095, 0.539536551973102, 0.6231673476868723, 0.502791612151777, 0.5679030346582625, 0.5810164889933674, 0.5210541161078143, 0.5666968534953145, 0.623745543989216, 0.4868965229635577, 0.6282334375555272, 0.49005954057882006, 0.584674792457818, 0.5438528339057062, 0.5313259556400257, 0.5487445634687034, 0.6158462993682833, 0.6243724003469656, 0.5812288120951978, 0.5739974005481772, 0.5560614060157784, 0.6745994105885321, 0.4901765893745292, 0.6139753569729534, 0.48903876599940754, 0.6886799615464391, 0.49361832572505976, 0.5262842028284107, 0.6143615702103992, 0.5838878874727972, 0.5218448686266691, 0.6336511551617052, 0.5825773875919659]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.656629886053051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5509698462044347\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5075647237657681\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5360776482801972\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.561215590334437\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49736748250892515\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5090338878340493\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6245315117297529\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5017650321817644\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5784225366775724\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5112691027012264\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.54264888597756\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5867549517150893\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5072639426113456\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5960000636444835\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.499775865559962\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5919112272047237\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5898332495095353\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5269797025221098\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5641273842288648\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49240056648415553\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5798251034065612\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.525385226784193\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4926086790834352\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48485369516606924\n","is min 0.48485369516606924 is smaller than [0.4953144397067215, 0.5144375268244277, 0.6004933009671859, 0.6050717361911311, 0.5360142065291152, 0.5323242494499048, 0.657989224928041, 0.5293429032516433, 0.5184082091317048, 0.5997247981448144, 0.5646794220992095, 0.539536551973102, 0.6231673476868723, 0.502791612151777, 0.5679030346582625, 0.5810164889933674, 0.5210541161078143, 0.5666968534953145, 0.623745543989216, 0.4868965229635577, 0.6282334375555272, 0.49005954057882006, 0.584674792457818, 0.5438528339057062, 0.5313259556400257, 0.5487445634687034, 0.6158462993682833, 0.6243724003469656, 0.5812288120951978, 0.5739974005481772, 0.5560614060157784, 0.6745994105885321, 0.4901765893745292, 0.6139753569729534, 0.48903876599940754, 0.6886799615464391, 0.49361832572505976, 0.5262842028284107, 0.6143615702103992, 0.5838878874727972, 0.5218448686266691, 0.6336511551617052, 0.5825773875919659, 0.4868331732161712, 0.656629886053051, 0.5509698462044347, 0.5075647237657681, 0.5360776482801972, 0.561215590334437, 0.49736748250892515, 0.5090338878340493, 0.6245315117297529, 0.5017650321817644, 0.5784225366775724, 0.5112691027012264, 0.54264888597756, 0.5867549517150893, 0.5072639426113456, 0.5960000636444835, 0.499775865559962, 0.5919112272047237, 0.5898332495095353, 0.5269797025221098, 0.5641273842288648, 0.49240056648415553, 0.5798251034065612, 0.525385226784193, 0.4926086790834352]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6297527867246406\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5068126856346773\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5678604319813738\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5678304093440979\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.521670021308183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5953430757704408\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.512740292874785\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5606524548508732\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.559998245325205\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5502041887726942\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5264223966706483\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5772060352097581\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6500640159648121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5165599431037481\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5745552502098622\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5306651883988752\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5519218020046995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6112144381270478\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5512826440631146\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46980371041775026\n","is min 0.46980371041775026 is smaller than [0.4953144397067215, 0.5144375268244277, 0.6004933009671859, 0.6050717361911311, 0.5360142065291152, 0.5323242494499048, 0.657989224928041, 0.5293429032516433, 0.5184082091317048, 0.5997247981448144, 0.5646794220992095, 0.539536551973102, 0.6231673476868723, 0.502791612151777, 0.5679030346582625, 0.5810164889933674, 0.5210541161078143, 0.5666968534953145, 0.623745543989216, 0.4868965229635577, 0.6282334375555272, 0.49005954057882006, 0.584674792457818, 0.5438528339057062, 0.5313259556400257, 0.5487445634687034, 0.6158462993682833, 0.6243724003469656, 0.5812288120951978, 0.5739974005481772, 0.5560614060157784, 0.6745994105885321, 0.4901765893745292, 0.6139753569729534, 0.48903876599940754, 0.6886799615464391, 0.49361832572505976, 0.5262842028284107, 0.6143615702103992, 0.5838878874727972, 0.5218448686266691, 0.6336511551617052, 0.5825773875919659, 0.4868331732161712, 0.656629886053051, 0.5509698462044347, 0.5075647237657681, 0.5360776482801972, 0.561215590334437, 0.49736748250892515, 0.5090338878340493, 0.6245315117297529, 0.5017650321817644, 0.5784225366775724, 0.5112691027012264, 0.54264888597756, 0.5867549517150893, 0.5072639426113456, 0.5960000636444835, 0.499775865559962, 0.5919112272047237, 0.5898332495095353, 0.5269797025221098, 0.5641273842288648, 0.49240056648415553, 0.5798251034065612, 0.525385226784193, 0.4926086790834352, 0.48485369516606924, 0.6297527867246406, 0.5068126856346773, 0.5678604319813738, 0.5678304093440979, 0.521670021308183, 0.5953430757704408, 0.512740292874785, 0.5606524548508732, 0.559998245325205, 0.5502041887726942, 0.5264223966706483, 0.5772060352097581, 0.6500640159648121, 0.5165599431037481, 0.5745552502098622, 0.5306651883988752, 0.5519218020046995, 0.6112144381270478, 0.5512826440631146]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48436232910642274\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5967707707616771\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6005982240933188\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686602368348934\n","is min 0.4686602368348934 is smaller than [0.4953144397067215, 0.5144375268244277, 0.6004933009671859, 0.6050717361911311, 0.5360142065291152, 0.5323242494499048, 0.657989224928041, 0.5293429032516433, 0.5184082091317048, 0.5997247981448144, 0.5646794220992095, 0.539536551973102, 0.6231673476868723, 0.502791612151777, 0.5679030346582625, 0.5810164889933674, 0.5210541161078143, 0.5666968534953145, 0.623745543989216, 0.4868965229635577, 0.6282334375555272, 0.49005954057882006, 0.584674792457818, 0.5438528339057062, 0.5313259556400257, 0.5487445634687034, 0.6158462993682833, 0.6243724003469656, 0.5812288120951978, 0.5739974005481772, 0.5560614060157784, 0.6745994105885321, 0.4901765893745292, 0.6139753569729534, 0.48903876599940754, 0.6886799615464391, 0.49361832572505976, 0.5262842028284107, 0.6143615702103992, 0.5838878874727972, 0.5218448686266691, 0.6336511551617052, 0.5825773875919659, 0.4868331732161712, 0.656629886053051, 0.5509698462044347, 0.5075647237657681, 0.5360776482801972, 0.561215590334437, 0.49736748250892515, 0.5090338878340493, 0.6245315117297529, 0.5017650321817644, 0.5784225366775724, 0.5112691027012264, 0.54264888597756, 0.5867549517150893, 0.5072639426113456, 0.5960000636444835, 0.499775865559962, 0.5919112272047237, 0.5898332495095353, 0.5269797025221098, 0.5641273842288648, 0.49240056648415553, 0.5798251034065612, 0.525385226784193, 0.4926086790834352, 0.48485369516606924, 0.6297527867246406, 0.5068126856346773, 0.5678604319813738, 0.5678304093440979, 0.521670021308183, 0.5953430757704408, 0.512740292874785, 0.5606524548508732, 0.559998245325205, 0.5502041887726942, 0.5264223966706483, 0.5772060352097581, 0.6500640159648121, 0.5165599431037481, 0.5745552502098622, 0.5306651883988752, 0.5519218020046995, 0.6112144381270478, 0.5512826440631146, 0.46980371041775026, 0.48436232910642274, 0.5967707707616771, 0.6005982240933188]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5811354190782156\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5272206120049308\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6214013653165822\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5156058898524541\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5117679446549703\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.612453031116803\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5349670808026892\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5213803174254934\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5700686357842261\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5558170476165826\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6602782918969434\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5915396732838559\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.525243000078168\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6467904415334986\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5023346343850056\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6312066193452113\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4756735822992615\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6798683335664447\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.510964006285655\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5965441624162958\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5443060087381687\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6347032803763053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5629250327033455\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5701837901313105\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5518421817206223\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5215377820868651\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5166311905831766\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5914030925692413\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.526088273535389\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5575961793267614\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6402175807167658\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.501073020070528\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5985822032995465\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.53099897350309\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49352015479926564\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.572808883082522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5145411856419254\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5942695068337892\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5500017742459065\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5148992457921968\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5793357496437491\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5796956161652895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5691627745053204\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5609643632168351\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.59666719568122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5921499949002257\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5965818668000006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5011762166428886\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5832868574033078\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5683814805411139\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5680558768562636\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5278571075021343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5379763327008851\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6282202283320111\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5164508978210074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.516607399243757\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5258594271998702\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6907715770881778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46873411558579176\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.624806643163011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5363363806328165\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.524836611281496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5676364939153847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5607982112520478\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5514716647976227\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:05, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.243000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.172500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.185100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.209900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.224100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.202700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.217200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.334000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.238600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.205000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.288900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.329600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.226800</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.219700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.237200</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.226200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.309000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.231200</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.311800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.266400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.273900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.352600</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.256500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.255800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.245900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.264900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.293600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.241900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.309600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.114500</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.256300</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.272000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.175300</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.286800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.283200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.267200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.283500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.272000</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.285800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.179100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.160700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.141900</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.141900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.165100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.199500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.097000</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.114700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.114900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.217400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.192900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.148900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.179500</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.155900</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.189200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.155700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.174700</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.131600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.212900</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.168000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.120400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.190700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.129300</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.160800</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.161300</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.127500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.230200</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.119300</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.187600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.153200</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.115500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.142500</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.150300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.202200</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.220000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.178800</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.172900</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.151500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.173800</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.155700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.085500</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.118100</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.085200</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.064100</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.103700</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.109300</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.087400</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.068900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.067800</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.079800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.118900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.101300</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.085400</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.082000</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.073600</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.092300</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.073900</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.075300</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.080400</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.120300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.088300</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.102300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.083700</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.075900</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.100400</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.074200</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.056000</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.106100</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.075100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.069800</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.077100</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.076700</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.097100</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.100700</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.093000</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.074100</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.081200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.093600</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.079600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.054700</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.044900</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.062200</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.069900</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.051900</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.031900</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.048900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.066500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.052800</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.047000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.076400</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.077600</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.065600</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.031100</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.059900</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.059800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.043200</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.032500</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.044300</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.066800</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.065500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.087100</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.049500</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.055400</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.064700</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.052100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:09,  1.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44115994435700023\n","is min 0.44115994435700023 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47165849534304594\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5082344423160194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48208753881881194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48171165704787006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5318960083911263\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4885532373962486\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5800235714107379\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5106240179351484\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.502677212267539\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5403788955740321\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49899109968010497\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.530315388831461\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4404248920458466\n","is min 0.4404248920458466 is smaller than [0.44115994435700023, 0.47165849534304594, 0.5082344423160194, 0.48208753881881194, 0.48171165704787006, 0.5318960083911263, 0.4885532373962486, 0.5800235714107379, 0.5106240179351484, 0.502677212267539, 0.5403788955740321, 0.49899109968010497, 0.530315388831461]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5921678287226048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4800198076091527\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4340765444735884\n","is min 0.4340765444735884 is smaller than [0.44115994435700023, 0.47165849534304594, 0.5082344423160194, 0.48208753881881194, 0.48171165704787006, 0.5318960083911263, 0.4885532373962486, 0.5800235714107379, 0.5106240179351484, 0.502677212267539, 0.5403788955740321, 0.49899109968010497, 0.530315388831461, 0.4404248920458466, 0.5921678287226048, 0.4800198076091527]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45621268158995076\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44818126773997813\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4692005683721586\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5245805842213145\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.621874403160289\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4412715936126459\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5504964106733079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5261902782965511\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4917756609514665\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5071424986784421\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6465244248154838\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4902667425622158\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5291633392470058\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5317025282706572\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4394582583122533\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6394017691098249\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47337149013972063\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5374402232136641\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4517125613539461\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.628114582657179\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46316995571337066\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45060737639855714\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5197893112597405\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5728201733440785\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43428477122622794\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5612538353725409\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5087009440844541\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4712361067492871\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4729777131424177\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4536668985782518\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5404317545952521\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5734920164102956\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46530653948356354\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6147312283839143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4598834168732074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4637948186305287\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49182668465149665\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6165475540042629\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5055706027207095\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.513828799636815\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48173582231995293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5208823350509443\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5161375276050312\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4980031928768054\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47007586610906144\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6690015989783894\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4436871487667796\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5617839624925358\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4789296991431992\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5153296327798268\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5785430362465143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47853703117380164\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5230323227952074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4391269789856267\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5640045816354077\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4866543557930962\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4930435495591659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5287028533252099\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5444442121342453\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5482523897013578\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4760422629389204\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44278759178735194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6753862753983844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44047513554341694\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5084720280259427\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.520201292084699\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48639587154313857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6684454055799446\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4626183410353166\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5387875976533425\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6368034140897989\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43075263368091365\n","is min 0.43075263368091365 is smaller than [0.44115994435700023, 0.47165849534304594, 0.5082344423160194, 0.48208753881881194, 0.48171165704787006, 0.5318960083911263, 0.4885532373962486, 0.5800235714107379, 0.5106240179351484, 0.502677212267539, 0.5403788955740321, 0.49899109968010497, 0.530315388831461, 0.4404248920458466, 0.5921678287226048, 0.4800198076091527, 0.4340765444735884, 0.45621268158995076, 0.44818126773997813, 0.4692005683721586, 0.5245805842213145, 0.621874403160289, 0.4412715936126459, 0.5504964106733079, 0.5261902782965511, 0.4917756609514665, 0.5071424986784421, 0.6465244248154838, 0.4902667425622158, 0.5291633392470058, 0.5317025282706572, 0.4394582583122533, 0.6394017691098249, 0.47337149013972063, 0.5374402232136641, 0.4517125613539461, 0.628114582657179, 0.46316995571337066, 0.45060737639855714, 0.5197893112597405, 0.5728201733440785, 0.43428477122622794, 0.5612538353725409, 0.5087009440844541, 0.4712361067492871, 0.4729777131424177, 0.4536668985782518, 0.5404317545952521, 0.5734920164102956, 0.46530653948356354, 0.6147312283839143, 0.4598834168732074, 0.4637948186305287, 0.49182668465149665, 0.6165475540042629, 0.5055706027207095, 0.513828799636815, 0.48173582231995293, 0.5208823350509443, 0.5161375276050312, 0.4980031928768054, 0.47007586610906144, 0.6690015989783894, 0.4436871487667796, 0.5617839624925358, 0.4789296991431992, 0.5153296327798268, 0.5785430362465143, 0.47853703117380164, 0.5230323227952074, 0.4391269789856267, 0.5640045816354077, 0.4866543557930962, 0.4930435495591659, 0.5287028533252099, 0.5444442121342453, 0.5482523897013578, 0.4760422629389204, 0.44278759178735194, 0.6753862753983844, 0.44047513554341694, 0.5084720280259427, 0.520201292084699, 0.48639587154313857, 0.6684454055799446, 0.4626183410353166, 0.5387875976533425, 0.6368034140897989]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5745002064728746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4880294451407614\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45342923827996495\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5922278629554995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.428908421298374\n","is min 0.428908421298374 is smaller than [0.44115994435700023, 0.47165849534304594, 0.5082344423160194, 0.48208753881881194, 0.48171165704787006, 0.5318960083911263, 0.4885532373962486, 0.5800235714107379, 0.5106240179351484, 0.502677212267539, 0.5403788955740321, 0.49899109968010497, 0.530315388831461, 0.4404248920458466, 0.5921678287226048, 0.4800198076091527, 0.4340765444735884, 0.45621268158995076, 0.44818126773997813, 0.4692005683721586, 0.5245805842213145, 0.621874403160289, 0.4412715936126459, 0.5504964106733079, 0.5261902782965511, 0.4917756609514665, 0.5071424986784421, 0.6465244248154838, 0.4902667425622158, 0.5291633392470058, 0.5317025282706572, 0.4394582583122533, 0.6394017691098249, 0.47337149013972063, 0.5374402232136641, 0.4517125613539461, 0.628114582657179, 0.46316995571337066, 0.45060737639855714, 0.5197893112597405, 0.5728201733440785, 0.43428477122622794, 0.5612538353725409, 0.5087009440844541, 0.4712361067492871, 0.4729777131424177, 0.4536668985782518, 0.5404317545952521, 0.5734920164102956, 0.46530653948356354, 0.6147312283839143, 0.4598834168732074, 0.4637948186305287, 0.49182668465149665, 0.6165475540042629, 0.5055706027207095, 0.513828799636815, 0.48173582231995293, 0.5208823350509443, 0.5161375276050312, 0.4980031928768054, 0.47007586610906144, 0.6690015989783894, 0.4436871487667796, 0.5617839624925358, 0.4789296991431992, 0.5153296327798268, 0.5785430362465143, 0.47853703117380164, 0.5230323227952074, 0.4391269789856267, 0.5640045816354077, 0.4866543557930962, 0.4930435495591659, 0.5287028533252099, 0.5444442121342453, 0.5482523897013578, 0.4760422629389204, 0.44278759178735194, 0.6753862753983844, 0.44047513554341694, 0.5084720280259427, 0.520201292084699, 0.48639587154313857, 0.6684454055799446, 0.4626183410353166, 0.5387875976533425, 0.6368034140897989, 0.43075263368091365, 0.5745002064728746, 0.4880294451407614, 0.45342923827996495, 0.5922278629554995]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5117507012044179\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5399681926591479\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4991754847974879\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4908040490999598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45176441918887794\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5027680321810866\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4930093670445011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47705992082062915\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4816863498320508\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5019834439173531\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.541252300014988\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5259002834792448\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4629747318948647\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5547417794234019\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5611834051806698\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43413147237250166\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6156358768946546\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45519938900811346\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4513823497573726\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6085459108719807\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4867270042149414\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5411750938590105\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5161541405572305\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5513392704832312\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4579359055337143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5144553525735215\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5435295117100112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4471706780009416\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6238809360489782\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45406179913229516\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5023970330471105\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5196157676826502\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48762305231682856\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4830049043849083\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6040038446371849\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5063105718596325\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47458152317817914\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5346885064213294\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5249706578808283\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45766513762030575\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5292016854313016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48609301783607234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5970211536508927\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45757813145370746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5086234252892111\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5049514987195357\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45483144004562687\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6103096831322496\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.560513965369114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4892002322865981\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5331405673028231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5256770020655387\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327415134235259\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47653021918480676\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6052089235877173\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5085136852007826\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5635636973528917\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4996216631766626\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5133944220693812\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4983125616216228\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4390741498006412\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6054470414919079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4653180803615165\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5575311774956899\n","Training done\n"]}],"source":["# deberta 1\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"GPvQ-fImNmVl"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:10, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.310600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.290100</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.193800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.239400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.299200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.312000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.218000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.231000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.195000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.228300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.187300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.168200</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.227500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.245400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.186000</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.241800</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.181100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.255400</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.235400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.239400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.172300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.233700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.234600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.232200</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.275100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.215800</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.213900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.238500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.219300</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.255900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.250900</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.200000</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.417300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.205900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.311200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.215100</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.231800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.201000</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.176700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.175900</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.146600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.086300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.110200</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.147500</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.178100</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.150400</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.241200</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.209700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.133200</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.169400</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.162000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.191400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.135500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.120900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.156200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.192300</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.170100</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.191800</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.177000</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.165600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.129500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.179200</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.100600</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.161900</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.180800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.202600</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.142600</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.128200</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.171200</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.173000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.125400</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.151800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.177000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.098100</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.132700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.122200</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.113500</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.093900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.064600</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.076000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.108700</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.103700</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.055700</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.056300</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.060800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.079200</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.129100</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.074300</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.100600</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.130100</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.113200</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.093500</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.066800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.087100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.085500</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.083100</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.080700</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.093000</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.119900</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.082400</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.114300</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.092600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.084700</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.090100</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.074400</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.085000</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.084200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.082300</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.073700</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.157200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.090300</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.075700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.054200</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.047700</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.073500</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.055400</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.044800</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.058500</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.091100</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.061200</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.056200</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.029500</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.044500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.047900</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.049400</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.053400</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.049700</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.038100</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.052000</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.057400</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.050000</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.043300</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.034500</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.040600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47585135438270953\n","is min 0.47585135438270953 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5067115804474044\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5533209036171477\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6305123937015664\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6275523134936952\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5483066411430665\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5266619611858655\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5536754301595592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5324538167742954\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579932779204595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5345651676280635\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4860080688824759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5941127932744458\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5011013856175109\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5289939895237524\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5763738554694106\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4718289248940371\n","is min 0.4718289248940371 is smaller than [0.47585135438270953, 0.5067115804474044, 0.5533209036171477, 0.6305123937015664, 0.6275523134936952, 0.5483066411430665, 0.5266619611858655, 0.5536754301595592, 0.5324538167742954, 0.5579932779204595, 0.5345651676280635, 0.4860080688824759, 0.5941127932744458, 0.5011013856175109, 0.5289939895237524, 0.5763738554694106]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5117493759219437\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5005044729894442\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6028698546139857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5010877136969988\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4707166673611489\n","is min 0.4707166673611489 is smaller than [0.47585135438270953, 0.5067115804474044, 0.5533209036171477, 0.6305123937015664, 0.6275523134936952, 0.5483066411430665, 0.5266619611858655, 0.5536754301595592, 0.5324538167742954, 0.5579932779204595, 0.5345651676280635, 0.4860080688824759, 0.5941127932744458, 0.5011013856175109, 0.5289939895237524, 0.5763738554694106, 0.4718289248940371, 0.5117493759219437, 0.5005044729894442, 0.6028698546139857, 0.5010877136969988]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5916270149472028\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5393876277143864\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.459941656682066\n","is min 0.459941656682066 is smaller than [0.47585135438270953, 0.5067115804474044, 0.5533209036171477, 0.6305123937015664, 0.6275523134936952, 0.5483066411430665, 0.5266619611858655, 0.5536754301595592, 0.5324538167742954, 0.5579932779204595, 0.5345651676280635, 0.4860080688824759, 0.5941127932744458, 0.5011013856175109, 0.5289939895237524, 0.5763738554694106, 0.4718289248940371, 0.5117493759219437, 0.5005044729894442, 0.6028698546139857, 0.5010877136969988, 0.4707166673611489, 0.5916270149472028, 0.5393876277143864]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5758681562196297\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5307783544844203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5253588817340821\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4610201386597383\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5714047244769676\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6533589873898547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5108370627963671\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8256143163746842\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.465151015580796\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6483402972689915\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49283939033129576\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5301981014450472\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5318679236611417\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5380291610726119\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5727890866899917\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5697979525939485\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47449319919441857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5874167273421221\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5350468436763419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.546227192284117\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5777640519053763\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5835461939932075\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49901635300230196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5821868387561151\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.50952581998427\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6336782356007282\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5795785665660055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5480017714529442\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49636998666572296\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6209917409810963\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5228030232534714\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5833194510263976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5120674356618328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5588136306657645\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49543714533936467\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5440019473812329\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5804891613179761\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5707876133389003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5405994634911879\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5256717100785804\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5656293051850778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6502212795476243\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5406843662350734\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5315328764432462\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5346759487422683\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6573542549795551\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5109358759217486\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5455039993515474\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6181480792331868\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.553284846911875\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5466572566713939\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5049981908498403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5408952058132949\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6853970051880686\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48317653679834727\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5431470109528979\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6100473959099307\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5367936807709028\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.485395574818948\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6207526662799707\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5483200754352127\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5752540570125577\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5726748701125598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5821488464445304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6431575044157881\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5113329483577603\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5932195510258238\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5872592007170374\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.61778592595283\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5711291383016268\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5765061811809391\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6203670800019833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49123377564868015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6432372387177467\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.521714065138062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5209633079368965\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.616332691528206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5340021007493685\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5420316121538844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5604052035702126\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5961582818730505\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.603662546407114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6005808360504253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5638589690634642\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6101081715039074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5139339209914776\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5959608994999316\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5402075626305882\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5151415331616798\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6535440827308491\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48649755323386157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6901410798624154\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5159973578686594\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6206298056709963\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5346109943159195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6108951395763356\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5514981466898228\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6200669913013482\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5979919051128634\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5697297937341733\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.526772135191607\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6015495775630693\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5162707520482067\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.531627436000967\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6118067393401436\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5198395283712098\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6250290970423062\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579390704876538\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5275545644987847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5489581304482392\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6164414032805104\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5408360843033897\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6214201274395391\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579241643334637\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5716697611478027\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5705196249195023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5483173054075192\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5853106306200412\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5338070040003599\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.597927370691871\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5699241560160677\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5484008963270388\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5479969859740249\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5382488353491922\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5898952930508015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5251788738740235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.606791505861781\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5542297531210868\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6248009519515607\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5264452306240031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5931866659585984\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6194628339933852\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5315243036561861\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:02, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.232200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.256600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.151000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.210900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.297500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.265500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.245700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.178700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.265000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.208300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.203500</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.294900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.297200</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.247700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.259400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.171700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.239400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.180000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.206500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.208600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.225800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.252900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.251800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.198500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.221100</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.271200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.210100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.230000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.210100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.304700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.225400</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.319100</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.190500</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.241500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.251700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.134800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.268400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.298700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.313000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.216900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.266100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.202000</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.187600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.159300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.133100</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.201600</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.124800</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.114300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.142300</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.228300</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.179000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.103300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.195200</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.174100</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.125800</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.177500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.202200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.177500</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.172200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.217200</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.196200</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.122300</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.194900</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.206200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.162000</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.158500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.207500</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.164100</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.108100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.189400</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.168500</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.107900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.170000</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.183300</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.137100</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.131300</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.164500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.107500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.158000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.080900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.067300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.106300</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.110400</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.072100</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.069900</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.122800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.064600</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.131700</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.115500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.091800</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.093000</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.093000</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.092300</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.099800</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.087900</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.094100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.092500</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.070600</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.084400</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.107500</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.102000</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.058700</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.124300</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.089000</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.068500</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.084400</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.073200</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.078000</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.085100</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.090500</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.110600</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.095600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.092800</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.070700</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.059600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.029900</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.034400</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.081400</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.067400</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.053500</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.063000</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.103100</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.041800</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.063800</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.036800</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.037300</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.077700</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.063500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.057800</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.062100</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.043900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4766813678952686\n","is min 0.4766813678952686 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4980874855687123\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462236907004822\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5938322530944025\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5118460632637422\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48945671884121056\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5454418062638657\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5387029291891534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5482561480754189\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5251511560308181\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4940706578776077\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5254155788182259\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5350102939948649\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.654976276471246\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4808659091286966\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.644602725183162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49815588502085795\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5086167842631463\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5049696976025279\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47218948294974017\n","is min 0.47218948294974017 is smaller than [0.4766813678952686, 0.4980874855687123, 0.5462236907004822, 0.5938322530944025, 0.5118460632637422, 0.48945671884121056, 0.5454418062638657, 0.5387029291891534, 0.5482561480754189, 0.5251511560308181, 0.4940706578776077, 0.5254155788182259, 0.5350102939948649, 0.654976276471246, 0.4808659091286966, 0.644602725183162, 0.49815588502085795, 0.5086167842631463, 0.5049696976025279]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6995700909949193\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45637222316568854\n","is min 0.45637222316568854 is smaller than [0.4766813678952686, 0.4980874855687123, 0.5462236907004822, 0.5938322530944025, 0.5118460632637422, 0.48945671884121056, 0.5454418062638657, 0.5387029291891534, 0.5482561480754189, 0.5251511560308181, 0.4940706578776077, 0.5254155788182259, 0.5350102939948649, 0.654976276471246, 0.4808659091286966, 0.644602725183162, 0.49815588502085795, 0.5086167842631463, 0.5049696976025279, 0.47218948294974017, 0.6995700909949193]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5266827912662875\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5035975117151507\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5240420421747468\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5263130274330108\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5577939119380343\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5015012045381629\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5686916787327154\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579171354326008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5020464698513322\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4700143012529226\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49480634676529056\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5252247604539536\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5477795156010073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4976319798620846\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7037125121059478\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.480152089368738\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7163023820808733\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4773953168979428\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6694265018876243\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4705714441344722\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6007637961237599\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48708472884059\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5813231669172502\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4929044705330661\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5259010628129239\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5345141203145877\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5037715377017903\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46703649924032337\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5532674153813357\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5006903268075531\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.588827889406195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5396661460986615\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6625160587379125\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.478535661942205\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5923263185276754\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5431259708560606\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6014724533975895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48767277516609364\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5657434660200418\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5233985540528663\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45707476850927703\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5370133807875529\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5621597217176135\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5707157857195768\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4634595556416514\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6267807819490505\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5329048986586518\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6206196754970641\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5172018856087983\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6870257148536091\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4784360907808032\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5868922791858671\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5317879779124682\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4667218478365692\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5386699510461297\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5222087907792529\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4914241888626952\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49971473095289204\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5445256416077879\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.528186942136955\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.505893326673073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5577941315840155\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5775069484935074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5617327206440433\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5386703356423307\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6099089343333858\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5433383869965034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5404330221416818\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5988232153929345\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5175326439033817\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6253268005464787\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5317885538056272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.57550196539485\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579329862411452\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5178876209410335\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5740510464319233\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5484832667245384\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5386779314832566\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6082724084314968\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.519227518803333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6114885318919919\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49031523002936533\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5865566049489481\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6324702072203684\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5502764539709446\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.563755024968422\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49608903855846354\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5609561266307417\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6347945561734147\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49270605096008285\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6176998883133109\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.503543973741531\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6604229280947883\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5192545207083024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6172355852025996\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.506779500095983\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5477745600167749\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5767913678191279\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5177166720082207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5240161752531726\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5715983913832438\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5486520890166868\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5494833283731633\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5301062117454463\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5538232413136145\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5828684358576598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5326761456762609\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5015675629686194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6232816893431191\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49305969414316536\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5357622184731403\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5322258214526342\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5537350727826097\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5392694055125541\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5694846059985126\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5731138507753724\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5270583684219021\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.526392070321456\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5982369310345872\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5124922600340065\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49280754150166844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.659721271100116\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47469669439706047\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5734755534419412\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.552310830693568\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5018973620834584\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5560769819462388\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5104234543342594\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5820521071047863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5096542883365036\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5685007579658744\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.577705301016816\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5081301403301076\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5644211794611691\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5459785694126019\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5332610653814448\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 49:37, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.367400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.230900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.215700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.249200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.157100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.190900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.219000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.246000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.257100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.200800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.250200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.232900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.283600</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.196000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.286600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.167400</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.251900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.279800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.337800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.398300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.373100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.294300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.299600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.213100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.245700</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.254400</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.236700</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.225500</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.223600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.167400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.238700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.260500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.256000</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.224400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.279800</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.204800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.227200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.227100</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.196900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.187300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.116300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.196300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.176600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.115800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.142100</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.178000</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.133800</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.165500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.176600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.185600</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.139900</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.164000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.170800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.169800</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.148300</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.121400</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.194700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.153300</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.177600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.100400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.133900</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.146300</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.154800</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.201100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.164300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.154900</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.211800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.118900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.169400</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.155000</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.156300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.146300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.213500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.125500</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.158700</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.213200</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.145300</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.173000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.093900</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.082900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.073400</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.121700</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.110900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.088500</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.063000</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.109700</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.073000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.134300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.098000</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.071000</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.092600</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.082300</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.072900</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.060100</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.119900</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.076300</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.080900</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.100700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.116300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.086000</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.073800</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.116200</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.090900</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.074200</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.088100</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.079400</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.084900</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.079600</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.069700</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.133200</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.110100</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.074700</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.099900</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.056200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.088200</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.053400</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.074900</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.055000</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.048100</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.066900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.043900</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.072700</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.058500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.047700</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.056600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.035000</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.051600</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.055900</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.047000</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.060800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.046300</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.046500</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.047000</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.055300</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.069500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4635158900241327\n","is min 0.4635158900241327 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4852383105877928\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5286656540393603\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49210391637061324\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49781279305916304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5233314016518084\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4582089881149707\n","is min 0.4582089881149707 is smaller than [0.4635158900241327, 0.4852383105877928, 0.5286656540393603, 0.49210391637061324, 0.49781279305916304, 0.5233314016518084]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5968488073778181\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5109833517349341\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5496645729491755\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.503898600871553\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5197630401902206\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.547899047015094\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5372595178766749\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5998649488026304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5709908147095261\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5303851708490044\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4698821470810043\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7433412167576371\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5315296371949997\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.531208660411192\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6297946807269703\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4800902689089128\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4736169370794365\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5324006064620547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5018867204237126\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4740349668795551\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6071168956352712\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5089211404684687\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5247351395495969\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6264023334988077\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.484327573167317\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5024988985488938\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6438836507458244\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5079130478731448\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4734585785067394\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5575526364831072\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6464499559880122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5309720454732971\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5030164640749889\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5308264703796328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5136328768046345\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5389774336390222\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5880746073744626\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47300922129435746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6134817894258976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4706266908498911\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7319875675524664\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4973862408781158\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5028847212691597\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5989918196093122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579696951638592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5600366619192653\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5143077805215116\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4863916470893114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6307588598635155\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4680611459562927\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6009805146464522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45962256522174794\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6514395181770462\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5294378796529554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4852586591389263\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5506667153718187\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.473018782353685\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5866130431535953\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5103197965138069\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5972448359993552\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.522316867209214\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5941364085040924\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5296225886797976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5468018018258265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5358893859120251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7227863224008862\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4640718696097804\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6045750230374549\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4738388091974681\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6670011704265074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4615594209638081\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5852807422303615\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5354849661723011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5824420433296281\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6363110942777146\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47625788912540673\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6310362067777341\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5371655119032791\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5283738838953491\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6632059862589442\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5019438450110184\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6563457020872995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5825860046530472\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5514300292934194\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4884283220195416\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6089987488621182\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5689336007916361\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5077194019626844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5915103738469303\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.465980945587751\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5569957175533526\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47863052216819996\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7130663861015688\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5485136266668141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5347940212086327\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5934515100304704\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.636878634718785\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4879948533959473\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6276987570439421\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262245429556731\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5841510443622624\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6400275803126769\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5494440627302778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6183239675398522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5937275384600375\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5828290687665578\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5907771643123595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5192372967460956\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5507045040638433\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5487932804842016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5573964414857648\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5468881058383571\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5446398288560207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6011038671580972\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5551185218426967\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5225868362302556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5682951216336656\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262359242015469\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462192844034348\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5467819095576885\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5690134292711002\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6117718879811955\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4864161274449183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5611125551061396\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5513715071344252\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5565600078717546\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6352617361278295\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5216173717641072\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6382361586507421\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6068590003354408\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5453480646004354\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5868641296674902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.558218209273852\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5464890799590316\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5252662619148137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6008357601912914\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.547425750320162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5881542312341741\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5404889331867266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5181560487183591\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5686969792523657\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5564726744173512\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5477105164580925\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5760191585047189\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5887116478906674\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.551105246661295\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5575539500038883\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5200059476525716\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6185690805865152\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5088710270286817\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6198099009531136\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:42, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.234400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.132000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.281400</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.266000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.155200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.228200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.171500</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.249000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.240900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.213300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.228500</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.279800</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.203400</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.272000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.214700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.155300</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.251300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.277000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.323300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.212300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.360000</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.267600</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.296500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.222300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.227600</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.213500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.257000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.193500</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.191700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.172700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.213800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.219600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.304100</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.183700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.251400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.228100</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.285900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.255400</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.239600</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.151300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.137200</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.125900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.151100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.119300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.184500</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.141400</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.160900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.188400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.182500</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.148900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.162100</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.170500</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.178300</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.205900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.151100</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.169200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.221400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.137300</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.168600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.174800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.171900</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.175600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.144200</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.110200</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.160200</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.195600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.154000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.121200</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.164500</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.141000</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.101600</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.206500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.219900</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.209700</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.189900</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.127600</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.107700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.088900</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.125800</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.089000</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.054300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.086100</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.073600</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.072600</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.089600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.092600</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.077400</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.090900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.101000</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.119000</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.083000</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.070400</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.060300</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.094800</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.098900</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.100800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.098900</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.100600</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.085400</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.096500</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.110600</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.070300</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.078300</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.072200</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.080100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.096800</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.072900</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.081800</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.117200</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.100100</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.087200</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.109600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.111100</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.096100</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.030200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.049000</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.060400</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.054900</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.056900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.035800</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.048600</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.054400</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.066900</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.041800</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.032900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.042100</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.071900</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.042100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.042400</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.041200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.055900</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.041700</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.033600</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.028200</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.046100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47118037208722485\n","is min 0.47118037208722485 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4778470651299342\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5064440504611682\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.512759722248191\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48973026300452815\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4973667167183596\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5143708261055577\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48301886481253054\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5177822548372272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5108834236192759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5267380143191882\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5199885439594948\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4885238084593963\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46956494829229684\n","is min 0.46956494829229684 is smaller than [0.47118037208722485, 0.4778470651299342, 0.5064440504611682, 0.512759722248191, 0.48973026300452815, 0.4973667167183596, 0.5143708261055577, 0.48301886481253054, 0.5177822548372272, 0.5108834236192759, 0.5267380143191882, 0.5199885439594948, 0.4885238084593963]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5171688252592918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46933643510704887\n","is min 0.46933643510704887 is smaller than [0.47118037208722485, 0.4778470651299342, 0.5064440504611682, 0.512759722248191, 0.48973026300452815, 0.4973667167183596, 0.5143708261055577, 0.48301886481253054, 0.5177822548372272, 0.5108834236192759, 0.5267380143191882, 0.5199885439594948, 0.4885238084593963, 0.46956494829229684, 0.5171688252592918]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46769443905376135\n","is min 0.46769443905376135 is smaller than [0.47118037208722485, 0.4778470651299342, 0.5064440504611682, 0.512759722248191, 0.48973026300452815, 0.4973667167183596, 0.5143708261055577, 0.48301886481253054, 0.5177822548372272, 0.5108834236192759, 0.5267380143191882, 0.5199885439594948, 0.4885238084593963, 0.46956494829229684, 0.5171688252592918, 0.46933643510704887]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4883987376707268\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5276843497102698\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4715476350854986\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6495283387834301\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4573186759476267\n","is min 0.4573186759476267 is smaller than [0.47118037208722485, 0.4778470651299342, 0.5064440504611682, 0.512759722248191, 0.48973026300452815, 0.4973667167183596, 0.5143708261055577, 0.48301886481253054, 0.5177822548372272, 0.5108834236192759, 0.5267380143191882, 0.5199885439594948, 0.4885238084593963, 0.46956494829229684, 0.5171688252592918, 0.46933643510704887, 0.46769443905376135, 0.4883987376707268, 0.5276843497102698, 0.4715476350854986, 0.6495283387834301]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48669106654277405\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5844862942237355\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4930703236193192\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5742245269124051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47122983999261736\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6191005821795034\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5269770494195242\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5142216464073687\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.506528684645845\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4795686920628054\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262450241624562\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5090297028748462\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5583039549195866\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44899366294176973\n","is min 0.44899366294176973 is smaller than [0.47118037208722485, 0.4778470651299342, 0.5064440504611682, 0.512759722248191, 0.48973026300452815, 0.4973667167183596, 0.5143708261055577, 0.48301886481253054, 0.5177822548372272, 0.5108834236192759, 0.5267380143191882, 0.5199885439594948, 0.4885238084593963, 0.46956494829229684, 0.5171688252592918, 0.46933643510704887, 0.46769443905376135, 0.4883987376707268, 0.5276843497102698, 0.4715476350854986, 0.6495283387834301, 0.4573186759476267, 0.48669106654277405, 0.5844862942237355, 0.4930703236193192, 0.5742245269124051, 0.47122983999261736, 0.6191005821795034, 0.5269770494195242, 0.5142216464073687, 0.506528684645845, 0.4795686920628054, 0.5262450241624562, 0.5090297028748462, 0.5583039549195866]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5269529562793636\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49821153558952624\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5560575296914899\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4553850602220533\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5588459574852176\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45718981021550875\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5140442599566126\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5208819678908069\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.514949711157723\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5588044445038195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5245603913428157\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4887961904148679\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.500031619815785\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5547927571775384\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5153219457353666\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47841519084730166\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.65517890588234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814252838720107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6478963678399816\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4691881462150818\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5853610543507471\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4803280254524361\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5166155622428226\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5082520944555382\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5118840068930435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5019678852227667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4973984328874409\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45542862229486375\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5894851484487619\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5183656649020917\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5325894060457866\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45661974687288165\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5846229483482345\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46248490903486544\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5681190973169172\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5079132154663958\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6326031999920982\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4546443806305383\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6244234005928122\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4454395219208624\n","is min 0.4454395219208624 is smaller than [0.47118037208722485, 0.4778470651299342, 0.5064440504611682, 0.512759722248191, 0.48973026300452815, 0.4973667167183596, 0.5143708261055577, 0.48301886481253054, 0.5177822548372272, 0.5108834236192759, 0.5267380143191882, 0.5199885439594948, 0.4885238084593963, 0.46956494829229684, 0.5171688252592918, 0.46933643510704887, 0.46769443905376135, 0.4883987376707268, 0.5276843497102698, 0.4715476350854986, 0.6495283387834301, 0.4573186759476267, 0.48669106654277405, 0.5844862942237355, 0.4930703236193192, 0.5742245269124051, 0.47122983999261736, 0.6191005821795034, 0.5269770494195242, 0.5142216464073687, 0.506528684645845, 0.4795686920628054, 0.5262450241624562, 0.5090297028748462, 0.5583039549195866, 0.44899366294176973, 0.5269529562793636, 0.49821153558952624, 0.5560575296914899, 0.4553850602220533, 0.5588459574852176, 0.45718981021550875, 0.5140442599566126, 0.5208819678908069, 0.514949711157723, 0.5588044445038195, 0.5245603913428157, 0.4887961904148679, 0.500031619815785, 0.5547927571775384, 0.5153219457353666, 0.47841519084730166, 0.65517890588234, 0.4814252838720107, 0.6478963678399816, 0.4691881462150818, 0.5853610543507471, 0.4803280254524361, 0.5166155622428226, 0.5082520944555382, 0.5118840068930435, 0.5019678852227667, 0.4973984328874409, 0.45542862229486375, 0.5894851484487619, 0.5183656649020917, 0.5325894060457866, 0.45661974687288165, 0.5846229483482345, 0.46248490903486544, 0.5681190973169172, 0.5079132154663958, 0.6326031999920982, 0.4546443806305383, 0.6244234005928122]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5051392826479926\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5248081457009426\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4809764217681852\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5297599705973154\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5373607838342508\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47698526690009646\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5179211275130108\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48256465841798607\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5384920546732282\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4898691058983641\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5190284227222407\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5359031383937612\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4622761737138711\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6008176055015547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4491266129402282\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6036932586775297\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48391236608128346\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5543830449523282\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5099421136947335\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5509499559168645\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4901461822488677\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5675852289168735\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48571255966280114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5720847261418918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4416836811947169\n","is min 0.4416836811947169 is smaller than [0.47118037208722485, 0.4778470651299342, 0.5064440504611682, 0.512759722248191, 0.48973026300452815, 0.4973667167183596, 0.5143708261055577, 0.48301886481253054, 0.5177822548372272, 0.5108834236192759, 0.5267380143191882, 0.5199885439594948, 0.4885238084593963, 0.46956494829229684, 0.5171688252592918, 0.46933643510704887, 0.46769443905376135, 0.4883987376707268, 0.5276843497102698, 0.4715476350854986, 0.6495283387834301, 0.4573186759476267, 0.48669106654277405, 0.5844862942237355, 0.4930703236193192, 0.5742245269124051, 0.47122983999261736, 0.6191005821795034, 0.5269770494195242, 0.5142216464073687, 0.506528684645845, 0.4795686920628054, 0.5262450241624562, 0.5090297028748462, 0.5583039549195866, 0.44899366294176973, 0.5269529562793636, 0.49821153558952624, 0.5560575296914899, 0.4553850602220533, 0.5588459574852176, 0.45718981021550875, 0.5140442599566126, 0.5208819678908069, 0.514949711157723, 0.5588044445038195, 0.5245603913428157, 0.4887961904148679, 0.500031619815785, 0.5547927571775384, 0.5153219457353666, 0.47841519084730166, 0.65517890588234, 0.4814252838720107, 0.6478963678399816, 0.4691881462150818, 0.5853610543507471, 0.4803280254524361, 0.5166155622428226, 0.5082520944555382, 0.5118840068930435, 0.5019678852227667, 0.4973984328874409, 0.45542862229486375, 0.5894851484487619, 0.5183656649020917, 0.5325894060457866, 0.45661974687288165, 0.5846229483482345, 0.46248490903486544, 0.5681190973169172, 0.5079132154663958, 0.6326031999920982, 0.4546443806305383, 0.6244234005928122, 0.4454395219208624, 0.5051392826479926, 0.5248081457009426, 0.4809764217681852, 0.5297599705973154, 0.5373607838342508, 0.47698526690009646, 0.5179211275130108, 0.48256465841798607, 0.5384920546732282, 0.4898691058983641, 0.5190284227222407, 0.5359031383937612, 0.4622761737138711, 0.6008176055015547, 0.4491266129402282, 0.6036932586775297, 0.48391236608128346, 0.5543830449523282, 0.5099421136947335, 0.5509499559168645, 0.4901461822488677, 0.5675852289168735, 0.48571255966280114, 0.5720847261418918]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5747815698794374\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4620270302454352\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.55145411011774\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5191236873841897\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5055344850477742\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5015125999676467\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6399738815852746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5289826924034423\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6123375111985523\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47687605206105793\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4930491660810264\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4887261870545487\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48790730597537135\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5236946655853884\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4941632169746196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5459131503967278\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5099360163388251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.510815828992367\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47525221259783845\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.558192904971641\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4949932755928051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5581739861406142\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4928841455755195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5225595168539394\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5872286671194313\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5270727593602579\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47272512067532013\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.526417774316759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4631657904184663\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5640803749196532\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47033841230481666\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5480738464017784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5081926219649153\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48374694168413757\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.579663336987554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5219717308765529\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4905084899403862\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5526077184166649\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46664578627436143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5233051144385787\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5035354675526941\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5372718102998428\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5047376023256847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48606353172863515\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5006585661302992\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5596787758368376\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.514635862756253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4838567176049667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5339002708332994\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5117971948613129\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5478618242484773\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4977657507295463\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5578870716374906\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5059737751158314\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5384922861951016\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5632880004195125\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5358419179753589\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:19, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.212900</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.203600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.286800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.256200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.186200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.187300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.303900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.234700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.200300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.187500</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.166700</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.206300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.187100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.223100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.177600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.180800</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.197800</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.214000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.256700</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.223600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.195400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.246800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.228500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.189100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.217600</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.302100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.268700</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.381200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.187600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.228600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.180400</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.249800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.302900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.232100</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.337900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.211700</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.212500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.191800</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.276900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.230900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.146200</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.145100</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.123500</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.130600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.098300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.111600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.167500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.205600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.164900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.166400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.213500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.240000</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.231900</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.200500</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.170200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.183100</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.120500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.151500</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.130600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.139200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.203500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.169000</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.182800</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.113500</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.117700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.123000</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.240900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.154100</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.133700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.136900</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.136900</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.147100</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.142300</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.143200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.074700</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.078400</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.067100</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.095800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.103900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.131900</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.121000</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.048300</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.064700</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.086000</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.103000</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.074300</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.066300</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.104900</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.101400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.078900</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.103700</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.093700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.055300</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.081500</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.086800</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.068400</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.076000</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.079400</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.080000</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.085200</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.116200</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.096400</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.115700</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.093100</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.057500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.074200</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.115000</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.105300</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.066000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.057300</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.029100</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.070800</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.066900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.063300</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.060100</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.053100</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.061400</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.028700</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.059200</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.055500</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.066200</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.067700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.086200</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.070600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.058200</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.047300</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.073500</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.059400</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.046000</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.044000</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.052700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948840490256836\n","is min 0.4948840490256836 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5078660052926143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5728240523050929\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5976380160115027\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5519568512844842\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5235969361198879\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6078555655353742\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5552852696205139\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.520846104086321\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5737648896896769\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5551422717595609\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5251618264447332\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6264186134477217\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5023564940000379\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5530354672177937\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.551096183021909\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5679573082939615\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5326311460294565\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.612224375530143\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.478360288373659\n","is min 0.478360288373659 is smaller than [0.4948840490256836, 0.5078660052926143, 0.5728240523050929, 0.5976380160115027, 0.5519568512844842, 0.5235969361198879, 0.6078555655353742, 0.5552852696205139, 0.520846104086321, 0.5737648896896769, 0.5551422717595609, 0.5251618264447332, 0.6264186134477217, 0.5023564940000379, 0.5530354672177937, 0.551096183021909, 0.5679573082939615, 0.5326311460294565, 0.612224375530143]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6482782240850965\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49388297294791017\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6183142857635585\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4982390831334698\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5200265858610797\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5365661202494326\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5730596677915454\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.636195777002826\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5685025038513748\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5884118786812902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5310648793164074\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6650807456519771\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4783999867027477\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6378558256807125\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47896194531705777\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5975347919319692\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5396779888948428\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5094627322726515\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5654282167462334\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5416062627309994\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5808260864746627\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6083200326126464\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5837272158385068\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4851737743786444\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6772727189905838\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5302826409626965\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5143053095867653\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5307819202593522\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5797892854366808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5084422450730627\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5094493148345735\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6092046981173277\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47820854829774384\n","is min 0.47820854829774384 is smaller than [0.4948840490256836, 0.5078660052926143, 0.5728240523050929, 0.5976380160115027, 0.5519568512844842, 0.5235969361198879, 0.6078555655353742, 0.5552852696205139, 0.520846104086321, 0.5737648896896769, 0.5551422717595609, 0.5251618264447332, 0.6264186134477217, 0.5023564940000379, 0.5530354672177937, 0.551096183021909, 0.5679573082939615, 0.5326311460294565, 0.612224375530143, 0.478360288373659, 0.6482782240850965, 0.49388297294791017, 0.6183142857635585, 0.4982390831334698, 0.5200265858610797, 0.5365661202494326, 0.5730596677915454, 0.636195777002826, 0.5685025038513748, 0.5884118786812902, 0.5310648793164074, 0.6650807456519771, 0.4783999867027477, 0.6378558256807125, 0.47896194531705777, 0.5975347919319692, 0.5396779888948428, 0.5094627322726515, 0.5654282167462334, 0.5416062627309994, 0.5808260864746627, 0.6083200326126464, 0.5837272158385068, 0.4851737743786444, 0.6772727189905838, 0.5302826409626965, 0.5143053095867653, 0.5307819202593522, 0.5797892854366808, 0.5084422450730627, 0.5094493148345735, 0.6092046981173277]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5472370715161177\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5773425652290353\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49078825786740937\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6337052725494796\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4750171652603004\n","is min 0.4750171652603004 is smaller than [0.4948840490256836, 0.5078660052926143, 0.5728240523050929, 0.5976380160115027, 0.5519568512844842, 0.5235969361198879, 0.6078555655353742, 0.5552852696205139, 0.520846104086321, 0.5737648896896769, 0.5551422717595609, 0.5251618264447332, 0.6264186134477217, 0.5023564940000379, 0.5530354672177937, 0.551096183021909, 0.5679573082939615, 0.5326311460294565, 0.612224375530143, 0.478360288373659, 0.6482782240850965, 0.49388297294791017, 0.6183142857635585, 0.4982390831334698, 0.5200265858610797, 0.5365661202494326, 0.5730596677915454, 0.636195777002826, 0.5685025038513748, 0.5884118786812902, 0.5310648793164074, 0.6650807456519771, 0.4783999867027477, 0.6378558256807125, 0.47896194531705777, 0.5975347919319692, 0.5396779888948428, 0.5094627322726515, 0.5654282167462334, 0.5416062627309994, 0.5808260864746627, 0.6083200326126464, 0.5837272158385068, 0.4851737743786444, 0.6772727189905838, 0.5302826409626965, 0.5143053095867653, 0.5307819202593522, 0.5797892854366808, 0.5084422450730627, 0.5094493148345735, 0.6092046981173277, 0.47820854829774384, 0.5472370715161177, 0.5773425652290353, 0.49078825786740937, 0.6337052725494796]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6561656621608524\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4925481725644032\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.582294053894695\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5209853546229316\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5541238196134227\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6881957128530138\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4693415289876953\n","is min 0.4693415289876953 is smaller than [0.4948840490256836, 0.5078660052926143, 0.5728240523050929, 0.5976380160115027, 0.5519568512844842, 0.5235969361198879, 0.6078555655353742, 0.5552852696205139, 0.520846104086321, 0.5737648896896769, 0.5551422717595609, 0.5251618264447332, 0.6264186134477217, 0.5023564940000379, 0.5530354672177937, 0.551096183021909, 0.5679573082939615, 0.5326311460294565, 0.612224375530143, 0.478360288373659, 0.6482782240850965, 0.49388297294791017, 0.6183142857635585, 0.4982390831334698, 0.5200265858610797, 0.5365661202494326, 0.5730596677915454, 0.636195777002826, 0.5685025038513748, 0.5884118786812902, 0.5310648793164074, 0.6650807456519771, 0.4783999867027477, 0.6378558256807125, 0.47896194531705777, 0.5975347919319692, 0.5396779888948428, 0.5094627322726515, 0.5654282167462334, 0.5416062627309994, 0.5808260864746627, 0.6083200326126464, 0.5837272158385068, 0.4851737743786444, 0.6772727189905838, 0.5302826409626965, 0.5143053095867653, 0.5307819202593522, 0.5797892854366808, 0.5084422450730627, 0.5094493148345735, 0.6092046981173277, 0.47820854829774384, 0.5472370715161177, 0.5773425652290353, 0.49078825786740937, 0.6337052725494796, 0.4750171652603004, 0.6561656621608524, 0.4925481725644032, 0.582294053894695, 0.5209853546229316, 0.5541238196134227, 0.6881957128530138]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6672397965068664\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49500620680703644\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5215544571806574\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48228662254418736\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6077808725308363\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5145660473921053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5666309894745691\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5871764231582778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48388858664286044\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6165399546305611\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5142675497938971\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5576021221853583\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.577613798134162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.558728151922556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5213015480438833\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5861117191720648\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6861798917714022\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48829484520786265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6582444158532872\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47217039127068616\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6725848226887232\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5572505730403976\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5380512008864677\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4716991468872749\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5222590151591555\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5919593738026652\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5622403836968267\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5303087785275663\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5666887427819006\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5647927698330909\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5903150834326107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5116580303138311\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5241338991941729\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.571398347146196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5264924764447443\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5795551880859356\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5564511115308802\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5683081053552231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6101036990651247\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6163165750356613\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5657413382979595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5665528230004148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5086417008031434\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.649089543649678\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47825821112859435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6763061515021234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4767397873880987\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7138096830761804\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5070376146272061\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7135811884721487\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5249912918540656\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6004548757926159\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5739751566254441\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5053122269818058\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5394931477471544\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5900975792805749\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5324368788701885\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5770564643492281\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5825145831580693\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5239397043650923\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5850303260062644\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5732011162974107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.524423197526977\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5093387507102404\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5617025481438231\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5421593101486376\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5914697444320843\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5374551296758314\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5924412450810049\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5522876457851479\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6430376443064831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5479113881980906\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5869637340478449\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6034635230829273\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5706344123271898\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5625901322610141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5498242661003973\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5532543162409334\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5741506448911287\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5560348017433729\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49877018574163046\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7183437433751252\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47642056350906303\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6054001123359265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5250171475469999\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6505640366979144\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49715879929302353\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6219597867449276\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5388195408248935\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5034977580929367\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5940256854390705\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5522607822335047\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5198217968671727\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 49:48, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.243800</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.175900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.184700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.209200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.223500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.205500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.204500</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.339000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.225800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.196500</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.277200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.316900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.219500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.221300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.221600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.259400</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.317300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.255300</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.281900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.223800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.239500</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.301700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.234000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.225500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.236600</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.248400</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.283300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.233600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.307400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.117400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.258700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.259300</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.187700</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.292700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.268300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.258800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.268000</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.236700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.177700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.153900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.150800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.142100</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.173700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.228500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.112700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.117700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.123000</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.215500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.206800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.134200</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.191800</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.132600</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.179600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.148600</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.176400</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.119800</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.197400</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.169200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.126800</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.172800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.126100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.173600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.162100</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.124700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.216400</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.130500</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.190400</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.142900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.119700</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.155300</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.149400</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.204300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.217400</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.176100</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.181800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.158300</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.157800</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.164000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.089300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.101000</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.079900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.133300</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.083200</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.085700</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.095500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.088100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.121900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.077100</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.096500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.076300</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.084600</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.113800</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.089800</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.086200</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.117500</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.086000</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.096100</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.074000</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.121400</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.075400</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.060800</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.104500</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.071400</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.069000</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.093400</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.084400</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.096800</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.072700</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.074400</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.078100</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.064100</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.058300</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.060100</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.075100</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.047300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.059000</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.035600</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.054700</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.037800</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.064500</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.071200</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.062000</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.058500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.035300</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.054500</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.038900</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.032600</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.057100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.059200</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.036100</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.065400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.050100</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.088000</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.049800</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.059000</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.040100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4406685715811537\n","is min 0.4406685715811537 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4613656371127895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4951817407946888\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4897130126464626\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49118732405602755\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5121444964374217\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48722418573453086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5565005480334592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5202186957800131\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4965317284846876\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.509032744376932\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5085169359881748\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.517147001240329\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43568688224736934\n","is min 0.43568688224736934 is smaller than [0.4406685715811537, 0.4613656371127895, 0.4951817407946888, 0.4897130126464626, 0.49118732405602755, 0.5121444964374217, 0.48722418573453086, 0.5565005480334592, 0.5202186957800131, 0.4965317284846876, 0.509032744376932, 0.5085169359881748, 0.517147001240329]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5665820978269905\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5716218269460692\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44646351846294025\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6200271475025478\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.42576029021459694\n","is min 0.42576029021459694 is smaller than [0.4406685715811537, 0.4613656371127895, 0.4951817407946888, 0.4897130126464626, 0.49118732405602755, 0.5121444964374217, 0.48722418573453086, 0.5565005480334592, 0.5202186957800131, 0.4965317284846876, 0.509032744376932, 0.5085169359881748, 0.517147001240329, 0.43568688224736934, 0.5665820978269905, 0.5716218269460692, 0.44646351846294025, 0.6200271475025478]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4520690631316599\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5141389938177311\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6355632032480303\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4394368904641447\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5722051698934973\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49731240978493557\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5102830518887735\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5153672014997424\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5910326095153756\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47024872268901385\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49586492889438266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5414569944534448\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4330841770226568\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6432388661192281\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4682088744047761\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5386679588633989\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4423658233132299\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5873406582064804\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48484721830748095\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43639904955345493\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5142180051430477\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5794651796782371\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4488298386849968\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6095805455934613\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4661917040996515\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5513398824445229\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46090438205741663\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45943730271438554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6062624921966003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.494500894069822\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.524932379439028\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5903468802407577\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4608543926016966\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5105441285249178\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4940054289585106\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5913141316878967\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5112884443977759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4907221478267392\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47109488856008086\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5358517765087276\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4815909043606959\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5251945764278676\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48072058126183015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6241069962367677\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46616503682054283\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5252402768273013\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49551452193950035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5062865695782752\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.627162324858975\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47675081151565724\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5251871788329264\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4399264610782547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5240016579737108\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47464928370665393\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5231583989797164\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.517656246769517\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5562867704537025\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5421977416464253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5000855731599971\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.444213270571171\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6386462996025272\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4651285258098409\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4913835074102211\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46658171725624165\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.543360205025317\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6277433019453997\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48143170273102154\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5249384435455032\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5967108270941183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4638588800332777\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5642722535248591\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46252190583309793\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45809988117611\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6157369253068131\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4255911220635944\n","is min 0.4255911220635944 is smaller than [0.4406685715811537, 0.4613656371127895, 0.4951817407946888, 0.4897130126464626, 0.49118732405602755, 0.5121444964374217, 0.48722418573453086, 0.5565005480334592, 0.5202186957800131, 0.4965317284846876, 0.509032744376932, 0.5085169359881748, 0.517147001240329, 0.43568688224736934, 0.5665820978269905, 0.5716218269460692, 0.44646351846294025, 0.6200271475025478, 0.42576029021459694, 0.4520690631316599, 0.5141389938177311, 0.6355632032480303, 0.4394368904641447, 0.5722051698934973, 0.49731240978493557, 0.5102830518887735, 0.5153672014997424, 0.5910326095153756, 0.47024872268901385, 0.49586492889438266, 0.5414569944534448, 0.4330841770226568, 0.6432388661192281, 0.4682088744047761, 0.5386679588633989, 0.4423658233132299, 0.5873406582064804, 0.48484721830748095, 0.43639904955345493, 0.5142180051430477, 0.5794651796782371, 0.4488298386849968, 0.6095805455934613, 0.4661917040996515, 0.5513398824445229, 0.46090438205741663, 0.45943730271438554, 0.6062624921966003, 0.494500894069822, 0.524932379439028, 0.5903468802407577, 0.4608543926016966, 0.5105441285249178, 0.4940054289585106, 0.5913141316878967, 0.5112884443977759, 0.4907221478267392, 0.47109488856008086, 0.5358517765087276, 0.4815909043606959, 0.5251945764278676, 0.48072058126183015, 0.6241069962367677, 0.46616503682054283, 0.5252402768273013, 0.49551452193950035, 0.5062865695782752, 0.627162324858975, 0.47675081151565724, 0.5251871788329264, 0.4399264610782547, 0.5240016579737108, 0.47464928370665393, 0.5231583989797164, 0.517656246769517, 0.5562867704537025, 0.5421977416464253, 0.5000855731599971, 0.444213270571171, 0.6386462996025272, 0.4651285258098409, 0.4913835074102211, 0.46658171725624165, 0.543360205025317, 0.6277433019453997, 0.48143170273102154, 0.5249384435455032, 0.5967108270941183, 0.4638588800332777, 0.5642722535248591, 0.46252190583309793, 0.45809988117611, 0.6157369253068131]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:09,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5384002664947972\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5004852639962376\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5270961619583269\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4741529513241577\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4875681945358634\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5105072015631127\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5047345744913587\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4966070162780078\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4686573150047313\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5532821990199603\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47971508646858546\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5522371999724301\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4704330681023381\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5734371041220444\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4823799374209759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4734297970789594\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5864105770008199\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4816992001027137\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5161257759934583\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5552288354117851\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5308282028261985\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4940823356677411\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5258417482341907\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.525971738209229\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4696334670816571\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5302913869348281\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5231591280726267\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45996850753928437\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.616720971569327\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47951292932574896\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5050623170485151\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4976602248270686\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4876102868089778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48820809966595863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5929394543770358\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5416857768863714\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48966096562201333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5391896583360003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5174729167361352\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5091059260468292\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5086925382133531\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48951123784120787\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6036631796903971\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48311025963922105\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5029334023317443\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.531435880901227\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46407720391078344\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5759755406874814\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5473563946543514\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49418232795821526\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5393238992994831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5064271738531455\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5258820904965605\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4868647017988475\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5641662169689001\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5002271220390244\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5878334472413009\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48299083722550046\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5081412158460096\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5047483839053829\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4404992941155763\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5831849226135195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49148617212427675\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5183273958241672\n","Training done\n"]}],"source":["# deberta 2\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 7e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_2\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"XEgot9YgN6at"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:28, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.309600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.283600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.191800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.237300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.294900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.313900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.219700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.228100</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.190800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.232100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.198300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.166400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.256500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.253500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.179100</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.262600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.179400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.253000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.241600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.275300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.183500</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.248800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.257200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.235800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.206900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.305900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.252900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.251100</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.255900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.239800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.269800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.275900</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.236200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.206200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.379400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.214300</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.298400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.258300</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.222500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.170500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.228700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.212700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.170300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.088200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.101900</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.165900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.191100</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.126300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.209500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.224900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.165100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.164000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.145400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.183400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.143100</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.122600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.153600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.183200</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.174900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.194500</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.182600</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.181800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.159900</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.128400</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.188700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.104700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.175800</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.180800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.187900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.163800</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.143200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.119500</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.171500</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.175600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.098300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.159700</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.090100</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.132900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.112400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.069800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.096800</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.118000</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.093000</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.079300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.072400</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.083300</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.132500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.072900</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.060300</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.086600</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.093400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.086700</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.086200</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.074800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.056600</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.062400</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.085300</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.100700</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.076500</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.096100</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.116500</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.077500</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.076000</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.078400</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.074000</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.085700</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.101600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.087200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.075100</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.060000</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.121500</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.063400</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.044700</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.088600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.065400</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.050400</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.044500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.037100</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.041700</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.059600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.053500</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.036400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.061400</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.060300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.043200</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.059700</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.034600</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.038200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47703367801001606\n","is min 0.47703367801001606 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5221506696716361\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5718476142883364\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6419265441496605\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6166129692249498\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5326910989028727\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5430578059876134\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5656817409589315\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5150571290655229\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5815989660896447\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5347773067877941\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5012151673618328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6415596664212037\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4831880855762377\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.573754708561215\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5351158291701841\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47652441401928103\n","is min 0.47652441401928103 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5016489952758868\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49404834863176456\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6507922914811309\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5029510398662091\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4817692577987704\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5884172010959134\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5753264107003344\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4764310233551438\n","is min 0.4764310233551438 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6380925393345241\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5180056921910857\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5040179088145673\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4717742390362436\n","is min 0.4717742390362436 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344, 0.4764310233551438, 0.6380925393345241, 0.5180056921910857, 0.5040179088145673]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5569355006687203\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6593605611021843\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5045907251531082\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8236392277495207\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779587009905688\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7353612737646396\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5148292314117991\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6648950589255433\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4725447033413721\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.557874436218457\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5061406819841241\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5951724728952308\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47155683071945526\n","is min 0.47155683071945526 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344, 0.4764310233551438, 0.6380925393345241, 0.5180056921910857, 0.5040179088145673, 0.4717742390362436, 0.5569355006687203, 0.6593605611021843, 0.5045907251531082, 0.8236392277495207, 0.4779587009905688, 0.7353612737646396, 0.5148292314117991, 0.6648950589255433, 0.4725447033413721, 0.557874436218457, 0.5061406819841241, 0.5951724728952308]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5930435525195703\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5089193600268562\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5761309321169713\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5224321631883367\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5968938119525932\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46804638704355506\n","is min 0.46804638704355506 is smaller than [0.47703367801001606, 0.5221506696716361, 0.5718476142883364, 0.6419265441496605, 0.6166129692249498, 0.5326910989028727, 0.5430578059876134, 0.5656817409589315, 0.5150571290655229, 0.5815989660896447, 0.5347773067877941, 0.5012151673618328, 0.6415596664212037, 0.4831880855762377, 0.573754708561215, 0.5351158291701841, 0.47652441401928103, 0.5016489952758868, 0.49404834863176456, 0.6507922914811309, 0.5029510398662091, 0.4817692577987704, 0.5884172010959134, 0.5753264107003344, 0.4764310233551438, 0.6380925393345241, 0.5180056921910857, 0.5040179088145673, 0.4717742390362436, 0.5569355006687203, 0.6593605611021843, 0.5045907251531082, 0.8236392277495207, 0.4779587009905688, 0.7353612737646396, 0.5148292314117991, 0.6648950589255433, 0.4725447033413721, 0.557874436218457, 0.5061406819841241, 0.5951724728952308, 0.47155683071945526, 0.5930435525195703, 0.5089193600268562, 0.5761309321169713, 0.5224321631883367, 0.5968938119525932]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7453988639775931\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4691394899258918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.679801744591401\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362558713283687\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5802365520335829\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5020308579075499\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6426111365921265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5396927012792163\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5470416931213515\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5579438258900236\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5709270101661293\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49494011280418915\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5466867277518042\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5881087546007047\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5269512135225746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5581269148823998\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5414285669482821\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5372871319272573\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6862310661924542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5318939744851962\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5532583739722806\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5630463871826742\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6232809763095079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5375853819340598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.530565453813205\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6160095070240592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5394420816270895\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5414822739609443\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5242688911163156\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5443419541127834\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6828392176860659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4998431459606332\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5338755611839251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6422497739343693\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5517647313748648\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4689763768144568\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6281335404558498\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5737914733186674\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5603309941576761\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362848924513425\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5716035163198269\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6651077084340784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.512295815325008\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5733000204549534\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327602947170454\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5685657220221865\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6095086926111724\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6277854741114055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5129538929644024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5809242914577333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5431719701047886\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5535497247839285\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5339983184469523\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.65578572888162\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5231561103463475\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5652360941663727\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5193087587764121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6328747119264554\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5638012366085483\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5784397124890265\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.593692753105692\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5671328932557911\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5056760727923532\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6177536623322608\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5170260800447141\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5694686971380368\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5661820800798948\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5007135294316831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6646445884273944\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5150136278527121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5701978123166815\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6063318088527985\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5814675884562527\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5648089227144053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5643418048344861\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6064759777773288\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5618868075234085\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5476825586511775\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5808053690693121\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5517903632678235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.523372609967995\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5938355907827831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5616149231516502\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5368710559055542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6058465058960971\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5133460959453876\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5529807581981707\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5655897759716327\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5433915176709639\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5954302456998195\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5368292198375011\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5892022443867176\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5727246768464208\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5174877543336114\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6068093620842527\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5578784558330329\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5665567139192612\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5615202144862046\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5621921783113997\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5271811834107533\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5430258322258779\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.553785552588941\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5365164411130097\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5585522756967048\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5470285361838741\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5981448670435362\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5193757563451824\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5529271799133848\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6043110776578204\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5114352477510816\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1576' max='1576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1576/1576 50:31, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.231200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.250500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.149600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.212300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.293000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.265700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.258000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.178700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.262100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.210100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.218200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.311000</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.307900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.248000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.282300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.251900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.180500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.218100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.209400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.268800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.260900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.272100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.227800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.235500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.288200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.212100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.251900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.231900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.340000</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.243800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.346500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.192200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.252700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.251300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.141200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.242600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.267900</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.285200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.216100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.230600</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.174500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.191700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.176200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.142800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.215500</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.112200</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.125600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.138400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.234600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.171200</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.102000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.200800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.172900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.133600</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.158500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.197200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.196700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.176700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.207200</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.208400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.139000</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.224500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.234900</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.191100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.168500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.229700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.162900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.111000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.200900</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.182200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.102900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.192800</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.167600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.111800</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.124800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.178300</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.108000</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.149400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.083400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.089700</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.094900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.099200</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.076700</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.058700</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.114900</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.081400</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.119400</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.112900</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.090500</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.087800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.098400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.076200</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.098800</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.096400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.092100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.074900</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.115600</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.113700</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.077200</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.059100</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.114700</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.096500</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.082500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.086000</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.107700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.124800</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.111100</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.087800</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.073000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.066000</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.060400</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.033000</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.047300</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.080400</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.035200</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.032000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.074500</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.089100</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.077500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.055700</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.063600</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.043000</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.043600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.052700</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.031200</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.039200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4779189142115054\n","is min 0.4779189142115054 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5078425572813257\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.553386152041744\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5920353677214419\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4916489285023035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.498862157755009\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5719067732936266\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5257007517324956\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5577176616797201\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5322195297824196\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49327249593616035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5241554717604623\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5379911169079183\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6699807609393124\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4794605517040894\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6475966580053409\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5019959362300873\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4749109066539285\n","is min 0.4749109066539285 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5423986219532434\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.474580201839206\n","is min 0.474580201839206 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7255309027543988\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4685621200883598\n","is min 0.4685621200883598 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434, 0.474580201839206, 0.7255309027543988]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5455682361445073\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5194289017321368\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5130006391669236\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5576259613702758\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5582287076055473\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47936017095351907\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6055120342138925\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5456576983087031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5169296879354051\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4652793814580609\n","is min 0.4652793814580609 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434, 0.474580201839206, 0.7255309027543988, 0.4685621200883598, 0.5455682361445073, 0.5194289017321368, 0.5130006391669236, 0.5576259613702758, 0.5582287076055473, 0.47936017095351907, 0.6055120342138925, 0.5456576983087031, 0.5169296879354051]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5230697756565715\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5241675863013191\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5455541279795989\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5206055006999931\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5722734566130102\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5141795628488773\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6480964929333759\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4830989709491082\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6059356434627031\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49691584896230273\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5694222068215262\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5709800530925823\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362996050229508\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.520797450487917\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5128396427574151\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5365154943259912\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4959396493175762\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4664682378251304\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5757590803688307\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4826815658788871\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6212309540483844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4884502147966541\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6628725811145003\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48754279072924783\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6579478220929482\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5058323258322253\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6258678949783816\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5009611044888808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5468364597761148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6231195594746775\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.488930434304781\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5494189279174589\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5502206757522247\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6251688141646902\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46621786305169244\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.630925279145884\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5227015576472264\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.640445023238784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4945754957917079\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7414215115908128\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46968437233388305\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6071009918709347\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5178351629224457\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46410988326144326\n","is min 0.46410988326144326 is smaller than [0.4779189142115054, 0.5078425572813257, 0.553386152041744, 0.5920353677214419, 0.4916489285023035, 0.498862157755009, 0.5719067732936266, 0.5257007517324956, 0.5577176616797201, 0.5322195297824196, 0.49327249593616035, 0.5241554717604623, 0.5379911169079183, 0.6699807609393124, 0.4794605517040894, 0.6475966580053409, 0.5019959362300873, 0.4749109066539285, 0.5423986219532434, 0.474580201839206, 0.7255309027543988, 0.4685621200883598, 0.5455682361445073, 0.5194289017321368, 0.5130006391669236, 0.5576259613702758, 0.5582287076055473, 0.47936017095351907, 0.6055120342138925, 0.5456576983087031, 0.5169296879354051, 0.4652793814580609, 0.5230697756565715, 0.5241675863013191, 0.5455541279795989, 0.5206055006999931, 0.5722734566130102, 0.5141795628488773, 0.6480964929333759, 0.4830989709491082, 0.6059356434627031, 0.49691584896230273, 0.5694222068215262, 0.5709800530925823, 0.5362996050229508, 0.520797450487917, 0.5128396427574151, 0.5365154943259912, 0.4959396493175762, 0.4664682378251304, 0.5757590803688307, 0.4826815658788871, 0.6212309540483844, 0.4884502147966541, 0.6628725811145003, 0.48754279072924783, 0.6579478220929482, 0.5058323258322253, 0.6258678949783816, 0.5009611044888808, 0.5468364597761148, 0.6231195594746775, 0.488930434304781, 0.5494189279174589, 0.5502206757522247, 0.6251688141646902, 0.46621786305169244, 0.630925279145884, 0.5227015576472264, 0.640445023238784, 0.4945754957917079, 0.7414215115908128, 0.46968437233388305, 0.6071009918709347, 0.5178351629224457]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5546390562364023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5359136650283193\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5039022561355481\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.502077094170129\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5668251470232049\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5153162526925182\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49281436844705584\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5509129382526858\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5715530450142052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5802916313717328\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5358364206865761\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6337576399139738\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5479519095490102\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5130221704591326\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6088081585847022\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5123259665071217\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5756517744598628\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5794441845043234\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5337250804990521\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6053442664226699\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.496557686827873\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5868315659568863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5872344994094415\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4914313644625566\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6320631087662177\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5137643803706039\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6485577538581658\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4769672412156923\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5881123054927584\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6115116452545251\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5406242082782831\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5564179067405235\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49849047591392814\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5421631710713625\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6159972568850012\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.496248564223014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6597055089234516\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4840178655735573\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6888549548969547\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5123346161234134\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6121070372270002\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5356749817038148\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5285640172445434\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5930204312398052\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5447187642659863\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.482252023758197\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5375252495672748\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.561744786244394\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5610433880650918\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5192668668942432\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5522927492295379\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5740891867873107\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5075299796480847\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5147202168276245\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.601477794279395\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5510716238214055\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49978456973784746\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5631518868907385\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5145920357366808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5799510468518355\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5391334457591738\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5587705446330001\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5413187294871035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5073798122950983\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.59603486044167\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948355950579042\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48940474513911025\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6380535794183867\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.510408849528039\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.527301115868737\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5535149933184556\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5212378309512435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5343256638691117\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5063830556814892\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5588043810322043\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5463276764368382\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5627971477345166\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.552914988358854\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5405408022405219\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462523296635715\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5076969836219132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:10,  1.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5124533041809607\n","Training done\n"]}],"source":["# deberta 3\n","# This deberta model was trained on data sampled using bootstrapping instead of cross validation\n","# Only models trained on 2 folds/bags were used in the final submission\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.08,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_3\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg,\n","    kfolds=[0,1]\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"aKRTt-uUPVAm"},"outputs":[],"source":["# Training the ELECTRA model\n","ELECTRA_PRETRAINED = os.path.join(BASE_PATH, 'models/electra-large-augmented')"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"aiQ3rJsUPXSq"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 47:34, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.511600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.435300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.253000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.225700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.304800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.321100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.205600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.224100</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.181800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.220100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.184100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.169900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.197000</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.234500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.177800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.247200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.163300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.254400</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.226800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.223400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.187100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.213700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.227100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.223500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.194500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.340800</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.247500</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.213400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.266000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.239800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.224900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.214700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.248900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.286800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.429200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.178300</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.227400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.226700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.202100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.231800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.194300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.181300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.129200</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.147300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.146800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.160500</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.181400</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.139500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.196300</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.219200</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.137900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.128700</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.154000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.196800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.109300</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.165700</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.118300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.198800</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.211700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.227000</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.198200</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.160500</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.156600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.119500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.242800</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.125700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.174300</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.230100</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.237100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.172500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.159500</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.143000</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.166600</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.201500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.126000</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.136800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.178500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.126600</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.132300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.132100</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.108900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.094100</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.056700</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.089200</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.110200</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.074500</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.070300</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.092400</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.061500</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.078100</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.090200</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.075100</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.104700</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.109500</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.111400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.120000</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.071000</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.139200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.092600</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.109300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.091400</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.084500</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.106200</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.107100</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.144300</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.103100</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.130100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.100600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.147700</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.110400</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.085900</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.084300</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.077700</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.155200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.064000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.102000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.068000</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.060500</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.056900</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.063300</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.067300</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.048100</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.058800</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.045300</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.067000</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.047000</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.063000</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.044100</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.067000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.060400</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.066000</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.076100</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.059500</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.078500</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.068200</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.050400</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.074100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.055700</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.055900</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.063100</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.039800</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.071600</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.044200</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.034000</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.028600</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.044300</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.025000</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.019500</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.041600</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.016800</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.033800</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.063200</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.048600</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.029700</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.015600</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.031400</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.035500</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.017500</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.027600</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.037000</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.023500</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.058300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:06,  2.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5009080389472447\n","is min 0.5009080389472447 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4743486688152853\n","is min 0.4743486688152853 is smaller than [0.5009080389472447]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.13it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5225706433315885\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.12it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6160605771969736\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.11it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6382010679233308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.10it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5662980337163501\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.09it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5465426867326635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.08it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4991890176741984\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.07it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5482363833998807\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.07it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5675167576447858\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.06it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5001070152398867\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.06it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5063636421802385\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5309302040355673\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5055831554952701\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5431798138798046\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5940536030752515\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.452075394893819\n","is min 0.452075394893819 is smaller than [0.5009080389472447, 0.4743486688152853, 0.5225706433315885, 0.6160605771969736, 0.6382010679233308, 0.5662980337163501, 0.5465426867326635, 0.4991890176741984, 0.5482363833998807, 0.5675167576447858, 0.5001070152398867, 0.5063636421802385, 0.5309302040355673, 0.5055831554952701, 0.5431798138798046, 0.5940536030752515]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5179319253957161\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5472864754700006\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5442724530953952\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.556295628861381\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4470399618086103\n","is min 0.4470399618086103 is smaller than [0.5009080389472447, 0.4743486688152853, 0.5225706433315885, 0.6160605771969736, 0.6382010679233308, 0.5662980337163501, 0.5465426867326635, 0.4991890176741984, 0.5482363833998807, 0.5675167576447858, 0.5001070152398867, 0.5063636421802385, 0.5309302040355673, 0.5055831554952701, 0.5431798138798046, 0.5940536030752515, 0.452075394893819, 0.5179319253957161, 0.5472864754700006, 0.5442724530953952, 0.556295628861381]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.635008128553017\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49439762559009826\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45721914938777214\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5920138427420982\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5455096915482932\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4919652605679019\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4543283774023412\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49821355623598323\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6045651171460227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5008735130083749\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8806907504655527\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4587529994311977\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462066656127003\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5288642956521562\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5813166562319511\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5918548937757215\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5124987948797197\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5543500683970375\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5674304934630633\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5250137735980589\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5289818959478124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6105875654484796\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5390881702793875\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262842096437838\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6180937683855192\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5406815258017558\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6564066601185728\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5084860696951615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6878238968896779\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5764184229131467\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5762553932817907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48712347137470186\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6093676774084716\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5670452367433103\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5419665384695873\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5461190067956072\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6257117068926271\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4584965399018303\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5616477408741505\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5818889188469597\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6200474398399324\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5190033937117368\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5146820664208628\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5966548829985031\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6741119664297603\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5131008070028458\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5330848774886606\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5089006322831566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6867780213691439\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48402927169684223\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5316860529022394\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5875914821808895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.564953467076567\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5254407915115565\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5350815524926863\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5809358045748564\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6195374094755188\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4503795620583465\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5380150388725204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5304633467249588\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5141625205239462\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5410572590081669\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6085314538951158\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.534228236796715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5334558182898268\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6401621015405372\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5368350820805937\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5795878418238335\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5426444920254575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5402225013864222\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5245264393704852\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7071608663475211\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5526490128169713\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5848984863131443\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5971409447643935\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5574986528953901\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5208996799064975\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4883591250753123\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5708675604377793\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5825203759436023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5244620278826039\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5195596119957296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5430055512178512\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5898162548770616\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6283169192617287\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6253479066240057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5365036113123726\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5352913947337427\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5508309030756054\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5523159840796822\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6054165159169301\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5083867082292152\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5849175624654628\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5079680220134665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6777698883577107\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.576390475822554\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4861117638468423\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5825055219924761\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6049432664825845\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5477954223002309\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5690600217541871\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6823857934513162\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5374619633348527\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5947163326199356\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6699196888560064\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5403068381023579\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5144881940180625\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6576357434489568\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5506394818847432\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6058373431122032\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5816312565840515\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5324181188174302\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6353488520531125\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5450843033794679\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5279229937520674\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.646257174704191\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5488021001333023\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.549640806254794\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6488573574543881\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5345852346611347\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.608956279907861\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5418592504987386\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6012983871086824\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5461569083701614\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6305368960618214\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49213918538076257\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6157397952516981\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5851542937231693\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5318053870337699\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.57483965236951\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5566408179438979\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5751859404969432\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5531058544284253\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5803251261717538\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5568518848847127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5837315600471434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.553515482359258\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5878298913995477\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5836960588629941\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5685926632773343\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5377335088870867\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5581456093274016\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5911961282705843\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5310946482964363\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5728565329340675\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6172225137973302\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6053483656864134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5418425602995105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5693214426991106\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5656133036474607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6468679702875987\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4953568416796801\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6037823550279985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5396432907480007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5630756259099049\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5489203088230562\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5692467276776785\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5458125171938576\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5887520131689152\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5790066663496661\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5999348876194817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5584596211455009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5192999136021428\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5768375299688485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6087162439991227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5671971360238977\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6119529947193664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5570613334051597\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5626483307007281\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.560076712095255\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6092999185021084\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5378599378212447\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.621131948038274\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5523534350908857\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5499394302189454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5499394302189454\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 48:38, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.430600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.353900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.181000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.222900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.265100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.278500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.226900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.204200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.287700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.184300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.203400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.307700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.290500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.242500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.247500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.161600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.289500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.176300</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.215500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.191200</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.231000</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.239900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.279400</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.260600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.238800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.272300</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.221300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.195300</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.217600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.241000</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.227600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.382500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.203300</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.254900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.243700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.141100</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.279100</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.189200</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.264500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.171500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.254900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.198400</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.198400</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.151400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.159700</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.188400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.153300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.106300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.125900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.221500</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.186300</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.113300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.208500</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.167300</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.146400</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.139900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.165800</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.156600</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.140000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.186100</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.161800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.166700</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.178600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.186000</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.174700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.141900</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.207400</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.168800</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.096200</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.195100</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.167600</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.139700</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.196400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.213100</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.121600</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.151400</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.136000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.145500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.178100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.077100</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.088300</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.117900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.067900</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.108000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.107800</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.085100</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.056900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.076500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.118600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.084900</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.104600</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.142700</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.112400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.079100</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.098400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.087600</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.078400</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.118200</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.078600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.104100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.099900</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.103100</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.082700</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.092900</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.082900</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.176100</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.091400</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.092600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.075800</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.091600</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.105300</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.095100</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.099600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.108900</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.091800</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.072700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.091800</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.073000</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.059900</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.083700</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.054700</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.067800</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.062000</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.039900</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.050000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.063100</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.032500</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.053500</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.047500</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.067900</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.081200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.079200</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.055300</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.057600</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.062400</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.042400</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.052600</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.048900</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.027000</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.058400</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.024500</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.035500</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.036100</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.025300</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.034900</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.025200</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.041800</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.056600</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.035300</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.052700</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.042700</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.028000</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.029500</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.046900</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.034600</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.043700</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.047900</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.026800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5178825147259969\n","is min 0.5178825147259969 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4898355332109073\n","is min 0.4898355332109073 is smaller than [0.5178825147259969]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5348420312558819\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6113428391919087\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5711320693013227\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5165303378263189\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5573317224809442\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5489048577508163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5228493257908147\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5209567626539846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4987182014190159\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5486287921060833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5474409534396321\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6430005635478102\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4957546127586365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5981319849765698\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49259680227882996\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5610446684075747\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5106729609349291\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48239435976372436\n","is min 0.48239435976372436 is smaller than [0.5178825147259969, 0.4898355332109073, 0.5348420312558819, 0.6113428391919087, 0.5711320693013227, 0.5165303378263189, 0.5573317224809442, 0.5489048577508163, 0.5228493257908147, 0.5209567626539846, 0.4987182014190159, 0.5486287921060833, 0.5474409534396321, 0.6430005635478102, 0.4957546127586365, 0.5981319849765698, 0.49259680227882996, 0.5610446684075747, 0.5106729609349291]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7152227575850586\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4739144391176035\n","is min 0.4739144391176035 is smaller than [0.5178825147259969, 0.4898355332109073, 0.5348420312558819, 0.6113428391919087, 0.5711320693013227, 0.5165303378263189, 0.5573317224809442, 0.5489048577508163, 0.5228493257908147, 0.5209567626539846, 0.4987182014190159, 0.5486287921060833, 0.5474409534396321, 0.6430005635478102, 0.4957546127586365, 0.5981319849765698, 0.49259680227882996, 0.5610446684075747, 0.5106729609349291, 0.48239435976372436, 0.7152227575850586]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5735565372092666\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4705998597640887\n","is min 0.4705998597640887 is smaller than [0.5178825147259969, 0.4898355332109073, 0.5348420312558819, 0.6113428391919087, 0.5711320693013227, 0.5165303378263189, 0.5573317224809442, 0.5489048577508163, 0.5228493257908147, 0.5209567626539846, 0.4987182014190159, 0.5486287921060833, 0.5474409534396321, 0.6430005635478102, 0.4957546127586365, 0.5981319849765698, 0.49259680227882996, 0.5610446684075747, 0.5106729609349291, 0.48239435976372436, 0.7152227575850586, 0.4739144391176035, 0.5735565372092666]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5667721078086266\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4821554035259073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5319921819550707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5514999691697196\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49097061557043475\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5765719165418743\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5159361159861858\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5142429941183051\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46761469595509403\n","is min 0.46761469595509403 is smaller than [0.5178825147259969, 0.4898355332109073, 0.5348420312558819, 0.6113428391919087, 0.5711320693013227, 0.5165303378263189, 0.5573317224809442, 0.5489048577508163, 0.5228493257908147, 0.5209567626539846, 0.4987182014190159, 0.5486287921060833, 0.5474409534396321, 0.6430005635478102, 0.4957546127586365, 0.5981319849765698, 0.49259680227882996, 0.5610446684075747, 0.5106729609349291, 0.48239435976372436, 0.7152227575850586, 0.4739144391176035, 0.5735565372092666, 0.4705998597640887, 0.5667721078086266, 0.4821554035259073, 0.5319921819550707, 0.5514999691697196, 0.49097061557043475, 0.5765719165418743, 0.5159361159861858, 0.5142429941183051]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6015593632803687\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48214114150309756\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5389429603513216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6352123711910814\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5158297411416667\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6183571787950004\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4693524096370333\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6779171469472217\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4618576351964693\n","is min 0.4618576351964693 is smaller than [0.5178825147259969, 0.4898355332109073, 0.5348420312558819, 0.6113428391919087, 0.5711320693013227, 0.5165303378263189, 0.5573317224809442, 0.5489048577508163, 0.5228493257908147, 0.5209567626539846, 0.4987182014190159, 0.5486287921060833, 0.5474409534396321, 0.6430005635478102, 0.4957546127586365, 0.5981319849765698, 0.49259680227882996, 0.5610446684075747, 0.5106729609349291, 0.48239435976372436, 0.7152227575850586, 0.4739144391176035, 0.5735565372092666, 0.4705998597640887, 0.5667721078086266, 0.4821554035259073, 0.5319921819550707, 0.5514999691697196, 0.49097061557043475, 0.5765719165418743, 0.5159361159861858, 0.5142429941183051, 0.46761469595509403, 0.6015593632803687, 0.48214114150309756, 0.5389429603513216, 0.6352123711910814, 0.5158297411416667, 0.6183571787950004, 0.4693524096370333, 0.6779171469472217]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5625990759584141\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5476926070143752\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5402129633102397\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4966403641316018\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5479998157723992\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5657215267211102\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48152291200874553\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5077785416899127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4988884927222828\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.541870843637831\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5845205086287921\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5271824513258891\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6510427834782656\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4740338547491173\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5311815690376476\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5687244600016714\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.638752729803063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5580669378281073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5957653132296018\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5402352555336349\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44886366620650026\n","is min 0.44886366620650026 is smaller than [0.5178825147259969, 0.4898355332109073, 0.5348420312558819, 0.6113428391919087, 0.5711320693013227, 0.5165303378263189, 0.5573317224809442, 0.5489048577508163, 0.5228493257908147, 0.5209567626539846, 0.4987182014190159, 0.5486287921060833, 0.5474409534396321, 0.6430005635478102, 0.4957546127586365, 0.5981319849765698, 0.49259680227882996, 0.5610446684075747, 0.5106729609349291, 0.48239435976372436, 0.7152227575850586, 0.4739144391176035, 0.5735565372092666, 0.4705998597640887, 0.5667721078086266, 0.4821554035259073, 0.5319921819550707, 0.5514999691697196, 0.49097061557043475, 0.5765719165418743, 0.5159361159861858, 0.5142429941183051, 0.46761469595509403, 0.6015593632803687, 0.48214114150309756, 0.5389429603513216, 0.6352123711910814, 0.5158297411416667, 0.6183571787950004, 0.4693524096370333, 0.6779171469472217, 0.4618576351964693, 0.5625990759584141, 0.5476926070143752, 0.5402129633102397, 0.4966403641316018, 0.5479998157723992, 0.5657215267211102, 0.48152291200874553, 0.5077785416899127, 0.4988884927222828, 0.541870843637831, 0.5845205086287921, 0.5271824513258891, 0.6510427834782656, 0.4740338547491173, 0.5311815690376476, 0.5687244600016714, 0.638752729803063, 0.5580669378281073, 0.5957653132296018, 0.5402352555336349]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5403442708802063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5676379839729706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6720306039644707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4431589232458016\n","is min 0.4431589232458016 is smaller than [0.5178825147259969, 0.4898355332109073, 0.5348420312558819, 0.6113428391919087, 0.5711320693013227, 0.5165303378263189, 0.5573317224809442, 0.5489048577508163, 0.5228493257908147, 0.5209567626539846, 0.4987182014190159, 0.5486287921060833, 0.5474409534396321, 0.6430005635478102, 0.4957546127586365, 0.5981319849765698, 0.49259680227882996, 0.5610446684075747, 0.5106729609349291, 0.48239435976372436, 0.7152227575850586, 0.4739144391176035, 0.5735565372092666, 0.4705998597640887, 0.5667721078086266, 0.4821554035259073, 0.5319921819550707, 0.5514999691697196, 0.49097061557043475, 0.5765719165418743, 0.5159361159861858, 0.5142429941183051, 0.46761469595509403, 0.6015593632803687, 0.48214114150309756, 0.5389429603513216, 0.6352123711910814, 0.5158297411416667, 0.6183571787950004, 0.4693524096370333, 0.6779171469472217, 0.4618576351964693, 0.5625990759584141, 0.5476926070143752, 0.5402129633102397, 0.4966403641316018, 0.5479998157723992, 0.5657215267211102, 0.48152291200874553, 0.5077785416899127, 0.4988884927222828, 0.541870843637831, 0.5845205086287921, 0.5271824513258891, 0.6510427834782656, 0.4740338547491173, 0.5311815690376476, 0.5687244600016714, 0.638752729803063, 0.5580669378281073, 0.5957653132296018, 0.5402352555336349, 0.44886366620650026, 0.5403442708802063, 0.5676379839729706, 0.6720306039644707]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6780857774331311\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5292254781369932\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5899217960856716\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5265159667462013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7247502207866766\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47057170544415217\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5919128358743445\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.538118951683689\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47112725000470984\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5771511247795039\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5722454544753265\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327236906433331\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5424349214817149\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48171331161033715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6442268466044039\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5113561918713491\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5181102668826122\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6931812790950868\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5585354378014359\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5885990692012485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6187780345072513\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5884162523249296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5222603844863805\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5401606621870052\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5897934364415082\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6097512022201836\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5311481229803944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6046726180127017\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.626454759957045\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4990126933936122\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5950782261562318\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6308842193740968\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4883689132552575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5790538997826513\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5829320699047269\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5777370492384476\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.523873961775929\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5395561713989454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6471607497355691\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4917815110164057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5776350653579496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5470355334894542\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5504849608972181\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5384131399706498\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5114245344755639\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6618415528599217\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48082655213598496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6287636448151391\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5251242787618013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.55074006497367\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6038428693943289\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5299662686745698\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6493681928970845\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.567831322371697\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5226616825093009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5841508810191848\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6561031209899366\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5233648852648595\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6165480210202072\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5097975717688901\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5851845809469134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.625339873560987\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5564339635946703\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5426996894831048\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.565995236736846\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4845829420256834\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5566597375474804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5791202496487073\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5832060986148615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6014100626990784\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5125424195485261\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6408059146035107\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4762810021618039\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5853632411679526\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6396950764548999\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5296400152099263\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6439917794349276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4814486118088919\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5832044077376233\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5890968788388654\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49791260830286066\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.649931836560901\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5166774608705778\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6514468340512105\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48013972281115486\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.732855858385583\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5157753475675168\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6051836989419692\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5515862889929034\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.547152182494112\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6391792281989621\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48945830559071163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5932804196431741\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5783124990801313\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5373796320999583\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5277654864553628\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5752581653080927\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462596929921004\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.626739872089146\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5333351229996413\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5468116804867136\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5270545397300906\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6131643438684246\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6185106611018664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5147755332646428\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.583644585721271\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5156510183159866\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5807182850918627\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5691480278175308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6043976201595364\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5886127963519461\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5319693832386081\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6128894986828413\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4958175556265222\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.612211976405143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5743748473971383\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6250867659790373\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5148745675424862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5988303939006131\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327532650516439\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.665577625179622\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5141085523450684\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5841339094385142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5693040463985662\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.558643347160646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5784793575792035\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5256344657583937\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5410450052520142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6224573791419451\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5297133358935108\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5297133358935108\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 47:45, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.463200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.354900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.280900</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.255700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.184000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.191200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.193700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.234800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.208800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.217600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.215400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.244800</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.246000</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.201700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.244700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.163100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.255700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.282800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.284100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.330600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.261600</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.255400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.333500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.205700</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.200800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.205700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.226600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.201500</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.217700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.207500</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.309000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.288000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.327400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.220100</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.217900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.211500</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.281300</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.158100</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.226400</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.144900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.110000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.170600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.160000</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.126400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.142100</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.169300</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.125600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.191500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.128300</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.160300</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.124400</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.179300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.204400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.184200</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.135400</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.138800</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.201700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.189700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.194400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.111400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.156200</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.163000</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.169600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.183300</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.157700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.126500</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.187900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.140800</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.188100</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.126700</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.145400</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.128300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.184200</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.151000</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.151700</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.193800</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.130200</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.131700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.109500</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.089900</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.089400</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.114800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.118800</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.110500</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.106600</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.107900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.078000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.112600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.098300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.060700</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.085600</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.094500</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.074500</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.071400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.098700</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.075300</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.075000</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.103300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.091600</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.100700</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.073600</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.103900</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.123000</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.068400</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.064700</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.141600</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.085200</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.136500</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.077300</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.114000</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.128800</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.087800</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.090900</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.104600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.083200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.056800</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.074900</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.058100</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.048600</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.078700</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.066300</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.052800</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.066900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.052200</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.068200</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.076800</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.040700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.064900</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.044900</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.054800</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.046900</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.053400</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.038800</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.054500</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.039700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.065600</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.057000</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.078400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.033500</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.051400</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.057000</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.054000</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.066600</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.043000</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.021400</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.032100</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.043900</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.040400</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.027400</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.028100</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.027500</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.035700</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.038400</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.046600</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.029100</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.031900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.052900</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.020600</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.026700</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.032300</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.050800</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.044800</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.029900</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.024300</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.046300</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.033400</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.060700</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.037000</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.029500</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.030600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.528655079860063\n","is min 0.528655079860063 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49829697134955564\n","is min 0.49829697134955564 is smaller than [0.528655079860063]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.523259589056835\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5435293435224381\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5223499332397478\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5300755011646934\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5077973531561366\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5924259521633074\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5461025343589012\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6026509909073721\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5734987325678207\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5616790609825003\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5522866757183748\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.577526305758584\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5737803673457664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5423513581910364\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5631718625700611\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49290504537806834\n","is min 0.49290504537806834 is smaller than [0.528655079860063, 0.49829697134955564, 0.523259589056835, 0.5435293435224381, 0.5223499332397478, 0.5300755011646934, 0.5077973531561366, 0.5924259521633074, 0.5461025343589012, 0.6026509909073721, 0.5734987325678207, 0.5616790609825003, 0.5522866757183748, 0.577526305758584, 0.5737803673457664, 0.5423513581910364, 0.5631718625700611]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6713015664821476\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4833085590461714\n","is min 0.4833085590461714 is smaller than [0.528655079860063, 0.49829697134955564, 0.523259589056835, 0.5435293435224381, 0.5223499332397478, 0.5300755011646934, 0.5077973531561366, 0.5924259521633074, 0.5461025343589012, 0.6026509909073721, 0.5734987325678207, 0.5616790609825003, 0.5522866757183748, 0.577526305758584, 0.5737803673457664, 0.5423513581910364, 0.5631718625700611, 0.49290504537806834, 0.6713015664821476]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5345886335411585\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6328909659146447\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5130788931100487\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4850320644643748\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6170848558872711\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5187926621275294\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5276974560564729\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5913283959381198\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5543179387466357\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4868096960445254\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7453741902327806\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5230582772174184\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5457788447974253\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5450975973517991\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6381013854730402\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47042795245654245\n","is min 0.47042795245654245 is smaller than [0.528655079860063, 0.49829697134955564, 0.523259589056835, 0.5435293435224381, 0.5223499332397478, 0.5300755011646934, 0.5077973531561366, 0.5924259521633074, 0.5461025343589012, 0.6026509909073721, 0.5734987325678207, 0.5616790609825003, 0.5522866757183748, 0.577526305758584, 0.5737803673457664, 0.5423513581910364, 0.5631718625700611, 0.49290504537806834, 0.6713015664821476, 0.4833085590461714, 0.5345886335411585, 0.6328909659146447, 0.5130788931100487, 0.4850320644643748, 0.6170848558872711, 0.5187926621275294, 0.5276974560564729, 0.5913283959381198, 0.5543179387466357, 0.4868096960445254, 0.7453741902327806, 0.5230582772174184, 0.5457788447974253, 0.5450975973517991, 0.6381013854730402]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6462312806105539\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6503338461218876\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5788565361043807\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5378103655294466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5200308455818518\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6192118745658439\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5781037833047358\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.628045354271124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5008495719957863\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7182065842300497\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.489455470021752\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7066211884742651\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5796941136581206\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4806837708233731\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6416435763148182\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5447093002193598\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6600582055059281\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5270182820760905\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5257024046141922\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.63374643655589\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47850058208579643\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.665864979691951\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47082877981731913\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7011557015139962\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5213047607393275\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5876521493872039\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.538420615613738\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5501980329218805\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5106641884504546\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5800184476800155\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5318274290894387\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5933287376449329\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6473815371047545\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5651298630231464\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6000080153438898\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.551879523316794\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5657629037228113\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5382334070840274\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5240786257759276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6628506661877079\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5441201042434403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5140233546781433\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6226110599688518\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5347930591860763\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5673627009313765\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7462992101651243\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49763207546808164\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6746893602489507\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.539288469798027\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5959861048270156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6728544879797083\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5140767440890878\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6671102401997591\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5949621806082273\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6310744666131762\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5335685428529003\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6937677328530887\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5950754077629422\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5442877049693434\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6542551050982236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5047171360730748\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5692078584318044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5458319691504679\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6966891365062221\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5438967993679943\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6191152779814024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.568888941964526\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6122050700386308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5644003833603216\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6081179553799466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6261652586140568\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5904545659581307\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6570959086979853\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.61987867567865\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6514047830912558\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6137578356904291\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6366029976033512\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6903628663441252\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5440594308585317\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6236343971277408\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5919786616413177\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.542717274565471\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5516320349276276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5987871966823429\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5908606366105941\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.630850974331101\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5166308879250682\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6343058238449825\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6163705787654553\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5528799159368781\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6122719321443945\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6226418173714382\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6438791966367674\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5245893072991387\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6928422096123742\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5368811095386063\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5940090248633623\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6844125826045209\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5949842149630676\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6500189299554755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6342740863989862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6073285261673912\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6190042474830362\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.568361313706052\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6107387476116606\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6516059399425614\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5931283287724123\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5610839337817669\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6391748389558708\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.66617377147948\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5828051256280258\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5269040761667164\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.691439013489654\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5414417972436804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5992900060085248\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6247846169300715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5939450681057313\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5845469437194737\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5616642261897447\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6381436702035246\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5857182897042361\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6411414594516776\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5380694413564826\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6137580266571907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6034593374375279\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6121214916605114\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5589835308959353\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5410332366262446\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.603460572400169\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5372164674948213\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6058969358984931\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5593682929435354\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.579783196590762\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5735386096265882\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6353258305143238\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5531627207552418\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6180397303311924\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5617019127706039\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5780833144211571\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6387117739149767\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5946215056143642\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5409118467932031\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5736543718364477\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5754593442842618\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6386809626721262\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6128510782094244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5695492645953367\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5556185277645933\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7385987888440895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5418375723134978\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6087332056219571\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5879705825371561\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5792538042768289\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5851900156596891\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6241125667537075\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.530139210080619\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7490481681326043\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5306778804158157\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6404713720496201\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5698560671565069\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5542215529808535\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5542215529808535\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 47:47, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.404700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.228600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.340000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.295300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.147800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.234000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.237200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.258100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.197600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.191400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.290900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.191500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.250100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.221300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.163200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.224200</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.220600</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.345400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.231500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.352700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.226700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.275000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.215900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.189200</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.210600</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.203000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.197800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.196000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.184900</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.223600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.213000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.341800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.202300</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.216300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.261000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.286800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.251000</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.179700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.263800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.128700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.142400</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.156700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.169000</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.150800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.173300</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.177200</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.186500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.182500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.198500</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.142300</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.157400</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.168700</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.160000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.167200</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.142900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.156300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.228100</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.140000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.192600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.206100</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.162700</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.180500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.153800</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.141900</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.102100</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.171800</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.199000</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.198500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.134200</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.172100</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.144600</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.101300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.146700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.166300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.226600</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.203500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.134000</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.088400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.079500</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.099500</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.105700</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.086400</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.085700</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.078600</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.095700</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.103600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.128500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.109400</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.109600</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.104700</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.127400</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.095100</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.057900</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.086400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.088900</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.110300</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.097200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.084000</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.100200</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.115900</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.091900</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.067100</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.087600</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.097700</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.082400</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.113900</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.077400</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.099000</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.106000</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.093100</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.127300</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.105500</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.143200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.095800</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.076900</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.071900</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.094800</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.078500</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.063200</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.049800</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.053700</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.061600</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.069300</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.043100</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.059600</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.063700</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.082500</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.054600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.047900</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.054500</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.069600</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.058200</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.054200</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.046400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.083500</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.055000</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.050600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.068300</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.078600</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.062000</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.067300</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.101400</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.068900</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.041000</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.056900</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.047400</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.035300</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.048000</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.022500</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.027700</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.031100</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.034200</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.037600</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.028900</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.033500</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.021300</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.037000</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.038300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.028500</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.073600</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.029100</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.036700</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.033400</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.036000</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.032000</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.046300</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.029500</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.028600</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.023200</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.044200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5238738013621437\n","is min 0.5238738013621437 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48320152047393555\n","is min 0.48320152047393555 is smaller than [0.5238738013621437]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4872108489739923\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5293716868289592\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5154473370094211\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.535264260507878\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5239718017184842\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4759973567687442\n","is min 0.4759973567687442 is smaller than [0.5238738013621437, 0.48320152047393555, 0.4872108489739923, 0.5293716868289592, 0.5154473370094211, 0.535264260507878, 0.5239718017184842]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4852858668422127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.536968834917797\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5002724945618683\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.574539591099261\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44845646726074956\n","is min 0.44845646726074956 is smaller than [0.5238738013621437, 0.48320152047393555, 0.4872108489739923, 0.5293716868289592, 0.5154473370094211, 0.535264260507878, 0.5239718017184842, 0.4759973567687442, 0.4852858668422127, 0.536968834917797, 0.5002724945618683, 0.574539591099261]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4801179617554805\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5362052168402167\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4633739640043451\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47027687176784405\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5015485987833761\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4855380299270947\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5343558725293077\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.577334162588235\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4546578414588031\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5150192598033422\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5680916896316199\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5306608038056708\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5701056128845369\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4712879939383202\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7184646530893163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5109314210797743\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5366358980095074\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4864025904779575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47710796260535887\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5226859026645992\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4916721831082441\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6890785091101432\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45402488296751287\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5692400550506009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4882686504248109\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.559719661509313\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48486410918273665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5881709534943598\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5014633360602168\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4641341921770398\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5095987460675308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4709734857602329\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6168332499029316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5096107888242025\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5886840273764851\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.545580713069209\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5310416459070012\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5082357530038936\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4806345283981027\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5706499445153006\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5003725182959949\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5358311209271057\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5563659526791725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4762901832868121\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.603097464681521\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.477605184821142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5617443160746807\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5184792165576864\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5139569722716164\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45976125670658236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4516574841757683\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6007204020693268\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.571520773460001\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5058159169632584\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46842204606410115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5459775357536011\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5060623121043905\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5806313931331627\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5052206727639927\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6007023258019826\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4706763500394456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5559991820921437\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4785910955289473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46163181534312353\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5611020235593894\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5580113966324625\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5715904186998707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5680928539797799\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47578132040004034\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.577864305642744\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5108691694527456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5040471742042892\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5702163607233764\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4948842147908455\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6247863924862732\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4541227944678691\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6711299673343532\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44446378067863257\n","is min 0.44446378067863257 is smaller than [0.5238738013621437, 0.48320152047393555, 0.4872108489739923, 0.5293716868289592, 0.5154473370094211, 0.535264260507878, 0.5239718017184842, 0.4759973567687442, 0.4852858668422127, 0.536968834917797, 0.5002724945618683, 0.574539591099261, 0.44845646726074956, 0.4801179617554805, 0.5362052168402167, 0.4633739640043451, 0.47027687176784405, 0.5015485987833761, 0.4855380299270947, 0.5343558725293077, 0.577334162588235, 0.4546578414588031, 0.5150192598033422, 0.5680916896316199, 0.5306608038056708, 0.5701056128845369, 0.4712879939383202, 0.7184646530893163, 0.5109314210797743, 0.5366358980095074, 0.4864025904779575, 0.47710796260535887, 0.5226859026645992, 0.4916721831082441, 0.6890785091101432, 0.45402488296751287, 0.5692400550506009, 0.4882686504248109, 0.559719661509313, 0.48486410918273665, 0.5881709534943598, 0.5014633360602168, 0.4641341921770398, 0.5095987460675308, 0.4709734857602329, 0.6168332499029316, 0.5096107888242025, 0.5886840273764851, 0.545580713069209, 0.5310416459070012, 0.5082357530038936, 0.4806345283981027, 0.5706499445153006, 0.5003725182959949, 0.5358311209271057, 0.5563659526791725, 0.4762901832868121, 0.603097464681521, 0.477605184821142, 0.5617443160746807, 0.5184792165576864, 0.5139569722716164, 0.45976125670658236, 0.4516574841757683, 0.6007204020693268, 0.571520773460001, 0.5058159169632584, 0.46842204606410115, 0.5459775357536011, 0.5060623121043905, 0.5806313931331627, 0.5052206727639927, 0.6007023258019826, 0.4706763500394456, 0.5559991820921437, 0.4785910955289473, 0.46163181534312353, 0.5611020235593894, 0.5580113966324625, 0.5715904186998707, 0.5680928539797799, 0.47578132040004034, 0.577864305642744, 0.5108691694527456, 0.5040471742042892, 0.5702163607233764, 0.4948842147908455, 0.6247863924862732, 0.4541227944678691, 0.6711299673343532]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6218176075814036\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4517595791980077\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5958661858798009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5480487969305827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5835366286023332\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5099791009040601\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5602777783401252\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.469517856972344\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5990503035139196\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4845987437554395\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5917989549346477\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4716607392352239\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5989731618169489\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5385224062579399\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5360460513927419\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.570946844379804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5879501791005868\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.570008379330488\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6770717045406349\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46337188650551814\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6104441466765201\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4872249349418259\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49539505213768686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6153242510869494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4802797908409657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5640790032761747\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5389138248764433\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5530686570621761\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5357254864057862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6008137987146873\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.515650177710367\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5787516339503559\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5063887080617921\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6531975448654036\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5737630741908133\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5695508517253276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5237094036685769\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5358491096791829\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5284841525877998\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6522967492744449\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48884609790535566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5591252407394494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5570207420633742\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5090937648987307\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5683767497591876\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.525960309682707\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5176997264354206\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5726997666118563\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4780530638436267\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5548646053239079\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6237777798894847\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49564323397370863\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5656258264828894\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4960547640579418\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5399585715443554\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5819200982373197\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5687703370384327\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47126497744511536\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6478044006764543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5050149014087256\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.554157461231244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4928014179757667\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.645600658859964\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49310288410427566\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5305008718655884\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5804356798268535\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5418048764745433\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6002450247233401\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5059703852418368\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5375651868543904\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5072211487470899\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5407251396796833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5331991161909524\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6031198305612142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4975806111435303\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6074329333941862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48162855406884125\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5495475852138925\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5629916704058346\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5602907289561706\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5336319231434331\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5319935896396518\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5316183073219635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5128623672951321\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5181635129950204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5170027045652268\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.545549144038055\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5400847058303634\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4999304341906816\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5215820328392892\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5534943005648533\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5067952564946401\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5715787086015703\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.607992915890599\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5482898630320389\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5735992207185734\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5857353032926683\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5674596769938286\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5085368410618715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6142323685665042\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5079640439303839\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5350703854997865\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5329406807017584\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48595574021017907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5476628955021456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5644087486220023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5644087486220023\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 48:09, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.302500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.297000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.335200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.283700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.214000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.232700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.294700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.194300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.217100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.186100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.202900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.181700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.192200</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.236000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.174500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.189800</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.184200</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.225500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.270900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.197800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.182800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.255200</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.209900</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.206100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.182600</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.253100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.229400</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.338200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.196800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.231100</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.174700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.290600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.207500</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.242700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.342100</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.287500</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.206400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.187600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.277300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.186100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.144500</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.150700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.141400</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.145000</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.094400</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.150900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.143500</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.150500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.206600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.165000</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.168000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.125600</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.141500</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.149500</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.203000</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.253900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.212100</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.196200</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.179700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.172600</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.104000</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.127400</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.187200</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.142000</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.186500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.133900</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.196000</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.151500</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.143900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.246900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.171500</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.189400</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.143600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.138300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.159300</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.157500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.158700</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.159000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.108000</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.071500</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.079900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.107200</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.088500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.081900</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.100100</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.130200</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.059300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.079300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.124100</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.106300</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.084500</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.123600</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.087800</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.093900</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.087200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.084000</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.102400</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.088800</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.088300</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.105000</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.071300</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.102300</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.148900</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.112500</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.136300</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.154600</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.072300</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.113100</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.081800</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.143100</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.089600</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.118700</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.057200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.063500</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.062400</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.057100</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.043900</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.071900</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.066900</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.049400</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.034100</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.040200</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.057900</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.067200</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.091000</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.050900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.048400</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.057800</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.068800</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.050600</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.060700</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.060900</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.048100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.056800</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.065000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.059800</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.062900</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.094600</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.073500</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.043400</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.051100</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.073700</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.067500</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.049000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.041600</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.056500</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.029000</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.045300</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.048700</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.031300</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.025500</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.046000</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.030700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.044300</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.034800</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.047800</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.032100</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.050000</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.030300</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.042300</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.026300</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.033200</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.044300</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.034000</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.059700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5377461561920038\n","is min 0.5377461561920038 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49864025521486466\n","is min 0.49864025521486466 is smaller than [0.5377461561920038]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5275641774394688\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6039510699893573\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5588799868071206\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.505104275570406\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5229024273500013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.597555322734826\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5612906128616393\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5101501541102007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5539601482100931\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5249684992984228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.601013989028035\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4945122605229366\n","is min 0.4945122605229366 is smaller than [0.5377461561920038, 0.49864025521486466, 0.5275641774394688, 0.6039510699893573, 0.5588799868071206, 0.505104275570406, 0.5229024273500013, 0.597555322734826, 0.5612906128616393, 0.5101501541102007, 0.5539601482100931, 0.5249684992984228, 0.601013989028035]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.53576213398725\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4925023963906183\n","is min 0.4925023963906183 is smaller than [0.5377461561920038, 0.49864025521486466, 0.5275641774394688, 0.6039510699893573, 0.5588799868071206, 0.505104275570406, 0.5229024273500013, 0.597555322734826, 0.5612906128616393, 0.5101501541102007, 0.5539601482100931, 0.5249684992984228, 0.601013989028035, 0.4945122605229366, 0.53576213398725]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6055500981942487\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5563132222313124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5369887241960503\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4918382898096172\n","is min 0.4918382898096172 is smaller than [0.5377461561920038, 0.49864025521486466, 0.5275641774394688, 0.6039510699893573, 0.5588799868071206, 0.505104275570406, 0.5229024273500013, 0.597555322734826, 0.5612906128616393, 0.5101501541102007, 0.5539601482100931, 0.5249684992984228, 0.601013989028035, 0.4945122605229366, 0.53576213398725, 0.4925023963906183, 0.6055500981942487, 0.5563132222313124, 0.5369887241960503]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5481645046688655\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5470579130099926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5526022099464429\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49880659421332657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.508724919099441\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6147942306708511\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.652598316423961\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.595945479378451\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5921078500522404\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5282906751157158\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5859337532479646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6286645333122969\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47500994922892237\n","is min 0.47500994922892237 is smaller than [0.5377461561920038, 0.49864025521486466, 0.5275641774394688, 0.6039510699893573, 0.5588799868071206, 0.505104275570406, 0.5229024273500013, 0.597555322734826, 0.5612906128616393, 0.5101501541102007, 0.5539601482100931, 0.5249684992984228, 0.601013989028035, 0.4945122605229366, 0.53576213398725, 0.4925023963906183, 0.6055500981942487, 0.5563132222313124, 0.5369887241960503, 0.4918382898096172, 0.5481645046688655, 0.5470579130099926, 0.5526022099464429, 0.49880659421332657, 0.508724919099441, 0.6147942306708511, 0.652598316423961, 0.595945479378451, 0.5921078500522404, 0.5282906751157158, 0.5859337532479646, 0.6286645333122969]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6000228730845062\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4795775821048047\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6742660840677622\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.539172253863228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5776692571149753\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5434483662705732\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6289461917622325\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6139791770555546\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5942300335370766\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6058120085575367\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48133382612302955\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6262667101347484\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5515126341313776\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4815779940713941\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5307585581296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5343656844470059\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5952494853167798\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5346278969803139\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5348131753901143\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.480424022282127\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462174791220011\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5785321493750963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327691936775667\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5877314060609578\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5145285857498231\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5426248942514567\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.569714167899573\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5956499246601024\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5862673131902412\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5031743689355769\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6490075103660302\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48317041998745996\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6488310372561862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5266811963362377\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4962103026841235\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5364094830650937\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5645051309921687\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5561869173453499\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5057679028475427\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5899759016520153\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4937508409725681\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5820757229039804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6213042509621831\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5009913934832668\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5506994803333749\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5560462168178685\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5169346484540162\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5985988474746466\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6803473437842268\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5056828673377447\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5697147440906833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6666470566012883\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5985613757141638\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6258743596286025\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5718517519044454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5431299449644948\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4900378932319917\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6176247619941343\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6676908202112667\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48229183585165414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6983440121313128\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5810726429225153\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6736526981643219\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4923337302258123\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.557693010736384\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49297708491289954\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5634868568604701\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.57246214810017\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.536410796058852\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5337970604109682\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.63154134044823\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5701523355556504\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5541202376318686\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6602334252415913\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5071889128883369\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.762505880951405\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45440669215806057\n","is min 0.45440669215806057 is smaller than [0.5377461561920038, 0.49864025521486466, 0.5275641774394688, 0.6039510699893573, 0.5588799868071206, 0.505104275570406, 0.5229024273500013, 0.597555322734826, 0.5612906128616393, 0.5101501541102007, 0.5539601482100931, 0.5249684992984228, 0.601013989028035, 0.4945122605229366, 0.53576213398725, 0.4925023963906183, 0.6055500981942487, 0.5563132222313124, 0.5369887241960503, 0.4918382898096172, 0.5481645046688655, 0.5470579130099926, 0.5526022099464429, 0.49880659421332657, 0.508724919099441, 0.6147942306708511, 0.652598316423961, 0.595945479378451, 0.5921078500522404, 0.5282906751157158, 0.5859337532479646, 0.6286645333122969, 0.47500994922892237, 0.6000228730845062, 0.4795775821048047, 0.6742660840677622, 0.539172253863228, 0.5776692571149753, 0.5434483662705732, 0.6289461917622325, 0.6139791770555546, 0.5942300335370766, 0.6058120085575367, 0.48133382612302955, 0.6262667101347484, 0.5515126341313776, 0.4815779940713941, 0.5307585581296, 0.5343656844470059, 0.5952494853167798, 0.5346278969803139, 0.5348131753901143, 0.480424022282127, 0.5462174791220011, 0.5785321493750963, 0.5327691936775667, 0.5877314060609578, 0.5145285857498231, 0.5426248942514567, 0.569714167899573, 0.5956499246601024, 0.5862673131902412, 0.5031743689355769, 0.6490075103660302, 0.48317041998745996, 0.6488310372561862, 0.5266811963362377, 0.4962103026841235, 0.5364094830650937, 0.5645051309921687, 0.5561869173453499, 0.5057679028475427, 0.5899759016520153, 0.4937508409725681, 0.5820757229039804, 0.6213042509621831, 0.5009913934832668, 0.5506994803333749, 0.5560462168178685, 0.5169346484540162, 0.5985988474746466, 0.6803473437842268, 0.5056828673377447, 0.5697147440906833, 0.6666470566012883, 0.5985613757141638, 0.6258743596286025, 0.5718517519044454, 0.5431299449644948, 0.4900378932319917, 0.6176247619941343, 0.6676908202112667, 0.48229183585165414, 0.6983440121313128, 0.5810726429225153, 0.6736526981643219, 0.4923337302258123, 0.557693010736384, 0.49297708491289954, 0.5634868568604701, 0.57246214810017, 0.536410796058852, 0.5337970604109682, 0.63154134044823, 0.5701523355556504, 0.5541202376318686, 0.6602334252415913, 0.5071889128883369, 0.762505880951405]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7116252022782021\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.537676723803615\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6258020852962827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48887784613296875\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8134159857632369\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48295368098389596\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7115090543065296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5066552085204904\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5823858204046491\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.572082378034812\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6302157839540553\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5441740084111926\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5109953143384\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.590177979229541\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6133053970469178\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47594854988927093\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6459367856922936\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5992667628070342\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5201339323522916\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5268583027604771\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.501716629208031\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6014212959298895\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49788428515717825\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5881011809426949\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5789911107364195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5552304049661312\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6135751051782031\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5795540839846701\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5661187367690482\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6495205892748295\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5481320725250817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6630295254367281\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5725515058944401\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5653152251969665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.581714575779812\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.557521909643274\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.638916884169248\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5300111685742755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5779439830168834\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6187331390509335\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5936877058536741\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5639074561746222\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6137499344104642\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5295397007457039\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5922817746525677\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327512757184771\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5613062274800898\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6001378839173888\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5884387161554894\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5860436795874965\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5717968532025547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5650611533124128\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.515527225184677\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.652510835193178\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5979055902304292\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5072702621925931\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5604945055573173\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5905795099316822\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5183794469404144\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6294040888066288\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5672000017623817\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48215012887228403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.594008855303463\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5462587611140148\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5434989756981163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6488186638119333\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4980658199118613\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5482395074881797\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6766830018813395\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5334734112461261\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5234378195329369\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6089445337813997\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5327863878374239\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5624234876610237\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5070571969465781\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6105521950124995\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5646951097677838\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5922815278403648\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5287647950699487\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5511139030237048\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5851280303461556\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5164654065884835\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6409312037982411\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5860003625939768\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.57702326856876\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.521298270755596\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6439227697278458\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6439227697278458\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1970' max='1970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1970/1970 47:54, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.421700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.272700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.203300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.229300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.231600</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.171900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.212000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.351400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.216500</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.225100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.251700</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.257000</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.174600</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.199900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.208900</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.236600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.256700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.264500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.209200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.195300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.252000</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.195100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.222200</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.220900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.241700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.315800</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.172100</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.307200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.165000</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.251700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.282900</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.231600</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.284800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.269100</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.222800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.285400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.210500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.160000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.150300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.183400</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.202300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.139000</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.168900</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.243000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.127000</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.116800</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.127700</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.194600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.194000</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.154100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.165600</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.181800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.176200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.147000</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.179400</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.098200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.207200</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.201600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.135200</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.163800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.157100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.221100</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.162600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.125900</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.204200</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.118800</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.192200</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.152900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.105500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.167200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.138800</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.202300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.203600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.136000</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.200300</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.157700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.167200</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.208200</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.101300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.118300</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.086800</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.076700</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.125400</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.097900</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.107000</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.097000</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.073800</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.085000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.119300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.104700</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.080200</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.067200</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.101800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.122800</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.060000</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.114500</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.079100</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.103200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.075400</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.088800</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.101300</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.073600</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.124300</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.073800</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.077200</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.107400</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.096100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.093200</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.067800</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.088900</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.119000</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.106600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.061900</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.093500</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.068800</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.095200</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.108000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.058800</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.045500</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.057300</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.047000</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.068000</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.072700</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.053700</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.083000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.044600</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.053700</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.057400</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.047600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.071200</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.070100</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.040500</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.044800</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.045500</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.037700</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.053000</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.077700</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.051900</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.063000</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.057800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.060100</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.059300</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.070200</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.090200</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.077300</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.066100</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.054100</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.026900</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.036100</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.032200</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.033100</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.035700</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.028800</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.038600</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.031900</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.037200</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.030800</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.032400</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.045100</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.045500</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.029800</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.036000</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.050900</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.037600</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.050100</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.061100</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.021900</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.043300</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.026300</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.036200</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.030000</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.041900</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.043000</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.029500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4964760832616118\n","is min 0.4964760832616118 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4605630295844683\n","is min 0.4605630295844683 is smaller than [0.4964760832616118]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.05it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4921249644097071\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5386745293281907\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5443891893290538\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5219064092638409\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5131141279751862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5760548995311244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5331220813200587\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5157497608984299\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5308141854387276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5545418814741571\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4911774895559212\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4563245595610917\n","is min 0.4563245595610917 is smaller than [0.4964760832616118, 0.4605630295844683, 0.4921249644097071, 0.5386745293281907, 0.5443891893290538, 0.5219064092638409, 0.5131141279751862, 0.5760548995311244, 0.5331220813200587, 0.5157497608984299, 0.5308141854387276, 0.5545418814741571, 0.4911774895559212]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5578498615295668\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5955060309890099\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4345797068027429\n","is min 0.4345797068027429 is smaller than [0.4964760832616118, 0.4605630295844683, 0.4921249644097071, 0.5386745293281907, 0.5443891893290538, 0.5219064092638409, 0.5131141279751862, 0.5760548995311244, 0.5331220813200587, 0.5157497608984299, 0.5308141854387276, 0.5545418814741571, 0.4911774895559212, 0.4563245595610917, 0.5578498615295668, 0.5955060309890099]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5250553108582587\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43332299237231026\n","is min 0.43332299237231026 is smaller than [0.4964760832616118, 0.4605630295844683, 0.4921249644097071, 0.5386745293281907, 0.5443891893290538, 0.5219064092638409, 0.5131141279751862, 0.5760548995311244, 0.5331220813200587, 0.5157497608984299, 0.5308141854387276, 0.5545418814741571, 0.4911774895559212, 0.4563245595610917, 0.5578498615295668, 0.5955060309890099, 0.4345797068027429, 0.5250553108582587]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46564903263811364\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6649579069063714\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5208589626155025\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5225395011951065\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5409433480653557\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48092670618027933\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.505839826206874\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5725674080913485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.604147184296778\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5162266208226124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4797604723918298\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6485774241354096\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43073845102699654\n","is min 0.43073845102699654 is smaller than [0.4964760832616118, 0.4605630295844683, 0.4921249644097071, 0.5386745293281907, 0.5443891893290538, 0.5219064092638409, 0.5131141279751862, 0.5760548995311244, 0.5331220813200587, 0.5157497608984299, 0.5308141854387276, 0.5545418814741571, 0.4911774895559212, 0.4563245595610917, 0.5578498615295668, 0.5955060309890099, 0.4345797068027429, 0.5250553108582587, 0.43332299237231026, 0.46564903263811364, 0.6649579069063714, 0.5208589626155025, 0.5225395011951065, 0.5409433480653557, 0.48092670618027933, 0.505839826206874, 0.5725674080913485, 0.604147184296778, 0.5162266208226124, 0.4797604723918298, 0.6485774241354096]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6175924561817169\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5020041974481492\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5000393399858335\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47116663203502646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5996505244118804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.522069479065695\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4538576360546852\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.53616373698596\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.701527141120538\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.43037621871896253\n","is min 0.43037621871896253 is smaller than [0.4964760832616118, 0.4605630295844683, 0.4921249644097071, 0.5386745293281907, 0.5443891893290538, 0.5219064092638409, 0.5131141279751862, 0.5760548995311244, 0.5331220813200587, 0.5157497608984299, 0.5308141854387276, 0.5545418814741571, 0.4911774895559212, 0.4563245595610917, 0.5578498615295668, 0.5955060309890099, 0.4345797068027429, 0.5250553108582587, 0.43332299237231026, 0.46564903263811364, 0.6649579069063714, 0.5208589626155025, 0.5225395011951065, 0.5409433480653557, 0.48092670618027933, 0.505839826206874, 0.5725674080913485, 0.604147184296778, 0.5162266208226124, 0.4797604723918298, 0.6485774241354096, 0.43073845102699654, 0.6175924561817169, 0.5020041974481492, 0.5000393399858335, 0.47116663203502646, 0.5996505244118804, 0.522069479065695, 0.4538576360546852, 0.53616373698596, 0.701527141120538]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6846523854501628\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4661427694398223\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5563227378085167\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5014725634428407\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4854415183798444\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.552690987506443\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5879534642864807\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4942014224205957\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6636888166314845\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49123720525329423\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.514531685750552\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.45595985395930355\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6388116467417978\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5599038069982494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5675553511723634\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4994509277285755\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6057276323444332\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47721427898923635\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6273952150769626\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46127461739188225\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6279634103924988\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4915517386985204\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5337969010594067\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5156353423048007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5302309801157276\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7020147769505132\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4953579527478646\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5615649451365067\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4485628908604381\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5850214848162163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4651613794249454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5715683084921418\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5863833985520198\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6088886823510833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5392341215408843\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.609669106561708\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44903985809752833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6910456452886241\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47404803498950876\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5647198353040833\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49255175234760473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6845584324811123\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5962615402610426\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5784303028289429\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5093764160015262\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6467859609992529\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.557939249402956\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5290842535890051\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5375180470316672\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5394629560084454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6612990465318748\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.44092764173751425\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6568753928071179\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5667734341160889\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5798444017655814\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5405225254595548\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48486370005536134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6625052753779888\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5246701959530495\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5687577996452315\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48160052388794855\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5880854647857515\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5225774205507974\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6280280791553989\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5653335164033074\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5332391065962885\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5497259899265134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49031501366040375\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7539580883944365\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49196821194563095\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5303799518668351\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5841749163287311\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5987187920424182\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5668667442276852\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5069841833140504\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6624582314179007\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.513614690625632\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6356146834627769\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49251644217834645\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5713959168807847\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6164658389328878\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5187551569241601\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.601187096375062\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5386640141458949\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5717478843737082\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.47844910515530237\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6331918599716517\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6075138133155489\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5256257808039905\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5564546193237421\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5205290362834144\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5714903419145902\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5307202673625929\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.543589283701035\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6338765292855038\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5077774227440689\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5864421640475862\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.542862608839318\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5118397791022913\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5902179007672005\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6129892064700698\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4897911093910759\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7005855365460754\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5159488921776872\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5755787586969465\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5753566224917108\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5203470548999113\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6147878903472279\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5874226715329189\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5262961083813836\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5600865794550893\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5676064401020872\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48468261720091665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6739295240673548\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48728580149663403\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.58409242031303\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.56590003501897\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5708099706553132\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5825806621313128\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5143438329778457\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5236779956208018\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5342916466801341\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5622043115016238\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6032550143202535\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5356423266584698\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5833514584593411\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5754942235150236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5659776830472761\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.546162976998177\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5369980382906621\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5893694278557904\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5515314888202141\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5206419975235698\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5724746212511518\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5083053813633532\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5154562903298106\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5659153455473331\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5441807405081605\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5091872826370645\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6619285903910224\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5500030732650413\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5102156768101617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5637437016115068\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5547961492730809\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5174890031750838\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5423906141860172\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.516186476114684\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5288644763801126\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5375340368304978\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5257224645395666\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5417427592975654\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5926520197478349\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5050155033250416\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6233701182757613\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5335168803972156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5335168803972156\n","Training done\n"]}],"source":["# electra 1\n","model_name = os.path.join(ELECTRA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 8e-6,\n","  'weight_decay': 0.1,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ELECTRA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"BcgBi10OP-_L"},"outputs":[],"source":["# Training the RoBERTa model\n","\n","ROBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/roberta-large-augmented')"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"TRWMXp9mQB2W"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='592' max='592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [592/592 16:46, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.376200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.286500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.316100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.208400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.233800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.264200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.224200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.243700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.249700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.341300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.231000</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.256100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.299300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.260400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.249500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.162200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.134900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.220600</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.207500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.194600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.169700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.189400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.255900</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.222600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.231000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.232600</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.161000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.182600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.182000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.184400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.144800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.149500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.140200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.122500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.133200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.175500</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.133400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.148700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.160000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.161700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.157700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.154400</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.128200</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.133500</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.108000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.075800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.094800</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.084300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.117200</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.094600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.116800</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.070400</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.086800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.109800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.070000</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.120600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.110300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.083100</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.125500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:06,  2.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5444286720350329\n","is min 0.5444286720350329 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:06,  2.16it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.802838308277896\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.14it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5782649247473219\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.13it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.678569378833547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.12it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.558425287344089\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.10it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6951404463369908\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7480557914504172\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.09it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7025130772849433\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.08it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7788400714415009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.07it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6287939196297405\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4984421046038069\n","is min 0.4984421046038069 is smaller than [0.5444286720350329, 0.802838308277896, 0.5782649247473219, 0.678569378833547, 0.558425287344089, 0.6951404463369908, 0.7480557914504172, 0.7025130772849433, 0.7788400714415009, 0.6287939196297405]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.07it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6974963514675266\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.06it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6360130460090975\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.06it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5164302115756975\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.703658593655253\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6943692656063568\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7483317305095583\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7993111773704782\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6987067153199525\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5509289349366574\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7474451664825877\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5923922837724983\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6791198131306176\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7261646097363249\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.843867025040793\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6096287192873537\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5990327890794644\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5751177410302201\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6011653595005515\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6668416649869784\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7490060448059088\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8271917390630183\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5725428461306747\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.607001509125011\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6542812445169923\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5566224545833556\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6852197286484445\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7842336865010993\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5657936914630273\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5894287357779266\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6341980137315154\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7027377299563617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7100672026987617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7947065658281295\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6707134034888664\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8568062811969226\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.630723233298601\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6357404111100086\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6799773407265665\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5711558420844494\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7133276686615032\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7381865793643645\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7497378862384745\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.616652323789539\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5768058981218319\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6072538943092226\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7466039861705287\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6594627931146333\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6337260049053757\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6957556605868992\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='592' max='592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [592/592 17:24, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.302300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.263600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.248600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.260100</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.325400</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.241800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.227200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.273400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.259600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.349000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.303000</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.406600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.426300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.295300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.300600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.197800</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.167900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.244300</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.263000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.167800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.244800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.281500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.214800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.211500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.209800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.241100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.283000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.217900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.193000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.152400</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.158700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.129900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.136900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.147700</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.131100</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.135500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.147900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.170900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.163100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.136400</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.135600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.167800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.177500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.085200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.112600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.073700</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.108500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.104900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.096300</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.096700</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.072000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.096700</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.116500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.093600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.091000</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.087000</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.091500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5639621507790794\n","is min 0.5639621507790794 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6896909610514742\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6699812606914609\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5010490364627167\n","is min 0.5010490364627167 is smaller than [0.5639621507790794, 0.6896909610514742, 0.6699812606914609]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7560633010275799\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5756526568946485\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5441277524948296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7898581205880958\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7492777498174523\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4933761197221558\n","is min 0.4933761197221558 is smaller than [0.5639621507790794, 0.6896909610514742, 0.6699812606914609, 0.5010490364627167, 0.7560633010275799, 0.5756526568946485, 0.5441277524948296, 0.7898581205880958, 0.7492777498174523]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.46582638600516213\n","is min 0.46582638600516213 is smaller than [0.5639621507790794, 0.6896909610514742, 0.6699812606914609, 0.5010490364627167, 0.7560633010275799, 0.5756526568946485, 0.5441277524948296, 0.7898581205880958, 0.7492777498174523, 0.4933761197221558]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.979616018752489\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4745605931504228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.533915563358595\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6772341966688284\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6047720473245857\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8306676733465221\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5910861953560111\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5101857638277763\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5498543714837165\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7573311323091804\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6365671257475797\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7817705584004553\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5259424168252378\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5156337408823571\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.87869662735921\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49162621850441607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5504820247279454\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6125532860365414\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6696449859661505\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6197273839010448\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7253896136419433\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6256385613815985\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6707740643107882\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.698328981655746\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6482467927334591\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5913212632508551\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6108503791693808\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5713785240215998\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8263388347031841\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7037462917281789\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7344525352225142\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6738418002820823\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6744284096967013\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5798751394301374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.569220580204033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6861627591979822\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7106417061128456\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7317435052554134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6391644655750507\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7672918660743592\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6869642370580512\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7109102225005374\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7317354782196844\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5651847175501296\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6561362165170727\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6281990922777121\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7059296822829058\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.709022244424475\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7001297940039509\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='592' max='592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [592/592 17:21, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.367600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.247500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.224500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.245700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.261500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.231600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.339200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.357200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.246700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.220000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.262100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.292100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.228500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.250600</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.195400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.194300</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.193100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.160600</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.186000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.227000</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.183800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.189900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.189500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.179300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.213100</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.205400</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.221700</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.217800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.175800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.132100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.171800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.153400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.137600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.140000</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.151200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.100200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.143500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.154600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.148800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.115200</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.144600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.153300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.116100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.092800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.092000</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.102800</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.096100</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.080100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.098400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.138200</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.094000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.066400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.075600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.078800</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.090500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.095200</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.077800</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.115200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5385391868944323\n","is min 0.5385391868944323 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5958139947245115\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6287505332817035\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.60916791329668\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6880616642508462\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6038471837308903\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7291670127362871\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.625651706931055\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5268733747396719\n","is min 0.5268733747396719 is smaller than [0.5385391868944323, 0.5958139947245115, 0.6287505332817035, 0.60916791329668, 0.6880616642508462, 0.6038471837308903, 0.7291670127362871, 0.625651706931055]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5168305029826729\n","is min 0.5168305029826729 is smaller than [0.5385391868944323, 0.5958139947245115, 0.6287505332817035, 0.60916791329668, 0.6880616642508462, 0.6038471837308903, 0.7291670127362871, 0.625651706931055, 0.5268733747396719]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7512934959375657\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6119761145213891\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6835733712367773\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5248585342283864\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49528027204582425\n","is min 0.49528027204582425 is smaller than [0.5385391868944323, 0.5958139947245115, 0.6287505332817035, 0.60916791329668, 0.6880616642508462, 0.6038471837308903, 0.7291670127362871, 0.625651706931055, 0.5268733747396719, 0.5168305029826729, 0.7512934959375657, 0.6119761145213891, 0.6835733712367773, 0.5248585342283864]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.02it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7257463702288108\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6090654592798654\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6846686030472429\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5131593946729429\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5484606269004682\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6120203403049803\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5409569682328816\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6574474880352487\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.64779917898158\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7647407667156\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.693026915037824\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6495726971332473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5567675648457774\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6107951543100171\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7538077070029271\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8548022493927137\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8470719610962482\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7306201094872112\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6630818751121863\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6658224200381248\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5736899781371124\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6426673333923231\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7084981209678128\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8778767674024472\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.689584751565009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7534516647277988\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8191292722562316\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5911315772409876\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6330997030020431\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5743490815071559\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7122765700120877\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7239707101734348\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.837503439242236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6147915733879866\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6202607190863225\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7878209411161511\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7209500987732146\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.704332681781426\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6852990518860426\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6848111925108337\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.795292370354582\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6352922900435999\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5512057007354827\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7013242294055326\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6124159057243401\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='592' max='592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [592/592 17:01, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.279100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.255700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.216200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.201200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.260700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.264300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.299400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.270000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.281600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.274600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.197300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.289900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.287800</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.286000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.261400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.257500</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.207700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.193500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.197400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.183100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.172700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.181700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.169800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.220500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.156200</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.245000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.194600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.202600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.226000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.172800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.122100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.148000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.179900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.261600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.152900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.123400</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.134300</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.117700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.137600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.131900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.164300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.099600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.123000</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.140200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.095600</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.095200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.109100</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.104500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.084000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.108900</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.082300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.088900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.099200</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.104200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.169500</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.101600</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.094500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.515844561793151\n","is min 0.515844561793151 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6256135542093014\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5786376072525009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49028156235853154\n","is min 0.49028156235853154 is smaller than [0.515844561793151, 0.6256135542093014, 0.5786376072525009]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.03it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6410077861045843\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7388749774246888\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5192413030268023\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6107712682130396\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8713672155687228\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5902304749045617\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6316454131282526\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6291402598488152\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7429523089666938\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.623904714121989\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5024207652247018\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.643085822259415\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.830657169069873\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6199455306278715\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6098681739479193\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6777883926667685\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6159500706937163\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6355872360344113\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6354571206283953\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5633316610438107\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6513602512402837\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5293401112211898\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5742484044412222\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5399809652733195\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5251897357106547\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5576005236604832\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5104114602832084\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49422114082404855\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8818367222536693\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.656083130977651\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5608308585877267\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5256539842235103\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6168841207242863\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6413867618385677\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6952559965861944\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5737935682263202\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7817205123092958\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6867285940160325\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.651875729386795\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6776470829626666\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.595243562933806\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6240554587261806\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6531223760401236\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7025315195533438\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6556741900748968\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6487293800124607\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7095538428987134\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6388238853054385\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6517329222708474\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6107626082122642\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5865354410772332\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5009170586847238\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8427479928627692\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5751036995083336\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6726411488207709\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.696756570085266\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='592' max='592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [592/592 17:57, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.286100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.264100</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.247900</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.255200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.209100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.249700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.255400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.244200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.265200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.309400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.278400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.249600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.305400</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.275400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.347900</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.184200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.181700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.208700</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.234600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.253800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.206300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.244300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.263000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.186200</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.268900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.173000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.187000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.213900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.168400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.121000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.182800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.157300</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.143000</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.125300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.153100</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.125400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.124500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.179900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.112100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.141700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.135100</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.134900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.140100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.107000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.104800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.094300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.103200</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.097900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.102700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.127800</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.085200</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.082700</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.099100</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.081400</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.101600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.101900</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.085500</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.096700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5463289146390643\n","is min 0.5463289146390643 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.99it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6434274071223947\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6378599037944457\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5400998492036693\n","is min 0.5400998492036693 is smaller than [0.5463289146390643, 0.6434274071223947, 0.6378599037944457]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8073012349745271\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5225094341583673\n","is min 0.5225094341583673 is smaller than [0.5463289146390643, 0.6434274071223947, 0.6378599037944457, 0.5400998492036693, 0.8073012349745271]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.520832871945521\n","is min 0.520832871945521 is smaller than [0.5463289146390643, 0.6434274071223947, 0.6378599037944457, 0.5400998492036693, 0.8073012349745271, 0.5225094341583673]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.00it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6337913848265472\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7693600552232452\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.598854648868821\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5849989447795519\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7613868229388917\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5160581812353497\n","is min 0.5160581812353497 is smaller than [0.5463289146390643, 0.6434274071223947, 0.6378599037944457, 0.5400998492036693, 0.8073012349745271, 0.5225094341583673, 0.520832871945521, 0.6337913848265472, 0.7693600552232452, 0.598854648868821, 0.5849989447795519, 0.7613868229388917]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49232767752515466\n","is min 0.49232767752515466 is smaller than [0.5463289146390643, 0.6434274071223947, 0.6378599037944457, 0.5400998492036693, 0.8073012349745271, 0.5225094341583673, 0.520832871945521, 0.6337913848265472, 0.7693600552232452, 0.598854648868821, 0.5849989447795519, 0.7613868229388917, 0.5160581812353497]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7583923217780009\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8217931909297543\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7300597126349151\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5290801535222017\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.88it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5568939836389849\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.89it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7561503373099471\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.90it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.65093727018729\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.49381197073780014\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.91it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8201339528624231\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6722576545422848\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.48665395602259004\n","is min 0.48665395602259004 is smaller than [0.5463289146390643, 0.6434274071223947, 0.6378599037944457, 0.5400998492036693, 0.8073012349745271, 0.5225094341583673, 0.520832871945521, 0.6337913848265472, 0.7693600552232452, 0.598854648868821, 0.5849989447795519, 0.7613868229388917, 0.5160581812353497, 0.49232767752515466, 0.7583923217780009, 0.8217931909297543, 0.7300597126349151, 0.5290801535222017, 0.5568939836389849, 0.7561503373099471, 0.65093727018729, 0.49381197073780014, 0.8201339528624231, 0.6722576545422848]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5460304075593915\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6721946893632876\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6879030256549988\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5862850913344375\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6831082427471128\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8695664008715972\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6421035428052512\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6511348935057825\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7214989581015191\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6479905123792902\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6693942391928792\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.658957672970201\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.836968958036172\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6209742886729702\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.93it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.638875170524847\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.655282383309499\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6949251753616561\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7354158119433376\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.710559838409244\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6519416356722205\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6135841220281877\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7165180066684925\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.661322128869088\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7464526763652033\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7891180474644932\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7515827212259965\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6461587386872082\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5774947657614575\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6756343262477649\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.620068019015388\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6075256088373489\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7343121483445398\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6892811531005714\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7262786392760515\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6727776558397227\n","Training done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='592' max='592' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [592/592 17:00, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.266500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.230900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.289200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.220600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.289900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.326200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.271500</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.231300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.257700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.279000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.258200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.259000</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.261400</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.302400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.215400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.201100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.215300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.181200</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.171500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.223100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.187800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.189200</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.193300</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.187200</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.209300</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.192600</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.191300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.221400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.242400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.223400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.135800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.153500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.174900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.164600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.204700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.212400</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.163400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.177300</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.132200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.125900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.133000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.130200</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.186900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.142900</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.127300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.102000</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.101900</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.090000</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.130100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.118400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.099000</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.086500</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.083700</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.100200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.118000</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.085000</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.114100</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.094000</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.102200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["15it [00:07,  2.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5163135007000824\n","is min 0.5163135007000824 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.01it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6305600553865569\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.668624744312633\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5706722210525768\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6242091844760282\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7199299739291323\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.4960685084973958\n","is min 0.4960685084973958 is smaller than [0.5163135007000824, 0.6305600553865569, 0.668624744312633, 0.5706722210525768, 0.6242091844760282, 0.7199299739291323]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","15it [00:07,  2.04it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.651969910749977\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7573396015060233\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.679561983055613\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6187701815765192\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5656732556319819\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.94it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5398047092606632\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.574089807584959\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6041779147602815\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6494256293223385\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5960019719336496\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6287414109371782\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6001057755942958\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6642515279085671\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8098124011672796\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6944442318185393\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6380780353032126\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7006395801909343\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5718742927480931\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5243810071355072\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5066619458727206\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7125589752837781\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.9220967639452786\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5477079242352887\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5269012596034346\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7593528679404625\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6182575928839437\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.85276367742332\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.9183849578952963\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5544487058819224\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5470023337923274\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8490924454270308\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6716463726555493\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7017473575992996\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5901123109358021\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7281663475128816\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7897645731761497\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6717087252999044\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7292685581170295\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.5802526806140252\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7852087198097473\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.611608261003335\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.8042541941038175\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.661053732549934\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6887362469962229\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6843029413378297\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6494003434486006\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.96it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6827292259488202\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6413797704634464\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6819195077582659\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7771853980766356\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.98it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7681509789406549\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.97it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7815393209021655\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:07,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.7868377045104237\n","Training done\n"]}],"source":["# roberta 1\n","model_name = os.path.join(ROBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 8,\n","  'lr': 1e-5,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ROBERTA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iyZmZulYQ-5U"},"source":["# Stacking"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"DHfTtt0QRC3B"},"outputs":[],"source":["model_dirs = [\n","    ALBERT_TRAINED_1,\n","    DEBERTA_TRAINED_1,\n","    ALBERT_TRAINED_2,\n","    DEBERTA_TRAINED_1,\n","    ROBERTA_TRAINED_1,\n","    ELECTRA_TRAINED_1\n","]\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = os.path.join(BASE_PATH,  'data/training/oof')"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"vLtSkIirhe7O"},"outputs":[{"name":"stderr","output_type":"stream","text":["15it [00:57,  3.86s/it]\n","15it [00:10,  1.40it/s]\n","15it [01:00,  4.02s/it]\n","15it [00:10,  1.41it/s]\n","15it [00:07,  1.95it/s]\n","15it [00:07,  1.96it/s]\n","/tmp/ipykernel_16155/3398867116.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append(fold_df, ignore_index=True)\n","15it [00:59,  3.94s/it]\n","15it [00:10,  1.42it/s]\n","15it [00:58,  3.93s/it]\n","15it [00:10,  1.44it/s]\n","15it [00:07,  1.98it/s]\n","15it [00:07,  1.98it/s]\n","/tmp/ipykernel_16155/3398867116.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append(fold_df, ignore_index=True)\n","15it [00:58,  3.90s/it]\n","15it [00:10,  1.44it/s]\n","15it [00:58,  3.90s/it]\n","15it [00:10,  1.45it/s]\n","15it [00:07,  2.00it/s]\n","15it [00:07,  2.01it/s]\n","/tmp/ipykernel_16155/3398867116.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append(fold_df, ignore_index=True)\n","15it [00:58,  3.89s/it]\n","15it [00:10,  1.45it/s]\n","15it [00:58,  3.89s/it]\n","15it [00:10,  1.45it/s]\n","15it [00:07,  2.01it/s]\n","15it [00:07,  2.00it/s]\n","/tmp/ipykernel_16155/3398867116.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append(fold_df, ignore_index=True)\n","15it [00:58,  3.89s/it]\n","15it [00:10,  1.44it/s]\n","15it [00:58,  3.90s/it]\n","15it [00:10,  1.44it/s]\n","15it [00:07,  1.99it/s]\n","15it [00:07,  1.99it/s]\n","/tmp/ipykernel_16155/3398867116.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append(fold_df, ignore_index=True)\n","15it [00:58,  3.89s/it]\n","15it [00:10,  1.45it/s]\n","15it [00:58,  3.89s/it]\n","15it [00:10,  1.45it/s]\n","15it [00:07,  2.01it/s]\n","15it [00:07,  2.01it/s]\n","/tmp/ipykernel_16155/3398867116.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append(fold_df, ignore_index=True)\n"]}],"source":["get_oof_predictions(model_dirs=model_dirs, fold_dir=fold_dir, out_dir=out_dir)"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"zNFUoYZsh1GF"},"outputs":[],"source":["model_names_ensemble_1 = [\n","    ALBERT_TRAINED_1.split('/')[-1],\n","    DEBERTA_TRAINED_1.split('/')[-1],\n","    ALBERT_TRAINED_2.split('/')[-1],\n","    DEBERTA_TRAINED_1.split('/')[-1],\n","    ROBERTA_TRAINED_1.split('/')[-1],\n","    ELECTRA_TRAINED_1.split('/')[-1],      \n","]\n","\n","#model_names_ensemble_2 = model_names_ensemble_1[:-1]\n","model_names_ensemble_2 = model_names_ensemble_1\n","\n","oof_dir = os.path.join(BASE_PATH, 'data/training/oof')\n","\n","out_dir_ensemble_1 = os.path.join(BASE_PATH, 'models/electra-larger-ensemble')\n","out_dir_ensemble_2 = os.path.join(BASE_PATH, 'models/huge-ensemble')"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"5Ruz_111qWoQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score is:  0.45536545111612503\n","Score is:  0.44102645950683217\n","Score is:  0.44455115946987456\n","Score is:  0.43465356645860115\n","Score is:  0.40216299968558455\n","Score is:  0.4159162886413556\n","CV ist:  0.43227932081306214\n"]}],"source":["# train ensemble 1\n","# [ ] DO NOW!!\n","train_leaky_ensembler(oof_dir=oof_dir, model_names=model_names_ensemble_1, out_dir=out_dir_ensemble_1)"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"Kt_VtNCgqa0v"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score is:  0.45536545111612503\n","Score is:  0.44102645950683217\n","Score is:  0.44455115946987456\n","Score is:  0.43465356645860115\n","Score is:  0.40216299968558455\n","Score is:  0.4159162886413556\n","CV ist:  0.43227932081306214\n"]}],"source":["# train ensemble 2\n","train_leaky_ensembler(oof_dir=oof_dir, model_names=model_names_ensemble_2, out_dir=out_dir_ensemble_2)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HJLfireQ0uoS"},"source":["You have finished training the models."]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNL/D3EW7Nf9IlW5+fqqTLT","collapsed_sections":["LZp4MeZUdFsm"],"name":"04_clrp_training.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"019d1122d3544181b5af8fcb0bf7ca0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02cf7113a3bd4029bee877c203b87de1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fc7897f470f4bbc86092083c0759e6a","placeholder":"â€‹","style":"IPY_MODEL_869a6a5af3e24c15a5f85fecb2450c22","value":"Downloading: 100%"}},"03dffc22176e4f86b5013ec5701961ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_457294515e36418ca6ba7b7c9fcb899d","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb6710f03f194276b008a53b5e120570","value":456318}},"0453164bfded49c8bb0b7826e9190f15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d257aaf71e41f8b93223540f12e546":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"072298bfd93644968c71b5fa7b84a952":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f317ba33d8df46bc811d8f21f45868e0","placeholder":"â€‹","style":"IPY_MODEL_5e13ecccb3774e1d8d66394f80788eb5","value":" 3.21k/? [00:00&lt;00:00, 73.9kB/s]"}},"0c05fa677771495296077d2cf6360cfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6890671c6b1043b38ffc66c85e2449c4","placeholder":"â€‹","style":"IPY_MODEL_019d1122d3544181b5af8fcb0bf7ca0d","value":"Downloading: 100%"}},"0c5ca114ea1f469da95325d91f38d79e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ddafe40e1774eb8a65e891e9c4d8005","placeholder":"â€‹","style":"IPY_MODEL_30194a43b72445389edeb445e7d71b9d","value":"Downloading: 100%"}},"0ddafe40e1774eb8a65e891e9c4d8005":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f8896d36a3e4c718ca5eb7d2a4db036":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ff0ac223dca4b2dbf0377c763eabdf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1062acd5853a4ab492415657e5b1639d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12726890add04fe6aa64cec205e05f05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1292580a726d491eaf064c9030ff1a35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b7307fbab5f4d71a75d3e7de2fefdf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c2543a0ab094134a25f6603ab1fd6d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b04c05d8dc8b4b71bbc8c4bce8b3d2b3","IPY_MODEL_beee0635e9634f0e9bdb43bf4036e422","IPY_MODEL_eb2d90da017b40618608151bafd7bcd1"],"layout":"IPY_MODEL_e8a73c92d4d646949922cd665cbda390"}},"1d41db217eec4602bf7f9838f5d769bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f290f5083de46cc8370d3949c8e36b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb2bbb9c3bc46e48ca6a93277c00b32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef0b635e92b4452a1e7d98fc9a303ac","placeholder":"â€‹","style":"IPY_MODEL_af2396e096a8459884990c8a9d63f9c9","value":" 1.36M/1.36M [00:00&lt;00:00, 3.86MB/s]"}},"1fbc5226341945e6b64a2ac45af52004":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fc7897f470f4bbc86092083c0759e6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2019d8e148a24245a802ad90d28f781c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"244ecc5b53a444d9b06b8981b85c970f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"246c3ab4a27e42b5bb00d25177c30065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27fc9f209c424da2b4d3036de96badc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ff5753d701940c0afdbc331012634e9","IPY_MODEL_3c9d5461f6414ef0a033c6a098419ae9","IPY_MODEL_4d7b09f0f3dd4299a7ce1d586fe15c08"],"layout":"IPY_MODEL_571ae312ec664826807dca5ccffb390b"}},"2a6557ecc21e4838a06786b3947a073d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b304b633c654429ba05a1f48447ddb4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cd178aa7c4f4ad8b8f07d72750a824a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e6b0ee16bbb480ca3dd6f81d080dca1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ebe8afbd64e4fe69559ff40eee28408":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ecbc2a60c2c43dc94a81fda94a8c65f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ef75b93f0cd4dc3ae0b74a21a967af8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30194a43b72445389edeb445e7d71b9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"308d554f512e47c0bec0eaea069ffa31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33641ab74dad49f3a86d0d8fa46b7a1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33976aa53a1641d486f194e3c19e5f03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_637523262dfc46d69847ca26bd009307","placeholder":"â€‹","style":"IPY_MODEL_cb6a512b72904f8f83f01ceacb5bd2ae","value":" 899k/899k [00:00&lt;00:00, 1.16MB/s]"}},"33f156b8e7874b87a9f61d1a065c4c96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c05fa677771495296077d2cf6360cfe","IPY_MODEL_613d68d5434a47c89ef55f0cd1436977","IPY_MODEL_e3b3b1add5944372a3349cee1957f85c"],"layout":"IPY_MODEL_1f290f5083de46cc8370d3949c8e36b6"}},"340ae92dba31406382b56af69026d5b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dd8f7a12ffe412182a4ccc5266dd050","placeholder":"â€‹","style":"IPY_MODEL_7f44c0772f544c6191df123810f7ede8","value":" 232k/232k [00:00&lt;00:00, 1.30MB/s]"}},"3b6ff42c143741f8ac1ef39ee7f4f5fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae4befe894374ea4ba4639e7238b0001","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3cb7aa5e15d4f62996e6b473ce6bcef","value":231508}},"3c9d5461f6414ef0a033c6a098419ae9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8829de1e90e04481a5ce6668558c22f8","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cd178aa7c4f4ad8b8f07d72750a824a","value":466062}},"41780e8505b04e1aa48fca3005dfcf3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed4cc8276fd947ee95e9e420cceaab0f","IPY_MODEL_4cf4929d93724b88be6d1d428bdfaa97","IPY_MODEL_902edc73112946b88d55afe299ff680a"],"layout":"IPY_MODEL_0f8896d36a3e4c718ca5eb7d2a4db036"}},"429edfad527e4e8caa4627e6f2f83bc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"457294515e36418ca6ba7b7c9fcb899d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462f1ab065bd4a68b44f3e5f82f6d6c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48f85b79c58d4cd59eca639d19bd1f90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f8b910cb89742648ffc9df643d8cca3","placeholder":"â€‹","style":"IPY_MODEL_04d257aaf71e41f8b93223540f12e546","value":" 475/475 [00:00&lt;00:00, 12.6kB/s]"}},"4a2d57e7f35d428393d374b5d9cc2f49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afd4111264f4a0fa9579d1b301b4601":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cf4929d93724b88be6d1d428bdfaa97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b304b633c654429ba05a1f48447ddb4","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75fab396ec05456093e052d7b5dfb596","value":898825}},"4d7b09f0f3dd4299a7ce1d586fe15c08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85f3e8aaf83748e899449c567244664e","placeholder":"â€‹","style":"IPY_MODEL_f3b7b30ad39d4bfd8fe8aeb462f9e091","value":" 466k/466k [00:00&lt;00:00, 1.13MB/s]"}},"4ff5753d701940c0afdbc331012634e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec386d7b500b440684b1050842a69ad4","placeholder":"â€‹","style":"IPY_MODEL_2ef75b93f0cd4dc3ae0b74a21a967af8","value":"Downloading: 100%"}},"5388dbecd0fb49c88abf02733747e01b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db12d6399bc941f59c6ae60d2beb11f2","IPY_MODEL_db59f537fd6049fe901d042905823c30","IPY_MODEL_072298bfd93644968c71b5fa7b84a952"],"layout":"IPY_MODEL_d56efd20fa814a9b957a7dc49056032d"}},"53a20cba91cb4d498efefa81f96292b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1062acd5853a4ab492415657e5b1639d","placeholder":"â€‹","style":"IPY_MODEL_f1db107c5f084fd384df120d75eac853","value":" 668/668 [00:00&lt;00:00, 24.0kB/s]"}},"551e0e9d097347aabc0c6bebd01d2082":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55fbffecf6d047b28a0ed099ccb3c394":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56267050b1354f1eb6ec79b758c5b31a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"571ae312ec664826807dca5ccffb390b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5757c3974b7b435e8ceb531a897f58ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a21c7fa7b0b4ac18487f03367a85246":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b14760830124e63b302f63944690cea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6b87bbdbf354587b1330eff467f6174","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6831b4a9736483aa3aefc9bb2318a2a","value":52}},"5cbcca203a664f5fa706408b54c9efda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cce9baee6c7e402199003c1fb98bd206","placeholder":"â€‹","style":"IPY_MODEL_5e750ab91db34b89a69ef11fe667069c","value":"Downloading: 100%"}},"5db45fe62cf54877bdd1bbd8cc98da28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e13ecccb3774e1d8d66394f80788eb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e750ab91db34b89a69ef11fe667069c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60548b7369d54fc09a1ecd823daa418a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"613d68d5434a47c89ef55f0cd1436977":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eac90ccd9584470cb7adfbc9c7e2679c","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7070960c8eac4935902546d358b07231","value":456318}},"6278a802693a48f089d2fb0d5c159cc9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62932fc171e54ad8a6e83d43bbecef28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_994983c7661840cda6a0d12d874605a5","IPY_MODEL_6a89755c37e849359f19ea453f7a64e1","IPY_MODEL_a3baefe68a214cc6a3f4616719547fed"],"layout":"IPY_MODEL_7e266f1c703b43e2a1380fce6f749f4c"}},"637523262dfc46d69847ca26bd009307":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6495b6f0569240ca9af463481aec94da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6890671c6b1043b38ffc66c85e2449c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"694cac06d91d4ef99bf0e817d8ed9b15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a38f1a6e951441a9defc9398c540098":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a656abe51244c5eaa8091bcc626c2d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9823b8716027416bb07fd2aa35fdae8d","IPY_MODEL_e4b9b2ea64e649918de011a1f1bfeac6","IPY_MODEL_87d2b417d2e547b48ef1deb064d07cdd"],"layout":"IPY_MODEL_a7ad68d3c6fc4eeeb8f47df6a893510b"}},"6a89755c37e849359f19ea453f7a64e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc943877ab974e009c3f603a77005346","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2019d8e148a24245a802ad90d28f781c","value":482}},"6b7bf1bf7414490dbfad3d33f9a44ab3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60548b7369d54fc09a1ecd823daa418a","placeholder":"â€‹","style":"IPY_MODEL_2e6b0ee16bbb480ca3dd6f81d080dca1","value":"Downloading: 100%"}},"6dd8f7a12ffe412182a4ccc5266dd050":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fe21e46a1b44bf8b5e43027e73376a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eebc87e23ac34b7d947d4a5bbb64f5ca","IPY_MODEL_be782cc5c1c8488a8c97131739437e05","IPY_MODEL_c3ddab55f4d744b1912d884122978df4"],"layout":"IPY_MODEL_12726890add04fe6aa64cec205e05f05"}},"704350d386904fdba4b2782392f4c0bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7070960c8eac4935902546d358b07231":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71b5c02f4d0e4ec8a4c0aedea3866491":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_751b8d67044b4e129014a26dcf0b442b","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ee23fd9355f4202b42c77215a50bcc9","value":1355863}},"71cb361ae38f4d8b95201eb7e3458965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c914f3f58ca3436a80c4f1a48bac0872","max":27,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3efb3aa702041de99815ae25b9ed9b3","value":27}},"7415cf21ec1f4148b19b1409784429d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc421dd21cf44c97a5a2feda0a02e72b","placeholder":"â€‹","style":"IPY_MODEL_ac2bd1da3ced4f3b91b484bd745e86da","value":"Downloading: 100%"}},"751b8d67044b4e129014a26dcf0b442b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75f19f654a4d4d26bb431102cdaf6ad6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b512229653d427985f4bf9cc4bcad3e","IPY_MODEL_3b6ff42c143741f8ac1ef39ee7f4f5fe","IPY_MODEL_340ae92dba31406382b56af69026d5b9"],"layout":"IPY_MODEL_0ff0ac223dca4b2dbf0377c763eabdf9"}},"75fab396ec05456093e052d7b5dfb596":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78d31076d57e40b2aec4106cc72d5331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b746096d32c84fd8b1661033502a7e34","placeholder":"â€‹","style":"IPY_MODEL_e2a41718e2684ff58ae266178918aaed","value":"Downloading: 100%"}},"7e13bdfc94c94de0abb94f660435a750":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e266f1c703b43e2a1380fce6f749f4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee23fd9355f4202b42c77215a50bcc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f44c0772f544c6191df123810f7ede8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80f2a430804c4705bb60ee001c6ad758":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b99e1a4caa4eb1ac8b0c99f71f88c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82c212bad67f4d948af30a2c77794710":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfede7c27a8c4499925944119f1a6be5","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_429edfad527e4e8caa4627e6f2f83bc0","value":898823}},"845c5936fd96438b87a1cce2974d78e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85f3e8aaf83748e899449c567244664e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869a6a5af3e24c15a5f85fecb2450c22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87d2b417d2e547b48ef1deb064d07cdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7e6cf2574994104a3e89c652ff0db22","placeholder":"â€‹","style":"IPY_MODEL_7e13bdfc94c94de0abb94f660435a750","value":" 1.34G/1.34G [00:46&lt;00:00, 30.1MB/s]"}},"8829de1e90e04481a5ce6668558c22f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886de66ecec3421886e3f50e479a6ff0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8df646e9927442ebbc00dcb84935a0cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902edc73112946b88d55afe299ff680a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba20d6ba371f4f96b3d379713ed39642","placeholder":"â€‹","style":"IPY_MODEL_aa8cf38b1fc54d47a2adc5c0a58ac504","value":" 899k/899k [00:00&lt;00:00, 2.09MB/s]"}},"916ed8c81bf64a8984fc1e40cefdaa00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91f8052331ba482e8380aaf7e83fc1db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7415cf21ec1f4148b19b1409784429d3","IPY_MODEL_d78f3bc7a3e24eab92569fdaf83f7ba4","IPY_MODEL_48f85b79c58d4cd59eca639d19bd1f90"],"layout":"IPY_MODEL_845c5936fd96438b87a1cce2974d78e5"}},"9792332c910147b6bf64cd330164c98d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9823b8716027416bb07fd2aa35fdae8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_308d554f512e47c0bec0eaea069ffa31","placeholder":"â€‹","style":"IPY_MODEL_986d22e0c67c4318aea89f64a3e1a7bc","value":"Downloading: 100%"}},"986d22e0c67c4318aea89f64a3e1a7bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"994983c7661840cda6a0d12d874605a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fa94d851b284aa0b6d8d8590f7a8d7f","placeholder":"â€‹","style":"IPY_MODEL_694cac06d91d4ef99bf0e817d8ed9b15","value":"Downloading: 100%"}},"9b512229653d427985f4bf9cc4bcad3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad8d432775134c2187fe3f53821049d7","placeholder":"â€‹","style":"IPY_MODEL_a06b96a650894594bd3e10c43b4e58f6","value":"Downloading: 100%"}},"9f23ccc019dc4046a6cb4347a397ad79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f8b910cb89742648ffc9df643d8cca3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa94d851b284aa0b6d8d8590f7a8d7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a06b96a650894594bd3e10c43b4e58f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3baefe68a214cc6a3f4616719547fed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9792332c910147b6bf64cd330164c98d","placeholder":"â€‹","style":"IPY_MODEL_e5c78f7c515a497a9c7a05f1a2661c3a","value":" 482/482 [00:00&lt;00:00, 13.1kB/s]"}},"a659a7f4171640ffa54d69ed7a7f1be2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a664243ec98b488f8479aefe34cef74e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a773068bd347414bb829a6e2e7c5e975":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbf7c6179c8940b999fb4980e1cd1ada","IPY_MODEL_cf79d819e9aa453d9779b735e3ed1be2","IPY_MODEL_d2c7ecc96bcf402582adaa75cfdc9ef8"],"layout":"IPY_MODEL_eb79e9523fe44d2ebc4b7c2baf578b2d"}},"a7ad68d3c6fc4eeeb8f47df6a893510b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a83dbb4207c647f59b814762bdb7c865":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8efe07af555436c803faeba3a090544":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78d31076d57e40b2aec4106cc72d5331","IPY_MODEL_71b5c02f4d0e4ec8a4c0aedea3866491","IPY_MODEL_1fb2bbb9c3bc46e48ca6a93277c00b32"],"layout":"IPY_MODEL_8df646e9927442ebbc00dcb84935a0cd"}},"a91b8640c5b5445494dee1952a9508fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa8cf38b1fc54d47a2adc5c0a58ac504":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac2bd1da3ced4f3b91b484bd745e86da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad8d432775134c2187fe3f53821049d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae4befe894374ea4ba4639e7238b0001":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2396e096a8459884990c8a9d63f9c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b02adf7749384b84a9928b183565ffe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c5ca114ea1f469da95325d91f38d79e","IPY_MODEL_f9fefdf355374256942ab6a0717ea8cc","IPY_MODEL_53a20cba91cb4d498efefa81f96292b6"],"layout":"IPY_MODEL_c8cf91d3257e40c6addbdab6e43c39fd"}},"b04c05d8dc8b4b71bbc8c4bce8b3d2b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33641ab74dad49f3a86d0d8fa46b7a1e","placeholder":"â€‹","style":"IPY_MODEL_fcb6c02ee7df43edaac1e1a2ade1f1a6","value":"Downloading: 100%"}},"b3cb7aa5e15d4f62996e6b473ce6bcef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6b87bbdbf354587b1330eff467f6174":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b746096d32c84fd8b1661033502a7e34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7e6cf2574994104a3e89c652ff0db22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b97a3a30bdfd4612b09b2d5e0447d381":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba0e39c775894ab897462870c7beadc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba20d6ba371f4f96b3d379713ed39642":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcc8278f44c34ec88a10a739a0cbeffc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cbcca203a664f5fa706408b54c9efda","IPY_MODEL_82c212bad67f4d948af30a2c77794710","IPY_MODEL_33976aa53a1641d486f194e3c19e5f03"],"layout":"IPY_MODEL_2a6557ecc21e4838a06786b3947a073d"}},"bd242afef0ab4c3cb6b9f87717cdd344":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c29f290b45d8475380626a8cad70c10f","IPY_MODEL_71cb361ae38f4d8b95201eb7e3458965","IPY_MODEL_bd8cf24968f24864a8e4f2c406426ac5"],"layout":"IPY_MODEL_1292580a726d491eaf064c9030ff1a35"}},"bd8cf24968f24864a8e4f2c406426ac5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0453164bfded49c8bb0b7826e9190f15","placeholder":"â€‹","style":"IPY_MODEL_c9d9fa1294954d3ebfc519a8aa155b2b","value":" 27.0/27.0 [00:00&lt;00:00, 764B/s]"}},"be782cc5c1c8488a8c97131739437e05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5db45fe62cf54877bdd1bbd8cc98da28","max":892728632,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4afd4111264f4a0fa9579d1b301b4601","value":892728632}},"beee0635e9634f0e9bdb43bf4036e422":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_886de66ecec3421886e3f50e479a6ff0","max":1627222675,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ecbc2a60c2c43dc94a81fda94a8c65f","value":1627222675}},"bff952736ffd4b50ae75acb020fd481b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e3e9263f584157beaa54ce480c74f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c29f290b45d8475380626a8cad70c10f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6278a802693a48f089d2fb0d5c159cc9","placeholder":"â€‹","style":"IPY_MODEL_e8461044e198445884fcdbbac79a937c","value":"Downloading: 100%"}},"c3ddab55f4d744b1912d884122978df4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_551e0e9d097347aabc0c6bebd01d2082","placeholder":"â€‹","style":"IPY_MODEL_6a38f1a6e951441a9defc9398c540098","value":" 893M/893M [00:17&lt;00:00, 52.1MB/s]"}},"c3efb3aa702041de99815ae25b9ed9b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8cf91d3257e40c6addbdab6e43c39fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c914f3f58ca3436a80c4f1a48bac0872":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9d9fa1294954d3ebfc519a8aa155b2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb6710f03f194276b008a53b5e120570":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb6a512b72904f8f83f01ceacb5bd2ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbf7c6179c8940b999fb4980e1cd1ada":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ebe8afbd64e4fe69559ff40eee28408","placeholder":"â€‹","style":"IPY_MODEL_a664243ec98b488f8479aefe34cef74e","value":"Downloading: 100%"}},"cc421dd21cf44c97a5a2feda0a02e72b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cce9baee6c7e402199003c1fb98bd206":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf79d819e9aa453d9779b735e3ed1be2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80f2a430804c4705bb60ee001c6ad758","max":1425941629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1e3e9263f584157beaa54ce480c74f2","value":1425941629}},"cfede7c27a8c4499925944119f1a6be5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1b7209908a64f4db31686c5d25f2fbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2c7ecc96bcf402582adaa75cfdc9ef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82b99e1a4caa4eb1ac8b0c99f71f88c9","placeholder":"â€‹","style":"IPY_MODEL_a83dbb4207c647f59b814762bdb7c865","value":" 1.43G/1.43G [00:28&lt;00:00, 50.1MB/s]"}},"d56efd20fa814a9b957a7dc49056032d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d78f3bc7a3e24eab92569fdaf83f7ba4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0baea8e01ce4a3cab96f14b4b9944e6","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e108e22beefe4dbfa21f01a189070bb0","value":475}},"d7a3a38272ff48ba8125b50be1b157d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b7bf1bf7414490dbfad3d33f9a44ab3","IPY_MODEL_5b14760830124e63b302f63944690cea","IPY_MODEL_dbb3d4a578cd4564a53414ceef71da2b"],"layout":"IPY_MODEL_bff952736ffd4b50ae75acb020fd481b"}},"db12d6399bc941f59c6ae60d2beb11f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_244ecc5b53a444d9b06b8981b85c970f","placeholder":"â€‹","style":"IPY_MODEL_b97a3a30bdfd4612b09b2d5e0447d381","value":"Downloading: "}},"db59f537fd6049fe901d042905823c30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_916ed8c81bf64a8984fc1e40cefdaa00","max":1421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f23ccc019dc4046a6cb4347a397ad79","value":1421}},"dbb3d4a578cd4564a53414ceef71da2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fbc5226341945e6b64a2ac45af52004","placeholder":"â€‹","style":"IPY_MODEL_462f1ab065bd4a68b44f3e5f82f6d6c8","value":" 52.0/52.0 [00:00&lt;00:00, 1.52kB/s]"}},"e0baea8e01ce4a3cab96f14b4b9944e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e108e22beefe4dbfa21f01a189070bb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2a41718e2684ff58ae266178918aaed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3b3b1add5944372a3349cee1957f85c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba0e39c775894ab897462870c7beadc5","placeholder":"â€‹","style":"IPY_MODEL_a659a7f4171640ffa54d69ed7a7f1be2","value":" 456k/456k [00:00&lt;00:00, 1.27MB/s]"}},"e4b9b2ea64e649918de011a1f1bfeac6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5757c3974b7b435e8ceb531a897f58ed","max":1344867008,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1b7209908a64f4db31686c5d25f2fbf","value":1344867008}},"e5c78f7c515a497a9c7a05f1a2661c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6831b4a9736483aa3aefc9bb2318a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8461044e198445884fcdbbac79a937c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8a73c92d4d646949922cd665cbda390":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eac90ccd9584470cb7adfbc9c7e2679c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb1139ebfb2a49249a58cda90cbc7ff8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02cf7113a3bd4029bee877c203b87de1","IPY_MODEL_03dffc22176e4f86b5013ec5701961ba","IPY_MODEL_f780e03a76924012a269932fe736d0ac"],"layout":"IPY_MODEL_1b7307fbab5f4d71a75d3e7de2fefdf9"}},"eb2d90da017b40618608151bafd7bcd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a21c7fa7b0b4ac18487f03367a85246","placeholder":"â€‹","style":"IPY_MODEL_55fbffecf6d047b28a0ed099ccb3c394","value":" 1.63G/1.63G [00:55&lt;00:00, 29.9MB/s]"}},"eb79e9523fe44d2ebc4b7c2baf578b2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec386d7b500b440684b1050842a69ad4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed4cc8276fd947ee95e9e420cceaab0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_704350d386904fdba4b2782392f4c0bc","placeholder":"â€‹","style":"IPY_MODEL_6495b6f0569240ca9af463481aec94da","value":"Downloading: 100%"}},"eebc87e23ac34b7d947d4a5bbb64f5ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d41db217eec4602bf7f9838f5d769bd","placeholder":"â€‹","style":"IPY_MODEL_f4dfe24236874484ad73205f2612257d","value":"Downloading: 100%"}},"f1db107c5f084fd384df120d75eac853":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f317ba33d8df46bc811d8f21f45868e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3b7b30ad39d4bfd8fe8aeb462f9e091":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4dfe24236874484ad73205f2612257d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f780e03a76924012a269932fe736d0ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a2d57e7f35d428393d374b5d9cc2f49","placeholder":"â€‹","style":"IPY_MODEL_56267050b1354f1eb6ec79b758c5b31a","value":" 456k/456k [00:00&lt;00:00, 1.27MB/s]"}},"f9fefdf355374256942ab6a0717ea8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_246c3ab4a27e42b5bb00d25177c30065","max":668,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a91b8640c5b5445494dee1952a9508fd","value":668}},"fc943877ab974e009c3f603a77005346":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcb6c02ee7df43edaac1e1a2ade1f1a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef0b635e92b4452a1e7d98fc9a303ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
