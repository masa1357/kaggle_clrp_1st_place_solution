{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_clrp_training.ipynb","provenance":[],"collapsed_sections":["LZp4MeZUdFsm"],"toc_visible":true,"authorship_tag":"ABX9TyNL/D3EW7Nf9IlW5+fqqTLT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6fe21e46a1b44bf8b5e43027e73376a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_12726890add04fe6aa64cec205e05f05","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eebc87e23ac34b7d947d4a5bbb64f5ca","IPY_MODEL_be782cc5c1c8488a8c97131739437e05","IPY_MODEL_c3ddab55f4d744b1912d884122978df4"]}},"12726890add04fe6aa64cec205e05f05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eebc87e23ac34b7d947d4a5bbb64f5ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f4dfe24236874484ad73205f2612257d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d41db217eec4602bf7f9838f5d769bd"}},"be782cc5c1c8488a8c97131739437e05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4afd4111264f4a0fa9579d1b301b4601","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":892728632,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":892728632,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5db45fe62cf54877bdd1bbd8cc98da28"}},"c3ddab55f4d744b1912d884122978df4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a38f1a6e951441a9defc9398c540098","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 893M/893M [00:17&lt;00:00, 52.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_551e0e9d097347aabc0c6bebd01d2082"}},"f4dfe24236874484ad73205f2612257d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1d41db217eec4602bf7f9838f5d769bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4afd4111264f4a0fa9579d1b301b4601":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5db45fe62cf54877bdd1bbd8cc98da28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a38f1a6e951441a9defc9398c540098":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"551e0e9d097347aabc0c6bebd01d2082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5388dbecd0fb49c88abf02733747e01b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d56efd20fa814a9b957a7dc49056032d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_db12d6399bc941f59c6ae60d2beb11f2","IPY_MODEL_db59f537fd6049fe901d042905823c30","IPY_MODEL_072298bfd93644968c71b5fa7b84a952"]}},"d56efd20fa814a9b957a7dc49056032d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db12d6399bc941f59c6ae60d2beb11f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b97a3a30bdfd4612b09b2d5e0447d381","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_244ecc5b53a444d9b06b8981b85c970f"}},"db59f537fd6049fe901d042905823c30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9f23ccc019dc4046a6cb4347a397ad79","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1421,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1421,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_916ed8c81bf64a8984fc1e40cefdaa00"}},"072298bfd93644968c71b5fa7b84a952":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e13ecccb3774e1d8d66394f80788eb5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3.21k/? [00:00&lt;00:00, 73.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f317ba33d8df46bc811d8f21f45868e0"}},"b97a3a30bdfd4612b09b2d5e0447d381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"244ecc5b53a444d9b06b8981b85c970f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f23ccc019dc4046a6cb4347a397ad79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"916ed8c81bf64a8984fc1e40cefdaa00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e13ecccb3774e1d8d66394f80788eb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f317ba33d8df46bc811d8f21f45868e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7a3a38272ff48ba8125b50be1b157d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bff952736ffd4b50ae75acb020fd481b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b7bf1bf7414490dbfad3d33f9a44ab3","IPY_MODEL_5b14760830124e63b302f63944690cea","IPY_MODEL_dbb3d4a578cd4564a53414ceef71da2b"]}},"bff952736ffd4b50ae75acb020fd481b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b7bf1bf7414490dbfad3d33f9a44ab3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e6b0ee16bbb480ca3dd6f81d080dca1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60548b7369d54fc09a1ecd823daa418a"}},"5b14760830124e63b302f63944690cea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e6831b4a9736483aa3aefc9bb2318a2a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":52,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":52,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6b87bbdbf354587b1330eff467f6174"}},"dbb3d4a578cd4564a53414ceef71da2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_462f1ab065bd4a68b44f3e5f82f6d6c8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 52.0/52.0 [00:00&lt;00:00, 1.52kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fbc5226341945e6b64a2ac45af52004"}},"2e6b0ee16bbb480ca3dd6f81d080dca1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"60548b7369d54fc09a1ecd823daa418a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6831b4a9736483aa3aefc9bb2318a2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b6b87bbdbf354587b1330eff467f6174":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"462f1ab065bd4a68b44f3e5f82f6d6c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1fbc5226341945e6b64a2ac45af52004":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91f8052331ba482e8380aaf7e83fc1db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_845c5936fd96438b87a1cce2974d78e5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7415cf21ec1f4148b19b1409784429d3","IPY_MODEL_d78f3bc7a3e24eab92569fdaf83f7ba4","IPY_MODEL_48f85b79c58d4cd59eca639d19bd1f90"]}},"845c5936fd96438b87a1cce2974d78e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7415cf21ec1f4148b19b1409784429d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ac2bd1da3ced4f3b91b484bd745e86da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc421dd21cf44c97a5a2feda0a02e72b"}},"d78f3bc7a3e24eab92569fdaf83f7ba4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e108e22beefe4dbfa21f01a189070bb0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":475,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":475,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0baea8e01ce4a3cab96f14b4b9944e6"}},"48f85b79c58d4cd59eca639d19bd1f90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_04d257aaf71e41f8b93223540f12e546","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 475/475 [00:00&lt;00:00, 12.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f8b910cb89742648ffc9df643d8cca3"}},"ac2bd1da3ced4f3b91b484bd745e86da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cc421dd21cf44c97a5a2feda0a02e72b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e108e22beefe4dbfa21f01a189070bb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e0baea8e01ce4a3cab96f14b4b9944e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04d257aaf71e41f8b93223540f12e546":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9f8b910cb89742648ffc9df643d8cca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41780e8505b04e1aa48fca3005dfcf3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0f8896d36a3e4c718ca5eb7d2a4db036","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed4cc8276fd947ee95e9e420cceaab0f","IPY_MODEL_4cf4929d93724b88be6d1d428bdfaa97","IPY_MODEL_902edc73112946b88d55afe299ff680a"]}},"0f8896d36a3e4c718ca5eb7d2a4db036":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed4cc8276fd947ee95e9e420cceaab0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6495b6f0569240ca9af463481aec94da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_704350d386904fdba4b2782392f4c0bc"}},"4cf4929d93724b88be6d1d428bdfaa97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_75fab396ec05456093e052d7b5dfb596","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898825,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898825,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b304b633c654429ba05a1f48447ddb4"}},"902edc73112946b88d55afe299ff680a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aa8cf38b1fc54d47a2adc5c0a58ac504","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 2.09MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba20d6ba371f4f96b3d379713ed39642"}},"6495b6f0569240ca9af463481aec94da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"704350d386904fdba4b2782392f4c0bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75fab396ec05456093e052d7b5dfb596":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2b304b633c654429ba05a1f48447ddb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa8cf38b1fc54d47a2adc5c0a58ac504":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba20d6ba371f4f96b3d379713ed39642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33f156b8e7874b87a9f61d1a065c4c96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1f290f5083de46cc8370d3949c8e36b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0c05fa677771495296077d2cf6360cfe","IPY_MODEL_613d68d5434a47c89ef55f0cd1436977","IPY_MODEL_e3b3b1add5944372a3349cee1957f85c"]}},"1f290f5083de46cc8370d3949c8e36b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c05fa677771495296077d2cf6360cfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_019d1122d3544181b5af8fcb0bf7ca0d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6890671c6b1043b38ffc66c85e2449c4"}},"613d68d5434a47c89ef55f0cd1436977":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7070960c8eac4935902546d358b07231","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eac90ccd9584470cb7adfbc9c7e2679c"}},"e3b3b1add5944372a3349cee1957f85c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a659a7f4171640ffa54d69ed7a7f1be2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 1.27MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba0e39c775894ab897462870c7beadc5"}},"019d1122d3544181b5af8fcb0bf7ca0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6890671c6b1043b38ffc66c85e2449c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7070960c8eac4935902546d358b07231":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eac90ccd9584470cb7adfbc9c7e2679c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a659a7f4171640ffa54d69ed7a7f1be2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba0e39c775894ab897462870c7beadc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c2543a0ab094134a25f6603ab1fd6d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e8a73c92d4d646949922cd665cbda390","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b04c05d8dc8b4b71bbc8c4bce8b3d2b3","IPY_MODEL_beee0635e9634f0e9bdb43bf4036e422","IPY_MODEL_eb2d90da017b40618608151bafd7bcd1"]}},"e8a73c92d4d646949922cd665cbda390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b04c05d8dc8b4b71bbc8c4bce8b3d2b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fcb6c02ee7df43edaac1e1a2ade1f1a6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33641ab74dad49f3a86d0d8fa46b7a1e"}},"beee0635e9634f0e9bdb43bf4036e422":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2ecbc2a60c2c43dc94a81fda94a8c65f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1627222675,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1627222675,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_886de66ecec3421886e3f50e479a6ff0"}},"eb2d90da017b40618608151bafd7bcd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_55fbffecf6d047b28a0ed099ccb3c394","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.63G/1.63G [00:55&lt;00:00, 29.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a21c7fa7b0b4ac18487f03367a85246"}},"fcb6c02ee7df43edaac1e1a2ade1f1a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33641ab74dad49f3a86d0d8fa46b7a1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ecbc2a60c2c43dc94a81fda94a8c65f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"886de66ecec3421886e3f50e479a6ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55fbffecf6d047b28a0ed099ccb3c394":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a21c7fa7b0b4ac18487f03367a85246":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62932fc171e54ad8a6e83d43bbecef28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7e266f1c703b43e2a1380fce6f749f4c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_994983c7661840cda6a0d12d874605a5","IPY_MODEL_6a89755c37e849359f19ea453f7a64e1","IPY_MODEL_a3baefe68a214cc6a3f4616719547fed"]}},"7e266f1c703b43e2a1380fce6f749f4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"994983c7661840cda6a0d12d874605a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_694cac06d91d4ef99bf0e817d8ed9b15","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9fa94d851b284aa0b6d8d8590f7a8d7f"}},"6a89755c37e849359f19ea453f7a64e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2019d8e148a24245a802ad90d28f781c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc943877ab974e009c3f603a77005346"}},"a3baefe68a214cc6a3f4616719547fed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e5c78f7c515a497a9c7a05f1a2661c3a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:00&lt;00:00, 13.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9792332c910147b6bf64cd330164c98d"}},"694cac06d91d4ef99bf0e817d8ed9b15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9fa94d851b284aa0b6d8d8590f7a8d7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2019d8e148a24245a802ad90d28f781c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fc943877ab974e009c3f603a77005346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e5c78f7c515a497a9c7a05f1a2661c3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9792332c910147b6bf64cd330164c98d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcc8278f44c34ec88a10a739a0cbeffc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2a6557ecc21e4838a06786b3947a073d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5cbcca203a664f5fa706408b54c9efda","IPY_MODEL_82c212bad67f4d948af30a2c77794710","IPY_MODEL_33976aa53a1641d486f194e3c19e5f03"]}},"2a6557ecc21e4838a06786b3947a073d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cbcca203a664f5fa706408b54c9efda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e750ab91db34b89a69ef11fe667069c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cce9baee6c7e402199003c1fb98bd206"}},"82c212bad67f4d948af30a2c77794710":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_429edfad527e4e8caa4627e6f2f83bc0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfede7c27a8c4499925944119f1a6be5"}},"33976aa53a1641d486f194e3c19e5f03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cb6a512b72904f8f83f01ceacb5bd2ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 1.16MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_637523262dfc46d69847ca26bd009307"}},"5e750ab91db34b89a69ef11fe667069c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cce9baee6c7e402199003c1fb98bd206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"429edfad527e4e8caa4627e6f2f83bc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cfede7c27a8c4499925944119f1a6be5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb6a512b72904f8f83f01ceacb5bd2ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"637523262dfc46d69847ca26bd009307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb1139ebfb2a49249a58cda90cbc7ff8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b7307fbab5f4d71a75d3e7de2fefdf9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_02cf7113a3bd4029bee877c203b87de1","IPY_MODEL_03dffc22176e4f86b5013ec5701961ba","IPY_MODEL_f780e03a76924012a269932fe736d0ac"]}},"1b7307fbab5f4d71a75d3e7de2fefdf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02cf7113a3bd4029bee877c203b87de1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_869a6a5af3e24c15a5f85fecb2450c22","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fc7897f470f4bbc86092083c0759e6a"}},"03dffc22176e4f86b5013ec5701961ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cb6710f03f194276b008a53b5e120570","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_457294515e36418ca6ba7b7c9fcb899d"}},"f780e03a76924012a269932fe736d0ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_56267050b1354f1eb6ec79b758c5b31a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 1.27MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a2d57e7f35d428393d374b5d9cc2f49"}},"869a6a5af3e24c15a5f85fecb2450c22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1fc7897f470f4bbc86092083c0759e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb6710f03f194276b008a53b5e120570":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"457294515e36418ca6ba7b7c9fcb899d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56267050b1354f1eb6ec79b758c5b31a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a2d57e7f35d428393d374b5d9cc2f49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8efe07af555436c803faeba3a090544":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8df646e9927442ebbc00dcb84935a0cd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_78d31076d57e40b2aec4106cc72d5331","IPY_MODEL_71b5c02f4d0e4ec8a4c0aedea3866491","IPY_MODEL_1fb2bbb9c3bc46e48ca6a93277c00b32"]}},"8df646e9927442ebbc00dcb84935a0cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78d31076d57e40b2aec4106cc72d5331":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e2a41718e2684ff58ae266178918aaed","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b746096d32c84fd8b1661033502a7e34"}},"71b5c02f4d0e4ec8a4c0aedea3866491":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7ee23fd9355f4202b42c77215a50bcc9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_751b8d67044b4e129014a26dcf0b442b"}},"1fb2bbb9c3bc46e48ca6a93277c00b32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_af2396e096a8459884990c8a9d63f9c9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 3.86MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fef0b635e92b4452a1e7d98fc9a303ac"}},"e2a41718e2684ff58ae266178918aaed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b746096d32c84fd8b1661033502a7e34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ee23fd9355f4202b42c77215a50bcc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"751b8d67044b4e129014a26dcf0b442b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af2396e096a8459884990c8a9d63f9c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fef0b635e92b4452a1e7d98fc9a303ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a773068bd347414bb829a6e2e7c5e975":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eb79e9523fe44d2ebc4b7c2baf578b2d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cbf7c6179c8940b999fb4980e1cd1ada","IPY_MODEL_cf79d819e9aa453d9779b735e3ed1be2","IPY_MODEL_d2c7ecc96bcf402582adaa75cfdc9ef8"]}},"eb79e9523fe44d2ebc4b7c2baf578b2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cbf7c6179c8940b999fb4980e1cd1ada":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a664243ec98b488f8479aefe34cef74e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ebe8afbd64e4fe69559ff40eee28408"}},"cf79d819e9aa453d9779b735e3ed1be2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c1e3e9263f584157beaa54ce480c74f2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1425941629,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1425941629,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80f2a430804c4705bb60ee001c6ad758"}},"d2c7ecc96bcf402582adaa75cfdc9ef8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a83dbb4207c647f59b814762bdb7c865","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.43G/1.43G [00:28&lt;00:00, 50.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82b99e1a4caa4eb1ac8b0c99f71f88c9"}},"a664243ec98b488f8479aefe34cef74e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2ebe8afbd64e4fe69559ff40eee28408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1e3e9263f584157beaa54ce480c74f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"80f2a430804c4705bb60ee001c6ad758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a83dbb4207c647f59b814762bdb7c865":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"82b99e1a4caa4eb1ac8b0c99f71f88c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd242afef0ab4c3cb6b9f87717cdd344":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1292580a726d491eaf064c9030ff1a35","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c29f290b45d8475380626a8cad70c10f","IPY_MODEL_71cb361ae38f4d8b95201eb7e3458965","IPY_MODEL_bd8cf24968f24864a8e4f2c406426ac5"]}},"1292580a726d491eaf064c9030ff1a35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c29f290b45d8475380626a8cad70c10f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8461044e198445884fcdbbac79a937c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6278a802693a48f089d2fb0d5c159cc9"}},"71cb361ae38f4d8b95201eb7e3458965":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c3efb3aa702041de99815ae25b9ed9b3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":27,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":27,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c914f3f58ca3436a80c4f1a48bac0872"}},"bd8cf24968f24864a8e4f2c406426ac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c9d9fa1294954d3ebfc519a8aa155b2b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 27.0/27.0 [00:00&lt;00:00, 764B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0453164bfded49c8bb0b7826e9190f15"}},"e8461044e198445884fcdbbac79a937c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6278a802693a48f089d2fb0d5c159cc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3efb3aa702041de99815ae25b9ed9b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c914f3f58ca3436a80c4f1a48bac0872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9d9fa1294954d3ebfc519a8aa155b2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0453164bfded49c8bb0b7826e9190f15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b02adf7749384b84a9928b183565ffe6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c8cf91d3257e40c6addbdab6e43c39fd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0c5ca114ea1f469da95325d91f38d79e","IPY_MODEL_f9fefdf355374256942ab6a0717ea8cc","IPY_MODEL_53a20cba91cb4d498efefa81f96292b6"]}},"c8cf91d3257e40c6addbdab6e43c39fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c5ca114ea1f469da95325d91f38d79e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30194a43b72445389edeb445e7d71b9d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ddafe40e1774eb8a65e891e9c4d8005"}},"f9fefdf355374256942ab6a0717ea8cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a91b8640c5b5445494dee1952a9508fd","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":668,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":668,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_246c3ab4a27e42b5bb00d25177c30065"}},"53a20cba91cb4d498efefa81f96292b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f1db107c5f084fd384df120d75eac853","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 668/668 [00:00&lt;00:00, 24.0kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1062acd5853a4ab492415657e5b1639d"}},"30194a43b72445389edeb445e7d71b9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0ddafe40e1774eb8a65e891e9c4d8005":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a91b8640c5b5445494dee1952a9508fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"246c3ab4a27e42b5bb00d25177c30065":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1db107c5f084fd384df120d75eac853":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1062acd5853a4ab492415657e5b1639d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75f19f654a4d4d26bb431102cdaf6ad6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ff0ac223dca4b2dbf0377c763eabdf9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b512229653d427985f4bf9cc4bcad3e","IPY_MODEL_3b6ff42c143741f8ac1ef39ee7f4f5fe","IPY_MODEL_340ae92dba31406382b56af69026d5b9"]}},"0ff0ac223dca4b2dbf0377c763eabdf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b512229653d427985f4bf9cc4bcad3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a06b96a650894594bd3e10c43b4e58f6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad8d432775134c2187fe3f53821049d7"}},"3b6ff42c143741f8ac1ef39ee7f4f5fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b3cb7aa5e15d4f62996e6b473ce6bcef","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae4befe894374ea4ba4639e7238b0001"}},"340ae92dba31406382b56af69026d5b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7f44c0772f544c6191df123810f7ede8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.30MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6dd8f7a12ffe412182a4ccc5266dd050"}},"a06b96a650894594bd3e10c43b4e58f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad8d432775134c2187fe3f53821049d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3cb7aa5e15d4f62996e6b473ce6bcef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae4befe894374ea4ba4639e7238b0001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f44c0772f544c6191df123810f7ede8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6dd8f7a12ffe412182a4ccc5266dd050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27fc9f209c424da2b4d3036de96badc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_571ae312ec664826807dca5ccffb390b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4ff5753d701940c0afdbc331012634e9","IPY_MODEL_3c9d5461f6414ef0a033c6a098419ae9","IPY_MODEL_4d7b09f0f3dd4299a7ce1d586fe15c08"]}},"571ae312ec664826807dca5ccffb390b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ff5753d701940c0afdbc331012634e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2ef75b93f0cd4dc3ae0b74a21a967af8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec386d7b500b440684b1050842a69ad4"}},"3c9d5461f6414ef0a033c6a098419ae9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2cd178aa7c4f4ad8b8f07d72750a824a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8829de1e90e04481a5ce6668558c22f8"}},"4d7b09f0f3dd4299a7ce1d586fe15c08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f3b7b30ad39d4bfd8fe8aeb462f9e091","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 1.13MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_85f3e8aaf83748e899449c567244664e"}},"2ef75b93f0cd4dc3ae0b74a21a967af8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ec386d7b500b440684b1050842a69ad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2cd178aa7c4f4ad8b8f07d72750a824a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8829de1e90e04481a5ce6668558c22f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3b7b30ad39d4bfd8fe8aeb462f9e091":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"85f3e8aaf83748e899449c567244664e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a656abe51244c5eaa8091bcc626c2d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a7ad68d3c6fc4eeeb8f47df6a893510b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9823b8716027416bb07fd2aa35fdae8d","IPY_MODEL_e4b9b2ea64e649918de011a1f1bfeac6","IPY_MODEL_87d2b417d2e547b48ef1deb064d07cdd"]}},"a7ad68d3c6fc4eeeb8f47df6a893510b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9823b8716027416bb07fd2aa35fdae8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_986d22e0c67c4318aea89f64a3e1a7bc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_308d554f512e47c0bec0eaea069ffa31"}},"e4b9b2ea64e649918de011a1f1bfeac6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d1b7209908a64f4db31686c5d25f2fbf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1344867008,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1344867008,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5757c3974b7b435e8ceb531a897f58ed"}},"87d2b417d2e547b48ef1deb064d07cdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e13bdfc94c94de0abb94f660435a750","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.34G/1.34G [00:46&lt;00:00, 30.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7e6cf2574994104a3e89c652ff0db22"}},"986d22e0c67c4318aea89f64a3e1a7bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"308d554f512e47c0bec0eaea069ffa31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1b7209908a64f4db31686c5d25f2fbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5757c3974b7b435e8ceb531a897f58ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e13bdfc94c94de0abb94f660435a750":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7e6cf2574994104a3e89c652ff0db22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"qVxUi7YlWDq6"},"source":["# README"]},{"cell_type":"markdown","metadata":{"id":"uwTVLCTXWGuR"},"source":["#Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6JW9m3nWIf-","executionInfo":{"status":"ok","timestamp":1628353277352,"user_tz":-120,"elapsed":25550,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"eb86b4d8-36bf-491b-eb39-99374066f147"},"source":["!pip install torch\n","!pip install transformers\n","!pip install numpy\n","!pip install pandas\n","!pip install sentence-transformers\n","!pip install sklearn\n","!pip install datasets\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 12.9 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 49.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 53.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 63.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Collecting sentence-transformers\n","  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.9.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 26.8 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=5ee9e039a3dd976c9a1fde5fa89ca792d7fe48e07b4660dac4354258a5c2df38\n","  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n","Successfully built sentence-transformers\n","Installing collected packages: sentencepiece, sentence-transformers\n","Successfully installed sentence-transformers-2.0.0 sentencepiece-0.1.96\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n","Collecting datasets\n","  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 11.8 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Collecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 70.1 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 64.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting tqdm>=4.42\n","  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: tqdm, xxhash, fsspec, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed datasets-1.11.0 fsspec-2021.7.0 tqdm-4.62.0 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VgAHilC2WZ16"},"source":["import numpy as np\n","import pandas as pd\n","import math\n","import itertools\n","import random\n","import torch\n","import os\n","import gzip\n","import json\n","from tqdm import tqdm\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge, LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sentence_transformers import SentenceTransformer, util, losses, models\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from transformers import AutoModelForMaskedLM, DataCollatorForWholeWordMask, DataCollatorForLanguageModeling, pipeline\n","from transformers import AdamW, get_linear_schedule_with_warmup, TrainerCallback\n","from sklearn.model_selection import StratifiedKFold\n","import shutil\n","from datasets import load_metric\n","import gc\n","gc.enable()\n","from sklearn.svm import SVR, LinearSVR\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.linear_model import Lasso, BayesianRidge, Perceptron, SGDRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FqQyqJrWYblS","executionInfo":{"status":"ok","timestamp":1628353306242,"user_tz":-120,"elapsed":23059,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"d05fade5-8ab3-4252-efde-b6c88d66e85d"},"source":["from google.colab import drive\n","drive.mount('gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YtQiZchuYObs"},"source":["# Constants"]},{"cell_type":"code","metadata":{"id":"MPuHJc1eYQJE"},"source":["BASE_PATH = 'gdrive/MyDrive/Lit/Lit_Submission'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIOcjB6-bHPj"},"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","SEED = 28\n","seed_everything(seed=SEED)\n","MAX_LENGTH = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEj-F1o6xHZC"},"source":["# fine-tuned model paths\n","# adjust path if you have saved the models in different directories\n","ALBERT_TRAINED_1 = os.path.join(BASE_PATH, 'models/albert-xxlarge-no-cv-continued')\n","ALBERT_TRAINED_2 = os.path.join(BASE_PATH, 'models/albert-xxlarge-no-cv-continued-low-lr')\n","ALBERT_TRAINED_3 = os.path.join(BASE_PATH, 'models/albert-xxlarge-all-data')\n","DEBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/deberta-large-augmented-continued')\n","DEBERTA_TRAINED_2 = os.path.join(BASE_PATH, 'models/deberta-large-augmented-continued-low-lr')\n","DEBERTA_TRAINED_3 = os.path.join(BASE_PATH, 'models/deberta-augmented-continued')\n","ROBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/roberta-large-2-models')\n","ELECTRA_TRAINED_1 = os.path.join(BASE_PATH, 'models/electra-large-continued')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xkLqmtm8Wsck"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"I3o18TZGWtqM"},"source":["def train_model(\n","    model_dir,\n","    out_dir,\n","    data,\n","    data_labels,\n","    test_data=None,\n","    test_labels=None,\n","    do_eval=False,\n","    do_epoch_eval=False,\n","    do_save_best=False,\n","    hyperparams={'bs': 16, 'lr': 1e-4, 'ep': 5, 'bias': False, 'init': None},\n","    cfg={'num_labels': 1, 'logging_steps': 500, 'is_multilabel': False, 'keep_layers': None}\n","    ):\n","  tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","  \n","  train_encodings = tokenizer(data, truncation=True, padding=True, max_length=MAX_LENGTH)\n","  if test_data:\n","    test_encodings = tokenizer(test_data, truncation=True, padding=True, max_length=MAX_LENGTH)\n","  \n","\n","  class LitDataset(torch.utils.data.Dataset):\n","      def __init__(self, encodings, labels):\n","          self.encodings = encodings\n","          self.labels = labels\n","\n","      def __getitem__(self, idx):\n","          item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","          item['labels'] = torch.tensor(self.labels[idx])\n","          return item\n","\n","      def __len__(self):\n","          return len(self.labels)\n","\n","  train_dataset = LitDataset(train_encodings, data_labels)\n","  if test_data:\n","    test_dataset = LitDataset(test_encodings, test_labels)\n","  \n","  train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=hyperparams['bs'])\n","  training_steps = len(train_dataloader) * hyperparams['ep'] \n","  warmup_steps = math.ceil(training_steps  * 0.06)\n","\n","  training_args = TrainingArguments(\n","      output_dir=out_dir,          # output directory\n","      num_train_epochs=hyperparams['ep'],              # total number of training epochs\n","      per_device_train_batch_size=hyperparams['bs'],  # batch size per device during training\n","      per_device_eval_batch_size=1,   # batch size for evaluationing rate scheduler\n","      logging_dir='/tmp/logs',            # directory for storing logs\n","      logging_steps=cfg['logging_steps'],\n","      seed=SEED,\n","      weight_decay=hyperparams['weight_decay'],\n","      learning_rate=hyperparams['lr'],\n","      save_strategy='no'\n","  )\n","  config = AutoConfig.from_pretrained(\n","      model_dir,\n","      num_labels=cfg['num_labels'],\n","      hidden_dropout_prob=hyperparams['hidden_dropout'],\n","      attention_probs_dropout_prob=hyperparams['attention_probs_dropout'])\n","  model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=cfg['num_labels'])\n","  if hyperparams['init']:\n","    model = reinitialize_layers(model, hyperparams['init'])\n","  model.config = AutoConfig.from_pretrained(model_dir, num_labels=cfg['num_labels'])\n","  model.num_labels = cfg['num_labels']\n","  if cfg['keep_layers']:\n","    new_layers = torch.nn.ModuleList([layer_module for i, layer_module in enumerate(model.base_model.encoder.layer) if i in cfg['keep_layers']])\n","    model.base_model.encoder.layer = new_layers\n","    model.config.num_hidden_layers = len(cfg['keep_layers'])\n","\n","  optimizer = AdamW(model.parameters(), correct_bias=hyperparams['bias'], lr=hyperparams['lr'])\n","  scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_training_steps=training_steps, num_warmup_steps=warmup_steps)\n","  device = \"cuda:0\"\n","  scores = []\n","  best_score = 1.0\n","  metric = load_metric(\"accuracy\")\n","\n","  class EvalCallback(TrainerCallback):\n","    def on_log(self, args, state, control, **kwargs):\n","      if do_save_best:\n","        model = kwargs['model']\n","        y_pred = predict_fast(init_model=model, tokenizer=tokenizer, data=test_data, num_labels=cfg['num_labels'], is_multilabel=cfg['is_multilabel'])\n","        model.train()\n","        curr_score = rms(test_labels, y_pred) if not cfg['is_multilabel'] else metric.compute(predictions=y_pred, references=test_labels)['accuracy']\n","        print('Score: ', curr_score)\n","\n","        if len(scores) == 0 or min(scores) > curr_score:\n","          print(f'is min {curr_score} is smaller than {scores}')\n","          best_score = curr_score\n","          save_dir = os.path.join(out_dir, 'best')\n","          model.save_pretrained(save_dir)\n","          tokenizer.save_pretrained(save_dir)\n","          with open(os.path.join(save_dir, 'hyperparams.txt'), 'w') as f:\n","            hyperparams['score'] = curr_score\n","            hyperparams['step'] = state.global_step\n","            hyperparams['trainset_size'] = len(data_labels)\n","            f.write(json.dumps(hyperparams))\n","        scores.append(curr_score)\n","\n","  trainer = Trainer(\n","      model=model,                         # the instantiated 🤗 Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset=train_dataset,         # training dataset\n","      optimizers=(optimizer, scheduler),\n","      callbacks=[EvalCallback]             # evaluation dataset\n","  )\n","\n","  trainer.train()\n","\n","  if not do_save_best:\n","    model.save_pretrained(out_dir)\n","    tokenizer.save_pretrained(out_dir)\n","  print('Training done')\n","\n","  if do_save_best:\n","    del model\n","    gc.collect()\n","    return min(scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flUcyrIbW7mE"},"source":["def train_cv_v2(model_dir, out_dir, fold_dir, hyperparams, cfg, kfolds=[0, 1, 2, 3, 4, 5], continue_training=False, deduplicate=False, soft_label_model=None):\n","  scores = []\n","  for fold in kfolds:\n","    train_df = pd.read_csv(fold_dir + '/train_fold_' + str(fold) + '.csv')\n","    val_df = pd.read_csv(fold_dir + '/val_fold_' + str(fold) + '.csv')\n","    if deduplicate:\n","      train_df = train_df.drop_duplicates(subset=['excerpt'])\n","    train_tx = [str(t) for t in train_df.excerpt.values]\n","    train_sc = [float(t) for t in train_df.target.values]\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(t) for t in val_df.target.values]\n","\n","    model_out_dir = out_dir + '/model_fold_' + str(fold)\n","    if continue_training:\n","      final_model_dir = model_dir + '/model_fold_' + str(fold) + '/best'\n","    else:\n","      final_model_dir = model_dir\n","    \n","    if cfg['soft_labels'] == 'add':\n","      preds = predict_fast(final_model_dir, train_tx)\n","      train_tx = train_tx + train_tx\n","      train_sc = train_sc + preds\n","    if cfg['soft_labels'] == 'only':\n","      preds = predict_fast(final_model_dir, train_tx)\n","      train_tx = train_tx\n","      train_sc = preds\n","    if soft_label_model and cfg['soft_labels'] == 'add':\n","      preds = predict_fast(soft_label_model + '/model_fold_' + str(fold) + '/best', train_tx)\n","      train_sc = train_sc + preds\n","      train_tx = train_tx + train_tx\n","    if soft_label_model and cfg['soft_labels'] == 'only':\n","      preds = predict_fast(soft_label_model + '/model_fold_' + str(fold) + '/best', train_tx)\n","      train_sc = preds\n","      train_tx = train_tx\n","      \n","    best_score = train_model(\n","        model_dir=final_model_dir,\n","        out_dir=model_out_dir,\n","        data=train_tx,\n","        data_labels=train_sc,\n","        test_data=val_tx,\n","        test_labels=val_sc,\n","        do_save_best=True,\n","        hyperparams=hyperparams,\n","        cfg=cfg\n","      )\n","    scores.append(best_score)\n","  cv_score = np.mean(scores)\n","  with open(out_dir + '/eval.txt', 'w') as f:\n","    f.write('CV score is ' + str(cv_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnFw0t5lXY03"},"source":["def predict_fast(model_name=None, data=None, init_model=None, tokenizer=None, num_labels=1, is_multilabel=False, output_logits=False, use_softmax=False):\n","  device = \"cuda:0\"\n","  tokenizer = AutoTokenizer.from_pretrained(model_name) if model_name else tokenizer\n","  config = AutoConfig.from_pretrained(model_name, num_labels=num_labels) if model_name else None\n","  model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config) if model_name else init_model\n","  model.to(device)\n","  model.eval()\n","  y_pred = []\n","  batches = chunks(data, 32)\n","  for batch in tqdm(batches):\n","    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n","    input_ids = inputs['input_ids'].to(device)\n","    attention = inputs['attention_mask'].to(device)\n","    inputs = {\n","        'input_ids': input_ids,\n","        'attention_mask': attention\n","    }\n","    with torch.no_grad():        \n","          outputs = model(**inputs)\n","    if not use_softmax:\n","      logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n","    else:\n","      logits = nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy().squeeze().tolist()\n","    if is_multilabel and not output_logits:\n","      logits = np.argmax(logits, axis=-1)\n","    y_pred.extend(logits)\n","  del model\n","  gc.collect()\n","  return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9nwoUWhXfgM"},"source":["def get_oof_predictions(model_dirs, fold_dir, out_dir, kfolds=[0,1,2,3,4,5]):\n","  df = pd.DataFrame()\n","  \n","  for fold in kfolds:\n","    val_df = pd.read_csv(fold_dir + '/val_fold_' + str(fold) + '.csv')\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(t) for t in val_df.target.values]\n","    fold_df = pd.DataFrame()\n","    fold_df['fold'] = [fold for v in val_sc]\n","    fold_df['excerpt'] = val_tx\n","    fold_df['target'] = val_sc\n","    fold_df['id'] = val_df['id']\n","\n","    for model in model_dirs:\n","      final_model_dir = model + '/model_fold_' + str(fold) + '/best'\n","      model_name = model.split('/')[-1]\n","      preds = predict_fast(final_model_dir, val_tx)\n","      fold_df[model_name] = preds\n","    df = df.append(fold_df, ignore_index=True)\n","  \n","  df.to_csv(out_dir)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0sehwzzrXqio"},"source":["def train_leaky_ensembler(oof_dir, model_names, out_dir, kfolds=[0,1,2,3,4,5], model_bins=[], clf='ridge', find_opt_avg=False, bin_avg_dir=None, use_postprocessing=False):\n","  df = pd.read_csv(oof_dir)\n","\n","  if find_opt_avg:\n","    msk = np.random.rand(len(df)) < 0.2\n","    df_test = df[msk].reset_index(drop=True)\n","    df = df[~msk].reset_index(drop=True)\n","    \n","  get_bin_stratified(df, n_splits=6)\n","\n","  results = []\n","  if find_opt_avg:\n","    avg_df = pd.DataFrame()\n","    avg_df['target'] = [float(f) for f in df_test['target']]\n","  for fold in kfolds:\n","    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n","    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n","    \n","    train_tx = [str(t) for t in train_df.excerpt.values]\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(f) for f in val_df.target.values]\n","    train_sc = [float(f) for f in train_df.target.values]\n","\n","    train_predictions = []\n","    val_predictions = []\n","    avg_predictions = []\n","\n","    if len(model_bins) > 0 and not use_postprocessing:\n","      for model_name in model_bins:\n","        preds = [json.loads(p) for p in train_df[model_name].values]\n","        preds_val = [json.loads(p) for p in val_df[model_name].values]\n","        if bin_avg_dir:\n","          with open(bin_avg_dir, 'r') as f:\n","            averages = json.loads(f.read())\n","          preds = [averages[np.argmax(p)] for p in preds]\n","          preds_val = [averages[np.argmax(p)] for p in preds_val]\n","\n","        train_predictions.append(preds)\n","        val_predictions.append(preds_val)\n","    \n","    for model_name in model_names:\n","      preds = [float(f) for f in train_df[model_name].values]\n","      train_predictions.append(np.array(preds))\n","      preds_val = [float(f) for f in val_df[model_name].values]\n","      val_predictions.append(np.array(preds_val))\n","      if find_opt_avg:\n","        preds_avg = [float(f) for f in df_test[model_name].values]\n","        avg_predictions.append(np.array(preds_avg))\n","    \n","    X = np.column_stack(train_predictions)\n","    \n","    if clf == 'ridge':\n","      clf = Ridge(alpha=1.0)\n","    elif clf == 'linearsvr':\n","      clf = LinearSVR(max_iter=1000000)\n","    elif clf == 'svr':\n","      clf = SVR()\n","    elif clf == 'kernel':\n","      clf = KernelRidge()\n","    elif clf == 'gbr':\n","      clf = GradientBoostingRegressor()\n","    elif clf == 'linear':\n","      clf = LinearRegression()\n","    elif clf == 'lasso':\n","      clf = Lasso()\n","    elif clf == 'bayes':\n","      clf = BayesianRidge()\n","    elif clf == 'perceptron':\n","      clf = SGDRegressor()\n","    \n","    clf.fit(X, train_sc)\n","\n","    final_out = out_dir + '/model_fold_' + str(fold) + '/'\n","    if not os.path.exists(os.path.dirname(final_out)):\n","      try:\n","          os.makedirs(os.path.dirname(final_out))\n","      except OSError as exc: # Guard against race condition\n","          if exc.errno != errno.EEXIST:\n","              raise\n","    dump(clf, final_out + 'ridge_model.joblib')\n","\n","    Y = np.column_stack(val_predictions)\n","\n","    y_preds = clf.predict(Y)\n","    if use_postprocessing:\n","      preds_val = [json.loads(p) for p in val_df[model_bins[0]].values]\n","      with open(bin_avg_dir, 'r') as f:\n","            averages = json.loads(f.read())\n","      preds_val_bins = [np.argmax(p) for p in preds_val]\n","      zipped = list(zip(preds_val_bins, preds_val))\n","      y_preds = postprocess_predictions(y_preds, zipped, averages)\n","\n","    score = rms(val_sc, y_preds)\n","    print('Score is: ', score)\n","    results.append(score)\n","\n","    if find_opt_avg:\n","      Y_test = np.column_stack(avg_predictions)\n","      y_preds_test = clf.predict(Y_test)\n","      avg_df['fold_' + str(fold)] = y_preds_test\n","  \n","  if find_opt_avg:\n","    ridge_names = ['fold_' + str(fold) for fold in range(kfolds)]\n","    print(find_best_stack(avg_df, ridge_names, drop_models=False))\n","\n","  with open(out_dir + '/eval.txt', 'w') as f:\n","    mean = np.mean(results)\n","    print('CV ist: ', mean)\n","    f.write('CV is: ' + str(mean))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0DBzdmgYEMy"},"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_GGOXV1bBJ1"},"source":["def rms(y_actual, y_predicted):\n","  return mean_squared_error(y_actual, y_predicted, squared=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FjBEUthJYFYy"},"source":["# Pretraining models"]},{"cell_type":"code","metadata":{"id":"CoQs5JkaYII6"},"source":["# Load the pseudo-labeled training data for pretraining models\n","train_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/predicted/predicted.csv'))\n","train_tx = [str(t) for t in train_df.excerpt.values]\n","train_sc = [float(t) for t in train_df.target.values]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jxQx9i8ZI7X"},"source":["# Load the entire training set from the original competition for validation during pretraining\n","val_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/original/train.csv'))\n","val_tx = [str(t) for t in train_df.excerpt.values]\n","val_sc = [float(t) for t in train_df.target.values]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uIoSp7aLZR4-"},"source":["# Train an ALBERT model\n","\n","model_name = 'albert-xxlarge-v2'\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.01,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.07,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 60,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ALBERT_PRETRAINED = os.path.join(BASE_PATH, 'models/albert-xxlarge-no-cv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751,"referenced_widgets":["6fe21e46a1b44bf8b5e43027e73376a7","12726890add04fe6aa64cec205e05f05","eebc87e23ac34b7d947d4a5bbb64f5ca","be782cc5c1c8488a8c97131739437e05","c3ddab55f4d744b1912d884122978df4","f4dfe24236874484ad73205f2612257d","1d41db217eec4602bf7f9838f5d769bd","4afd4111264f4a0fa9579d1b301b4601","5db45fe62cf54877bdd1bbd8cc98da28","6a38f1a6e951441a9defc9398c540098","551e0e9d097347aabc0c6bebd01d2082","5388dbecd0fb49c88abf02733747e01b","d56efd20fa814a9b957a7dc49056032d","db12d6399bc941f59c6ae60d2beb11f2","db59f537fd6049fe901d042905823c30","072298bfd93644968c71b5fa7b84a952","b97a3a30bdfd4612b09b2d5e0447d381","244ecc5b53a444d9b06b8981b85c970f","9f23ccc019dc4046a6cb4347a397ad79","916ed8c81bf64a8984fc1e40cefdaa00","5e13ecccb3774e1d8d66394f80788eb5","f317ba33d8df46bc811d8f21f45868e0"]},"id":"trfdyCkAaEgS","executionInfo":{"status":"ok","timestamp":1628353410510,"user_tz":-120,"elapsed":41725,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"fc68485e-37c3-48ae-b167-6545dc0e4d78"},"source":["train_model(\n","    model_dir=model_name,\n","    out_dir=ALBERT_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fe21e46a1b44bf8b5e43027e73376a7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/893M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.weight']\n","- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5388dbecd0fb49c88abf02733747e01b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 3\n","  Total train batch size (w. parallel, distributed & accumulation) = 3\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 15\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15/15 00:09, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.778000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1it [00:00, 44.42it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n"],"name":"stderr"},{"output_type":"stream","text":["Score:  0.28811585903167725\n","is min 0.28811585903167725 is smaller than []\n"],"name":"stdout"},{"output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","1it [00:00, 41.79it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n"],"name":"stderr"},{"output_type":"stream","text":["Score:  0.11282766610383987\n","is min 0.11282766610383987 is smaller than [0.28811585903167725]\n"],"name":"stdout"},{"output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"stream","text":["Training done\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.11282766610383987"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d7a3a38272ff48ba8125b50be1b157d4","bff952736ffd4b50ae75acb020fd481b","6b7bf1bf7414490dbfad3d33f9a44ab3","5b14760830124e63b302f63944690cea","dbb3d4a578cd4564a53414ceef71da2b","2e6b0ee16bbb480ca3dd6f81d080dca1","60548b7369d54fc09a1ecd823daa418a","e6831b4a9736483aa3aefc9bb2318a2a","b6b87bbdbf354587b1330eff467f6174","462f1ab065bd4a68b44f3e5f82f6d6c8","1fbc5226341945e6b64a2ac45af52004","91f8052331ba482e8380aaf7e83fc1db","845c5936fd96438b87a1cce2974d78e5","7415cf21ec1f4148b19b1409784429d3","d78f3bc7a3e24eab92569fdaf83f7ba4","48f85b79c58d4cd59eca639d19bd1f90","ac2bd1da3ced4f3b91b484bd745e86da","cc421dd21cf44c97a5a2feda0a02e72b","e108e22beefe4dbfa21f01a189070bb0","e0baea8e01ce4a3cab96f14b4b9944e6","04d257aaf71e41f8b93223540f12e546","9f8b910cb89742648ffc9df643d8cca3","41780e8505b04e1aa48fca3005dfcf3e","0f8896d36a3e4c718ca5eb7d2a4db036","ed4cc8276fd947ee95e9e420cceaab0f","4cf4929d93724b88be6d1d428bdfaa97","902edc73112946b88d55afe299ff680a","6495b6f0569240ca9af463481aec94da","704350d386904fdba4b2782392f4c0bc","75fab396ec05456093e052d7b5dfb596","2b304b633c654429ba05a1f48447ddb4","aa8cf38b1fc54d47a2adc5c0a58ac504","ba20d6ba371f4f96b3d379713ed39642","33f156b8e7874b87a9f61d1a065c4c96","1f290f5083de46cc8370d3949c8e36b6","0c05fa677771495296077d2cf6360cfe","613d68d5434a47c89ef55f0cd1436977","e3b3b1add5944372a3349cee1957f85c","019d1122d3544181b5af8fcb0bf7ca0d","6890671c6b1043b38ffc66c85e2449c4","7070960c8eac4935902546d358b07231","eac90ccd9584470cb7adfbc9c7e2679c","a659a7f4171640ffa54d69ed7a7f1be2","ba0e39c775894ab897462870c7beadc5","1c2543a0ab094134a25f6603ab1fd6d9","e8a73c92d4d646949922cd665cbda390","b04c05d8dc8b4b71bbc8c4bce8b3d2b3","beee0635e9634f0e9bdb43bf4036e422","eb2d90da017b40618608151bafd7bcd1","fcb6c02ee7df43edaac1e1a2ade1f1a6","33641ab74dad49f3a86d0d8fa46b7a1e","2ecbc2a60c2c43dc94a81fda94a8c65f","886de66ecec3421886e3f50e479a6ff0","55fbffecf6d047b28a0ed099ccb3c394","5a21c7fa7b0b4ac18487f03367a85246"]},"id":"LfjD9r7TayIc","executionInfo":{"status":"ok","timestamp":1628353662900,"user_tz":-120,"elapsed":99248,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"b3c4b548-a0cc-44d0-84b9-1dd5a61323ee"},"source":["# Train a DEBERTA model\n","model_name = 'microsoft/deberta-large'\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 20,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","DEBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/deberta-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp16ymkjh4\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7a3a38272ff48ba8125b50be1b157d4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/fa4e12e9e6e1a899fe94275a0e60bdc59474baa2cc8e6fa0c207c7d9caaa2598.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n","creating metadata file for /root/.cache/huggingface/transformers/fa4e12e9e6e1a899fe94275a0e60bdc59474baa2cc8e6fa0c207c7d9caaa2598.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n","https://huggingface.co/microsoft/deberta-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpq8pc4uxt\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91f8052331ba482e8380aaf7e83fc1db","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","creating metadata file for /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/microsoft/deberta-large/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpw7o_a33j\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41780e8505b04e1aa48fca3005dfcf3e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/4614a858d4552a0a399dc77bafbbeb75b20fe49259f690eb561898f8975626fa.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n","creating metadata file for /root/.cache/huggingface/transformers/4614a858d4552a0a399dc77bafbbeb75b20fe49259f690eb561898f8975626fa.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n","https://huggingface.co/microsoft/deberta-large/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpx78gned3\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33f156b8e7874b87a9f61d1a065c4c96","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/7a87aa12b220b9a983b98dbd9ad35624b3fe2ce2e83d1ce621eddcdac1c04654.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","creating metadata file for /root/.cache/huggingface/transformers/7a87aa12b220b9a983b98dbd9ad35624b3fe2ce2e83d1ce621eddcdac1c04654.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4614a858d4552a0a399dc77bafbbeb75b20fe49259f690eb561898f8975626fa.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/7a87aa12b220b9a983b98dbd9ad35624b3fe2ce2e83d1ce621eddcdac1c04654.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/fa4e12e9e6e1a899fe94275a0e60bdc59474baa2cc8e6fa0c207c7d9caaa2598.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/microsoft/deberta-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpir5ni2dj\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c2543a0ab094134a25f6603ab1fd6d9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/236b63dfb5e690fb2e194403aebda39508d60877a8903da58f4fff7a147ec0dd.e8bb754209aab7decd8d3faee51cce4d572131b439d5360c168d43998e3ceb13\n","creating metadata file for /root/.cache/huggingface/transformers/236b63dfb5e690fb2e194403aebda39508d60877a8903da58f4fff7a147ec0dd.e8bb754209aab7decd8d3faee51cce4d572131b439d5360c168d43998e3ceb13\n","loading weights file https://huggingface.co/microsoft/deberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/236b63dfb5e690fb2e194403aebda39508d60877a8903da58f4fff7a147ec0dd.e8bb754209aab7decd8d3faee51cce4d572131b439d5360c168d43998e3ceb13\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'config', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-large and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 3\n","  Total train batch size (w. parallel, distributed & accumulation) = 3\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:29, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.010100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1it [00:00, 27.96it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/config.json\n"],"name":"stderr"},{"output_type":"stream","text":["Score:  0.03461174666881561\n","is min 0.03461174666881561 is smaller than []\n"],"name":"stdout"},{"output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","1it [00:00, 27.54it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/config.json\n"],"name":"stderr"},{"output_type":"stream","text":["Score:  0.033117204904556274\n","is min 0.033117204904556274 is smaller than [0.03461174666881561]\n"],"name":"stdout"},{"output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"stream","text":["Training done\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.033117204904556274"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["62932fc171e54ad8a6e83d43bbecef28","7e266f1c703b43e2a1380fce6f749f4c","994983c7661840cda6a0d12d874605a5","6a89755c37e849359f19ea453f7a64e1","a3baefe68a214cc6a3f4616719547fed","694cac06d91d4ef99bf0e817d8ed9b15","9fa94d851b284aa0b6d8d8590f7a8d7f","2019d8e148a24245a802ad90d28f781c","fc943877ab974e009c3f603a77005346","e5c78f7c515a497a9c7a05f1a2661c3a","9792332c910147b6bf64cd330164c98d","bcc8278f44c34ec88a10a739a0cbeffc","2a6557ecc21e4838a06786b3947a073d","5cbcca203a664f5fa706408b54c9efda","82c212bad67f4d948af30a2c77794710","33976aa53a1641d486f194e3c19e5f03","5e750ab91db34b89a69ef11fe667069c","cce9baee6c7e402199003c1fb98bd206","429edfad527e4e8caa4627e6f2f83bc0","cfede7c27a8c4499925944119f1a6be5","cb6a512b72904f8f83f01ceacb5bd2ae","637523262dfc46d69847ca26bd009307","eb1139ebfb2a49249a58cda90cbc7ff8","1b7307fbab5f4d71a75d3e7de2fefdf9","02cf7113a3bd4029bee877c203b87de1","03dffc22176e4f86b5013ec5701961ba","f780e03a76924012a269932fe736d0ac","869a6a5af3e24c15a5f85fecb2450c22","1fc7897f470f4bbc86092083c0759e6a","cb6710f03f194276b008a53b5e120570","457294515e36418ca6ba7b7c9fcb899d","56267050b1354f1eb6ec79b758c5b31a","4a2d57e7f35d428393d374b5d9cc2f49","a8efe07af555436c803faeba3a090544","8df646e9927442ebbc00dcb84935a0cd","78d31076d57e40b2aec4106cc72d5331","71b5c02f4d0e4ec8a4c0aedea3866491","1fb2bbb9c3bc46e48ca6a93277c00b32","e2a41718e2684ff58ae266178918aaed","b746096d32c84fd8b1661033502a7e34","7ee23fd9355f4202b42c77215a50bcc9","751b8d67044b4e129014a26dcf0b442b","af2396e096a8459884990c8a9d63f9c9","fef0b635e92b4452a1e7d98fc9a303ac","a773068bd347414bb829a6e2e7c5e975","eb79e9523fe44d2ebc4b7c2baf578b2d","cbf7c6179c8940b999fb4980e1cd1ada","cf79d819e9aa453d9779b735e3ed1be2","d2c7ecc96bcf402582adaa75cfdc9ef8","a664243ec98b488f8479aefe34cef74e","2ebe8afbd64e4fe69559ff40eee28408","c1e3e9263f584157beaa54ce480c74f2","80f2a430804c4705bb60ee001c6ad758","a83dbb4207c647f59b814762bdb7c865","82b99e1a4caa4eb1ac8b0c99f71f88c9"]},"id":"_WSipbOPb2LW","executionInfo":{"status":"ok","timestamp":1628353769881,"user_tz":-120,"elapsed":49162,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"c3f0984e-40ce-45b9-d243-862531f18c30"},"source":["# Train a RoBERTa model\n","model_name = 'roberta-large'\n","hyperparams = {\n","  'bs': 8,\n","  'lr': 1e-5,\n","  'weight_decay': 0.01,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ROBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/roberta-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","https://huggingface.co/roberta-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpa8qjr58p\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62932fc171e54ad8a6e83d43bbecef28","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","creating metadata file for /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/roberta-large/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpg4m9vcoe\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcc8278f44c34ec88a10a739a0cbeffc","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","creating metadata file for /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","https://huggingface.co/roberta-large/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpht4u0dqe\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb1139ebfb2a49249a58cda90cbc7ff8","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","creating metadata file for /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","https://huggingface.co/roberta-large/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp6eu4fwib\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8efe07af555436c803faeba3a090544","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","creating metadata file for /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfg09s6l1\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a773068bd347414bb829a6e2e7c5e975","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n","creating metadata file for /root/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n","loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8/8 00:07, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","1it [00:00, 48.35it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/config.json\n"],"name":"stderr"},{"output_type":"stream","text":["Score:  0.028184428811073303\n","is min 0.028184428811073303 is smaller than []\n"],"name":"stdout"},{"output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"stream","text":["Training done\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.028184428811073303"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bd242afef0ab4c3cb6b9f87717cdd344","1292580a726d491eaf064c9030ff1a35","c29f290b45d8475380626a8cad70c10f","71cb361ae38f4d8b95201eb7e3458965","bd8cf24968f24864a8e4f2c406426ac5","e8461044e198445884fcdbbac79a937c","6278a802693a48f089d2fb0d5c159cc9","c3efb3aa702041de99815ae25b9ed9b3","c914f3f58ca3436a80c4f1a48bac0872","c9d9fa1294954d3ebfc519a8aa155b2b","0453164bfded49c8bb0b7826e9190f15","b02adf7749384b84a9928b183565ffe6","c8cf91d3257e40c6addbdab6e43c39fd","0c5ca114ea1f469da95325d91f38d79e","f9fefdf355374256942ab6a0717ea8cc","53a20cba91cb4d498efefa81f96292b6","30194a43b72445389edeb445e7d71b9d","0ddafe40e1774eb8a65e891e9c4d8005","a91b8640c5b5445494dee1952a9508fd","246c3ab4a27e42b5bb00d25177c30065","f1db107c5f084fd384df120d75eac853","1062acd5853a4ab492415657e5b1639d","75f19f654a4d4d26bb431102cdaf6ad6","0ff0ac223dca4b2dbf0377c763eabdf9","9b512229653d427985f4bf9cc4bcad3e","3b6ff42c143741f8ac1ef39ee7f4f5fe","340ae92dba31406382b56af69026d5b9","a06b96a650894594bd3e10c43b4e58f6","ad8d432775134c2187fe3f53821049d7","b3cb7aa5e15d4f62996e6b473ce6bcef","ae4befe894374ea4ba4639e7238b0001","7f44c0772f544c6191df123810f7ede8","6dd8f7a12ffe412182a4ccc5266dd050","27fc9f209c424da2b4d3036de96badc1","571ae312ec664826807dca5ccffb390b","4ff5753d701940c0afdbc331012634e9","3c9d5461f6414ef0a033c6a098419ae9","4d7b09f0f3dd4299a7ce1d586fe15c08","2ef75b93f0cd4dc3ae0b74a21a967af8","ec386d7b500b440684b1050842a69ad4","2cd178aa7c4f4ad8b8f07d72750a824a","8829de1e90e04481a5ce6668558c22f8","f3b7b30ad39d4bfd8fe8aeb462f9e091","85f3e8aaf83748e899449c567244664e","6a656abe51244c5eaa8091bcc626c2d2","a7ad68d3c6fc4eeeb8f47df6a893510b","9823b8716027416bb07fd2aa35fdae8d","e4b9b2ea64e649918de011a1f1bfeac6","87d2b417d2e547b48ef1deb064d07cdd","986d22e0c67c4318aea89f64a3e1a7bc","308d554f512e47c0bec0eaea069ffa31","d1b7209908a64f4db31686c5d25f2fbf","5757c3974b7b435e8ceb531a897f58ed","7e13bdfc94c94de0abb94f660435a750","b7e6cf2574994104a3e89c652ff0db22"]},"id":"TKTR9SyZcasB","executionInfo":{"status":"ok","timestamp":1628353943089,"user_tz":-120,"elapsed":68800,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"db4e1ba6-ebf4-44fd-a2ff-232c66a0cd1f"},"source":["# Train an ELECTRA model\n","model_name = 'google/electra-large-discriminator'\n","hyperparams = {\n","  'bs': 4,\n","  'lr': 8e-6,\n","  'weight_decay': 0.1,\n","  'ep': 7,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ELECTRA_PRETRAINED = os.path.join(BASE_PATH, 'models/electra-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=ELECTRA_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3n2ytear\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd242afef0ab4c3cb6b9f87717cdd344","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/26ad81c46898598ce9aed0b02fd3c9175a28daa30317e4f1980b5e871d823b67.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n","creating metadata file for /root/.cache/huggingface/transformers/26ad81c46898598ce9aed0b02fd3c9175a28daa30317e4f1980b5e871d823b67.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpii3zb0or\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b02adf7749384b84a9928b183565ffe6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/668 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","creating metadata file for /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpq443cx8e\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75f19f654a4d4d26bb431102cdaf6ad6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/48a62a60c85c63546f3623e592c2ddfd0628ed7749e6d503a11eb80cb04fc19c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","creating metadata file for /root/.cache/huggingface/transformers/48a62a60c85c63546f3623e592c2ddfd0628ed7749e6d503a11eb80cb04fc19c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdo4t0sba\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27fc9f209c424da2b4d3036de96badc1","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/ed8095412008e8a8159d4bbdcecd02e5e72b79a1fc7dbfdc32e6aef638d4b9a9.65c74b3f0086fae55b99a8c9173a6739a53ae5ae0441c0811095141532f33ff8\n","creating metadata file for /root/.cache/huggingface/transformers/ed8095412008e8a8159d4bbdcecd02e5e72b79a1fc7dbfdc32e6aef638d4b9a9.65c74b3f0086fae55b99a8c9173a6739a53ae5ae0441c0811095141532f33ff8\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/48a62a60c85c63546f3623e592c2ddfd0628ed7749e6d503a11eb80cb04fc19c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/ed8095412008e8a8159d4bbdcecd02e5e72b79a1fc7dbfdc32e6aef638d4b9a9.65c74b3f0086fae55b99a8c9173a6739a53ae5ae0441c0811095141532f33ff8\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/26ad81c46898598ce9aed0b02fd3c9175a28daa30317e4f1980b5e871d823b67.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp1cx5351y\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a656abe51244c5eaa8091bcc626c2d2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/6a9790a4cce0d5f0f7d5c78b57955d681fe9cb564edc75aab3733c5ba3a5550d.a2ee8c7426aca3bd41c92ad0b3e07d731d9bf61c950403e6a82b1d566b8923db\n","creating metadata file for /root/.cache/huggingface/transformers/6a9790a4cce0d5f0f7d5c78b57955d681fe9cb564edc75aab3733c5ba3a5550d.a2ee8c7426aca3bd41c92ad0b3e07d731d9bf61c950403e6a82b1d566b8923db\n","loading weights file https://huggingface.co/google/electra-large-discriminator/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/6a9790a4cce0d5f0f7d5c78b57955d681fe9cb564edc75aab3733c5ba3a5550d.a2ee8c7426aca3bd41c92ad0b3e07d731d9bf61c950403e6a82b1d566b8923db\n","Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 14\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14/14 00:08, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.005900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1it [00:00, 43.78it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/config.json\n"],"name":"stderr"},{"output_type":"stream","text":["Score:  0.03945397585630417\n","is min 0.03945397585630417 is smaller than []\n"],"name":"stdout"},{"output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","1it [00:00, 43.76it/s]"],"name":"stderr"},{"output_type":"stream","text":["Score:  0.04779457300901413\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Training done\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.03945397585630417"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"LZp4MeZUdFsm"},"source":["# Training models"]},{"cell_type":"markdown","metadata":{"id":"J3deWnW2dLTv"},"source":["In total, I trained 3 deberta-large, 1 roberta-large, 3 albert-xxlarge and 1 electra-large model for my winning submission.\n","\n"]},{"cell_type":"code","metadata":{"id":"3Ze54BKZdYvk"},"source":["# Training the ALBERT models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRuHZIARd-GJ"},"source":["# albert 1\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.01,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.07,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ALBERT_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0YuArTWeglx"},"source":["# albert 2\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 7e-6,\n","  'weight_decay': 0.07,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ALBERT_TRAINED_2\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"m2iQGSPFe7pW","executionInfo":{"status":"ok","timestamp":1628357046530,"user_tz":-120,"elapsed":21564,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"}},"outputId":"da793891-b87d-434b-a7ea-b1d188e38ef3"},"source":["# albert 3\n","# albert 3 is special it is trained on all training data without evaluation.\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 600,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","train_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/original/train.csv'))\n","train_tx = [str(t) for t in train_df.excerpt.values]\n","train_sc = [float(t) for t in train_df.target.values]\n","\n","out_dir = ALBERT_TRAINED_3\n","\n","\n","train_model(\n","   model_dir=model_name,\n","   out_dir=out_dir,\n","   data=train_tx,\n","   data_labels=train_sc,\n","   hyperparams=hyperparams,\n","   cfg=cfg\n",")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Didn't find file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/added_tokens.json. We won't load it.\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/spiece.model\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/tokenizer.json\n","loading file None\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/special_tokens_map.json\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/tokenizer_config.json\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n","Model config AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 4096,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 16384,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"layers_to_keep\": [],\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","loading configuration file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n","Model config AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 4096,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 16384,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"layers_to_keep\": [],\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","loading weights file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/pytorch_model.bin\n","All model checkpoint weights were used when initializing AlbertForSequenceClassification.\n","\n","All the weights of AlbertForSequenceClassification were initialized from the model checkpoint at gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForSequenceClassification for predictions without further training.\n","loading configuration file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n","Model config AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 4096,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 16384,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"layers_to_keep\": [],\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 3\n","  Total train batch size (w. parallel, distributed & accumulation) = 3\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:01, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/config.json\n","Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"stream","text":["Training done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QnKSaQWGpAUa"},"source":["# Training the deberta models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HXYFgmVApREy"},"source":["# deberta 1\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPvQ-fImNmVl"},"source":["# deberta 2\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 7e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_2\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEgot9YgN6at"},"source":["# deberta 3\n","# This deberta model was trained on data sampled using bootstrapping instead of cross validation\n","# Only models trained on 2 folds/bags were used in the final submission\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.08,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_3\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg,\n","    kfolds=[0,1]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKRTt-uUPVAm"},"source":["# Training the ELECTRA model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aiQ3rJsUPXSq"},"source":["# electra 1\n","model_name = os.path.join(ELECTRA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 8e-6,\n","  'weight_decay': 0.1,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ELECTRA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcgBi10OP-_L"},"source":["# Training the RoBERTa model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRWMXp9mQB2W"},"source":["# roberta 1\n","model_name = os.path.join(ROBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 8,\n","  'lr': 1e-5,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ROBERTA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iyZmZulYQ-5U"},"source":["# Stacking"]},{"cell_type":"code","metadata":{"id":"DHfTtt0QRC3B"},"source":["model_dirs = [\n","    ALBERT_TRAINED_1,\n","    DEBERTA_TRAINED_1,\n","    ALBERT_TRAINED_2,\n","    DEBERTA_TRAINED_1,\n","    ROBERTA_TRAINED_1,\n","    ELECTRA_TRAINED_1\n","]\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = os.path.join(BASE_PATH, 'data/training/oof')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vLtSkIirhe7O"},"source":["get_oof_predictions(model_dirs=model_dirs, fold_dir=fold_dir, out_dir=out_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zNFUoYZsh1GF"},"source":["model_names_ensemble_1 = [\n","    ALBERT_TRAINED_1.split('/')[-1],\n","    DEBERTA_TRAINED_1.split('/')[-1],\n","    ALBERT_TRAINED_2.split('/')[-1],\n","    DEBERTA_TRAINED_1.split('/')[-1],\n","    ROBERTA_TRAINED_1.split('/')[-1],\n","    ELECTRA_TRAINED_1.split('/')[-1],      \n","]\n","\n","model_names_ensemble_2 = model_names_ensemble_1[:-1]\n","\n","oof_dir = os.path.join(BASE_PATH, 'data/training/oof')\n","\n","out_dir_ensemble_1 = os.path.join(BASE_PATH, 'models/electra-larger-ensemble')\n","out_dir_ensemble_2 = os.path.join(BASE_PATH, 'models/huge-ensemble')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Ruz_111qWoQ"},"source":["# train ensemble 1\n","train_leaky_ensembler(oof_dir=oof_dir, model_names=model_names_ensemble_1, out_dir=out_dir_ensemble_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kt_VtNCgqa0v"},"source":["# train ensemble 2\n","train_leaky_ensembler(oof_dir=oof_dir, model_names=model_names_ensemble_2, out_dir=out_dir_ensemble_2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HJLfireQ0uoS"},"source":["You have finished training the models."]}]}