{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"qVxUi7YlWDq6"},"source":["# README"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uwTVLCTXWGuR"},"source":["#Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25550,"status":"ok","timestamp":1628353277352,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"M6JW9m3nWIf-","outputId":"eb86b4d8-36bf-491b-eb39-99374066f147"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.26.4)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (59.6.0)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (0.37.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.26.4)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: sklearn in /usr/local/lib/python3.10/dist-packages (0.0.post5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (12.0.1)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install torch\n","!pip install transformers\n","!pip install numpy\n","!pip install pandas\n","!pip install sentence-transformers\n","!pip install sklearn\n","!pip install datasets\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VgAHilC2WZ16"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math\n","import itertools\n","import random\n","import torch\n","import os\n","import gzip\n","import json\n","from tqdm import tqdm\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge, LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sentence_transformers import SentenceTransformer, util, losses, models\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from transformers import AutoModelForMaskedLM, DataCollatorForWholeWordMask, DataCollatorForLanguageModeling, pipeline\n","from transformers import AdamW, get_linear_schedule_with_warmup, TrainerCallback\n","from sklearn.model_selection import StratifiedKFold\n","import shutil\n","from datasets import load_metric\n","import gc\n","gc.enable()\n","from sklearn.svm import SVR, LinearSVR\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.linear_model import Lasso, BayesianRidge, Perceptron, SGDRegressor"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23059,"status":"ok","timestamp":1628353306242,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"FqQyqJrWYblS","outputId":"d05fade5-8ab3-4252-efde-b6c88d66e85d"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('gdrive')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YtQiZchuYObs"},"source":["# Constants"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"MPuHJc1eYQJE"},"outputs":[],"source":["BASE_PATH = '/home/masa1357/gitfile/kaggle_clrp_1st_place_solution/'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VIOcjB6-bHPj"},"outputs":[],"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","SEED = 28\n","seed_everything(seed=SEED)\n","MAX_LENGTH = 256"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EEj-F1o6xHZC"},"outputs":[],"source":["# fine-tuned model paths\n","# adjust path if you have saved the models in different directories\n","ALBERT_TRAINED_1 = os.path.join(BASE_PATH, 'models/albert-xxlarge-2-models')#OK\n","ALBERT_TRAINED_2 = os.path.join(BASE_PATH, 'models/albert-xxlarge-low-lr')#OK\n","ALBERT_TRAINED_3 = os.path.join(BASE_PATH, 'models/ALBERT_3/albert-xxlarge-all-data')#OK\n","DEBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/deberta-large')#OK\n","DEBERTA_TRAINED_2 = os.path.join(BASE_PATH, 'models/deberta-large-low-lr')#OK\n","DEBERTA_TRAINED_3 = os.path.join(BASE_PATH, 'models/deberta-augmented-continued')#OK\n","ROBERTA_TRAINED_1 = os.path.join(BASE_PATH, 'models/roberta-large-two-models')#OK\n","ELECTRA_TRAINED_1 = os.path.join(BASE_PATH, 'models/electra-large')#OK"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xkLqmtm8Wsck"},"source":["# Functions"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"I3o18TZGWtqM"},"outputs":[],"source":["def train_model(\n","    model_dir,\n","    out_dir,\n","    data,\n","    data_labels,\n","    test_data=None,\n","    test_labels=None,\n","    do_eval=False,\n","    do_epoch_eval=False,\n","    do_save_best=False,\n","    hyperparams={'bs': 16, 'lr': 1e-4, 'ep': 5, 'bias': False, 'init': None},\n","    cfg={'num_labels': 1, 'logging_steps': 500, 'is_multilabel': False, 'keep_layers': None}\n","    ):\n","  tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","  \n","  train_encodings = tokenizer(data, truncation=True, padding=True, max_length=MAX_LENGTH)\n","  if test_data:\n","    test_encodings = tokenizer(test_data, truncation=True, padding=True, max_length=MAX_LENGTH)\n","  \n","\n","  class LitDataset(torch.utils.data.Dataset):\n","      def __init__(self, encodings, labels):\n","          self.encodings = encodings\n","          self.labels = labels\n","\n","      def __getitem__(self, idx):\n","          item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","          item['labels'] = torch.tensor(self.labels[idx])\n","          return item\n","\n","      def __len__(self):\n","          return len(self.labels)\n","\n","  train_dataset = LitDataset(train_encodings, data_labels)\n","  if test_data:\n","    test_dataset = LitDataset(test_encodings, test_labels)\n","  \n","  train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=hyperparams['bs'])\n","  training_steps = len(train_dataloader) * hyperparams['ep'] \n","  warmup_steps = math.ceil(training_steps  * 0.06)\n","\n","  training_args = TrainingArguments(\n","      output_dir=out_dir,          # output directory\n","      num_train_epochs=hyperparams['ep'],              # total number of training epochs\n","      per_device_train_batch_size=hyperparams['bs'],  # batch size per device during training\n","      per_device_eval_batch_size=1,   # batch size for evaluationing rate scheduler\n","      logging_dir='/tmp/logs',            # directory for storing logs\n","      logging_steps=cfg['logging_steps'],\n","      seed=SEED,\n","      weight_decay=hyperparams['weight_decay'],\n","      learning_rate=hyperparams['lr'],\n","      save_strategy='no'\n","  )\n","  config = AutoConfig.from_pretrained(\n","      model_dir,\n","      num_labels=cfg['num_labels'],\n","      hidden_dropout_prob=hyperparams['hidden_dropout'],\n","      attention_probs_dropout_prob=hyperparams['attention_probs_dropout'])\n","  model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=cfg['num_labels'])\n","  if hyperparams['init']:\n","    model = reinitialize_layers(model, hyperparams['init'])\n","  model.config = AutoConfig.from_pretrained(model_dir, num_labels=cfg['num_labels'])\n","  model.num_labels = cfg['num_labels']\n","  if cfg['keep_layers']:\n","    new_layers = torch.nn.ModuleList([layer_module for i, layer_module in enumerate(model.base_model.encoder.layer) if i in cfg['keep_layers']])\n","    model.base_model.encoder.layer = new_layers\n","    model.config.num_hidden_layers = len(cfg['keep_layers'])\n","\n","  optimizer = AdamW(model.parameters(), correct_bias=hyperparams['bias'], lr=hyperparams['lr'])\n","  scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_training_steps=training_steps, num_warmup_steps=warmup_steps)\n","  device = \"cuda:0\"\n","  scores = []\n","  best_score = 1.0\n","  metric = load_metric(\"accuracy\")\n","\n","  class EvalCallback(TrainerCallback):\n","    def on_log(self, args, state, control, **kwargs):\n","      if do_save_best:\n","        model = kwargs['model']\n","        y_pred = predict_fast(init_model=model, tokenizer=tokenizer, data=test_data, num_labels=cfg['num_labels'], is_multilabel=cfg['is_multilabel'])\n","        model.train()\n","        curr_score = rms(test_labels, y_pred) if not cfg['is_multilabel'] else metric.compute(predictions=y_pred, references=test_labels)['accuracy']\n","        print('Score: ', curr_score)\n","\n","        if len(scores) == 0 or min(scores) > curr_score:\n","          print(f'is min {curr_score} is smaller than {scores}')\n","          best_score = curr_score\n","          save_dir = os.path.join(out_dir, 'best')\n","          model.save_pretrained(save_dir)\n","          tokenizer.save_pretrained(save_dir)\n","          with open(os.path.join(save_dir, 'hyperparams.txt'), 'w') as f:\n","            hyperparams['score'] = curr_score\n","            hyperparams['step'] = state.global_step\n","            hyperparams['trainset_size'] = len(data_labels)\n","            f.write(json.dumps(hyperparams))\n","        scores.append(curr_score)\n","\n","  trainer = Trainer(\n","      model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset=train_dataset,         # training dataset\n","      optimizers=(optimizer, scheduler),\n","      callbacks=[EvalCallback]             # evaluation dataset\n","  )\n","\n","  trainer.train()\n","\n","  if not do_save_best:\n","    model.save_pretrained(out_dir)\n","    tokenizer.save_pretrained(out_dir)\n","  print('Training done')\n","\n","  if do_save_best:\n","    del model\n","    gc.collect()\n","    return min(scores)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"flUcyrIbW7mE"},"outputs":[],"source":["def train_cv_v2(model_dir, out_dir, fold_dir, hyperparams, cfg, kfolds=[0, 1, 2, 3, 4, 5], continue_training=False, deduplicate=False, soft_label_model=None):\n","  scores = []\n","  for fold in kfolds:\n","    train_df = pd.read_csv(fold_dir + '/train_fold_' + str(fold) + '.csv')\n","    val_df = pd.read_csv(fold_dir + '/val_fold_' + str(fold) + '.csv')\n","    if deduplicate:\n","      train_df = train_df.drop_duplicates(subset=['excerpt'])\n","    train_tx = [str(t) for t in train_df.excerpt.values]\n","    train_sc = [float(t) for t in train_df.target.values]\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(t) for t in val_df.target.values]\n","\n","    model_out_dir = out_dir + '/model_fold_' + str(fold)\n","    if continue_training:\n","      final_model_dir = model_dir + '/model_fold_' + str(fold) + '/best'\n","    else:\n","      final_model_dir = model_dir\n","    \n","    if cfg['soft_labels'] == 'add':\n","      preds = predict_fast(final_model_dir, train_tx)\n","      train_tx = train_tx + train_tx\n","      train_sc = train_sc + preds\n","    if cfg['soft_labels'] == 'only':\n","      preds = predict_fast(final_model_dir, train_tx)\n","      train_tx = train_tx\n","      train_sc = preds\n","    if soft_label_model and cfg['soft_labels'] == 'add':\n","      preds = predict_fast(soft_label_model + '/model_fold_' + str(fold) + '/best', train_tx)\n","      train_sc = train_sc + preds\n","      train_tx = train_tx + train_tx\n","    if soft_label_model and cfg['soft_labels'] == 'only':\n","      preds = predict_fast(soft_label_model + '/model_fold_' + str(fold) + '/best', train_tx)\n","      train_sc = preds\n","      train_tx = train_tx\n","      \n","    best_score = train_model(\n","        model_dir=final_model_dir,\n","        out_dir=model_out_dir,\n","        data=train_tx,\n","        data_labels=train_sc,\n","        test_data=val_tx,\n","        test_labels=val_sc,\n","        do_save_best=True,\n","        hyperparams=hyperparams,\n","        cfg=cfg\n","      )\n","    scores.append(best_score)\n","  cv_score = np.mean(scores)\n","  with open(out_dir + '/eval.txt', 'w') as f:\n","    f.write('CV score is ' + str(cv_score))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"EnFw0t5lXY03"},"outputs":[],"source":["def predict_fast(model_name=None, data=None, init_model=None, tokenizer=None, num_labels=1, is_multilabel=False, output_logits=False, use_softmax=False):\n","  device = \"cuda:0\"\n","  tokenizer = AutoTokenizer.from_pretrained(model_name) if model_name else tokenizer\n","  config = AutoConfig.from_pretrained(model_name, num_labels=num_labels) if model_name else None\n","  model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config) if model_name else init_model\n","  model.to(device)\n","  model.eval()\n","  y_pred = []\n","  batches = chunks(data, 32)\n","  for batch in tqdm(batches):\n","    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n","    input_ids = inputs['input_ids'].to(device)\n","    attention = inputs['attention_mask'].to(device)\n","    inputs = {\n","        'input_ids': input_ids,\n","        'attention_mask': attention\n","    }\n","    with torch.no_grad():        \n","          outputs = model(**inputs)\n","    if not use_softmax:\n","      logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n","    else:\n","      logits = nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy().squeeze().tolist()\n","    if is_multilabel and not output_logits:\n","      logits = np.argmax(logits, axis=-1)\n","    y_pred.extend(logits)\n","  del model\n","  gc.collect()\n","  return y_pred"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"V9nwoUWhXfgM"},"outputs":[],"source":["def get_oof_predictions(model_dirs, fold_dir, out_dir, kfolds=[0,1,2,3,4,5]):\n","  df = pd.DataFrame()\n","  \n","  for fold in kfolds:\n","    val_df = pd.read_csv(fold_dir + '/val_fold_' + str(fold) + '.csv')\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(t) for t in val_df.target.values]\n","    fold_df = pd.DataFrame()\n","    fold_df['fold'] = [fold for v in val_sc]\n","    fold_df['excerpt'] = val_tx\n","    fold_df['target'] = val_sc\n","    fold_df['id'] = val_df['id']\n","\n","    for model in model_dirs:\n","      final_model_dir = model + '/model_fold_' + str(fold) + '/best'\n","      model_name = model.split('/')[-1]\n","      preds = predict_fast(final_model_dir, val_tx)\n","      fold_df[model_name] = preds\n","    df = df.append(fold_df, ignore_index=True)\n","  \n","  df.to_csv(out_dir)  "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"0sehwzzrXqio"},"outputs":[],"source":["def train_leaky_ensembler(oof_dir, model_names, out_dir, kfolds=[0,1,2,3,4,5], model_bins=[], clf='ridge', find_opt_avg=False, bin_avg_dir=None, use_postprocessing=False):\n","  df = pd.read_csv(oof_dir)\n","\n","  if find_opt_avg:\n","    msk = np.random.rand(len(df)) < 0.2\n","    df_test = df[msk].reset_index(drop=True)\n","    df = df[~msk].reset_index(drop=True)\n","    \n","  get_bin_stratified(df, n_splits=6)\n","\n","  results = []\n","  if find_opt_avg:\n","    avg_df = pd.DataFrame()\n","    avg_df['target'] = [float(f) for f in df_test['target']]\n","  for fold in kfolds:\n","    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n","    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n","    \n","    train_tx = [str(t) for t in train_df.excerpt.values]\n","    val_tx = [str(t) for t in val_df.excerpt.values]\n","    val_sc = [float(f) for f in val_df.target.values]\n","    train_sc = [float(f) for f in train_df.target.values]\n","\n","    train_predictions = []\n","    val_predictions = []\n","    avg_predictions = []\n","\n","    if len(model_bins) > 0 and not use_postprocessing:\n","      for model_name in model_bins:\n","        preds = [json.loads(p) for p in train_df[model_name].values]\n","        preds_val = [json.loads(p) for p in val_df[model_name].values]\n","        if bin_avg_dir:\n","          with open(bin_avg_dir, 'r') as f:\n","            averages = json.loads(f.read())\n","          preds = [averages[np.argmax(p)] for p in preds]\n","          preds_val = [averages[np.argmax(p)] for p in preds_val]\n","\n","        train_predictions.append(preds)\n","        val_predictions.append(preds_val)\n","    \n","    for model_name in model_names:\n","      preds = [float(f) for f in train_df[model_name].values]\n","      train_predictions.append(np.array(preds))\n","      preds_val = [float(f) for f in val_df[model_name].values]\n","      val_predictions.append(np.array(preds_val))\n","      if find_opt_avg:\n","        preds_avg = [float(f) for f in df_test[model_name].values]\n","        avg_predictions.append(np.array(preds_avg))\n","    \n","    X = np.column_stack(train_predictions)\n","    \n","    if clf == 'ridge':\n","      clf = Ridge(alpha=1.0)\n","    elif clf == 'linearsvr':\n","      clf = LinearSVR(max_iter=1000000)\n","    elif clf == 'svr':\n","      clf = SVR()\n","    elif clf == 'kernel':\n","      clf = KernelRidge()\n","    elif clf == 'gbr':\n","      clf = GradientBoostingRegressor()\n","    elif clf == 'linear':\n","      clf = LinearRegression()\n","    elif clf == 'lasso':\n","      clf = Lasso()\n","    elif clf == 'bayes':\n","      clf = BayesianRidge()\n","    elif clf == 'perceptron':\n","      clf = SGDRegressor()\n","    \n","    clf.fit(X, train_sc)\n","\n","    final_out = out_dir + '/model_fold_' + str(fold) + '/'\n","    if not os.path.exists(os.path.dirname(final_out)):\n","      try:\n","          os.makedirs(os.path.dirname(final_out))\n","      except OSError as exc: # Guard against race condition\n","          if exc.errno != errno.EEXIST:\n","              raise\n","    dump(clf, final_out + 'ridge_model.joblib')\n","\n","    Y = np.column_stack(val_predictions)\n","\n","    y_preds = clf.predict(Y)\n","    if use_postprocessing:\n","      preds_val = [json.loads(p) for p in val_df[model_bins[0]].values]\n","      with open(bin_avg_dir, 'r') as f:\n","            averages = json.loads(f.read())\n","      preds_val_bins = [np.argmax(p) for p in preds_val]\n","      zipped = list(zip(preds_val_bins, preds_val))\n","      y_preds = postprocess_predictions(y_preds, zipped, averages)\n","\n","    score = rms(val_sc, y_preds)\n","    print('Score is: ', score)\n","    results.append(score)\n","\n","    if find_opt_avg:\n","      Y_test = np.column_stack(avg_predictions)\n","      y_preds_test = clf.predict(Y_test)\n","      avg_df['fold_' + str(fold)] = y_preds_test\n","  \n","  if find_opt_avg:\n","    ridge_names = ['fold_' + str(fold) for fold in range(kfolds)]\n","    print(find_best_stack(avg_df, ridge_names, drop_models=False))\n","\n","  with open(out_dir + '/eval.txt', 'w') as f:\n","    mean = np.mean(results)\n","    print('CV ist: ', mean)\n","    f.write('CV is: ' + str(mean))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"J0DBzdmgYEMy"},"outputs":[],"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Y_GGOXV1bBJ1"},"outputs":[],"source":["def rms(y_actual, y_predicted):\n","  return mean_squared_error(y_actual, y_predicted, squared=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FjBEUthJYFYy"},"source":["# Pretraining models"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"CoQs5JkaYII6"},"outputs":[],"source":["# Load the pseudo-labeled training data for pretraining models\n","train_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/predicted/predicted.csv'))\n","train_tx = [str(t) for t in train_df.excerpt.values]\n","train_sc = [float(t) for t in train_df.target.values]"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_jxQx9i8ZI7X"},"outputs":[],"source":["# Load the entire training set from the original competition for validation during pretraining\n","val_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/original/train.csv'))\n","val_tx = [str(t) for t in train_df.excerpt.values]\n","val_sc = [float(t) for t in train_df.target.values]"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"uIoSp7aLZR4-"},"outputs":[],"source":["# Train an ALBERT model\n","\n","model_name = 'albert-xxlarge-v2'\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.01,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.07,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 60,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ALBERT_PRETRAINED = os.path.join(BASE_PATH, 'models/albert-xxlarge-no-cv')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751,"referenced_widgets":["6fe21e46a1b44bf8b5e43027e73376a7","12726890add04fe6aa64cec205e05f05","eebc87e23ac34b7d947d4a5bbb64f5ca","be782cc5c1c8488a8c97131739437e05","c3ddab55f4d744b1912d884122978df4","f4dfe24236874484ad73205f2612257d","1d41db217eec4602bf7f9838f5d769bd","4afd4111264f4a0fa9579d1b301b4601","5db45fe62cf54877bdd1bbd8cc98da28","6a38f1a6e951441a9defc9398c540098","551e0e9d097347aabc0c6bebd01d2082","5388dbecd0fb49c88abf02733747e01b","d56efd20fa814a9b957a7dc49056032d","db12d6399bc941f59c6ae60d2beb11f2","db59f537fd6049fe901d042905823c30","072298bfd93644968c71b5fa7b84a952","b97a3a30bdfd4612b09b2d5e0447d381","244ecc5b53a444d9b06b8981b85c970f","9f23ccc019dc4046a6cb4347a397ad79","916ed8c81bf64a8984fc1e40cefdaa00","5e13ecccb3774e1d8d66394f80788eb5","f317ba33d8df46bc811d8f21f45868e0"]},"executionInfo":{"elapsed":41725,"status":"ok","timestamp":1628353410510,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"trfdyCkAaEgS","outputId":"fc68485e-37c3-48ae-b167-6545dc0e4d78"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef9f8a2aa253437c9a99d3bd5900b1fa","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/893M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']\n","- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/tmp/ipykernel_1571047/3347279979.py:74: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d15b971800b4c719ad8902256559e7d","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='31' max='7630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  31/7630 09:13 < 40:15:55, 0.05 it/s, Epoch 0.02/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["train_model(\n","    model_dir=model_name,\n","    out_dir=ALBERT_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d7a3a38272ff48ba8125b50be1b157d4","bff952736ffd4b50ae75acb020fd481b","6b7bf1bf7414490dbfad3d33f9a44ab3","5b14760830124e63b302f63944690cea","dbb3d4a578cd4564a53414ceef71da2b","2e6b0ee16bbb480ca3dd6f81d080dca1","60548b7369d54fc09a1ecd823daa418a","e6831b4a9736483aa3aefc9bb2318a2a","b6b87bbdbf354587b1330eff467f6174","462f1ab065bd4a68b44f3e5f82f6d6c8","1fbc5226341945e6b64a2ac45af52004","91f8052331ba482e8380aaf7e83fc1db","845c5936fd96438b87a1cce2974d78e5","7415cf21ec1f4148b19b1409784429d3","d78f3bc7a3e24eab92569fdaf83f7ba4","48f85b79c58d4cd59eca639d19bd1f90","ac2bd1da3ced4f3b91b484bd745e86da","cc421dd21cf44c97a5a2feda0a02e72b","e108e22beefe4dbfa21f01a189070bb0","e0baea8e01ce4a3cab96f14b4b9944e6","04d257aaf71e41f8b93223540f12e546","9f8b910cb89742648ffc9df643d8cca3","41780e8505b04e1aa48fca3005dfcf3e","0f8896d36a3e4c718ca5eb7d2a4db036","ed4cc8276fd947ee95e9e420cceaab0f","4cf4929d93724b88be6d1d428bdfaa97","902edc73112946b88d55afe299ff680a","6495b6f0569240ca9af463481aec94da","704350d386904fdba4b2782392f4c0bc","75fab396ec05456093e052d7b5dfb596","2b304b633c654429ba05a1f48447ddb4","aa8cf38b1fc54d47a2adc5c0a58ac504","ba20d6ba371f4f96b3d379713ed39642","33f156b8e7874b87a9f61d1a065c4c96","1f290f5083de46cc8370d3949c8e36b6","0c05fa677771495296077d2cf6360cfe","613d68d5434a47c89ef55f0cd1436977","e3b3b1add5944372a3349cee1957f85c","019d1122d3544181b5af8fcb0bf7ca0d","6890671c6b1043b38ffc66c85e2449c4","7070960c8eac4935902546d358b07231","eac90ccd9584470cb7adfbc9c7e2679c","a659a7f4171640ffa54d69ed7a7f1be2","ba0e39c775894ab897462870c7beadc5","1c2543a0ab094134a25f6603ab1fd6d9","e8a73c92d4d646949922cd665cbda390","b04c05d8dc8b4b71bbc8c4bce8b3d2b3","beee0635e9634f0e9bdb43bf4036e422","eb2d90da017b40618608151bafd7bcd1","fcb6c02ee7df43edaac1e1a2ade1f1a6","33641ab74dad49f3a86d0d8fa46b7a1e","2ecbc2a60c2c43dc94a81fda94a8c65f","886de66ecec3421886e3f50e479a6ff0","55fbffecf6d047b28a0ed099ccb3c394","5a21c7fa7b0b4ac18487f03367a85246"]},"executionInfo":{"elapsed":99248,"status":"ok","timestamp":1628353662900,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"LfjD9r7TayIc","outputId":"b3c4b548-a0cc-44d0-84b9-1dd5a61323ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp16ymkjh4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7a3a38272ff48ba8125b50be1b157d4","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/fa4e12e9e6e1a899fe94275a0e60bdc59474baa2cc8e6fa0c207c7d9caaa2598.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n","creating metadata file for /root/.cache/huggingface/transformers/fa4e12e9e6e1a899fe94275a0e60bdc59474baa2cc8e6fa0c207c7d9caaa2598.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n","https://huggingface.co/microsoft/deberta-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpq8pc4uxt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91f8052331ba482e8380aaf7e83fc1db","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","creating metadata file for /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/microsoft/deberta-large/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpw7o_a33j\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41780e8505b04e1aa48fca3005dfcf3e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/4614a858d4552a0a399dc77bafbbeb75b20fe49259f690eb561898f8975626fa.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n","creating metadata file for /root/.cache/huggingface/transformers/4614a858d4552a0a399dc77bafbbeb75b20fe49259f690eb561898f8975626fa.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n","https://huggingface.co/microsoft/deberta-large/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpx78gned3\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33f156b8e7874b87a9f61d1a065c4c96","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/7a87aa12b220b9a983b98dbd9ad35624b3fe2ce2e83d1ce621eddcdac1c04654.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","creating metadata file for /root/.cache/huggingface/transformers/7a87aa12b220b9a983b98dbd9ad35624b3fe2ce2e83d1ce621eddcdac1c04654.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4614a858d4552a0a399dc77bafbbeb75b20fe49259f690eb561898f8975626fa.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/7a87aa12b220b9a983b98dbd9ad35624b3fe2ce2e83d1ce621eddcdac1c04654.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/microsoft/deberta-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/fa4e12e9e6e1a899fe94275a0e60bdc59474baa2cc8e6fa0c207c7d9caaa2598.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/microsoft/deberta-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpir5ni2dj\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c2543a0ab094134a25f6603ab1fd6d9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/microsoft/deberta-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/236b63dfb5e690fb2e194403aebda39508d60877a8903da58f4fff7a147ec0dd.e8bb754209aab7decd8d3faee51cce4d572131b439d5360c168d43998e3ceb13\n","creating metadata file for /root/.cache/huggingface/transformers/236b63dfb5e690fb2e194403aebda39508d60877a8903da58f4fff7a147ec0dd.e8bb754209aab7decd8d3faee51cce4d572131b439d5360c168d43998e3ceb13\n","loading weights file https://huggingface.co/microsoft/deberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/236b63dfb5e690fb2e194403aebda39508d60877a8903da58f4fff7a147ec0dd.e8bb754209aab7decd8d3faee51cce4d572131b439d5360c168d43998e3ceb13\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'config', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-large and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/microsoft/deberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7c686202d9db9b0aee3e649d42a50257a76d278858dc7ad32b886f02cf8303e4.5286a902fea63d3276108ffa66a65e2b4355a7df6cfab5be091bf20f7eae85f8\n","Model config DebertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"c2p\",\n","    \"p2c\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"relative_attention\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 3\n","  Total train batch size (w. parallel, distributed & accumulation) = 3\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:29, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.010100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["1it [00:00, 27.96it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/config.json\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.03461174666881561\n","is min 0.03461174666881561 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","1it [00:00, 27.54it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/config.json\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.033117204904556274\n","is min 0.033117204904556274 is smaller than [0.03461174666881561]\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/deberta-large-augmented/best/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"data":{"text/plain":["0.033117204904556274"]},"execution_count":19,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Train a DEBERTA model\n","model_name = 'microsoft/deberta-large'\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 20,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","DEBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/deberta-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["62932fc171e54ad8a6e83d43bbecef28","7e266f1c703b43e2a1380fce6f749f4c","994983c7661840cda6a0d12d874605a5","6a89755c37e849359f19ea453f7a64e1","a3baefe68a214cc6a3f4616719547fed","694cac06d91d4ef99bf0e817d8ed9b15","9fa94d851b284aa0b6d8d8590f7a8d7f","2019d8e148a24245a802ad90d28f781c","fc943877ab974e009c3f603a77005346","e5c78f7c515a497a9c7a05f1a2661c3a","9792332c910147b6bf64cd330164c98d","bcc8278f44c34ec88a10a739a0cbeffc","2a6557ecc21e4838a06786b3947a073d","5cbcca203a664f5fa706408b54c9efda","82c212bad67f4d948af30a2c77794710","33976aa53a1641d486f194e3c19e5f03","5e750ab91db34b89a69ef11fe667069c","cce9baee6c7e402199003c1fb98bd206","429edfad527e4e8caa4627e6f2f83bc0","cfede7c27a8c4499925944119f1a6be5","cb6a512b72904f8f83f01ceacb5bd2ae","637523262dfc46d69847ca26bd009307","eb1139ebfb2a49249a58cda90cbc7ff8","1b7307fbab5f4d71a75d3e7de2fefdf9","02cf7113a3bd4029bee877c203b87de1","03dffc22176e4f86b5013ec5701961ba","f780e03a76924012a269932fe736d0ac","869a6a5af3e24c15a5f85fecb2450c22","1fc7897f470f4bbc86092083c0759e6a","cb6710f03f194276b008a53b5e120570","457294515e36418ca6ba7b7c9fcb899d","56267050b1354f1eb6ec79b758c5b31a","4a2d57e7f35d428393d374b5d9cc2f49","a8efe07af555436c803faeba3a090544","8df646e9927442ebbc00dcb84935a0cd","78d31076d57e40b2aec4106cc72d5331","71b5c02f4d0e4ec8a4c0aedea3866491","1fb2bbb9c3bc46e48ca6a93277c00b32","e2a41718e2684ff58ae266178918aaed","b746096d32c84fd8b1661033502a7e34","7ee23fd9355f4202b42c77215a50bcc9","751b8d67044b4e129014a26dcf0b442b","af2396e096a8459884990c8a9d63f9c9","fef0b635e92b4452a1e7d98fc9a303ac","a773068bd347414bb829a6e2e7c5e975","eb79e9523fe44d2ebc4b7c2baf578b2d","cbf7c6179c8940b999fb4980e1cd1ada","cf79d819e9aa453d9779b735e3ed1be2","d2c7ecc96bcf402582adaa75cfdc9ef8","a664243ec98b488f8479aefe34cef74e","2ebe8afbd64e4fe69559ff40eee28408","c1e3e9263f584157beaa54ce480c74f2","80f2a430804c4705bb60ee001c6ad758","a83dbb4207c647f59b814762bdb7c865","82b99e1a4caa4eb1ac8b0c99f71f88c9"]},"executionInfo":{"elapsed":49162,"status":"ok","timestamp":1628353769881,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"_WSipbOPb2LW","outputId":"c3f0984e-40ce-45b9-d243-862531f18c30"},"outputs":[{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","https://huggingface.co/roberta-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpa8qjr58p\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62932fc171e54ad8a6e83d43bbecef28","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","creating metadata file for /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/roberta-large/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpg4m9vcoe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcc8278f44c34ec88a10a739a0cbeffc","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","creating metadata file for /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","https://huggingface.co/roberta-large/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpht4u0dqe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb1139ebfb2a49249a58cda90cbc7ff8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","creating metadata file for /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","https://huggingface.co/roberta-large/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp6eu4fwib\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8efe07af555436c803faeba3a090544","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","creating metadata file for /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfg09s6l1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a773068bd347414bb829a6e2e7c5e975","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n","creating metadata file for /root/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n","loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8/8 00:07, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","1it [00:00, 48.35it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/config.json\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.028184428811073303\n","is min 0.028184428811073303 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/roberta-large-augmented/best/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"data":{"text/plain":["0.028184428811073303"]},"execution_count":20,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Train a RoBERTa model\n","model_name = 'roberta-large'\n","hyperparams = {\n","  'bs': 8,\n","  'lr': 1e-5,\n","  'weight_decay': 0.01,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ROBERTA_PRETRAINED = os.path.join(BASE_PATH, 'models/roberta-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bd242afef0ab4c3cb6b9f87717cdd344","1292580a726d491eaf064c9030ff1a35","c29f290b45d8475380626a8cad70c10f","71cb361ae38f4d8b95201eb7e3458965","bd8cf24968f24864a8e4f2c406426ac5","e8461044e198445884fcdbbac79a937c","6278a802693a48f089d2fb0d5c159cc9","c3efb3aa702041de99815ae25b9ed9b3","c914f3f58ca3436a80c4f1a48bac0872","c9d9fa1294954d3ebfc519a8aa155b2b","0453164bfded49c8bb0b7826e9190f15","b02adf7749384b84a9928b183565ffe6","c8cf91d3257e40c6addbdab6e43c39fd","0c5ca114ea1f469da95325d91f38d79e","f9fefdf355374256942ab6a0717ea8cc","53a20cba91cb4d498efefa81f96292b6","30194a43b72445389edeb445e7d71b9d","0ddafe40e1774eb8a65e891e9c4d8005","a91b8640c5b5445494dee1952a9508fd","246c3ab4a27e42b5bb00d25177c30065","f1db107c5f084fd384df120d75eac853","1062acd5853a4ab492415657e5b1639d","75f19f654a4d4d26bb431102cdaf6ad6","0ff0ac223dca4b2dbf0377c763eabdf9","9b512229653d427985f4bf9cc4bcad3e","3b6ff42c143741f8ac1ef39ee7f4f5fe","340ae92dba31406382b56af69026d5b9","a06b96a650894594bd3e10c43b4e58f6","ad8d432775134c2187fe3f53821049d7","b3cb7aa5e15d4f62996e6b473ce6bcef","ae4befe894374ea4ba4639e7238b0001","7f44c0772f544c6191df123810f7ede8","6dd8f7a12ffe412182a4ccc5266dd050","27fc9f209c424da2b4d3036de96badc1","571ae312ec664826807dca5ccffb390b","4ff5753d701940c0afdbc331012634e9","3c9d5461f6414ef0a033c6a098419ae9","4d7b09f0f3dd4299a7ce1d586fe15c08","2ef75b93f0cd4dc3ae0b74a21a967af8","ec386d7b500b440684b1050842a69ad4","2cd178aa7c4f4ad8b8f07d72750a824a","8829de1e90e04481a5ce6668558c22f8","f3b7b30ad39d4bfd8fe8aeb462f9e091","85f3e8aaf83748e899449c567244664e","6a656abe51244c5eaa8091bcc626c2d2","a7ad68d3c6fc4eeeb8f47df6a893510b","9823b8716027416bb07fd2aa35fdae8d","e4b9b2ea64e649918de011a1f1bfeac6","87d2b417d2e547b48ef1deb064d07cdd","986d22e0c67c4318aea89f64a3e1a7bc","308d554f512e47c0bec0eaea069ffa31","d1b7209908a64f4db31686c5d25f2fbf","5757c3974b7b435e8ceb531a897f58ed","7e13bdfc94c94de0abb94f660435a750","b7e6cf2574994104a3e89c652ff0db22"]},"executionInfo":{"elapsed":68800,"status":"ok","timestamp":1628353943089,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"TKTR9SyZcasB","outputId":"db4e1ba6-ebf4-44fd-a2ff-232c66a0cd1f"},"outputs":[{"name":"stderr","output_type":"stream","text":["https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3n2ytear\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd242afef0ab4c3cb6b9f87717cdd344","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/26ad81c46898598ce9aed0b02fd3c9175a28daa30317e4f1980b5e871d823b67.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n","creating metadata file for /root/.cache/huggingface/transformers/26ad81c46898598ce9aed0b02fd3c9175a28daa30317e4f1980b5e871d823b67.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpii3zb0or\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b02adf7749384b84a9928b183565ffe6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/668 [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","creating metadata file for /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpq443cx8e\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75f19f654a4d4d26bb431102cdaf6ad6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/48a62a60c85c63546f3623e592c2ddfd0628ed7749e6d503a11eb80cb04fc19c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","creating metadata file for /root/.cache/huggingface/transformers/48a62a60c85c63546f3623e592c2ddfd0628ed7749e6d503a11eb80cb04fc19c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdo4t0sba\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27fc9f209c424da2b4d3036de96badc1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/ed8095412008e8a8159d4bbdcecd02e5e72b79a1fc7dbfdc32e6aef638d4b9a9.65c74b3f0086fae55b99a8c9173a6739a53ae5ae0441c0811095141532f33ff8\n","creating metadata file for /root/.cache/huggingface/transformers/ed8095412008e8a8159d4bbdcecd02e5e72b79a1fc7dbfdc32e6aef638d4b9a9.65c74b3f0086fae55b99a8c9173a6739a53ae5ae0441c0811095141532f33ff8\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/48a62a60c85c63546f3623e592c2ddfd0628ed7749e6d503a11eb80cb04fc19c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/ed8095412008e8a8159d4bbdcecd02e5e72b79a1fc7dbfdc32e6aef638d4b9a9.65c74b3f0086fae55b99a8c9173a6739a53ae5ae0441c0811095141532f33ff8\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/google/electra-large-discriminator/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/26ad81c46898598ce9aed0b02fd3c9175a28daa30317e4f1980b5e871d823b67.4f2213f5603276adf12967b32e4444c0f187f34ca4f8b22a65f03e13514589e9\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","https://huggingface.co/google/electra-large-discriminator/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp1cx5351y\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a656abe51244c5eaa8091bcc626c2d2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/google/electra-large-discriminator/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/6a9790a4cce0d5f0f7d5c78b57955d681fe9cb564edc75aab3733c5ba3a5550d.a2ee8c7426aca3bd41c92ad0b3e07d731d9bf61c950403e6a82b1d566b8923db\n","creating metadata file for /root/.cache/huggingface/transformers/6a9790a4cce0d5f0f7d5c78b57955d681fe9cb564edc75aab3733c5ba3a5550d.a2ee8c7426aca3bd41c92ad0b3e07d731d9bf61c950403e6a82b1d566b8923db\n","loading weights file https://huggingface.co/google/electra-large-discriminator/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/6a9790a4cce0d5f0f7d5c78b57955d681fe9cb564edc75aab3733c5ba3a5550d.a2ee8c7426aca3bd41c92ad0b3e07d731d9bf61c950403e6a82b1d566b8923db\n","Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/google/electra-large-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/344f5be314c0b91e28096c6730a1a43d61ba11aee91fd8ff026aba39138181d1.c4309b08c8b9d0909e488ef6b4cefe6a11ebc271247617cbdbb73361b191cc33\n","Model config ElectraConfig {\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"embedding_size\": 1024,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 14\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14/14 00:08, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.005900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["1it [00:00, 43.78it/s]\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/config.json\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.03945397585630417\n","is min 0.03945397585630417 is smaller than []\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/electra-large-augmented/best/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","1it [00:00, 43.76it/s]"]},{"name":"stdout","output_type":"stream","text":["Score:  0.04779457300901413\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]},{"data":{"text/plain":["0.03945397585630417"]},"execution_count":21,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Train an ELECTRA model\n","model_name = 'google/electra-large-discriminator'\n","hyperparams = {\n","  'bs': 4,\n","  'lr': 8e-6,\n","  'weight_decay': 0.1,\n","  'ep': 7,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","ELECTRA_PRETRAINED = os.path.join(BASE_PATH, 'models/electra-large-augmented')\n","\n","train_model(\n","    model_dir=model_name,\n","    out_dir=ELECTRA_PRETRAINED,\n","    data=train_tx,\n","    data_labels=train_sc,\n","    test_data=val_tx,\n","    test_labels=val_sc,\n","    do_save_best=True,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LZp4MeZUdFsm"},"source":["# Training models"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"J3deWnW2dLTv"},"source":["In total, I trained 3 deberta-large, 1 roberta-large, 3 albert-xxlarge and 1 electra-large model for my winning submission.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ze54BKZdYvk"},"outputs":[],"source":["# Training the ALBERT models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRuHZIARd-GJ"},"outputs":[],"source":["# albert 1\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.01,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.07,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ALBERT_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0YuArTWeglx"},"outputs":[],"source":["# albert 2\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 7e-6,\n","  'weight_decay': 0.07,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ALBERT_TRAINED_2\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":21564,"status":"ok","timestamp":1628357046530,"user":{"displayName":"Mathis Lucka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhthkjGUPZoLLxPuKrqVqOhzkL6AX8O9OT0agPB=s64","userId":"17007389841511802481"},"user_tz":-120},"id":"m2iQGSPFe7pW","outputId":"da793891-b87d-434b-a7ea-b1d188e38ef3"},"outputs":[{"name":"stderr","output_type":"stream","text":["Didn't find file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/added_tokens.json. We won't load it.\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/spiece.model\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/tokenizer.json\n","loading file None\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/special_tokens_map.json\n","loading file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/tokenizer_config.json\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n","Model config AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 4096,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 16384,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"layers_to_keep\": [],\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","loading configuration file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n","Model config AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 4096,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 16384,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"layers_to_keep\": [],\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","loading weights file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/pytorch_model.bin\n","All model checkpoint weights were used when initializing AlbertForSequenceClassification.\n","\n","All the weights of AlbertForSequenceClassification were initialized from the model checkpoint at gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForSequenceClassification for predictions without further training.\n","loading configuration file gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-no-cv/best/config.json\n","Model config AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 4096,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 16384,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"layers_to_keep\": [],\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","***** Running training *****\n","  Num examples = 7\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 3\n","  Total train batch size (w. parallel, distributed & accumulation) = 3\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:01, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/config.json\n","Model weights saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Lit/Lit_Submission/models/albert-xxlarge-all-data/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["Training done\n"]}],"source":["# albert 3\n","# albert 3 is special it is trained on all training data without evaluation.\n","model_name = os.path.join(ALBERT_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 600,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","train_df = pd.read_csv(os.path.join(BASE_PATH, 'data/training/original/train.csv'))\n","train_tx = [str(t) for t in train_df.excerpt.values]\n","train_sc = [float(t) for t in train_df.target.values]\n","\n","out_dir = ALBERT_TRAINED_3\n","\n","\n","train_model(\n","   model_dir=model_name,\n","   out_dir=out_dir,\n","   data=train_tx,\n","   data_labels=train_sc,\n","   hyperparams=hyperparams,\n","   cfg=cfg\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnKSaQWGpAUa"},"outputs":[],"source":["# Training the deberta models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HXYFgmVApREy"},"outputs":[],"source":["# deberta 1\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GPvQ-fImNmVl"},"outputs":[],"source":["# deberta 2\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 7e-6,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_2\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEgot9YgN6at"},"outputs":[],"source":["# deberta 3\n","# This deberta model was trained on data sampled using bootstrapping instead of cross validation\n","# Only models trained on 2 folds/bags were used in the final submission\n","model_name = os.path.join(DEBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 9e-6,\n","  'weight_decay': 0.08,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = DEBERTA_TRAINED_3\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg,\n","    kfolds=[0,1]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKRTt-uUPVAm"},"outputs":[],"source":["# Training the ELECTRA model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aiQ3rJsUPXSq"},"outputs":[],"source":["# electra 1\n","model_name = os.path.join(ELECTRA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 3,\n","  'lr': 8e-6,\n","  'weight_decay': 0.1,\n","  'ep': 5,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ELECTRA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcgBi10OP-_L"},"outputs":[],"source":["# Training the RoBERTa model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRWMXp9mQB2W"},"outputs":[],"source":["# roberta 1\n","model_name = os.path.join(ROBERTA_PRETRAINED, 'best')\n","hyperparams = {\n","  'bs': 8,\n","  'lr': 1e-5,\n","  'weight_decay': 0.1,\n","  'ep': 4,\n","  'bias': True,\n","  'init': None,\n","  'hidden_dropout': 0.1,\n","  'attention_probs_dropout': 0.1\n","}\n","cfg = {\n","  'num_labels': 1,\n","  'is_multilabel': False,\n","  'logging_steps': 10,\n","  'keep_layers': None,\n","  'soft_labels': None\n","}\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = ROBERTA_TRAINED_1\n","\n","train_cv_v2(\n","    model_dir=model_name,\n","    out_dir=out_dir,\n","    fold_dir=fold_dir,\n","    hyperparams=hyperparams,\n","    cfg=cfg\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iyZmZulYQ-5U"},"source":["# Stacking"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHfTtt0QRC3B"},"outputs":[],"source":["model_dirs = [\n","    ALBERT_TRAINED_1,\n","    DEBERTA_TRAINED_1,\n","    ALBERT_TRAINED_2,\n","    DEBERTA_TRAINED_1,\n","    ROBERTA_TRAINED_1,\n","    ELECTRA_TRAINED_1\n","]\n","\n","fold_dir = os.path.join(BASE_PATH, 'data/training/cv')\n","out_dir = os.path.join(BASE_PATH, 'data/training/oof')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLtSkIirhe7O"},"outputs":[],"source":["get_oof_predictions(model_dirs=model_dirs, fold_dir=fold_dir, out_dir=out_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNFUoYZsh1GF"},"outputs":[],"source":["model_names_ensemble_1 = [\n","    ALBERT_TRAINED_1.split('/')[-1],\n","    DEBERTA_TRAINED_1.split('/')[-1],\n","    ALBERT_TRAINED_2.split('/')[-1],\n","    DEBERTA_TRAINED_1.split('/')[-1],\n","    ROBERTA_TRAINED_1.split('/')[-1],\n","    ELECTRA_TRAINED_1.split('/')[-1],      \n","]\n","\n","model_names_ensemble_2 = model_names_ensemble_1[:-1]\n","\n","oof_dir = os.path.join(BASE_PATH, 'data/training/oof')\n","\n","out_dir_ensemble_1 = os.path.join(BASE_PATH, 'models/electra-larger-ensemble')\n","out_dir_ensemble_2 = os.path.join(BASE_PATH, 'models/huge-ensemble')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Ruz_111qWoQ"},"outputs":[],"source":["# train ensemble 1\n","train_leaky_ensembler(oof_dir=oof_dir, model_names=model_names_ensemble_1, out_dir=out_dir_ensemble_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kt_VtNCgqa0v"},"outputs":[],"source":["# train ensemble 2\n","train_leaky_ensembler(oof_dir=oof_dir, model_names=model_names_ensemble_2, out_dir=out_dir_ensemble_2)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HJLfireQ0uoS"},"source":["You have finished training the models."]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNL/D3EW7Nf9IlW5+fqqTLT","collapsed_sections":["LZp4MeZUdFsm"],"name":"04_clrp_training.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"019d1122d3544181b5af8fcb0bf7ca0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02cf7113a3bd4029bee877c203b87de1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fc7897f470f4bbc86092083c0759e6a","placeholder":"â€‹","style":"IPY_MODEL_869a6a5af3e24c15a5f85fecb2450c22","value":"Downloading: 100%"}},"03dffc22176e4f86b5013ec5701961ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_457294515e36418ca6ba7b7c9fcb899d","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb6710f03f194276b008a53b5e120570","value":456318}},"0453164bfded49c8bb0b7826e9190f15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d257aaf71e41f8b93223540f12e546":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"072298bfd93644968c71b5fa7b84a952":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f317ba33d8df46bc811d8f21f45868e0","placeholder":"â€‹","style":"IPY_MODEL_5e13ecccb3774e1d8d66394f80788eb5","value":" 3.21k/? [00:00&lt;00:00, 73.9kB/s]"}},"0c05fa677771495296077d2cf6360cfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6890671c6b1043b38ffc66c85e2449c4","placeholder":"â€‹","style":"IPY_MODEL_019d1122d3544181b5af8fcb0bf7ca0d","value":"Downloading: 100%"}},"0c5ca114ea1f469da95325d91f38d79e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ddafe40e1774eb8a65e891e9c4d8005","placeholder":"â€‹","style":"IPY_MODEL_30194a43b72445389edeb445e7d71b9d","value":"Downloading: 100%"}},"0ddafe40e1774eb8a65e891e9c4d8005":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f8896d36a3e4c718ca5eb7d2a4db036":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ff0ac223dca4b2dbf0377c763eabdf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1062acd5853a4ab492415657e5b1639d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12726890add04fe6aa64cec205e05f05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1292580a726d491eaf064c9030ff1a35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b7307fbab5f4d71a75d3e7de2fefdf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c2543a0ab094134a25f6603ab1fd6d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b04c05d8dc8b4b71bbc8c4bce8b3d2b3","IPY_MODEL_beee0635e9634f0e9bdb43bf4036e422","IPY_MODEL_eb2d90da017b40618608151bafd7bcd1"],"layout":"IPY_MODEL_e8a73c92d4d646949922cd665cbda390"}},"1d41db217eec4602bf7f9838f5d769bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f290f5083de46cc8370d3949c8e36b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb2bbb9c3bc46e48ca6a93277c00b32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef0b635e92b4452a1e7d98fc9a303ac","placeholder":"â€‹","style":"IPY_MODEL_af2396e096a8459884990c8a9d63f9c9","value":" 1.36M/1.36M [00:00&lt;00:00, 3.86MB/s]"}},"1fbc5226341945e6b64a2ac45af52004":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fc7897f470f4bbc86092083c0759e6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2019d8e148a24245a802ad90d28f781c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"244ecc5b53a444d9b06b8981b85c970f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"246c3ab4a27e42b5bb00d25177c30065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27fc9f209c424da2b4d3036de96badc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ff5753d701940c0afdbc331012634e9","IPY_MODEL_3c9d5461f6414ef0a033c6a098419ae9","IPY_MODEL_4d7b09f0f3dd4299a7ce1d586fe15c08"],"layout":"IPY_MODEL_571ae312ec664826807dca5ccffb390b"}},"2a6557ecc21e4838a06786b3947a073d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b304b633c654429ba05a1f48447ddb4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cd178aa7c4f4ad8b8f07d72750a824a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e6b0ee16bbb480ca3dd6f81d080dca1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ebe8afbd64e4fe69559ff40eee28408":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ecbc2a60c2c43dc94a81fda94a8c65f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ef75b93f0cd4dc3ae0b74a21a967af8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30194a43b72445389edeb445e7d71b9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"308d554f512e47c0bec0eaea069ffa31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33641ab74dad49f3a86d0d8fa46b7a1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33976aa53a1641d486f194e3c19e5f03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_637523262dfc46d69847ca26bd009307","placeholder":"â€‹","style":"IPY_MODEL_cb6a512b72904f8f83f01ceacb5bd2ae","value":" 899k/899k [00:00&lt;00:00, 1.16MB/s]"}},"33f156b8e7874b87a9f61d1a065c4c96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c05fa677771495296077d2cf6360cfe","IPY_MODEL_613d68d5434a47c89ef55f0cd1436977","IPY_MODEL_e3b3b1add5944372a3349cee1957f85c"],"layout":"IPY_MODEL_1f290f5083de46cc8370d3949c8e36b6"}},"340ae92dba31406382b56af69026d5b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dd8f7a12ffe412182a4ccc5266dd050","placeholder":"â€‹","style":"IPY_MODEL_7f44c0772f544c6191df123810f7ede8","value":" 232k/232k [00:00&lt;00:00, 1.30MB/s]"}},"3b6ff42c143741f8ac1ef39ee7f4f5fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae4befe894374ea4ba4639e7238b0001","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3cb7aa5e15d4f62996e6b473ce6bcef","value":231508}},"3c9d5461f6414ef0a033c6a098419ae9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8829de1e90e04481a5ce6668558c22f8","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cd178aa7c4f4ad8b8f07d72750a824a","value":466062}},"41780e8505b04e1aa48fca3005dfcf3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed4cc8276fd947ee95e9e420cceaab0f","IPY_MODEL_4cf4929d93724b88be6d1d428bdfaa97","IPY_MODEL_902edc73112946b88d55afe299ff680a"],"layout":"IPY_MODEL_0f8896d36a3e4c718ca5eb7d2a4db036"}},"429edfad527e4e8caa4627e6f2f83bc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"457294515e36418ca6ba7b7c9fcb899d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462f1ab065bd4a68b44f3e5f82f6d6c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48f85b79c58d4cd59eca639d19bd1f90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f8b910cb89742648ffc9df643d8cca3","placeholder":"â€‹","style":"IPY_MODEL_04d257aaf71e41f8b93223540f12e546","value":" 475/475 [00:00&lt;00:00, 12.6kB/s]"}},"4a2d57e7f35d428393d374b5d9cc2f49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afd4111264f4a0fa9579d1b301b4601":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cf4929d93724b88be6d1d428bdfaa97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b304b633c654429ba05a1f48447ddb4","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75fab396ec05456093e052d7b5dfb596","value":898825}},"4d7b09f0f3dd4299a7ce1d586fe15c08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85f3e8aaf83748e899449c567244664e","placeholder":"â€‹","style":"IPY_MODEL_f3b7b30ad39d4bfd8fe8aeb462f9e091","value":" 466k/466k [00:00&lt;00:00, 1.13MB/s]"}},"4ff5753d701940c0afdbc331012634e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec386d7b500b440684b1050842a69ad4","placeholder":"â€‹","style":"IPY_MODEL_2ef75b93f0cd4dc3ae0b74a21a967af8","value":"Downloading: 100%"}},"5388dbecd0fb49c88abf02733747e01b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db12d6399bc941f59c6ae60d2beb11f2","IPY_MODEL_db59f537fd6049fe901d042905823c30","IPY_MODEL_072298bfd93644968c71b5fa7b84a952"],"layout":"IPY_MODEL_d56efd20fa814a9b957a7dc49056032d"}},"53a20cba91cb4d498efefa81f96292b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1062acd5853a4ab492415657e5b1639d","placeholder":"â€‹","style":"IPY_MODEL_f1db107c5f084fd384df120d75eac853","value":" 668/668 [00:00&lt;00:00, 24.0kB/s]"}},"551e0e9d097347aabc0c6bebd01d2082":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55fbffecf6d047b28a0ed099ccb3c394":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56267050b1354f1eb6ec79b758c5b31a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"571ae312ec664826807dca5ccffb390b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5757c3974b7b435e8ceb531a897f58ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a21c7fa7b0b4ac18487f03367a85246":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b14760830124e63b302f63944690cea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6b87bbdbf354587b1330eff467f6174","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6831b4a9736483aa3aefc9bb2318a2a","value":52}},"5cbcca203a664f5fa706408b54c9efda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cce9baee6c7e402199003c1fb98bd206","placeholder":"â€‹","style":"IPY_MODEL_5e750ab91db34b89a69ef11fe667069c","value":"Downloading: 100%"}},"5db45fe62cf54877bdd1bbd8cc98da28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e13ecccb3774e1d8d66394f80788eb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e750ab91db34b89a69ef11fe667069c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60548b7369d54fc09a1ecd823daa418a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"613d68d5434a47c89ef55f0cd1436977":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eac90ccd9584470cb7adfbc9c7e2679c","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7070960c8eac4935902546d358b07231","value":456318}},"6278a802693a48f089d2fb0d5c159cc9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62932fc171e54ad8a6e83d43bbecef28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_994983c7661840cda6a0d12d874605a5","IPY_MODEL_6a89755c37e849359f19ea453f7a64e1","IPY_MODEL_a3baefe68a214cc6a3f4616719547fed"],"layout":"IPY_MODEL_7e266f1c703b43e2a1380fce6f749f4c"}},"637523262dfc46d69847ca26bd009307":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6495b6f0569240ca9af463481aec94da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6890671c6b1043b38ffc66c85e2449c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"694cac06d91d4ef99bf0e817d8ed9b15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a38f1a6e951441a9defc9398c540098":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a656abe51244c5eaa8091bcc626c2d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9823b8716027416bb07fd2aa35fdae8d","IPY_MODEL_e4b9b2ea64e649918de011a1f1bfeac6","IPY_MODEL_87d2b417d2e547b48ef1deb064d07cdd"],"layout":"IPY_MODEL_a7ad68d3c6fc4eeeb8f47df6a893510b"}},"6a89755c37e849359f19ea453f7a64e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc943877ab974e009c3f603a77005346","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2019d8e148a24245a802ad90d28f781c","value":482}},"6b7bf1bf7414490dbfad3d33f9a44ab3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60548b7369d54fc09a1ecd823daa418a","placeholder":"â€‹","style":"IPY_MODEL_2e6b0ee16bbb480ca3dd6f81d080dca1","value":"Downloading: 100%"}},"6dd8f7a12ffe412182a4ccc5266dd050":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fe21e46a1b44bf8b5e43027e73376a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eebc87e23ac34b7d947d4a5bbb64f5ca","IPY_MODEL_be782cc5c1c8488a8c97131739437e05","IPY_MODEL_c3ddab55f4d744b1912d884122978df4"],"layout":"IPY_MODEL_12726890add04fe6aa64cec205e05f05"}},"704350d386904fdba4b2782392f4c0bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7070960c8eac4935902546d358b07231":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71b5c02f4d0e4ec8a4c0aedea3866491":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_751b8d67044b4e129014a26dcf0b442b","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ee23fd9355f4202b42c77215a50bcc9","value":1355863}},"71cb361ae38f4d8b95201eb7e3458965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c914f3f58ca3436a80c4f1a48bac0872","max":27,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3efb3aa702041de99815ae25b9ed9b3","value":27}},"7415cf21ec1f4148b19b1409784429d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc421dd21cf44c97a5a2feda0a02e72b","placeholder":"â€‹","style":"IPY_MODEL_ac2bd1da3ced4f3b91b484bd745e86da","value":"Downloading: 100%"}},"751b8d67044b4e129014a26dcf0b442b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75f19f654a4d4d26bb431102cdaf6ad6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b512229653d427985f4bf9cc4bcad3e","IPY_MODEL_3b6ff42c143741f8ac1ef39ee7f4f5fe","IPY_MODEL_340ae92dba31406382b56af69026d5b9"],"layout":"IPY_MODEL_0ff0ac223dca4b2dbf0377c763eabdf9"}},"75fab396ec05456093e052d7b5dfb596":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78d31076d57e40b2aec4106cc72d5331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b746096d32c84fd8b1661033502a7e34","placeholder":"â€‹","style":"IPY_MODEL_e2a41718e2684ff58ae266178918aaed","value":"Downloading: 100%"}},"7e13bdfc94c94de0abb94f660435a750":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e266f1c703b43e2a1380fce6f749f4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee23fd9355f4202b42c77215a50bcc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f44c0772f544c6191df123810f7ede8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80f2a430804c4705bb60ee001c6ad758":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b99e1a4caa4eb1ac8b0c99f71f88c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82c212bad67f4d948af30a2c77794710":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfede7c27a8c4499925944119f1a6be5","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_429edfad527e4e8caa4627e6f2f83bc0","value":898823}},"845c5936fd96438b87a1cce2974d78e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85f3e8aaf83748e899449c567244664e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869a6a5af3e24c15a5f85fecb2450c22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87d2b417d2e547b48ef1deb064d07cdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7e6cf2574994104a3e89c652ff0db22","placeholder":"â€‹","style":"IPY_MODEL_7e13bdfc94c94de0abb94f660435a750","value":" 1.34G/1.34G [00:46&lt;00:00, 30.1MB/s]"}},"8829de1e90e04481a5ce6668558c22f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886de66ecec3421886e3f50e479a6ff0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8df646e9927442ebbc00dcb84935a0cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902edc73112946b88d55afe299ff680a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba20d6ba371f4f96b3d379713ed39642","placeholder":"â€‹","style":"IPY_MODEL_aa8cf38b1fc54d47a2adc5c0a58ac504","value":" 899k/899k [00:00&lt;00:00, 2.09MB/s]"}},"916ed8c81bf64a8984fc1e40cefdaa00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91f8052331ba482e8380aaf7e83fc1db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7415cf21ec1f4148b19b1409784429d3","IPY_MODEL_d78f3bc7a3e24eab92569fdaf83f7ba4","IPY_MODEL_48f85b79c58d4cd59eca639d19bd1f90"],"layout":"IPY_MODEL_845c5936fd96438b87a1cce2974d78e5"}},"9792332c910147b6bf64cd330164c98d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9823b8716027416bb07fd2aa35fdae8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_308d554f512e47c0bec0eaea069ffa31","placeholder":"â€‹","style":"IPY_MODEL_986d22e0c67c4318aea89f64a3e1a7bc","value":"Downloading: 100%"}},"986d22e0c67c4318aea89f64a3e1a7bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"994983c7661840cda6a0d12d874605a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fa94d851b284aa0b6d8d8590f7a8d7f","placeholder":"â€‹","style":"IPY_MODEL_694cac06d91d4ef99bf0e817d8ed9b15","value":"Downloading: 100%"}},"9b512229653d427985f4bf9cc4bcad3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad8d432775134c2187fe3f53821049d7","placeholder":"â€‹","style":"IPY_MODEL_a06b96a650894594bd3e10c43b4e58f6","value":"Downloading: 100%"}},"9f23ccc019dc4046a6cb4347a397ad79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f8b910cb89742648ffc9df643d8cca3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa94d851b284aa0b6d8d8590f7a8d7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a06b96a650894594bd3e10c43b4e58f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3baefe68a214cc6a3f4616719547fed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9792332c910147b6bf64cd330164c98d","placeholder":"â€‹","style":"IPY_MODEL_e5c78f7c515a497a9c7a05f1a2661c3a","value":" 482/482 [00:00&lt;00:00, 13.1kB/s]"}},"a659a7f4171640ffa54d69ed7a7f1be2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a664243ec98b488f8479aefe34cef74e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a773068bd347414bb829a6e2e7c5e975":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbf7c6179c8940b999fb4980e1cd1ada","IPY_MODEL_cf79d819e9aa453d9779b735e3ed1be2","IPY_MODEL_d2c7ecc96bcf402582adaa75cfdc9ef8"],"layout":"IPY_MODEL_eb79e9523fe44d2ebc4b7c2baf578b2d"}},"a7ad68d3c6fc4eeeb8f47df6a893510b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a83dbb4207c647f59b814762bdb7c865":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8efe07af555436c803faeba3a090544":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78d31076d57e40b2aec4106cc72d5331","IPY_MODEL_71b5c02f4d0e4ec8a4c0aedea3866491","IPY_MODEL_1fb2bbb9c3bc46e48ca6a93277c00b32"],"layout":"IPY_MODEL_8df646e9927442ebbc00dcb84935a0cd"}},"a91b8640c5b5445494dee1952a9508fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa8cf38b1fc54d47a2adc5c0a58ac504":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac2bd1da3ced4f3b91b484bd745e86da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad8d432775134c2187fe3f53821049d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae4befe894374ea4ba4639e7238b0001":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2396e096a8459884990c8a9d63f9c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b02adf7749384b84a9928b183565ffe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c5ca114ea1f469da95325d91f38d79e","IPY_MODEL_f9fefdf355374256942ab6a0717ea8cc","IPY_MODEL_53a20cba91cb4d498efefa81f96292b6"],"layout":"IPY_MODEL_c8cf91d3257e40c6addbdab6e43c39fd"}},"b04c05d8dc8b4b71bbc8c4bce8b3d2b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33641ab74dad49f3a86d0d8fa46b7a1e","placeholder":"â€‹","style":"IPY_MODEL_fcb6c02ee7df43edaac1e1a2ade1f1a6","value":"Downloading: 100%"}},"b3cb7aa5e15d4f62996e6b473ce6bcef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6b87bbdbf354587b1330eff467f6174":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b746096d32c84fd8b1661033502a7e34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7e6cf2574994104a3e89c652ff0db22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b97a3a30bdfd4612b09b2d5e0447d381":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba0e39c775894ab897462870c7beadc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba20d6ba371f4f96b3d379713ed39642":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcc8278f44c34ec88a10a739a0cbeffc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cbcca203a664f5fa706408b54c9efda","IPY_MODEL_82c212bad67f4d948af30a2c77794710","IPY_MODEL_33976aa53a1641d486f194e3c19e5f03"],"layout":"IPY_MODEL_2a6557ecc21e4838a06786b3947a073d"}},"bd242afef0ab4c3cb6b9f87717cdd344":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c29f290b45d8475380626a8cad70c10f","IPY_MODEL_71cb361ae38f4d8b95201eb7e3458965","IPY_MODEL_bd8cf24968f24864a8e4f2c406426ac5"],"layout":"IPY_MODEL_1292580a726d491eaf064c9030ff1a35"}},"bd8cf24968f24864a8e4f2c406426ac5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0453164bfded49c8bb0b7826e9190f15","placeholder":"â€‹","style":"IPY_MODEL_c9d9fa1294954d3ebfc519a8aa155b2b","value":" 27.0/27.0 [00:00&lt;00:00, 764B/s]"}},"be782cc5c1c8488a8c97131739437e05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5db45fe62cf54877bdd1bbd8cc98da28","max":892728632,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4afd4111264f4a0fa9579d1b301b4601","value":892728632}},"beee0635e9634f0e9bdb43bf4036e422":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_886de66ecec3421886e3f50e479a6ff0","max":1627222675,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ecbc2a60c2c43dc94a81fda94a8c65f","value":1627222675}},"bff952736ffd4b50ae75acb020fd481b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e3e9263f584157beaa54ce480c74f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c29f290b45d8475380626a8cad70c10f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6278a802693a48f089d2fb0d5c159cc9","placeholder":"â€‹","style":"IPY_MODEL_e8461044e198445884fcdbbac79a937c","value":"Downloading: 100%"}},"c3ddab55f4d744b1912d884122978df4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_551e0e9d097347aabc0c6bebd01d2082","placeholder":"â€‹","style":"IPY_MODEL_6a38f1a6e951441a9defc9398c540098","value":" 893M/893M [00:17&lt;00:00, 52.1MB/s]"}},"c3efb3aa702041de99815ae25b9ed9b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8cf91d3257e40c6addbdab6e43c39fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c914f3f58ca3436a80c4f1a48bac0872":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9d9fa1294954d3ebfc519a8aa155b2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb6710f03f194276b008a53b5e120570":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb6a512b72904f8f83f01ceacb5bd2ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbf7c6179c8940b999fb4980e1cd1ada":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ebe8afbd64e4fe69559ff40eee28408","placeholder":"â€‹","style":"IPY_MODEL_a664243ec98b488f8479aefe34cef74e","value":"Downloading: 100%"}},"cc421dd21cf44c97a5a2feda0a02e72b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cce9baee6c7e402199003c1fb98bd206":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf79d819e9aa453d9779b735e3ed1be2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80f2a430804c4705bb60ee001c6ad758","max":1425941629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1e3e9263f584157beaa54ce480c74f2","value":1425941629}},"cfede7c27a8c4499925944119f1a6be5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1b7209908a64f4db31686c5d25f2fbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2c7ecc96bcf402582adaa75cfdc9ef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82b99e1a4caa4eb1ac8b0c99f71f88c9","placeholder":"â€‹","style":"IPY_MODEL_a83dbb4207c647f59b814762bdb7c865","value":" 1.43G/1.43G [00:28&lt;00:00, 50.1MB/s]"}},"d56efd20fa814a9b957a7dc49056032d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d78f3bc7a3e24eab92569fdaf83f7ba4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0baea8e01ce4a3cab96f14b4b9944e6","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e108e22beefe4dbfa21f01a189070bb0","value":475}},"d7a3a38272ff48ba8125b50be1b157d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b7bf1bf7414490dbfad3d33f9a44ab3","IPY_MODEL_5b14760830124e63b302f63944690cea","IPY_MODEL_dbb3d4a578cd4564a53414ceef71da2b"],"layout":"IPY_MODEL_bff952736ffd4b50ae75acb020fd481b"}},"db12d6399bc941f59c6ae60d2beb11f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_244ecc5b53a444d9b06b8981b85c970f","placeholder":"â€‹","style":"IPY_MODEL_b97a3a30bdfd4612b09b2d5e0447d381","value":"Downloading: "}},"db59f537fd6049fe901d042905823c30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_916ed8c81bf64a8984fc1e40cefdaa00","max":1421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f23ccc019dc4046a6cb4347a397ad79","value":1421}},"dbb3d4a578cd4564a53414ceef71da2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fbc5226341945e6b64a2ac45af52004","placeholder":"â€‹","style":"IPY_MODEL_462f1ab065bd4a68b44f3e5f82f6d6c8","value":" 52.0/52.0 [00:00&lt;00:00, 1.52kB/s]"}},"e0baea8e01ce4a3cab96f14b4b9944e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e108e22beefe4dbfa21f01a189070bb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2a41718e2684ff58ae266178918aaed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3b3b1add5944372a3349cee1957f85c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba0e39c775894ab897462870c7beadc5","placeholder":"â€‹","style":"IPY_MODEL_a659a7f4171640ffa54d69ed7a7f1be2","value":" 456k/456k [00:00&lt;00:00, 1.27MB/s]"}},"e4b9b2ea64e649918de011a1f1bfeac6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5757c3974b7b435e8ceb531a897f58ed","max":1344867008,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1b7209908a64f4db31686c5d25f2fbf","value":1344867008}},"e5c78f7c515a497a9c7a05f1a2661c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6831b4a9736483aa3aefc9bb2318a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8461044e198445884fcdbbac79a937c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8a73c92d4d646949922cd665cbda390":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eac90ccd9584470cb7adfbc9c7e2679c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb1139ebfb2a49249a58cda90cbc7ff8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02cf7113a3bd4029bee877c203b87de1","IPY_MODEL_03dffc22176e4f86b5013ec5701961ba","IPY_MODEL_f780e03a76924012a269932fe736d0ac"],"layout":"IPY_MODEL_1b7307fbab5f4d71a75d3e7de2fefdf9"}},"eb2d90da017b40618608151bafd7bcd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a21c7fa7b0b4ac18487f03367a85246","placeholder":"â€‹","style":"IPY_MODEL_55fbffecf6d047b28a0ed099ccb3c394","value":" 1.63G/1.63G [00:55&lt;00:00, 29.9MB/s]"}},"eb79e9523fe44d2ebc4b7c2baf578b2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec386d7b500b440684b1050842a69ad4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed4cc8276fd947ee95e9e420cceaab0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_704350d386904fdba4b2782392f4c0bc","placeholder":"â€‹","style":"IPY_MODEL_6495b6f0569240ca9af463481aec94da","value":"Downloading: 100%"}},"eebc87e23ac34b7d947d4a5bbb64f5ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d41db217eec4602bf7f9838f5d769bd","placeholder":"â€‹","style":"IPY_MODEL_f4dfe24236874484ad73205f2612257d","value":"Downloading: 100%"}},"f1db107c5f084fd384df120d75eac853":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f317ba33d8df46bc811d8f21f45868e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3b7b30ad39d4bfd8fe8aeb462f9e091":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4dfe24236874484ad73205f2612257d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f780e03a76924012a269932fe736d0ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a2d57e7f35d428393d374b5d9cc2f49","placeholder":"â€‹","style":"IPY_MODEL_56267050b1354f1eb6ec79b758c5b31a","value":" 456k/456k [00:00&lt;00:00, 1.27MB/s]"}},"f9fefdf355374256942ab6a0717ea8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_246c3ab4a27e42b5bb00d25177c30065","max":668,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a91b8640c5b5445494dee1952a9508fd","value":668}},"fc943877ab974e009c3f603a77005346":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcb6c02ee7df43edaac1e1a2ade1f1a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef0b635e92b4452a1e7d98fc9a303ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
