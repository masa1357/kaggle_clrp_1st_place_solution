{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"SKAX5C8gAJxT"},"source":["# Intro\n","\n","This notebook contains code to prepare any additional data that I used during the competition. For each dataset, I performed some preprocessing and then transformed the data to sentence embeddings."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fre87Ny_AJxW"},"source":["# Setup"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:25:55.975113Z","iopub.status.busy":"2021-08-06T19:25:55.974604Z","iopub.status.idle":"2021-08-06T19:30:21.616528Z","shell.execute_reply":"2021-08-06T19:30:21.615321Z","shell.execute_reply.started":"2021-08-06T19:25:55.974974Z"},"id":"ma5qUjE0AJxX","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.0)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.2)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.26.4)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.0)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.0.53)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.65.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (0.42.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (59.6.0)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (0.37.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.26.4)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (12.0.1)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["# Install dependencies\n","%pip install pandas\n","%pip install numpy\n","%pip install matplotlib\n","%pip install seaborn\n","%pip install h5py\n","%pip install torch\n","%pip install scipy\n","%pip install sacremoses\n","%pip install sentencepiece\n","%pip install jieba\n","%pip install numpy\n","%pip install nltk\n","%pip install sentence-transformers\n","%pip install datasets"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:21.620946Z","iopub.status.busy":"2021-08-06T19:30:21.620590Z","iopub.status.idle":"2021-08-06T19:30:30.517727Z","shell.execute_reply":"2021-08-06T19:30:30.516515Z","shell.execute_reply.started":"2021-08-06T19:30:21.620910Z"},"id":"76RWMJbeAJxY","trusted":true},"outputs":[],"source":["# Import dependencies\n","import gzip\n","import json\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","plt.style.use('ggplot')\n","import seaborn as sns\n","import re\n","import math\n","import torch\n","from scipy.stats import truncnorm\n","from tqdm import tqdm\n","from sentence_transformers import SentenceTransformer, util\n","from pathlib import Path\n","from datasets import load_dataset, concatenate_datasets\n","import gc\n","gc.enable()"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"rZWvodEntfD8"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('gdrive')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cdrg0ARyAJxY"},"source":["# Constants"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.520683Z","iopub.status.busy":"2021-08-06T19:30:30.520238Z","iopub.status.idle":"2021-08-06T19:30:30.526596Z","shell.execute_reply":"2021-08-06T19:30:30.525031Z","shell.execute_reply.started":"2021-08-06T19:30:30.520639Z"},"id":"EKydXLEiAJxZ","trusted":true},"outputs":[],"source":["BASE_INPUT = '/home/masa1357/git/kaggle_clrp_1st_place_solution'\n","BASE_OUTPUT = '/home/masa1357/git/kaggle_clrp_1st_place_solution'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"R8L-nIaeAJxZ"},"source":["# Functions"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.529739Z","iopub.status.busy":"2021-08-06T19:30:30.529129Z","iopub.status.idle":"2021-08-06T19:30:30.538626Z","shell.execute_reply":"2021-08-06T19:30:30.537620Z","shell.execute_reply.started":"2021-08-06T19:30:30.529694Z"},"id":"XNcrpinYAJxZ","trusted":true},"outputs":[],"source":["def create_dir_if_not_exist(out_dir):\n","    output_dir = Path(out_dir)\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","    return output_dir"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.540946Z","iopub.status.busy":"2021-08-06T19:30:30.540211Z","iopub.status.idle":"2021-08-06T19:30:30.550093Z","shell.execute_reply":"2021-08-06T19:30:30.548848Z","shell.execute_reply.started":"2021-08-06T19:30:30.540900Z"},"id":"zAUsYdcbAJxa","trusted":true},"outputs":[],"source":["# a utility function to save a pandas dataframe to csv\n","# it will create directories if they don't exist\n","def df_to_csv(df, out_dir, out_file):\n","    output_dir = create_dir_if_not_exist(os.path.join(BASE_OUTPUT, out_dir))\n","    df.to_csv(output_dir / out_file)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.552514Z","iopub.status.busy":"2021-08-06T19:30:30.551921Z","iopub.status.idle":"2021-08-06T19:30:30.563591Z","shell.execute_reply":"2021-08-06T19:30:30.561087Z","shell.execute_reply.started":"2021-08-06T19:30:30.552471Z"},"id":"7zsIY-0EAJxb","trusted":true},"outputs":[],"source":["def encode_and_save(sentences, out_dir, data_name, scores=None, model_name='paraphrase-TinyBERT-L6-v2'):\n","  model = SentenceTransformer(model_name)\n","\n","  encoded = model.encode(sentences, convert_to_tensor=True)\n","  output_dir = create_dir_if_not_exist(os.path.join(BASE_OUTPUT, out_dir))  \n","  out_file = os.path.join(output_dir, 'encoded-' + data_name + '-' + model_name + '.pt')\n","  pairs = []\n","  for idx, sent in enumerate(sentences):\n","    pair = [sent, encoded[idx]]\n","    if scores:\n","      pair.append(score[idx])\n","  with open(out_file, 'wb') as f:\n","    torch.save(encoded, f)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.565871Z","iopub.status.busy":"2021-08-06T19:30:30.565319Z","iopub.status.idle":"2021-08-06T19:30:30.573940Z","shell.execute_reply":"2021-08-06T19:30:30.572606Z","shell.execute_reply.started":"2021-08-06T19:30:30.565827Z"},"id":"htB1uaTVAJxc","trusted":true},"outputs":[],"source":["def get_simple_wiki():\n","    simplewiki_path = os.path.join(BASE_OUTPUT, 'data/external/simplewiki-2020-11-01.jsonl.gz')\n","    if not os.path.exists(simplewiki_path):\n","        util.http_get('https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/simplewiki-2020-11-01.jsonl.gz', simplewiki_path)\n","    passages = []\n","    with gzip.open(simplewiki_path, 'rt', encoding='utf8') as fIn:\n","        for line in fIn:\n","            data = json.loads(line.strip())\n","            passages.extend(data['paragraphs'])\n","    return passages"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.579790Z","iopub.status.busy":"2021-08-06T19:30:30.578660Z","iopub.status.idle":"2021-08-06T19:30:30.589398Z","shell.execute_reply":"2021-08-06T19:30:30.588186Z","shell.execute_reply.started":"2021-08-06T19:30:30.579741Z"},"id":"PD7meGCVAJxc","trusted":true},"outputs":[],"source":["def truncated_normal(mean=180, sd=17, low=135, high=205):\n","    \"\"\"\n","    Return a number that belong to a normal distribution\n","    \n","    Parameters:\n","    -----------\n","    \n","    mean: (int/float)\n","        Mean of the distribution\n","        \n","    sd: (int/float)\n","        Standard deviation of the distribution\n","        \n","    low: (int/float)\n","        Lowest number fo the distribution\n","        \n","    high: (int/float)\n","    \"\"\"\n","    return truncnorm( (low - mean) / sd, (high - mean) / sd, loc=mean, scale=sd ).rvs()"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.593523Z","iopub.status.busy":"2021-08-06T19:30:30.592789Z","iopub.status.idle":"2021-08-06T19:30:30.601438Z","shell.execute_reply":"2021-08-06T19:30:30.600312Z","shell.execute_reply.started":"2021-08-06T19:30:30.593451Z"},"id":"bXL2yFzEAJxd","trusted":true},"outputs":[],"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.604096Z","iopub.status.busy":"2021-08-06T19:30:30.603329Z","iopub.status.idle":"2021-08-06T19:30:30.612268Z","shell.execute_reply":"2021-08-06T19:30:30.610962Z","shell.execute_reply.started":"2021-08-06T19:30:30.604049Z"},"id":"D5eeAXN1AJxd","trusted":true},"outputs":[],"source":["def get_trainset_word_distribution(text):\n","  words = text.split()\n","  cut = math.floor(truncated_normal())\n","  chunked = chunks(words, cut)\n","  texts = [' '.join(c) for c in chunked]\n","  return texts"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.614641Z","iopub.status.busy":"2021-08-06T19:30:30.614334Z","iopub.status.idle":"2021-08-06T19:30:30.624219Z","shell.execute_reply":"2021-08-06T19:30:30.622790Z","shell.execute_reply.started":"2021-08-06T19:30:30.614612Z"},"id":"q1qwwUtQAJxd","trusted":true},"outputs":[],"source":["def clean_file(file):\n","  attribution = ''\n","  texts = []\n","  attribution_start = False\n","  current_text = ''\n","  max_len = truncated_normal()\n","  for ln in file:\n","    line = ln.strip()\n","    if line != '':\n","      if re.search('free to download', line) or attribution_start:\n","        attribution = attribution + ' ' + line \n","        attribution_start = True\n","      else:\n","        if len(current_text) < max_len:\n","          current_text = current_text + ' ' + line\n","        else:\n","          texts.append(current_text)\n","          current_text = line\n","          max_len = truncated_normal()\n","  attributions = [attribution for _ in texts]\n","  return texts, attributions"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.626866Z","iopub.status.busy":"2021-08-06T19:30:30.625992Z","iopub.status.idle":"2021-08-06T19:30:30.637468Z","shell.execute_reply":"2021-08-06T19:30:30.636352Z","shell.execute_reply.started":"2021-08-06T19:30:30.626820Z"},"id":"lYe582JUAJxe","trusted":true},"outputs":[],"source":["def get_cb_corpus():\n","    in_dir = os.path.join(BASE_INPUT, 'data/external/cb_corpus.txt')\n","    chapters = []\n","    current_chapter = []\n","    \n","    with open(in_dir, 'r') as f:\n","        for line in tqdm(f):\n","          ln = line.strip()\n","          if ln[:7] == 'CHAPTER':\n","            chapters.append(current_chapter)\n","            current_chapter = []\n","          elif not re.match(r'_BOOK_TITLE_|-LCB-|-RCB-', ln) and ln != '':\n","            rand_div = truncated_normal()\n","            curr_len = len(' '.join(current_chapter).split(' '))\n","            if curr_len < rand_div:\n","              current_chapter.append(ln)\n","            else:\n","              chapters.append(current_chapter)\n","              current_chapter = []\n","    return chapters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-m803VNuAJxf"},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"n55xb-TkAJxf"},"source":["# Wikipedia data\n","\n","This data contains text snippets from Wikipedia. It was downloaded from https://huggingface.co/datasets/wikitext and some preprocessing was applied."]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:30:30.641679Z","iopub.status.busy":"2021-08-06T19:30:30.641278Z","iopub.status.idle":"2021-08-06T19:46:41.094211Z","shell.execute_reply":"2021-08-06T19:46:41.093092Z","shell.execute_reply.started":"2021-08-06T19:30:30.641641Z"},"id":"qkKIHyRKAJxg","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset wikitext/wikitext-103-v1 to /root/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1210e2dbea13402c9ea212c019e61b46","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/190M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ConnectionError","evalue":"HTTPSConnectionPool(host='s3.amazonaws.com', port=443): Read timed out.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py:710\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    713\u001b[0m     \u001b[39m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[39m# there is yet no clean way to get at it from this context.\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 814\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m    816\u001b[0m         \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         \u001b[39m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 799\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n","File \u001b[0;32m/usr/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n","File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n","File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m \u001b[39melse\u001b[39;00m:\n","\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py:940\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    942\u001b[0m     \u001b[39mif\u001b[39;00m data:\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer\u001b[39m.\u001b[39mget(amt)\n\u001b[0;32m--> 879\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[1;32m    881\u001b[0m flush_decoder \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py:813\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    811\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m    814\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n","File \u001b[0;32m/usr/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py:715\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    713\u001b[0m     \u001b[39m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[39m# there is yet no clean way to get at it from this context.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeoutError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool, \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mRead timed out.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[39mexcept\u001b[39;00m BaseSSLError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    718\u001b[0m     \u001b[39m# FIXME: Is there a better way to differentiate between SSLErrors?\u001b[39;00m\n","\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='s3.amazonaws.com', port=443): Read timed out.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# download the dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wikitext_dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39;49m\u001b[39mwikitext\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwikitext-103-v1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# apply some preprocessing\u001b[39;00m\n\u001b[1;32m      5\u001b[0m wikitext_train \u001b[39m=\u001b[39m wikitext_dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py:1809\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1808\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   1810\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1811\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1812\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   1813\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   1814\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   1815\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1816\u001b[0m )\n\u001b[1;32m   1818\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1819\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1820\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1821\u001b[0m )\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py:909\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m--> 909\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    910\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    911\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m    912\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    913\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    914\u001b[0m     )\n\u001b[1;32m    915\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py:1670\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1670\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m   1671\u001b[0m         dl_manager,\n\u001b[1;32m   1672\u001b[0m         verification_mode,\n\u001b[1;32m   1673\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39;49mverification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mBASIC_CHECKS\n\u001b[1;32m   1674\u001b[0m         \u001b[39mor\u001b[39;49;00m verification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mALL_CHECKS,\n\u001b[1;32m   1675\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_splits_kwargs,\n\u001b[1;32m   1676\u001b[0m     )\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py:982\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m    981\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 982\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m    984\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n","File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/wikitext.py:106\u001b[0m, in \u001b[0;36mWikitext._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m# TODO(wikitext): Downloads the data and defines the splits\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m# dl_manager is a datasets.download.DownloadManager that can be used to\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m# download and extract URLs\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwikitext-103-v1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 106\u001b[0m     data_file \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdata_url)\n\u001b[1;32m    107\u001b[0m     data_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_file, \u001b[39m\"\u001b[39m\u001b[39mwikitext-103\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    109\u001b[0m         datasets\u001b[39m.\u001b[39mSplitGenerator(\n\u001b[1;32m    110\u001b[0m             name\u001b[39m=\u001b[39mdatasets\u001b[39m.\u001b[39mSplit\u001b[39m.\u001b[39mTEST,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m         ),\n\u001b[1;32m    121\u001b[0m     ]\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py:564\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_and_extract\u001b[39m(\u001b[39mself\u001b[39m, url_or_urls):\n\u001b[1;32m    549\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[39m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload(url_or_urls))\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py:427\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    424\u001b[0m download_func \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[1;32m    426\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m--> 427\u001b[0m downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[1;32m    428\u001b[0m     download_func,\n\u001b[1;32m    429\u001b[0m     url_or_urls,\n\u001b[1;32m    430\u001b[0m     map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    431\u001b[0m     num_proc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mnum_proc,\n\u001b[1;32m    432\u001b[0m     disable_tqdm\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_progress_bar_enabled(),\n\u001b[1;32m    433\u001b[0m     desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading data files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    434\u001b[0m )\n\u001b[1;32m    435\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    436\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py:436\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m# Singleton\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 436\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    438\u001b[0m disable_tqdm \u001b[39m=\u001b[39m disable_tqdm \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m    439\u001b[0m iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_struct\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m data_struct\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py:453\u001b[0m, in \u001b[0;36mDownloadManager._download\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    451\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py:182\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     url_or_filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url_or_filename)\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    181\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    183\u001b[0m         url_or_filename,\n\u001b[1;32m    184\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    185\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[1;32m    186\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    187\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[1;32m    188\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m    189\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[1;32m    190\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[1;32m    191\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    192\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_auth_token,\n\u001b[1;32m    193\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[1;32m    194\u001b[0m         storage_options\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    195\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    198\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py:610\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, use_auth_token, ignore_url_params, storage_options, download_desc)\u001b[0m\n\u001b[1;32m    608\u001b[0m         fsspec_get(url, temp_file, storage_options\u001b[39m=\u001b[39mstorage_options, desc\u001b[39m=\u001b[39mdownload_desc)\n\u001b[1;32m    609\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m         http_get(\n\u001b[1;32m    611\u001b[0m             url,\n\u001b[1;32m    612\u001b[0m             temp_file,\n\u001b[1;32m    613\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    614\u001b[0m             resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m    615\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    616\u001b[0m             cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    617\u001b[0m             max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    618\u001b[0m             desc\u001b[39m=\u001b[39;49mdownload_desc,\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    621\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    622\u001b[0m shutil\u001b[39m.\u001b[39mmove(temp_file\u001b[39m.\u001b[39mname, cache_path)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py:402\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries, desc)\u001b[0m\n\u001b[1;32m    393\u001b[0m total \u001b[39m=\u001b[39m resume_size \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(content_length) \u001b[39mif\u001b[39;00m content_length \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m    395\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    396\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m    401\u001b[0m ) \u001b[39mas\u001b[39;00m progress:\n\u001b[0;32m--> 402\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    403\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n\u001b[1;32m    404\u001b[0m         temp_file\u001b[39m.\u001b[39mwrite(chunk)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py:822\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[39mraise\u001b[39;00m ContentDecodingError(e)\n\u001b[1;32m    821\u001b[0m \u001b[39mexcept\u001b[39;00m ReadTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 822\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e)\n\u001b[1;32m    823\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    824\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsSSLError(e)\n","\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='s3.amazonaws.com', port=443): Read timed out."]}],"source":["# download the dataset\n","wikitext_dataset = load_dataset('wikitext', 'wikitext-103-v1')\n","\n","# apply some preprocessing\n","wikitext_train = wikitext_dataset['train']\n","wikitext_train = wikitext_train.filter(lambda example: len(example['text'])>100)\n","\n","def replace_n(example):\n","  example['text'] = example['text'].replace('\\n', ' ')\n","  return example\n","\n","wikitext_train = wikitext_train.map(replace_n)\n","\n","# we only want samples between 600 and 1100 characters\n","wikitext_train = wikitext_train.filter(lambda example: len(example['text']) < 1100 and len(example['text']) > 600)\n","\n","# convert the dataset to a dataframe and save it\n","wikitext_train_pd = wikitext_train.to_pandas()\n","df_to_csv(df=wikitext_train_pd, out_dir='data/preprocessed', out_file='wiki_snippets.csv')\n","\n","# convert the dataset to sentence embeddings and save the result\n","wiki_snippets = wikitext_train_pd.text.tolist()\n","encode_and_save(sentences=wiki_snippets, out_dir='embeddings', data_name='wiki_snippets')\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0UZQ-LFEAJxh"},"source":["# SimpleWiki data\n","\n","This data contains snippets from Simple Wiki. It was downloaded from https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/simplewiki-2020-11-01.jsonl.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:46:41.097398Z","iopub.status.busy":"2021-08-06T19:46:41.097062Z","iopub.status.idle":"2021-08-06T19:56:43.826303Z","shell.execute_reply":"2021-08-06T19:56:43.825081Z","shell.execute_reply.started":"2021-08-06T19:46:41.097361Z"},"id":"evHHrlLAAJxh","trusted":true},"outputs":[],"source":["simplewiki_snippets = get_simple_wiki()\n","\n","# filter out snippets which are too long\n","simplewiki_filtered = [p for p in simplewiki_snippets if len(p) < 1200]\n","\n","# convert the dataset to a dataframe and save it\n","simple_df = pd.DataFrame(simplewiki_filtered, columns=['text'])\n","df_to_csv(df=simple_df, out_dir='data/preprocessed', out_file='simplewiki.csv')\n","\n","# convert the dataset to sentence embeddings and save the result\n","encode_and_save(sentences=simplewiki_filtered, out_dir='embeddings', data_name='simplewiki') "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tiqi73kKAJxi"},"source":["# Bookcorpus data\n","This data contains part of the book corpus. It was downloaded from https://huggingface.co/datasets/bookcorpusopen\n","\n","**Please note:**\n","\n","Due to processing resource limitations, only 20% of the bookcorpus dataset were selected. I made the selection randomly. The code can still be used to see how I preprocessed the data, but the resulting selection may produce different results during model training."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T19:56:43.830939Z","iopub.status.busy":"2021-08-06T19:56:43.830445Z"},"id":"Kzh-uWzZAJxi","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Found cached dataset bookcorpusopen (/root/.cache/huggingface/datasets/bookcorpusopen/plain_text/1.0.0/98559c92eb612e150a676c5b5131f9f8f07d4cab88e7f3761fda266ad22ff2a7)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63e7c6a754b548bc846bd941c015056b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"882291eeb3544ebeaa176689ad68e3db","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/17868 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82aecebfd79b4a9193b8037724fc12cc","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/6736669 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# load the dataset\n","bookcorpus = load_dataset('bookcorpusopen')\n","\n","# apply some preprocessing\n","bookcorpus = bookcorpus['train'].remove_columns('title')\n","\n","def process_batch(batch):\n","  out = []\n","  for text in batch['text']:\n","    out.extend(get_trainset_word_distribution(text))\n","  return {'text': out}\n","\n","bookcorpus_chunked = bookcorpus.map(process_batch, batched=True)\n","bookcorpus_chunked = bookcorpus_chunked.filter(lambda example: len(example['text']) < 1200)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'dict'>\n"]}],"source":["\n","# convert to pandas, select 20% and save\n","bookcorpus_df = bookcorpus_chunked.to_pandas()\n","msk = np.random.rand(len(bookcorpus)) < 0.2\n","bookcorpus_02 = bookcorpus[msk]\n","print(type(bookcorpus_02))\n","bookcorpus_02 = pd.DataFrame(bookcorpus_02)\n","df = bookcorpus_02\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["\n","df_to_csv(df, out_dir='data/preprocessed', out_file='bookcorpus.csv')\n","\n","# convert the dataset to sentence embeddings and save the result\n","bookcorpus_texts = bookcorpus_02.text.tolist()\n","encode_and_save(bookcorpus_texts, out_dir='embeddings', data_name='bookcorpus')\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gDd4xEIuAJxi"},"source":["# African Storybooks data\n","\n","This data was downloaded manually from https://www.africanstorybook.org/ .\n","I downloaded all books starting from letter A up to and including letter D.\n","The downloaded books were converted from .epub to .txt using Calibre (`ebook-convert input.epub output.txt`).\n","\n","The full bash script used to convert the books:\n","```\n","#!/bin/bash\n","for filename in *.epub; do\n","        ebook-convert $filename \"$filename.txt\"\n","done\n","```\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga6UklouAJxj","trusted":true},"outputs":[{"ename":"RuntimeError","evalue":"stack expects a non-empty TensorList","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# convert the dataset to sentence embeddings and save the result\u001b[39;00m\n\u001b[1;32m     17\u001b[0m asb_sents \u001b[39m=\u001b[39m asb_df\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> 18\u001b[0m encode_and_save(sentences\u001b[39m=\u001b[39;49masb_sents, out_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m'\u001b[39;49m, data_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39masb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n","Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mencode_and_save\u001b[0;34m(sentences, out_dir, data_name, scores, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_and_save\u001b[39m(sentences, out_dir, data_name, scores\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mparaphrase-TinyBERT-L6-v2\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m   model \u001b[39m=\u001b[39m SentenceTransformer(model_name)\n\u001b[0;32m----> 4\u001b[0m   encoded \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(sentences, convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m   output_dir \u001b[39m=\u001b[39m create_dir_if_not_exist(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(BASE_OUTPUT, out_dir))  \n\u001b[1;32m      6\u001b[0m   out_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39m'\u001b[39m\u001b[39mencoded-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m data_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m model_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py:195\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    192\u001b[0m all_embeddings \u001b[39m=\u001b[39m [all_embeddings[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39margsort(length_sorted_idx)]\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m convert_to_tensor:\n\u001b[0;32m--> 195\u001b[0m     all_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(all_embeddings)\n\u001b[1;32m    196\u001b[0m \u001b[39melif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m    197\u001b[0m     all_embeddings \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([emb\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m emb \u001b[39min\u001b[39;00m all_embeddings])\n","\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"]}],"source":["# read in the data and clean the texts\n","in_dir = os.path.join(BASE_INPUT, 'data/external/a_d_txt')\n","all_texts = []\n","all_attributions = []\n","for file in os.listdir(in_dir):\n","  with open(os.path.join(in_dir, file), 'r') as f:\n","    txt, attr = clean_file(f)\n","    if txt != '' and attr != '':    \n","      all_texts.extend(txt)\n","      all_attributions.extend(attr)\n","\n","# create and save as pandas dataframe\n","asb_df = pd.DataFrame.from_dict({'text': all_texts, 'attribution': all_attributions})\n","df_to_csv(df=asb_df, out_dir='data/preprocessed', out_file='asb.csv')\n","\n","# convert the dataset to sentence embeddings and save the result\n","asb_sents = asb_df.text.tolist()\n","encode_and_save(sentences=asb_sents, out_dir='embeddings', data_name='asb')\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sbhS_InuAJxj"},"source":["# Scraped data\n","This dataset contains scraped data from wikipedia, wikibooks, simplewiki and kids.frontiersin.org. It was taken from https://www.kaggle.com/teeyee314/readability-url-scrape."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vEk46ZmAJxk","trusted":true},"outputs":[],"source":["in_dir = os.path.join(BASE_INPUT, 'data/external/external_df.csv')\n","scraped_data = pd.read_csv(in_dir)\n","\n","txts = []\n","for txt in scraped_data.usable_external.values:\n","  txts.extend(get_trainset_word_distribution(txt))\n","\n","scraped_df = pd.DataFrame(txts, columns=['text'])\n","df_to_csv(df=scraped_df, out_dir='data/preprocessed', out_file='kaggle_scraped.csv')\n","\n","scraped_sents = scraped_df.text.tolist()\n","encode_and_save(sentences=scraped_sents, out_dir='embeddings', data_name='kaggle_scraped')\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"biCYWNXQAJxk"},"source":["# Onestop Corpus data\n","This dataset was downloaded from https://huggingface.co/datasets/onestop_english"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NNxfhHGAJxl","trusted":true},"outputs":[],"source":["onestop_data = load_dataset('onestop_english')\n","onestop_data = onestop_data['train']\n","onestop_df = onestop_data.to_pandas()\n","\n","df_to_csv(df=onestop_df, out_dir='data/preprocessed', out_file='onestop.csv')\n","\n","onestop_sents = onestop_df.text.tolist()\n","encode_and_save(sentences=onestop_sents, out_dir='embeddings', data_name='onestop')\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Hl-rPWnuAJxl"},"source":["# CC News data\n","This dataset was downloaded from https://huggingface.co/datasets/cc_news"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gfXRfNUAJxl","trusted":true},"outputs":[],"source":["news_data = load_dataset('cc_news')\n","news_data = news_data['train']\n","news_data = news_data.filter(lambda example: len(example['text']) < 1200)\n","news_df = pd.DataFrame(news_data['text'], columns=['text'])\n","\n","df_to_csv(df=news_df, out_dir='data/preprocessed', out_file='news.csv')\n","\n","news_sents = news_df.text.tolist()\n","encode_and_save(sentences=news_sents, out_dir='embeddings', data_name='news')\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pfD6GfmIAJxm"},"source":["# Children's book corpus data\n","This dataset was downloaded from https://research.fb.com/downloads/babi/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2gSUV5vAJxm","trusted":true},"outputs":[],"source":["cb_corpus = get_cb_corpus()\n","cb_corpus = [' '.join(c) for c in cb_corpus]\n","cb_corpus = pd.DataFrame(cb_corpus, columns=['text'])\n","cb_corpus.drop([0])\n","\n","df_to_csv(df=cb_corpus, out_dir='data/preprocessed', out_file='cb_corpus.csv')\n","\n","cb_sents = cb_corpus.text.tolist()\n","encode_and_save(sentences=cb_sents, out_dir='embeddings', data_name='cb_corpus')\n","gc.collect()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"02_clrp_external_data_prep.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}
